============================= test session starts ==============================
platform darwin -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0 -- /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python
cachedir: .pytest_cache
hypothesis profile 'default'
rootdir: /Users/odosmatthews/Documents/coding/sparkforge
configfile: pytest.ini
plugins: anyio-4.11.0, cov-7.0.0, green-light-0.2.0, asyncio-1.2.0, xdist-3.8.0, hypothesis-6.148.7, alt-pytest-asyncio-0.9.3, async-sqlalchemy-0.2.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
created: 10/10 workers
10 workers [1790 items]

scheduling tests via LoadScheduling

tests/builder_pyspark_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_complete_customer_360_pipeline_execution 
[gw0] [  0%] SKIPPED tests/builder_pyspark_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_complete_customer_360_pipeline_execution 
tests/builder_pyspark_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_churn_prediction 
[gw0] [  0%] SKIPPED tests/builder_pyspark_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_churn_prediction 
tests/builder_pyspark_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_lifetime_value_analysis 
[gw0] [  0%] SKIPPED tests/builder_pyspark_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_lifetime_value_analysis 
tests/builder_pyspark_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_analytics_logging 
[gw0] [  0%] SKIPPED tests/builder_pyspark_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_analytics_logging 
tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_complete_financial_transaction_pipeline_execution 
tests/system/test_logger.py::TestPipelineLogger::test_logger_creation 
[gw9] [  0%] PASSED tests/system/test_logger.py::TestPipelineLogger::test_logger_creation 
tests/system/test_logger.py::TestPipelineLogger::test_logger_with_file 
tests/builder_pyspark_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_complete_data_quality_pipeline_execution 
[gw0] [  0%] SKIPPED tests/builder_pyspark_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_complete_data_quality_pipeline_execution 
tests/builder_pyspark_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_incremental_data_quality_processing 
[gw0] [  0%] SKIPPED tests/builder_pyspark_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_incremental_data_quality_processing 
tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_execution_engine_with_mock_steps 
tests/security/test_security_integration.py::TestSecurityIntegration::test_security_thresholds_integration 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_type_detection_flow 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_success 
[gw4] [  0%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_success 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_failure 
[gw4] [  0%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_failure 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_without_active_report 
[gw4] [  0%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_without_active_report 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_failure_without_error_message 
[gw4] [  0%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_failure_without_error_message 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_success 
[gw4] [  0%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_success 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_failure 
[gw4] [  0%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_failure 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_without_active_report 
[gw4] [  0%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_without_active_report 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_with_zero_steps 
[gw4] [  0%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_with_zero_steps 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_with_mocked_time 
[gw4] [  0%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_with_mocked_time 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_mixed_results 
[gw4] [  0%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_mixed_results 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_pipeline_monitor_alias 
[gw4] [  1%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_pipeline_monitor_alias 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_monitor_logging_calls 
[gw4] [  1%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_monitor_logging_calls 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_runner_initialization_with_all_parameters 
[gw4] [  1%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_runner_initialization_with_all_parameters 
tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_creation 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_unified_validator_initialization 
tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_schema_evolution 
tests/builder_pyspark_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_complete_ecommerce_pipeline_execution 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_complete_ecommerce_pipeline_execution 
tests/builder_pyspark_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_incremental_order_processing 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_incremental_order_processing 
tests/builder_pyspark_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_validation_failures 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_validation_failures 
tests/builder_pyspark_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_logging_and_monitoring 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_logging_and_monitoring 
tests/builder_pyspark_tests/test_financial_pipeline.py::TestFinancialPipeline::test_complete_financial_transaction_pipeline_execution 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_financial_pipeline.py::TestFinancialPipeline::test_complete_financial_transaction_pipeline_execution 
tests/builder_pyspark_tests/test_financial_pipeline.py::TestFinancialPipeline::test_fraud_detection_scenarios 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_financial_pipeline.py::TestFinancialPipeline::test_fraud_detection_scenarios 
tests/builder_pyspark_tests/test_financial_pipeline.py::TestFinancialPipeline::test_compliance_monitoring 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_financial_pipeline.py::TestFinancialPipeline::test_compliance_monitoring 
tests/builder_pyspark_tests/test_financial_pipeline.py::TestFinancialPipeline::test_financial_audit_logging 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_financial_pipeline.py::TestFinancialPipeline::test_financial_audit_logging 
tests/builder_pyspark_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_complete_healthcare_pipeline_execution 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_complete_healthcare_pipeline_execution 
tests/builder_pyspark_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_incremental_healthcare_processing 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_incremental_healthcare_processing 
tests/builder_pyspark_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_healthcare_logging 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_healthcare_logging 
tests/builder_pyspark_tests/test_iot_pipeline.py::TestIotPipeline::test_complete_iot_sensor_pipeline_execution 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_iot_pipeline.py::TestIotPipeline::test_complete_iot_sensor_pipeline_execution 
tests/builder_pyspark_tests/test_iot_pipeline.py::TestIotPipeline::test_incremental_sensor_processing 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_iot_pipeline.py::TestIotPipeline::test_incremental_sensor_processing 
tests/builder_pyspark_tests/test_iot_pipeline.py::TestIotPipeline::test_anomaly_detection_pipeline 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_iot_pipeline.py::TestIotPipeline::test_anomaly_detection_pipeline 
tests/builder_pyspark_tests/test_iot_pipeline.py::TestIotPipeline::test_performance_monitoring 
[gw0] [  1%] SKIPPED tests/builder_pyspark_tests/test_iot_pipeline.py::TestIotPipeline::test_performance_monitoring 
tests/builder_pyspark_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_complete_marketing_pipeline_execution 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_complete_marketing_pipeline_execution 
tests/builder_pyspark_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_incremental_marketing_processing 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_incremental_marketing_processing 
tests/builder_pyspark_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_complete_multi_source_integration_pipeline_execution 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_complete_multi_source_integration_pipeline_execution 
tests/builder_pyspark_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_schema_evolution_handling 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_schema_evolution_handling 
tests/builder_pyspark_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_complex_dependency_handling 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_complex_dependency_handling 
tests/builder_pyspark_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_multi_source_logging 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_multi_source_logging 
tests/builder_pyspark_tests/test_simple.py::test_simple_pipeline_creation 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_simple.py::test_simple_pipeline_creation 
tests/builder_pyspark_tests/test_simple_pipeline.py::TestSimplePipeline::test_simple_pipeline_execution 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_simple_pipeline.py::TestSimplePipeline::test_simple_pipeline_execution 
tests/builder_pyspark_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_complete_streaming_hybrid_pipeline_execution 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_complete_streaming_hybrid_pipeline_execution 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_runner_initialization_with_minimal_parameters 
[gw4] [  2%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_runner_initialization_with_minimal_parameters 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_runner_initialization_with_none_steps 
[gw4] [  2%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_runner_initialization_with_none_steps 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_initial 
[gw4] [  2%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_initial 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_incremental 
[gw4] [  2%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_incremental 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_full_refresh 
[gw4] [  2%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_full_refresh 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_validation_only 
[gw4] [  2%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_validation_only 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_unknown 
[gw4] [  2%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_unknown 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_success 
tests/builder_pyspark_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_incremental_streaming_processing 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_incremental_streaming_processing 
tests/builder_pyspark_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_complete_supply_chain_pipeline_execution 
[gw0] [  2%] SKIPPED tests/builder_pyspark_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_complete_supply_chain_pipeline_execution 
tests/builder_pyspark_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_incremental_supply_chain_processing 
[gw0] [  3%] SKIPPED tests/builder_pyspark_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_incremental_supply_chain_processing 
tests/builder_pyspark_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_supply_chain_logging 
[gw0] [  3%] SKIPPED tests/builder_pyspark_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_supply_chain_logging 
tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_complete_customer_360_pipeline_execution 
[gw9] [  3%] PASSED tests/system/test_logger.py::TestPipelineLogger::test_logger_with_file 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_bronze_rules_with_schema 
[gw3] [  3%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_execution_engine_with_mock_steps 
[gw9] [  3%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_bronze_rules_with_schema 
tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_execution_engine_error_handling 
[gw3] [  3%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_execution_engine_error_handling 
tests/integration/test_execution_engine_new.py::TestExecutionEnginePerformance::test_execution_engine_memory_usage 
[gw3] [  3%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEnginePerformance::test_execution_engine_memory_usage 
tests/integration/test_execution_engine_new.py::TestExecutionEnginePerformance::test_execution_engine_concurrent_creation 
[gw3] [  3%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEnginePerformance::test_execution_engine_concurrent_creation 
tests/integration/test_execution_engine_new.py::TestExecutionEngineLogging::test_execution_engine_logging_initialization 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_bronze_rules_without_schema 
[gw9] [  3%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_bronze_rules_without_schema 
[gw3] [  3%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngineLogging::test_execution_engine_logging_initialization 
[gw6] [  3%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_unified_validator_initialization 
tests/integration/test_execution_engine_new.py::TestExecutionEngineLogging::test_execution_engine_default_logging 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_silver_rules_with_schema 
[gw3] [  3%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngineLogging::test_execution_engine_default_logging 
[gw9] [  3%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_silver_rules_with_schema 
[gw8] [  3%] SKIPPED tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_schema_evolution 
tests/integration/test_execution_engine_new.py::TestExecutionEngineLogging::test_execution_engine_logging_methods 
[gw3] [  3%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngineLogging::test_execution_engine_logging_methods 
tests/integration/test_parallel_execution.py::test_parallel_execution 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_silver_transform_with_schema 
[gw9] [  3%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_silver_transform_with_schema 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_gold_transform_with_schema 
[gw9] [  3%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_gold_transform_with_schema 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_validation_success 
[gw9] [  3%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_validation_success 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_validation_failure 
[gw9] [  4%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_validation_failure 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_get_effective_schema 
[gw9] [  4%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_get_effective_schema 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_creation 
[gw9] [  4%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_creation 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_creation_failure 
[gw9] [  4%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_creation_failure 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_cross_schema_pipeline 
[gw9] [  4%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_cross_schema_pipeline 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_mixed_schema_usage 
[gw9] [  4%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_mixed_schema_usage 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_validation_integration 
[gw9] [  4%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_validation_integration 
tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_backward_compatibility 
[gw9] [  4%] PASSED tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_backward_compatibility 
tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_silver_schema_evolution_on_initial_load_rerun 
tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_time_travel 
[gw8] [  4%] SKIPPED tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_time_travel 
tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_merge_operations 
[gw8] [  4%] SKIPPED tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_merge_operations 
tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_optimization 
[gw8] [  4%] SKIPPED tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_optimization 
tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_history_and_metadata 
[gw4] [  4%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_success 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_with_bronze_sources 
[gw2] [  4%] PASSED tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_creation 
[gw4] [  4%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_with_bronze_sources 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_without_bronze_sources 
[gw4] [  4%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_without_bronze_sources 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_execution_failure 
[gw4] [  4%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_execution_failure 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_initial_load_with_steps 
[gw4] [  4%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_initial_load_with_steps 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_initial_load_without_steps 
[gw4] [  4%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_initial_load_without_steps 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_incremental 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_incremental 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_full_refresh 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_full_refresh 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_validation_only 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_validation_only 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_success 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_success 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_failure 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_failure 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_without_end_time 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_without_end_time 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_error_report 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_error_report 
[gw8] [  5%] SKIPPED tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_history_and_metadata 
tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_concurrent_writes 
[gw8] [  5%] SKIPPED tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_concurrent_writes 
tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_performance_characteristics 
[gw8] [  5%] SKIPPED tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_performance_characteristics 
tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_data_quality_constraints 
[gw8] [  5%] SKIPPED tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_data_quality_constraints 
tests/system/test_delta_overwrite_real.py::test_initial_load_overwrite_delta 
[gw8] [  5%] SKIPPED tests/system/test_delta_overwrite_real.py::test_initial_load_overwrite_delta 
tests/system/test_full_pipeline_with_logging.py::TestFullPipelineWithLogging::test_full_pipeline_with_logging 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_pipeline_runner_alias 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_pipeline_runner_alias 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_with_empty_steps 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_with_empty_steps 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_row_counts_accuracy 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_row_counts_accuracy 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_duration_by_layer_accuracy 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_duration_by_layer_accuracy 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_with_failed_steps 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_with_failed_steps 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_with_no_rows_processed 
[gw4] [  5%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_with_no_rows_processed 
tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_mixed_layers_comprehensive 
[gw4] [  6%] PASSED tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_mixed_layers_comprehensive 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_bronze_step_execution_flow 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_unified_validator_with_custom_logger 
tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_with_all_fields 
[gw4] [  6%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_bronze_step_execution_flow 
[gw5] [  6%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_type_detection_flow 
[gw6] [  6%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_unified_validator_with_custom_logger 
[gw2] [  6%] PASSED tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_with_all_fields 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_silver_step_execution_flow 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_execution_context_flow 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_add_validator 
[gw6] [  6%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_add_validator 
[gw4] [  6%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_silver_step_execution_flow 
tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_duration_calculation 
[gw5] [  6%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_execution_context_flow 
[gw2] [  6%] PASSED tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_duration_calculation 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_gold_step_execution_flow 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_step_with_custom_validators 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_execution_result_flow 
[gw4] [  6%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_gold_step_execution_flow 
[gw5] [  6%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_execution_result_flow 
[gw6] [  6%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_step_with_custom_validators 
tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_no_duration_without_end_time 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_validation_flow 
[gw2] [  6%] PASSED tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_no_duration_without_end_time 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_execution_mode_flow 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_step_validator_exception 
[gw4] [  6%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_validation_flow 
tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_creation 
[gw5] [  6%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_execution_mode_flow 
[gw6] [  6%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_step_validator_exception 
[gw2] [  6%] PASSED tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_creation 
tests/system/test_utils.py::TestDataValidation::test_and_all_rules_empty 
[gw4] [  6%] PASSED tests/system/test_utils.py::TestDataValidation::test_and_all_rules_empty 
tests/system/test_utils.py::TestDataValidation::test_apply_column_rules 
[gw1] [  7%] PASSED tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_complete_financial_transaction_pipeline_execution 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_status_flow 
tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_fraud_detection_scenarios 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_pipeline_config_validation 
[gw0] [  7%] PASSED tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_complete_customer_360_pipeline_execution 
tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_with_all_fields 
tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_churn_prediction 
[gw5] [  7%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_status_flow 
[gw4] [  7%] PASSED tests/system/test_utils.py::TestDataValidation::test_apply_column_rules 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_pipeline_configuration_flow 
[gw2] [  7%] PASSED tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_with_all_fields 
[gw5] [  7%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_pipeline_configuration_flow 
[gw0] [  7%] PASSED tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_churn_prediction 
tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_lifetime_value_analysis 
tests/system/test_utils.py::TestDataValidation::test_apply_column_rules_none_rules 
[gw4] [  7%] PASSED tests/system/test_utils.py::TestDataValidation::test_apply_column_rules_none_rules 
tests/system/test_utils.py::TestDataValidation::test_assess_data_quality 
[gw4] [  7%] PASSED tests/system/test_utils.py::TestDataValidation::test_assess_data_quality 
tests/system/test_utils.py::TestDataValidation::test_get_dataframe_info 
[gw4] [  7%] PASSED tests/system/test_utils.py::TestDataValidation::test_get_dataframe_info 
tests/system/test_utils.py::TestDataValidation::test_validate_dataframe_schema 
[gw4] [  7%] PASSED tests/system/test_utils.py::TestDataValidation::test_validate_dataframe_schema 
tests/system/test_utils.py::TestDataTransformationUtilities::test_basic_dataframe_operations 
[gw4] [  7%] PASSED tests/system/test_utils.py::TestDataTransformationUtilities::test_basic_dataframe_operations 
tests/system/test_utils.py::TestDataTransformationUtilities::test_dataframe_filtering 
[gw4] [  7%] PASSED tests/system/test_utils.py::TestDataTransformationUtilities::test_dataframe_filtering 
tests/system/test_utils.py::TestFactoryFunctions::test_create_validation_dict 
[gw4] [  7%] PASSED tests/system/test_utils.py::TestFactoryFunctions::test_create_validation_dict 
tests/system/test_utils.py::TestFactoryFunctions::test_create_write_dict 
[gw4] [  7%] PASSED tests/system/test_utils.py::TestFactoryFunctions::test_create_write_dict 
tests/system/test_utils.py::TestPerformanceWithRealData::test_large_dataset_validation 
[gw6] [  7%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_pipeline_config_validation 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_pipeline_success 
tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_duration_calculation 
[gw4] [  7%] PASSED tests/system/test_utils.py::TestPerformanceWithRealData::test_large_dataset_validation 
[gw6] [  7%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_pipeline_success 
tests/system/test_utils.py::TestPerformanceWithRealData::test_complex_transformations 
[gw1] [  8%] PASSED tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_fraud_detection_scenarios 
tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_compliance_monitoring 
[gw2] [  8%] PASSED tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_duration_calculation 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_execution_engine_initialization_flow 
[gw0] [  8%] PASSED tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_lifetime_value_analysis 
tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_analytics_logging 
[gw1] [  8%] PASSED tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_compliance_monitoring 
tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_financial_audit_logging 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_bronze_steps 
[gw9] [  8%] PASSED tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_silver_schema_evolution_on_initial_load_rerun 
[gw4] [  8%] PASSED tests/system/test_utils.py::TestPerformanceWithRealData::test_complex_transformations 
tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_silver_schema_evolution_incremental_should_error 
[gw5] [  8%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_execution_engine_initialization_flow 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_execution_error_handling_flow 
tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_steps_initialization 
[gw2] [  8%] PASSED tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_steps_initialization 
[gw6] [  8%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_bronze_steps 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_silver_steps 
tests/unit/dependencies/test_analyzer.py::TestAnalysisStrategy::test_analysis_strategy_values 
[gw4] [  8%] PASSED tests/unit/dependencies/test_analyzer.py::TestAnalysisStrategy::test_analysis_strategy_values 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalysisResult::test_dependency_analysis_result_creation 
[gw4] [  8%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalysisResult::test_dependency_analysis_result_creation 
[gw5] [  8%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_execution_error_handling_flow 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_dependency_analyzer_creation_default 
[gw4] [  8%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_dependency_analyzer_creation_default 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_dependency_analyzer_creation_custom 
[gw4] [  8%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_dependency_analyzer_creation_custom 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_empty 
[gw4] [  8%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_empty 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_bronze_only 
[gw4] [  8%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_bronze_only 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_silver_with_bronze 
[gw4] [  8%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_silver_with_bronze 
[gw6] [  8%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_silver_steps 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_gold_with_silver 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_gold_with_silver 
tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_execution_with_mock_data 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execution_engine_initialization_with_logger 
[gw2] [  9%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execution_engine_initialization_with_logger 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_gold_steps 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_missing_bronze_dependency 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_missing_bronze_dependency 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_warning_scenarios 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_warning_scenarios 
[gw5] [  9%] PASSED tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_execution_with_mock_data 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_silver_depends_on_warning 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_silver_depends_on_warning 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_missing_silver_dependency 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_missing_silver_dependency 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_force_refresh 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_force_refresh 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execution_engine_initialization_without_logger 
[gw6] [  9%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_gold_steps 
tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_not_null_rule 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_cached 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_cached 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_exception 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_exception 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_empty 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_empty 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_bronze_steps 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_bronze_steps 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_silver_steps 
[gw1] [  9%] PASSED tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_financial_audit_logging 
[gw5] [  9%] PASSED tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_not_null_rule 
[gw0] [  9%] PASSED tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_analytics_logging 
tests/builder_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_complete_data_quality_pipeline_execution 
[gw4] [  9%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_silver_steps 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_gold_steps 
[gw4] [ 10%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_gold_steps 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_resolve_cycles 
[gw4] [ 10%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_resolve_cycles 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_detect_conflicts 
[gw4] [ 10%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_detect_conflicts 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_cycle_warning 
[gw4] [ 10%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_cycle_warning 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_conflict_warning 
[gw4] [ 10%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_conflict_warning 
tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_validate_missing_dependencies 
[gw4] [ 10%] PASSED tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_validate_missing_dependencies 
tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_execution_groups 
[gw4] [ 10%] PASSED tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_execution_groups 
tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_stats 
[gw4] [ 10%] PASSED tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_stats 
[gw2] [ 10%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execution_engine_initialization_without_logger 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_bronze_success 
tests/builder_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_complete_healthcare_pipeline_execution 
tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_dependencies 
tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_positive_rule 
[gw6] [ 10%] PASSED tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_dependencies 
tests/integration/test_validation_integration.py::TestApplyValidationRules::test_apply_column_rules_deprecated 
[gw2] [ 10%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_bronze_success 
tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_parallel_candidates 
[gw4] [ 10%] PASSED tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_parallel_candidates 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_base_builder_initialization 
[gw4] [ 10%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_base_builder_initialization 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_base_builder_default_logger 
[gw4] [ 10%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_base_builder_default_logger 
[gw6] [ 10%] PASSED tests/integration/test_validation_integration.py::TestApplyValidationRules::test_apply_column_rules_deprecated 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_bronze 
[gw4] [ 10%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_bronze 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_silver 
[gw4] [ 10%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_silver 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_gold 
[gw4] [ 10%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_gold 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_no_duplicate 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_no_duplicate 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_silver_valid 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_silver_valid 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_silver_missing 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_silver_missing 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_success 
[gw2] [ 11%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_success 
[gw5] [ 11%] PASSED tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_positive_rule 
tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_non_negative_rule 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_gold_valid 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_gold_valid 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_gold_missing 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_gold_missing 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_gold_invalid_list 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_gold_invalid_list 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_auto_inference 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_auto_inference 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_schema_valid 
tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_incremental_pipeline_preserves_data 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_schema_valid 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_schema_invalid 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_schema_invalid 
tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_pipeline 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_pipeline 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_bronze 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_bronze 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_silver 
[gw5] [ 11%] PASSED tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_non_negative_rule 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_success 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_silver 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_gold 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_gold 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_from_attribute 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_from_attribute 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_unknown 
[gw4] [ 11%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_unknown 
tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_non_zero_rule 
[gw2] [ 12%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_success 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_extract_step_dependencies_silver 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_extract_step_dependencies_silver 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_extract_step_dependencies_gold 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_extract_step_dependencies_gold 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_extract_step_dependencies_none 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_extract_step_dependencies_none 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_group_steps_by_type 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_group_steps_by_type 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_get_all_step_names 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_get_all_step_names 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_build_dependency_graph 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_build_dependency_graph 
tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_get_execution_order 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_get_execution_order 
[gw5] [ 12%] PASSED tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_non_zero_rule 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_unknown_type 
tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_bronze_step_dict 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_bronze_step_dict 
tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_bronze_step_dict_with_metadata 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_bronze_step_dict_with_metadata 
tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_silver_step_dict 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_silver_step_dict 
tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_silver_step_dict_with_watermark 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_silver_step_dict_with_watermark 
tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_gold_step_dict 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_gold_step_dict 
tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_gold_step_dict_no_sources 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_gold_step_dict_no_sources 
[gw6] [ 12%] PASSED tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_incremental_pipeline_preserves_data 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_development_config 
[gw2] [ 12%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_unknown_type 
[gw4] [ 12%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_development_config 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_development_config_overrides 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_development_config_overrides 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_production_config 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_production_config 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_production_config_overrides 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_production_config_overrides 
tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_unknown_rule 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_test_config 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_test_config 
[gw9] [ 13%] PASSED tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_silver_schema_evolution_incremental_should_error 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_test_config_overrides 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_test_config_overrides 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_pipeline_config_valid 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_pipeline_config_valid 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_pipeline_config_invalid 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_pipeline_config_invalid 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_bronze_without_source_path 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_parallel_config_valid 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_parallel_config_valid 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_parallel_config_invalid 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_parallel_config_invalid 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_parallel_config_too_large 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_parallel_config_too_large 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_valid 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_valid 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_invalid 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_invalid 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_range 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_range 
tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_order 
[gw4] [ 13%] PASSED tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_order 
[gw5] [ 13%] PASSED tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_unknown_rule 
tests/integration/test_validation_integration.py::TestConvertRulesToExpressions::test_string_rules_conversion 
[gw2] [ 13%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_bronze_without_source_path 
tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_silver_schema_evolution_with_multiple_new_columns 
tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_initial_pipeline_overwrites_data 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_bronze_step_not_in_context 
[gw6] [ 13%] PASSED tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_initial_pipeline_overwrites_data 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_dependency_graph_initialization 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_dependency_graph_initialization 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_add_node 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_add_node 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_add_dependency 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_add_dependency 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_add_dependency_missing_node 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_add_dependency_missing_node 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_node 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_node 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_node_missing 
[gw5] [ 14%] PASSED tests/integration/test_validation_integration.py::TestConvertRulesToExpressions::test_string_rules_conversion 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_node_missing 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_dependencies 
tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_write_mode_consistency_across_pipeline_runs 
[gw2] [ 14%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_bronze_step_not_in_context 
[gw8] [ 14%] PASSED tests/system/test_full_pipeline_with_logging.py::TestFullPipelineWithLogging::test_full_pipeline_with_logging 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_dependencies 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_dependents 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_dependents 
tests/system/test_full_pipeline_with_logging_variations.py::TestMinimalPipelines::test_minimal_pipeline_with_logging 
tests/integration/test_validation_integration.py::TestConvertRulesToExpressions::test_mixed_rules_conversion 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_has_cycle 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_has_cycle 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_has_cycle_no_cycle 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_has_cycle_no_cycle 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_topological_sort 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_topological_sort 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_topological_sort_cycle 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_topological_sort_cycle 
[gw5] [ 14%] PASSED tests/integration/test_validation_integration.py::TestConvertRulesToExpressions::test_mixed_rules_conversion 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_execution_groups 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_execution_groups 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_execution_groups_parallel 
[gw4] [ 14%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_execution_groups_parallel 
tests/unit/pipeline_builder_base/test_dependencies.py::TestStepNode::test_step_node_creation 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestStepNode::test_step_node_creation 
tests/unit/pipeline_builder_base/test_dependencies.py::TestStepNode::test_step_node_with_dependencies 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_bronze_step_with_data 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestStepNode::test_step_node_with_dependencies 
[gw2] [ 15%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_bronze_step_with_data 
tests/unit/pipeline_builder_base/test_dependencies.py::TestStepNode::test_step_node_with_metadata 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestStepNode::test_step_node_with_metadata 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_dependency_error_creation 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_dependency_error_creation 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_cycle_error_creation 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_cycle_error_creation 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_missing_dependency_error 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_missing_dependency_error 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_dependency_analysis_error 
tests/integration/test_validation_integration.py::TestConvertRulesToExpressions::test_empty_rules 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_dependency_analysis_error 
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_dependency_conflict_error 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_dependency_conflict_error 
tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_creation 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_creation 
tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_to_dict 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_to_dict 
tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_add 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_add 
tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_merge 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_merge 
tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_suggestion_generator_initialization 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_suggestion_generator_initialization 
tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_validation_error 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_validation_error 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_without_dependencies 
[gw5] [ 15%] PASSED tests/integration/test_validation_integration.py::TestConvertRulesToExpressions::test_empty_rules 
tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_dependency_error 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_dependency_error 
tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_config_error 
[gw4] [ 15%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_config_error 
tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_empty 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_empty 
tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_execution_context 
[gw2] [ 16%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_without_dependencies 
tests/integration/test_validation_integration.py::TestAndAllRules::test_empty_rules 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_execution_context 
tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_execution_context_with_metadata 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_execution_context_with_metadata 
tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_validation_context 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_validation_context 
tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_validation_context_gold 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_validation_context_gold 
tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_builder_runner_integration 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_builder_runner_integration 
[gw6] [ 16%] PASSED tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_write_mode_consistency_across_pipeline_runs 
[gw5] [ 16%] PASSED tests/integration/test_validation_integration.py::TestAndAllRules::test_empty_rules 
tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_validator_builder_integration 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_validator_builder_integration 
tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_config_factory_validation 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_config_factory_validation 
tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_dependency_graph_builder 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_missing_dependency 
tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_mixed_pipeline_modes_have_correct_write_modes 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_dependency_graph_builder 
tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_error_context_full_flow 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_error_context_full_flow 
tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_validation_report_creation 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_validation_report_creation 
tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_validation_report_to_dict 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_validation_report_to_dict 
tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_transform_report_creation 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_transform_report_creation 
tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_write_report_creation 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_write_report_creation 
tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_execution_summary_creation 
[gw4] [ 16%] PASSED tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_execution_summary_creation 
tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_performance_metrics_creation 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_performance_metrics_creation 
tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_data_metrics_creation 
tests/integration/test_validation_integration.py::TestAndAllRules::test_single_column_single_rule 
[gw5] [ 17%] PASSED tests/integration/test_validation_integration.py::TestAndAllRules::test_single_column_single_rule 
[gw2] [ 17%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_missing_dependency 
[gw8] [ 17%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestMinimalPipelines::test_minimal_pipeline_with_logging 
tests/system/test_full_pipeline_with_logging_variations.py::TestLargePipelines::test_large_pipeline_with_logging 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_data_metrics_creation 
tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_summary_report_creation 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_summary_report_creation 
tests/unit/pipeline_builder_base/test_reporting.py::TestReportUtilities::test_create_validation_dict 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_reporting.py::TestReportUtilities::test_create_validation_dict 
tests/unit/pipeline_builder_base/test_reporting.py::TestReportUtilities::test_create_validation_dict_none_stats 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_reporting.py::TestReportUtilities::test_create_validation_dict_none_stats 
tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_base_runner_initialization 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_base_runner_initialization 
tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_base_runner_default_logger 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_base_runner_default_logger 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_without_transform 
tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_handle_step_error 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_handle_step_error 
tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_handle_step_error_with_context 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_handle_step_error_with_context 
tests/integration/test_validation_integration.py::TestAndAllRules::test_single_column_multiple_rules 
[gw2] [ 17%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_without_transform 
tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_collect_step_results 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_collect_step_results 
tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_collect_step_results_empty 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_collect_step_results_empty 
tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_collect_step_results_with_errors 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_collect_step_results_with_errors 
tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_create_pipeline_report 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_create_pipeline_report 
tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_aggregate_step_reports 
[gw4] [ 17%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_aggregate_step_reports 
tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_aggregate_step_reports_empty 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_aggregate_step_reports_empty 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_determine_execution_mode_initial 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_determine_execution_mode_initial 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_determine_execution_mode_initial_empty_sources 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_determine_execution_mode_initial_empty_sources 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_determine_execution_mode_incremental 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_determine_execution_mode_incremental 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_should_run_incremental_with_last_run 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_should_run_incremental_with_last_run 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_should_run_incremental_no_last_run 
[gw5] [ 18%] PASSED tests/integration/test_validation_integration.py::TestAndAllRules::test_single_column_multiple_rules 
[gw6] [ 18%] PASSED tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_mixed_pipeline_modes_have_correct_write_modes 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_without_dependencies 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_should_run_incremental_no_last_run 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_prepare_sources_for_execution_bronze 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_prepare_sources_for_execution_bronze 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_prepare_sources_for_execution_silver 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_prepare_sources_for_execution_silver 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_prepare_sources_for_execution_gold 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_prepare_sources_for_execution_gold 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_valid 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_valid 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_missing 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_missing 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_unexpected 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_unexpected 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_with_validator 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_with_validator 
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_pipeline_structure 
tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_write_mode_regression_prevention 
tests/integration/test_validation_integration.py::TestAndAllRules::test_multiple_columns 
[gw5] [ 18%] PASSED tests/integration/test_validation_integration.py::TestAndAllRules::test_multiple_columns 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_pipeline_structure 
tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_step_validator_initialization 
[gw4] [ 18%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_step_validator_initialization 
tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_step_name_valid 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_step_name_valid 
tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_step_name_invalid 
[gw2] [ 19%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_without_dependencies 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_missing_dependency 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_step_name_invalid 
tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_step_name_reserved 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_step_name_reserved 
tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_schema_name_valid 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_schema_name_valid 
tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_schema_name_invalid 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_schema_name_invalid 
tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_check_duplicate_names 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_check_duplicate_names 
tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_check_duplicate_names_no_duplicates 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_check_duplicate_names_no_duplicates 
[gw2] [ 19%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_missing_dependency 
tests/integration/test_validation_integration.py::TestAndAllRules::test_complex_rules 
tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_validate_dependency_chain 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_validate_dependency_chain 
tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_validate_schema_name 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_validate_schema_name 
tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_validate_step_name 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_validate_step_name 
tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_safe_divide 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_safe_divide 
tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_safe_divide_by_zero 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_safe_divide_by_zero 
tests/unit/pipeline_builder_base/test_writer.py::TestBaseWriter::test_base_writer_initialization 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestBaseWriter::test_base_writer_initialization 
[gw6] [ 19%] PASSED tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_write_mode_regression_prevention 
tests/unit/pipeline_builder_base/test_writer.py::TestBaseWriter::test_base_writer_abstract_methods 
[gw4] [ 19%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestBaseWriter::test_base_writer_abstract_methods 
tests/unit/pipeline_builder_base/test_writer.py::TestBaseWriter::test_base_writer_table_fqn 
[gw4] [ 20%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestBaseWriter::test_base_writer_table_fqn 
tests/unit/pipeline_builder_base/test_writer.py::TestWriterModels::test_write_result_creation 
[gw4] [ 20%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestWriterModels::test_write_result_creation 
tests/unit/pipeline_builder_base/test_writer.py::TestWriterModels::test_writer_metrics_creation 
[gw4] [ 20%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestWriterModels::test_writer_metrics_creation 
tests/unit/pipeline_builder_base/test_writer.py::TestWriterModels::test_log_row_creation 
[gw4] [ 20%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestWriterModels::test_log_row_creation 
[gw9] [ 20%] PASSED tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_silver_schema_evolution_with_multiple_new_columns 
tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_write_error_creation 
[gw4] [ 20%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_write_error_creation 
tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_table_error_creation 
[gw4] [ 20%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_table_error_creation 
tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_validation_error_creation 
tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_gold_schema_evolution_without_override 
[gw4] [ 20%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_validation_error_creation 
tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_configuration_error_creation 
[gw4] [ 20%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_configuration_error_creation 
tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_data_quality_error_creation 
[gw4] [ 20%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_data_quality_error_creation 
tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_performance_error_creation 
[gw4] [ 20%] PASSED tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_performance_error_creation 
tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_missing_columns_validation_error 
[gw5] [ 20%] PASSED tests/integration/test_validation_integration.py::TestAndAllRules::test_complex_rules 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_without_transform 
[gw4] [ 20%] PASSED tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_missing_columns_validation_error 
tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_log_writer_receives_correct_write_mode 
[gw2] [ 20%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_without_transform 
tests/integration/test_validation_integration.py::TestAndAllRules::test_empty_rules_returns_true 
tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_existing_columns_validation_success 
[gw1] [ 20%] FAILED tests/builder_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_complete_healthcare_pipeline_execution 
[gw5] [ 20%] PASSED tests/integration/test_validation_integration.py::TestAndAllRules::test_empty_rules_returns_true 
[gw6] [ 20%] PASSED tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_log_writer_receives_correct_write_mode 
tests/builder_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_incremental_healthcare_processing 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_validation_only_mode 
[gw4] [ 20%] PASSED tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_existing_columns_validation_success 
[gw9] [ 21%] PASSED tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_gold_schema_evolution_without_override 
tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_dataframe_operations 
[gw9] [ 21%] PASSED tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_dataframe_operations 
tests/integration/test_validation_integration.py::TestAndAllRules::test_no_valid_expressions_returns_true 
[gw5] [ 21%] PASSED tests/integration/test_validation_integration.py::TestAndAllRules::test_no_valid_expressions_returns_true 
tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_valid_schema 
tests/performance/test_performance.py::TestValidationPerformance::test_safe_divide_performance 
[gw6] [ 21%] PASSED tests/performance/test_performance.py::TestValidationPerformance::test_safe_divide_performance 
tests/performance/test_performance.py::TestValidationPerformance::test_safe_divide_zero_denominator_performance 
[gw6] [ 21%] PASSED tests/performance/test_performance.py::TestValidationPerformance::test_safe_divide_zero_denominator_performance 
tests/performance/test_performance.py::TestValidationPerformance::test_validate_dataframe_schema_performance 
[gw6] [ 21%] PASSED tests/performance/test_performance.py::TestValidationPerformance::test_validate_dataframe_schema_performance 
tests/performance/test_performance.py::TestValidationPerformance::test_assess_data_quality_performance 
[gw6] [ 21%] PASSED tests/performance/test_performance.py::TestValidationPerformance::test_assess_data_quality_performance 
[gw5] [ 21%] PASSED tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_valid_schema 
tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_transformations 
[gw2] [ 21%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_validation_only_mode 
tests/unit/test_constants.py::TestValidationConstants::test_default_gold_threshold 
[gw4] [ 21%] PASSED tests/unit/test_constants.py::TestValidationConstants::test_default_gold_threshold 
tests/unit/test_constants.py::TestValidationConstants::test_threshold_ordering 
[gw4] [ 21%] PASSED tests/unit/test_constants.py::TestValidationConstants::test_threshold_ordering 
tests/performance/test_performance.py::TestValidationPerformance::test_get_dataframe_info_performance 
[gw9] [ 21%] PASSED tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_transformations 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_exception_handling 
tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_missing_columns 
tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_validation_rules 
[gw2] [ 21%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_exception_handling 
[gw5] [ 21%] PASSED tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_missing_columns 
[gw9] [ 21%] PASSED tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_validation_rules 
tests/unit/test_constants.py::TestTimeoutConstants::test_default_timeout_seconds 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_success 
tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_extra_columns 
[gw4] [ 21%] PASSED tests/unit/test_constants.py::TestTimeoutConstants::test_default_timeout_seconds 
[gw2] [ 21%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_success 
tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_data_quality 
tests/unit/test_constants.py::TestTimeoutConstants::test_default_retry_timeout_seconds 
[gw9] [ 21%] PASSED tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_data_quality 
[gw4] [ 22%] PASSED tests/unit/test_constants.py::TestTimeoutConstants::test_default_retry_timeout_seconds 
tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_metadata_operations 
tests/unit/test_constants.py::TestTimeoutConstants::test_timeout_ordering 
[gw4] [ 22%] PASSED tests/unit/test_constants.py::TestTimeoutConstants::test_timeout_ordering 
[gw5] [ 22%] PASSED tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_extra_columns 
[gw6] [ 22%] PASSED tests/performance/test_performance.py::TestValidationPerformance::test_get_dataframe_info_performance 
tests/performance/test_performance.py::TestModelCreationPerformance::test_validation_thresholds_creation_performance 
[gw9] [ 22%] PASSED tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_metadata_operations 
tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_performance 
[gw9] [ 22%] PASSED tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_performance 
tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_error_handling 
[gw9] [ 22%] PASSED tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_error_handling 
tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_schema_operations 
[gw9] [ 22%] PASSED tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_schema_operations 
tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_joins 
[gw9] [ 22%] SKIPPED tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_joins 
tests/system/test_system_exceptions.py::TestValidationError::test_validation_error_creation 
[gw9] [ 22%] PASSED tests/system/test_system_exceptions.py::TestValidationError::test_validation_error_creation 
tests/system/test_system_exceptions.py::TestValidationError::test_validation_error_inheritance 
[gw9] [ 22%] PASSED tests/system/test_system_exceptions.py::TestValidationError::test_validation_error_inheritance 
tests/system/test_system_exceptions.py::TestTableOperationError::test_table_operation_error_creation 
[gw9] [ 22%] PASSED tests/system/test_system_exceptions.py::TestTableOperationError::test_table_operation_error_creation 
tests/system/test_system_exceptions.py::TestTableOperationError::test_table_operation_error_inheritance 
[gw9] [ 22%] PASSED tests/system/test_system_exceptions.py::TestTableOperationError::test_table_operation_error_inheritance 
tests/system/test_system_exceptions.py::TestPerformanceError::test_performance_error_creation 
[gw9] [ 22%] PASSED tests/system/test_system_exceptions.py::TestPerformanceError::test_performance_error_creation 
tests/system/test_system_exceptions.py::TestPerformanceError::test_performance_error_inheritance 
[gw9] [ 22%] PASSED tests/system/test_system_exceptions.py::TestPerformanceError::test_performance_error_inheritance 
tests/system/test_system_exceptions.py::TestPipelineValidationError::test_pipeline_validation_error_creation 
[gw9] [ 22%] PASSED tests/system/test_system_exceptions.py::TestPipelineValidationError::test_pipeline_validation_error_creation 
tests/system/test_system_exceptions.py::TestPipelineValidationError::test_pipeline_validation_error_inheritance 
[gw9] [ 22%] PASSED tests/system/test_system_exceptions.py::TestPipelineValidationError::test_pipeline_validation_error_inheritance 
tests/system/test_system_exceptions.py::TestExecutionError::test_execution_error_creation 
[gw9] [ 22%] PASSED tests/system/test_system_exceptions.py::TestExecutionError::test_execution_error_creation 
tests/system/test_system_exceptions.py::TestExecutionError::test_execution_error_inheritance 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_failure 
tests/unit/test_constants.py::TestLoggingConstants::test_default_log_level 
[gw4] [ 23%] PASSED tests/unit/test_constants.py::TestLoggingConstants::test_default_log_level 
tests/unit/test_constants.py::TestLoggingConstants::test_default_verbose 
[gw4] [ 23%] PASSED tests/unit/test_constants.py::TestLoggingConstants::test_default_verbose 
tests/unit/test_constants.py::TestSchemaConstants::test_default_schema 
[gw4] [ 23%] PASSED tests/unit/test_constants.py::TestSchemaConstants::test_default_schema 
[gw6] [ 23%] PASSED tests/performance/test_performance.py::TestModelCreationPerformance::test_validation_thresholds_creation_performance 
tests/performance/test_performance.py::TestModelCreationPerformance::test_parallel_config_creation_performance 
[gw9] [ 23%] PASSED tests/system/test_system_exceptions.py::TestExecutionError::test_execution_error_inheritance 
tests/system/test_system_exceptions.py::TestConfigurationError::test_configuration_error_creation 
[gw9] [ 23%] PASSED tests/system/test_system_exceptions.py::TestConfigurationError::test_configuration_error_creation 
[gw6] [ 23%] PASSED tests/performance/test_performance.py::TestModelCreationPerformance::test_parallel_config_creation_performance 
tests/performance/test_performance.py::TestModelCreationPerformance::test_pipeline_config_creation_performance 
tests/unit/test_constants.py::TestSchemaConstants::test_test_schema 
[gw4] [ 23%] PASSED tests/unit/test_constants.py::TestSchemaConstants::test_test_schema 
tests/unit/test_constants.py::TestErrorConstants::test_max_error_message_length 
[gw4] [ 23%] PASSED tests/unit/test_constants.py::TestErrorConstants::test_max_error_message_length 
tests/unit/test_constants.py::TestErrorConstants::test_max_stack_trace_lines 
[gw4] [ 23%] PASSED tests/unit/test_constants.py::TestErrorConstants::test_max_stack_trace_lines 
tests/unit/test_constants.py::TestPerformanceMonitoringConstants::test_default_metrics_interval_seconds 
[gw4] [ 23%] PASSED tests/unit/test_constants.py::TestPerformanceMonitoringConstants::test_default_metrics_interval_seconds 
[gw6] [ 23%] PASSED tests/performance/test_performance.py::TestModelCreationPerformance::test_pipeline_config_creation_performance 
tests/performance/test_performance.py::TestModelCreationPerformance::test_bronze_step_creation_performance 
[gw2] [ 23%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_failure 
tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_empty_expected_columns 
tests/system/test_system_exceptions.py::TestConfigurationError::test_configuration_error_inheritance 
[gw9] [ 23%] PASSED tests/system/test_system_exceptions.py::TestConfigurationError::test_configuration_error_inheritance 
tests/system/test_system_exceptions.py::TestExceptionChaining::test_exception_with_cause 
[gw9] [ 23%] PASSED tests/system/test_system_exceptions.py::TestExceptionChaining::test_exception_with_cause 
tests/system/test_system_exceptions.py::TestExceptionChaining::test_exception_context 
[gw9] [ 23%] PASSED tests/system/test_system_exceptions.py::TestExceptionChaining::test_exception_context 
tests/system/test_utils.py::TestDataValidation::test_and_all_rules 
[gw9] [ 23%] PASSED tests/system/test_utils.py::TestDataValidation::test_and_all_rules 
tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_constructor_parameters 
[gw9] [ 23%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_constructor_parameters 
tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_basic 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_with_different_step_types 
tests/unit/test_constants.py::TestPerformanceMonitoringConstants::test_default_alert_threshold_percent 
[gw4] [ 24%] PASSED tests/unit/test_constants.py::TestPerformanceMonitoringConstants::test_default_alert_threshold_percent 
tests/unit/test_constants.py::TestConstantsIntegration::test_memory_calculations 
[gw4] [ 24%] PASSED tests/unit/test_constants.py::TestConstantsIntegration::test_memory_calculations 
tests/unit/test_constants.py::TestConstantsIntegration::test_threshold_percentages 
[gw4] [ 24%] PASSED tests/unit/test_constants.py::TestConstantsIntegration::test_threshold_percentages 
tests/unit/test_constants.py::TestConstantsIntegration::test_positive_values 
[gw4] [ 24%] PASSED tests/unit/test_constants.py::TestConstantsIntegration::test_positive_values 
tests/unit/test_constants.py::TestConstantsIntegration::test_string_constants_not_empty 
[gw4] [ 24%] PASSED tests/unit/test_constants.py::TestConstantsIntegration::test_string_constants_not_empty 
tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_import 
[gw4] [ 24%] PASSED tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_import 
tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_values 
[gw4] [ 24%] PASSED tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_values 
tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_types 
[gw4] [ 24%] PASSED tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_types 
tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_ranges 
[gw4] [ 24%] PASSED tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_ranges 
tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_consistency 
[gw4] [ 24%] PASSED tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_consistency 
tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_immutability 
[gw4] [ 24%] PASSED tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_immutability 
tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_documentation 
[gw4] [ 24%] PASSED tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_documentation 
tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_usage_examples 
[gw4] [ 24%] PASSED tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_usage_examples 
tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_error_handling 
[gw4] [ 24%] PASSED tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_error_handling 
tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_module_attributes 
[gw4] [ 24%] PASSED tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_module_attributes 
tests/unit/test_edge_cases.py::TestEdgeCases::test_error_conditions 
[gw4] [ 24%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_error_conditions 
tests/unit/test_edge_cases.py::TestEdgeCases::test_boundary_values 
[gw4] [ 24%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_boundary_values 
tests/unit/test_edge_cases.py::TestEdgeCases::test_concurrent_operations 
[gw4] [ 24%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_concurrent_operations 
tests/unit/test_edge_cases.py::TestEdgeCases::test_memory_management 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_basic 
tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_with_step_name 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_with_step_name 
[gw6] [ 25%] PASSED tests/performance/test_performance.py::TestModelCreationPerformance::test_bronze_step_creation_performance 
tests/performance/test_performance.py::TestModelCreationPerformance::test_silver_step_creation_performance 
[gw2] [ 25%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_with_different_step_types 
[gw5] [ 25%] PASSED tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_empty_expected_columns 
tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_empty_dataframe 
[gw5] [ 25%] PASSED tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_empty_dataframe 
tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_empty_cycle 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_empty_cycle 
tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_single_step_cycle 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_single_step_cycle 
tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_inheritance 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_inheritance 
tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_cycle_immutability 
tests/integration/test_validation_integration.py::TestSafeDivide::test_normal_division 
[gw5] [ 25%] PASSED tests/integration/test_validation_integration.py::TestSafeDivide::test_normal_division 
tests/integration/test_validation_integration.py::TestSafeDivide::test_division_by_zero 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_cycle_immutability 
tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_basic 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_basic 
tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_with_step_name 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_with_step_name 
tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_empty_list 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_empty_list 
[gw6] [ 25%] PASSED tests/performance/test_performance.py::TestModelCreationPerformance::test_silver_step_creation_performance 
tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_single_dependency 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_single_dependency 
tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_inheritance 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_inheritance 
tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_list_immutability 
[gw9] [ 25%] PASSED tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_list_immutability 
tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_basic 
[gw9] [ 26%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_basic 
tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_with_step_name 
[gw9] [ 26%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_with_step_name 
tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_empty_list 
[gw4] [ 26%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_memory_management 
tests/unit/test_edge_cases.py::TestEdgeCases::test_schema_evolution 
[gw4] [ 26%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_schema_evolution 
tests/unit/test_edge_cases.py::TestEdgeCases::test_pipeline_builder_edge_cases 
[gw4] [ 26%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_pipeline_builder_edge_cases 
tests/unit/test_edge_cases.py::TestEdgeCases::test_execution_engine_edge_cases 
[gw4] [ 26%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_execution_engine_edge_cases 
tests/unit/test_edge_cases.py::TestEdgeCases::test_validation_edge_cases 
tests/performance/test_performance.py::TestModelCreationPerformance::test_gold_step_creation_performance 
[gw5] [ 26%] PASSED tests/integration/test_validation_integration.py::TestSafeDivide::test_division_by_zero 
tests/integration/test_validation_integration.py::TestSafeDivide::test_division_by_zero_custom_default 
[gw5] [ 26%] PASSED tests/integration/test_validation_integration.py::TestSafeDivide::test_division_by_zero_custom_default 
[gw4] [ 26%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_validation_edge_cases 
tests/unit/test_edge_cases.py::TestEdgeCases::test_writer_edge_cases 
[gw4] [ 26%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_writer_edge_cases 
tests/unit/test_edge_cases.py::TestEdgeCases::test_storage_edge_cases 
[gw4] [ 26%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_storage_edge_cases 
tests/unit/test_edge_cases.py::TestEdgeCases::test_function_edge_cases 
[gw4] [ 26%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_function_edge_cases 
tests/unit/test_edge_cases.py::TestEdgeCases::test_dataframe_edge_cases 
[gw4] [ 26%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_dataframe_edge_cases 
tests/unit/test_edge_cases.py::TestEdgeCases::test_session_edge_cases 
[gw4] [ 26%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_session_edge_cases 
tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_has_all_required_values 
[gw4] [ 26%] PASSED tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_has_all_required_values 
tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_models_matches_base 
[gw4] [ 26%] PASSED tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_models_matches_base 
tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_matches_pipeline_mode 
[gw6] [ 26%] PASSED tests/performance/test_performance.py::TestModelCreationPerformance::test_gold_step_creation_performance 
tests/performance/test_performance.py::TestSerializationPerformance::test_model_to_dict_performance 
[gw6] [ 26%] PASSED tests/performance/test_performance.py::TestSerializationPerformance::test_model_to_dict_performance 
tests/performance/test_performance.py::TestSerializationPerformance::test_model_to_json_performance 
[gw4] [ 27%] PASSED tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_matches_pipeline_mode 
[gw9] [ 27%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_empty_list 
tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_single_step 
tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_enum_values_exist 
[gw4] [ 27%] PASSED tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_enum_values_exist 
tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_models_has_basic_values 
[gw4] [ 27%] PASSED tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_models_has_basic_values 
tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_writer_has_all_values 
[gw4] [ 27%] PASSED tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_writer_has_all_values 
tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_consistency_across_locations 
[gw4] [ 27%] PASSED tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_consistency_across_locations 
tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_enum_values_exist 
[gw6] [ 27%] PASSED tests/performance/test_performance.py::TestSerializationPerformance::test_model_to_json_performance 
tests/performance/test_performance.py::TestSerializationPerformance::test_model_validation_performance 
[gw4] [ 27%] PASSED tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_enum_values_exist 
tests/unit/test_enum_consistency.py::TestStepTypeConsistency::test_step_type_has_all_required_values 
[gw4] [ 27%] PASSED tests/unit/test_enum_consistency.py::TestStepTypeConsistency::test_step_type_has_all_required_values 
tests/unit/test_enum_consistency.py::TestStepTypeConsistency::test_step_type_consistency_across_locations 
[gw4] [ 27%] PASSED tests/unit/test_enum_consistency.py::TestStepTypeConsistency::test_step_type_consistency_across_locations 
[gw9] [ 27%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_single_step 
tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_inheritance 
[gw9] [ 27%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_inheritance 
tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_list_immutability 
tests/unit/test_enum_consistency.py::TestStepStatusConsistency::test_step_status_has_all_required_values 
[gw4] [ 27%] PASSED tests/unit/test_enum_consistency.py::TestStepStatusConsistency::test_step_status_has_all_required_values 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_with_max_workers 
[gw2] [ 27%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_with_max_workers 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_empty_steps 
[gw2] [ 27%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_empty_steps 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_step_failure_continues 
[gw9] [ 27%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_list_immutability 
tests/unit/dependencies/test_exceptions.py::TestExceptionChaining::test_dependency_error_chaining 
[gw9] [ 27%] PASSED tests/unit/dependencies/test_exceptions.py::TestExceptionChaining::test_dependency_error_chaining 
tests/unit/dependencies/test_exceptions.py::TestExceptionChaining::test_circular_dependency_error_chaining 
[gw9] [ 27%] PASSED tests/unit/dependencies/test_exceptions.py::TestExceptionChaining::test_circular_dependency_error_chaining 
tests/unit/dependencies/test_exceptions.py::TestExceptionChaining::test_exception_attributes_preserved 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_exceptions.py::TestExceptionChaining::test_exception_attributes_preserved 
tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_dependency_error_str 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_dependency_error_str 
tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_dependency_analysis_error_str 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_dependency_analysis_error_str 
tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_circular_dependency_error_str 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_circular_dependency_error_str 
tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_invalid_dependency_error_str 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_invalid_dependency_error_str 
tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_dependency_conflict_error_str 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_dependency_conflict_error_str 
tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_add_dependency_missing_nodes 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_add_dependency_missing_nodes 
tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_dependencies_missing_node 
[gw6] [ 28%] PASSED tests/performance/test_performance.py::TestSerializationPerformance::test_model_validation_performance 
tests/performance/test_performance.py::TestMemoryUsagePerformance::test_model_creation_memory_usage 
tests/integration/test_validation_integration.py::TestSafeDivide::test_float_division 
[gw5] [ 28%] PASSED tests/integration/test_validation_integration.py::TestSafeDivide::test_float_division 
tests/integration/test_validation_integration.py::TestSafeDivide::test_negative_numbers 
[gw5] [ 28%] PASSED tests/integration/test_validation_integration.py::TestSafeDivide::test_negative_numbers 
[gw2] [ 28%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_step_failure_continues 
tests/integration/test_execution_engine.py::TestExecutionEngine::test_backward_compatibility_aliases 
[gw2] [ 28%] PASSED tests/integration/test_execution_engine.py::TestExecutionEngine::test_backward_compatibility_aliases 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_dependencies_missing_node 
tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_dependents_missing_node 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_dependents_missing_node 
tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_detect_cycles 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_detect_cycles 
tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_execution_groups_missing_dependency 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_execution_groups_missing_dependency 
tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_validate_cycles 
[gw9] [ 28%] PASSED tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_validate_cycles 
tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_gold_step_success 
[gw9] [ 28%] PASSED tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_gold_step_success 
tests/unit/test_enum_consistency.py::TestStepStatusConsistency::test_step_status_consistency_across_locations 
[gw4] [ 29%] PASSED tests/unit/test_enum_consistency.py::TestStepStatusConsistency::test_step_status_consistency_across_locations 
tests/unit/test_enum_consistency.py::TestPipelineModeExecutionModeMapping::test_pipeline_mode_to_execution_mode_mapping 
[gw4] [ 29%] PASSED tests/unit/test_enum_consistency.py::TestPipelineModeExecutionModeMapping::test_pipeline_mode_to_execution_mode_mapping 
tests/unit/test_enum_consistency.py::TestPipelineModeExecutionModeMapping::test_all_pipeline_modes_have_execution_mode_equivalents 
[gw4] [ 29%] PASSED tests/unit/test_enum_consistency.py::TestPipelineModeExecutionModeMapping::test_all_pipeline_modes_have_execution_mode_equivalents 
[gw1] [ 29%] PASSED tests/builder_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_incremental_healthcare_processing 
tests/builder_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_healthcare_logging 
tests/unit/test_enum_consistency.py::TestEnumCompleteness::test_execution_mode_completeness 
[gw4] [ 29%] PASSED tests/unit/test_enum_consistency.py::TestEnumCompleteness::test_execution_mode_completeness 
tests/unit/test_enum_consistency.py::TestEnumCompleteness::test_pipeline_mode_completeness 
[gw4] [ 29%] PASSED tests/unit/test_enum_consistency.py::TestEnumCompleteness::test_pipeline_mode_completeness 
tests/unit/test_errors.py::TestErrorTypeSafety::test_error_context_value_type_validation 
[gw6] [ 29%] PASSED tests/performance/test_performance.py::TestMemoryUsagePerformance::test_model_creation_memory_usage 
tests/performance/test_performance.py::TestMemoryUsagePerformance::test_serialization_memory_usage 
[gw6] [ 29%] PASSED tests/performance/test_performance.py::TestMemoryUsagePerformance::test_serialization_memory_usage 
tests/performance/test_performance.py::test_performance_summary 
[gw6] [ 29%] PASSED tests/performance/test_performance.py::test_performance_summary 
tests/performance/test_performance.py::test_update_baselines 
[gw6] [ 29%] PASSED tests/performance/test_performance.py::test_update_baselines 
tests/security/test_security_integration.py::TestSecurityIntegration::test_security_test_suite_integration 
tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_engine_initialization 
[gw2] [ 29%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_engine_initialization 
tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_engine_without_logger 
[gw2] [ 29%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_engine_without_logger 
tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_type_detection 
[gw2] [ 29%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_type_detection 
tests/integration/test_validation_integration.py::TestSafeDivide::test_zero_numerator 
[gw5] [ 29%] PASSED tests/integration/test_validation_integration.py::TestSafeDivide::test_zero_numerator 
tests/integration/test_validation_integration.py::TestGetDataframeInfo::test_basic_info 
[gw4] [ 29%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_error_context_value_type_validation 
tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_with_rules_validation 
tests/unit/test_errors.py::TestErrorTypeSafety::test_error_context_type_validation 
[gw4] [ 29%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_error_context_type_validation 
tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_context_creation 
[gw2] [ 29%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_context_creation 
tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_execution_result_creation 
[gw2] [ 30%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_execution_result_creation 
tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_mode_enum 
[gw2] [ 30%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_mode_enum 
tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_status_enum 
[gw2] [ 30%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_status_enum 
[gw9] [ 30%] PASSED tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_with_rules_validation 
tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_validation_only_mode 
tests/unit/test_errors.py::TestErrorTypeSafety::test_error_suggestions_type_validation 
[gw4] [ 30%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_error_suggestions_type_validation 
tests/unit/test_errors.py::TestErrorTypeSafety::test_base_error_explicit_types 
[gw4] [ 30%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_base_error_explicit_types 
tests/unit/test_errors.py::TestErrorTypeSafety::test_configuration_error_explicit_types 
[gw5] [ 30%] PASSED tests/integration/test_validation_integration.py::TestGetDataframeInfo::test_basic_info 
tests/integration/test_validation_integration.py::TestGetDataframeInfo::test_empty_dataframe 
[gw5] [ 30%] PASSED tests/integration/test_validation_integration.py::TestGetDataframeInfo::test_empty_dataframe 
[gw4] [ 30%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_configuration_error_explicit_types 
tests/unit/test_errors.py::TestErrorTypeSafety::test_data_error_explicit_types 
[gw4] [ 30%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_data_error_explicit_types 
tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_type_enum 
[gw2] [ 30%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_type_enum 
tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_bronze_step_validation 
[gw2] [ 30%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_bronze_step_validation 
tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_silver_step_validation 
[gw2] [ 30%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_silver_step_validation 
tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_gold_step_validation 
[gw2] [ 30%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_gold_step_validation 
tests/unit/test_errors.py::TestErrorTypeSafety::test_pipeline_error_explicit_types 
[gw4] [ 30%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_pipeline_error_explicit_types 
tests/unit/test_errors.py::TestErrorTypeSafety::test_step_error_explicit_types 
[gw4] [ 30%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_step_error_explicit_types 
tests/unit/test_errors.py::TestErrorTypeSafety::test_execution_error_explicit_types 
[gw4] [ 30%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_execution_error_explicit_types 
tests/unit/test_errors.py::TestErrorTypeSafety::test_system_error_explicit_types 
[gw4] [ 30%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_system_error_explicit_types 
tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_pipeline_config_validation 
[gw2] [ 31%] PASSED tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_pipeline_config_validation 
tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_with_invalid_validator 
[gw2] [ 31%] PASSED tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_with_invalid_validator 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_step_manager_initialization 
[gw2] [ 31%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_step_manager_initialization 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_add_step 
[gw2] [ 31%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_add_step 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_add_step_duplicate 
[gw2] [ 31%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_add_step_duplicate 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_step 
[gw2] [ 31%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_step 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_step_missing 
[gw2] [ 31%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_step_missing 
tests/unit/test_errors.py::TestErrorTypeSafety::test_performance_error_explicit_types 
[gw4] [ 31%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_performance_error_explicit_types 
tests/unit/test_errors.py::TestErrorTypeSafety::test_error_serialization_explicit_types 
[gw4] [ 31%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_error_serialization_explicit_types 
tests/unit/test_errors.py::TestErrorTypeSafety::test_error_context_manipulation_explicit_types 
tests/integration/test_validation_integration.py::TestGetDataframeInfo::test_error_handling 
[gw9] [ 31%] PASSED tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_validation_only_mode 
[gw4] [ 31%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_error_context_manipulation_explicit_types 
tests/unit/test_errors.py::TestErrorTypeSafety::test_error_suggestion_manipulation_explicit_types 
[gw4] [ 31%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_error_suggestion_manipulation_explicit_types 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_step_all_types 
[gw2] [ 31%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_step_all_types 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_steps_by_type 
[gw2] [ 31%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_steps_by_type 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_remove_step 
[gw2] [ 31%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_remove_step 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_clear_steps 
[gw2] [ 31%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_clear_steps 
[gw5] [ 31%] PASSED tests/integration/test_validation_integration.py::TestGetDataframeInfo::test_error_handling 
tests/unit/test_errors.py::TestErrorTypeSafety::test_no_any_types_in_error_classes 
[gw4] [ 31%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_no_any_types_in_error_classes 
tests/unit/test_errors.py::TestErrorTypeSafety::test_no_args_kwargs_in_error_constructors 
[gw4] [ 32%] PASSED tests/unit/test_errors.py::TestErrorTypeSafety::test_no_args_kwargs_in_error_constructors 
tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_existing_error_usage_still_works 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_all_steps 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_all_steps 
tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_validate_all_steps 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_validate_all_steps 
tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_classify_step_type 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_classify_step_type 
tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_classify_step_type_from_attribute 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_classify_step_type_from_attribute 
tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_extract_step_dependencies 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_extract_step_dependencies 
tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_extract_step_dependencies_gold 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_extract_step_dependencies_gold 
tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_get_step_target 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_get_step_target 
tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_get_step_target_missing 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_get_step_target_missing 
[gw4] [ 32%] PASSED tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_existing_error_usage_still_works 
tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_error_inheritance_still_works 
[gw4] [ 32%] PASSED tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_error_inheritance_still_works 
tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_silver_missing_schema 
tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_normalize_step_name 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_normalize_step_name 
tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_normalize_step_name_edge_cases 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_normalize_step_name_edge_cases 
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_pipeline_validator_initialization 
[gw2] [ 32%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_pipeline_validator_initialization 
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_pipeline_validator_default_logger 
tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_error_context_manipulation_still_works 
[gw4] [ 32%] PASSED tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_error_context_manipulation_still_works 
tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_error_serialization_still_works 
[gw4] [ 32%] PASSED tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_error_serialization_still_works 
tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_resource_error_creation 
[gw4] [ 32%] PASSED tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_resource_error_creation 
tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_silver_step_success 
[gw4] [ 32%] PASSED tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_silver_step_success 
[gw2] [ 33%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_pipeline_validator_default_logger 
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_step_names_unique 
[gw2] [ 33%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_step_names_unique 
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_step_names_duplicate 
[gw2] [ 33%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_step_names_duplicate 
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_step_names_invalid 
[gw2] [ 33%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_step_names_invalid 
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_dependency_chain_valid 
[gw8] [ 33%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestLargePipelines::test_large_pipeline_with_logging 
tests/system/test_full_pipeline_with_logging_variations.py::TestEdgeCases::test_pipeline_with_empty_data 
tests/integration/test_validation_integration.py::TestAssessDataQuality::test_empty_dataframe 
[gw9] [ 33%] PASSED tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_silver_missing_schema 
tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_gold_missing_schema 
[gw5] [ 33%] PASSED tests/integration/test_validation_integration.py::TestAssessDataQuality::test_empty_dataframe 
tests/integration/test_validation_integration.py::TestAssessDataQuality::test_dataframe_without_rules 
tests/unit/test_execution_comprehensive.py::TestStepType::test_step_type_enumeration 
[gw4] [ 33%] PASSED tests/unit/test_execution_comprehensive.py::TestStepType::test_step_type_enumeration 
tests/unit/test_execution_comprehensive.py::TestStepExecutionResult::test_step_execution_result_creation 
[gw4] [ 33%] PASSED tests/unit/test_execution_comprehensive.py::TestStepExecutionResult::test_step_execution_result_creation 
tests/unit/test_execution_comprehensive.py::TestStepExecutionResult::test_step_execution_result_with_end_time 
[gw4] [ 33%] PASSED tests/unit/test_execution_comprehensive.py::TestStepExecutionResult::test_step_execution_result_with_end_time 
tests/unit/test_execution_comprehensive.py::TestStepExecutionResult::test_step_execution_result_with_all_fields 
[gw4] [ 33%] PASSED tests/unit/test_execution_comprehensive.py::TestStepExecutionResult::test_step_execution_result_with_all_fields 
[gw5] [ 33%] PASSED tests/integration/test_validation_integration.py::TestAssessDataQuality::test_dataframe_without_rules 
tests/unit/test_execution_comprehensive.py::TestExecutionResult::test_execution_result_creation 
[gw4] [ 33%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutionResult::test_execution_result_creation 
tests/unit/test_execution_comprehensive.py::TestExecutionResult::test_execution_result_with_end_time 
[gw8] [ 33%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestEdgeCases::test_pipeline_with_empty_data 
tests/system/test_full_pipeline_with_logging_variations.py::TestEdgeCases::test_pipeline_with_partial_validation_failures 
[gw4] [ 33%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutionResult::test_execution_result_with_end_time 
tests/unit/test_execution_comprehensive.py::TestExecutionResult::test_execution_result_with_steps 
[gw4] [ 33%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutionResult::test_execution_result_with_steps 
tests/unit/test_execution_comprehensive.py::TestExecutionEngineInitialization::test_execution_engine_initialization 
[gw4] [ 33%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutionEngineInitialization::test_execution_engine_initialization 
tests/unit/test_execution_comprehensive.py::TestExecutionEngineInitialization::test_execution_engine_with_custom_logger 
[gw4] [ 33%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutionEngineInitialization::test_execution_engine_with_custom_logger 
tests/unit/test_execution_comprehensive.py::TestExecutionEngineInitialization::test_execution_engine_with_none_logger 
[gw4] [ 34%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutionEngineInitialization::test_execution_engine_with_none_logger 
tests/unit/test_execution_comprehensive.py::TestExecuteStep::test_execute_bronze_step_success 
[gw4] [ 34%] PASSED tests/unit/test_execution_comprehensive.py::TestExecuteStep::test_execute_bronze_step_success 
tests/unit/test_execution_comprehensive.py::TestExecuteStep::test_execute_step_unknown_step_type 
[gw4] [ 34%] PASSED tests/unit/test_execution_comprehensive.py::TestExecuteStep::test_execute_step_unknown_step_type 
tests/unit/test_execution_comprehensive.py::TestExecuteStep::test_execute_bronze_step_missing_context 
[gw4] [ 34%] PASSED tests/unit/test_execution_comprehensive.py::TestExecuteStep::test_execute_bronze_step_missing_context 
tests/unit/test_execution_comprehensive.py::TestExecutePipeline::test_execute_pipeline_with_none_context 
[gw4] [ 34%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutePipeline::test_execute_pipeline_with_none_context 
[gw2] [ 34%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_dependency_chain_valid 
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_dependency_chain_cycle 
[gw2] [ 34%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_dependency_chain_cycle 
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_schema_valid 
[gw2] [ 34%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_schema_valid 
tests/integration/test_validation_integration.py::TestAssessDataQuality::test_dataframe_with_rules 
[gw9] [ 34%] PASSED tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_gold_missing_schema 
[gw1] [ 34%] PASSED tests/builder_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_healthcare_logging 
tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_complete_iot_sensor_pipeline_execution 
tests/unit/test_execution_comprehensive.py::TestExecutePipeline::test_execute_pipeline_invalid_context_type 
[gw4] [ 34%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutePipeline::test_execute_pipeline_invalid_context_type 
tests/unit/test_execution_comprehensive.py::TestExecutePipeline::test_execute_pipeline_empty_steps 
[gw4] [ 34%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutePipeline::test_execute_pipeline_empty_steps 
tests/unit/test_execution_comprehensive.py::TestPrivateMethods::test_execute_bronze_step_empty_dataframe 
[gw4] [ 34%] PASSED tests/unit/test_execution_comprehensive.py::TestPrivateMethods::test_execute_bronze_step_empty_dataframe 
tests/unit/test_execution_comprehensive.py::TestBackwardCompatibility::test_unified_execution_engine_alias 
[gw4] [ 34%] PASSED tests/unit/test_execution_comprehensive.py::TestBackwardCompatibility::test_unified_execution_engine_alias 
tests/unit/test_execution_comprehensive.py::TestBackwardCompatibility::test_unified_step_execution_result_alias 
[gw4] [ 34%] PASSED tests/unit/test_execution_comprehensive.py::TestBackwardCompatibility::test_unified_step_execution_result_alias 
tests/unit/test_execution_comprehensive.py::TestExecutionIntegration::test_different_execution_modes 
tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_silver_missing_source 
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_schema_invalid 
[gw2] [ 34%] PASSED tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_schema_invalid 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_get_spark 
[gw2] [ 34%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_get_spark 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_get_mode 
[gw2] [ 34%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_get_mode 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_default_mode 
[gw2] [ 35%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_default_mode 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_step_status_enum 
[gw2] [ 35%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_step_status_enum 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_step_type_enum 
[gw2] [ 35%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_step_type_enum 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_execution_mode_enum 
[gw2] [ 35%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_execution_mode_enum 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_step_execution_result_creation 
[gw2] [ 35%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_step_execution_result_creation 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_result_creation 
[gw2] [ 35%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_result_creation 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_with_empty_data 
[gw2] [ 35%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_with_empty_data 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_with_sample_data 
[gw2] [ 35%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_with_sample_data 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_error_handling 
[gw2] [ 35%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_error_handling 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_metrics_collection 
[gw2] [ 35%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_metrics_collection 
tests/unit/test_execution_final_coverage.py::TestExecutionFinalCoverage::test_execute_pipeline_with_none_steps_result 
[gw2] [ 35%] PASSED tests/unit/test_execution_final_coverage.py::TestExecutionFinalCoverage::test_execute_pipeline_with_none_steps_result 
tests/unit/test_execution_final_coverage.py::TestExecutionFinalCoverage::test_execute_pipeline_silver_step_no_schema_logging 
[gw2] [ 35%] PASSED tests/unit/test_execution_final_coverage.py::TestExecutionFinalCoverage::test_execute_pipeline_silver_step_no_schema_logging 
tests/unit/test_execution_final_coverage.py::TestExecutionFinalCoverage::test_execute_pipeline_gold_step_no_schema_logging 
[gw2] [ 35%] PASSED tests/unit/test_execution_final_coverage.py::TestExecutionFinalCoverage::test_execute_pipeline_gold_step_no_schema_logging 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_mode_uses_append_for_silver_step 
[gw4] [ 35%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutionIntegration::test_different_execution_modes 
tests/unit/test_execution_comprehensive.py::TestExecutionIntegration::test_logging_integration 
[gw4] [ 35%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutionIntegration::test_logging_integration 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_initialization 
[gw2] [ 35%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_mode_uses_append_for_silver_step 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_mode_uses_overwrite_for_gold_step 
[gw2] [ 35%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_mode_uses_overwrite_for_gold_step 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_initial_mode_uses_overwrite_for_silver_step 
[gw2] [ 35%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_initial_mode_uses_overwrite_for_silver_step 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_initial_mode_uses_overwrite_for_gold_step 
[gw2] [ 36%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_initial_mode_uses_overwrite_for_gold_step 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_full_refresh_mode_uses_overwrite_for_silver_step 
[gw2] [ 36%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_full_refresh_mode_uses_overwrite_for_silver_step 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_full_refresh_mode_uses_overwrite_for_gold_step 
[gw2] [ 36%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_full_refresh_mode_uses_overwrite_for_gold_step 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_validation_only_mode_has_no_write_mode_for_silver_step 
[gw2] [ 36%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_validation_only_mode_has_no_write_mode_for_silver_step 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_filter_excludes_existing_rows 
[gw2] [ 36%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_filter_excludes_existing_rows 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_context_manager 
[gw2] [ 36%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_context_manager 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_context_manager_exception 
[gw2] [ 36%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_context_manager_exception 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_setup_handlers_console_only 
[gw2] [ 36%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_setup_handlers_console_only 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_setup_handlers_with_file 
[gw9] [ 36%] PASSED tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_silver_missing_source 
tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_gold_missing_source 
[gw9] [ 36%] PASSED tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_gold_missing_source 
tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_transform_error 
[gw4] [ 36%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_initialization 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_initialization_with_mode 
[gw4] [ 36%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_initialization_with_mode 
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_invalid_spark_session 
[gw4] [ 36%] PASSED tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_invalid_spark_session 
tests/unit/test_log_row_fields.py::TestMultiStepLogRowFields::test_multiple_steps_each_have_correct_fields 
[gw4] [ 36%] PASSED tests/unit/test_log_row_fields.py::TestMultiStepLogRowFields::test_multiple_steps_each_have_correct_fields 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_pipeline_start 
[gw4] [ 36%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_pipeline_start 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_pipeline_start_custom_mode 
[gw4] [ 36%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_pipeline_start_custom_mode 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_pipeline_end_success 
[gw4] [ 36%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_pipeline_end_success 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_pipeline_end_failure 
[gw4] [ 36%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_pipeline_end_failure 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_performance_metric 
[gw4] [ 37%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_performance_metric 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_performance_metric_custom_unit 
[gw4] [ 37%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_performance_metric_custom_unit 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_format_message_with_kwargs 
[gw4] [ 37%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_format_message_with_kwargs 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_format_message_without_kwargs 
[gw4] [ 37%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_format_message_without_kwargs 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_context_manager 
[gw4] [ 37%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_context_manager 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_context_manager_with_existing_extra 
[gw4] [ 37%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_context_manager_with_existing_extra 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_start 
[gw4] [ 37%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_start 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_start_different_stage 
[gw4] [ 37%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_start_different_stage 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_complete 
[gw4] [ 37%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_complete 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_complete_no_rows 
[gw4] [ 37%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_complete_no_rows 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_failed 
[gw4] [ 37%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_failed 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_failed_no_duration 
[gw4] [ 37%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_failed_no_duration 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_validation_passed 
[gw4] [ 37%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_validation_passed 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_validation_failed 
[gw4] [ 37%] SKIPPED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_validation_failed 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_start 
[gw4] [ 37%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_start 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_end 
[gw4] [ 37%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_end 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_end_nonexistent 
[gw4] [ 37%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_end_nonexistent 
tests/unit/test_models.py::TestBronzeStep::test_bronze_step_creation_minimal 
[gw4] [ 37%] PASSED tests/unit/test_models.py::TestBronzeStep::test_bronze_step_creation_minimal 
tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_success 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_success 
tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_empty_name 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_empty_name 
tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_none_name 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_none_name 
tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_invalid_rules_type 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_invalid_rules_type 
tests/unit/test_models.py::TestBronzeStep::test_bronze_step_has_incremental_capability 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestBronzeStep::test_bronze_step_has_incremental_capability 
tests/unit/test_models.py::TestSilverStep::test_silver_step_creation 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestSilverStep::test_silver_step_creation 
[gw9] [ 38%] PASSED tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_transform_error 
tests/unit/test_models.py::TestSilverStep::test_silver_step_creation_minimal 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestSilverStep::test_silver_step_creation_minimal 
tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_success 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_success 
tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_empty_name 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_empty_name 
tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_empty_source_bronze 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_empty_source_bronze 
tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_none_transform 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_none_transform 
tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_invalid_rules_type 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_invalid_rules_type 
tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_empty_table_name 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_empty_table_name 
tests/unit/test_models.py::TestGoldStep::test_gold_step_creation 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestGoldStep::test_gold_step_creation 
tests/unit/test_models.py::TestGoldStep::test_gold_step_creation_minimal 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestGoldStep::test_gold_step_creation_minimal 
tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_success 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_success 
tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_empty_name 
[gw4] [ 38%] PASSED tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_empty_name 
tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_none_transform 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_none_transform 
tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_success_with_silver_steps 
tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_invalid_rules_type 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_invalid_rules_type 
tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_empty_table_name 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_empty_table_name 
tests/unit/test_models.py::TestStepResult::test_step_result_creation 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestStepResult::test_step_result_creation 
tests/unit/test_models.py::TestStepResult::test_step_result_is_high_quality 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestStepResult::test_step_result_is_high_quality 
tests/unit/test_models.py::TestStepResult::test_step_result_create_success 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestStepResult::test_step_result_create_success 
tests/unit/test_models.py::TestStepResult::test_step_result_create_failure 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestStepResult::test_step_result_create_failure 
tests/unit/test_models.py::TestPipelineMetrics::test_pipeline_metrics_creation_default 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestPipelineMetrics::test_pipeline_metrics_creation_default 
tests/unit/test_models.py::TestPipelineMetrics::test_pipeline_metrics_creation_custom 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestPipelineMetrics::test_pipeline_metrics_creation_custom 
tests/unit/test_models.py::TestPipelineConfig::test_pipeline_config_creation_default 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestPipelineConfig::test_pipeline_config_creation_default 
tests/unit/test_models.py::TestPipelineConfig::test_pipeline_config_creation_custom 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestPipelineConfig::test_pipeline_config_creation_custom 
tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_creation 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_creation 
tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_validation_success 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_validation_success 
tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_validation_empty_step_name 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_validation_empty_step_name 
[gw9] [ 39%] PASSED tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_success_with_silver_steps 
tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_validation_empty_source_bronze 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_validation_empty_source_bronze 
tests/unit/test_models.py::TestParallelConfig::test_parallel_config_creation 
[gw4] [ 39%] PASSED tests/unit/test_models.py::TestParallelConfig::test_parallel_config_creation 
tests/unit/test_models.py::TestParallelConfig::test_parallel_config_creation_minimal 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_parallel_config_creation_minimal 
tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_success 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_success 
tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_negative_max_workers 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_negative_max_workers 
tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_negative_worker_timeout 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_negative_worker_timeout 
tests/unit/test_models.py::TestParallelConfig::test_base_model_to_dict_with_nested_objects 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_base_model_to_dict_with_nested_objects 
tests/unit/test_models.py::TestParallelConfig::test_base_model_to_dict_without_nested_objects 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_base_model_to_dict_without_nested_objects 
tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_validation_edge_cases 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_validation_edge_cases 
tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_get_threshold 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_get_threshold 
tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_validation_invalid_schema 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_validation_invalid_schema 
tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_create_default 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_create_default 
tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_create_high_performance 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_create_high_performance 
tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_success_with_gold_steps 
tests/unit/test_models.py::TestParallelConfig::test_base_model_to_json 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_base_model_to_json 
[gw1] [ 40%] PASSED tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_complete_iot_sensor_pipeline_execution 
tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_incremental_sensor_processing 
[gw1] [ 40%] PASSED tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_incremental_sensor_processing 
tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_anomaly_detection_pipeline 
tests/unit/test_models.py::TestParallelConfig::test_base_model_str_representation 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_base_model_str_representation 
tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_create_loose 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_create_loose 
tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_create_strict 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_create_strict 
tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_max_workers_exceeded 
[gw4] [ 40%] PASSED tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_max_workers_exceeded 
tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_properties 
[gw4] [ 41%] PASSED tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_properties 
tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_create_conservative 
[gw4] [ 41%] PASSED tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_create_conservative 
tests/unit/test_models_new.py::TestBaseModel::test_validate_default 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestBaseModel::test_validate_default 
tests/unit/test_models_new.py::TestBaseModel::test_to_dict_simple 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestBaseModel::test_to_dict_simple 
tests/unit/test_models_new.py::TestBaseModel::test_to_dict_nested_objects 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestBaseModel::test_to_dict_nested_objects 
[gw2] [ 41%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_setup_handlers_with_file 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_setup_handlers_verbose_false 
[gw2] [ 41%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_setup_handlers_verbose_false 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_logger_creation_with_custom_name 
[gw2] [ 41%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_logger_creation_with_custom_name 
[gw8] [ 41%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestEdgeCases::test_pipeline_with_partial_validation_failures 
tests/system/test_full_pipeline_with_logging_variations.py::TestEdgeCases::test_pipeline_all_invalid_data 
tests/unit/test_models_new.py::TestBaseModel::test_to_json 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestBaseModel::test_to_json 
tests/unit/test_models_new.py::TestBaseModel::test_str_representation 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestBaseModel::test_str_representation 
tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_creation 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_creation 
tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_defaults 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_defaults 
[gw9] [ 41%] PASSED tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_success_with_gold_steps 
tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_validation 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_validation 
tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_invalid_bronze 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_invalid_bronze 
tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_invalid_silver 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_invalid_silver 
tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_invalid_gold 
[gw4] [ 41%] PASSED tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_invalid_gold 
tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_hierarchy 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_hierarchy 
tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_creation 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_creation 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_logger_creation_with_custom_level 
[gw2] [ 42%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_logger_creation_with_custom_level 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_logger_creation_with_file 
tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_defaults 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_defaults 
tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_validation 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_validation 
tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_invalid_max_workers 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_invalid_max_workers 
tests/unit/test_models_new.py::TestPipelineConfig::test_pipeline_config_creation 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestPipelineConfig::test_pipeline_config_creation 
tests/unit/test_models_new.py::TestPipelineConfig::test_pipeline_config_validation 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestPipelineConfig::test_pipeline_config_validation 
tests/unit/test_models_new.py::TestPipelineConfig::test_pipeline_config_invalid_schema 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestPipelineConfig::test_pipeline_config_invalid_schema 
tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_creation 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_creation 
tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_with_failed_silver_step 
tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_validation 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_validation 
tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_invalid_name 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_invalid_name 
tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_invalid_rules 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_invalid_rules 
tests/unit/test_models_new.py::TestSilverStep::test_silver_step_creation 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestSilverStep::test_silver_step_creation 
tests/unit/test_models_new.py::TestSilverStep::test_silver_step_validation 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestSilverStep::test_silver_step_validation 
tests/unit/test_models_new.py::TestSilverStep::test_silver_step_invalid_source_bronze 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestSilverStep::test_silver_step_invalid_source_bronze 
tests/unit/test_models_new.py::TestSilverStep::test_silver_step_invalid_transform 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestSilverStep::test_silver_step_invalid_transform 
tests/unit/test_models_new.py::TestSilverStep::test_silver_step_invalid_table_name 
[gw4] [ 42%] PASSED tests/unit/test_models_new.py::TestSilverStep::test_silver_step_invalid_table_name 
tests/unit/test_models_new.py::TestGoldStep::test_gold_step_creation 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestGoldStep::test_gold_step_creation 
tests/unit/test_models_new.py::TestGoldStep::test_gold_step_validation 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestGoldStep::test_gold_step_validation 
tests/unit/test_models_new.py::TestGoldStep::test_gold_step_invalid_transform 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestGoldStep::test_gold_step_invalid_transform 
[gw9] [ 43%] PASSED tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_with_failed_silver_step 
tests/unit/test_models_new.py::TestGoldStep::test_gold_step_invalid_table_name 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestGoldStep::test_gold_step_invalid_table_name 
tests/unit/test_models_new.py::TestGoldStep::test_gold_step_invalid_source_silvers 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestGoldStep::test_gold_step_invalid_source_silvers 
tests/unit/test_models_new.py::TestStageStats::test_stage_stats_creation 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestStageStats::test_stage_stats_creation 
tests/unit/test_models_new.py::TestStageStats::test_stage_stats_validation 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestStageStats::test_stage_stats_validation 
tests/unit/test_models_new.py::TestStageStats::test_stage_stats_invalid_validation_rate 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestStageStats::test_stage_stats_invalid_validation_rate 
tests/unit/test_models_new.py::TestStageStats::test_stage_stats_negative_values 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestStageStats::test_stage_stats_negative_values 
tests/unit/test_models_new.py::TestExecutionContext::test_execution_context_creation 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestExecutionContext::test_execution_context_creation 
tests/unit/test_models_new.py::TestExecutionContext::test_execution_context_validation 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestExecutionContext::test_execution_context_validation 
tests/unit/test_models_new.py::TestExecutionContext::test_execution_context_invalid_pipeline_id 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestExecutionContext::test_execution_context_invalid_pipeline_id 
tests/unit/test_models_new.py::TestPipelineMetrics::test_pipeline_metrics_creation 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestPipelineMetrics::test_pipeline_metrics_creation 
tests/unit/test_models_new.py::TestPipelineMetrics::test_pipeline_metrics_validation 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestPipelineMetrics::test_pipeline_metrics_validation 
tests/unit/test_models_new.py::TestPipelineMetrics::test_pipeline_metrics_invalid_values 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestPipelineMetrics::test_pipeline_metrics_invalid_values 
tests/unit/test_models_new.py::TestPipelineReport::test_pipeline_report_creation 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestPipelineReport::test_pipeline_report_creation 
tests/unit/test_models_new.py::TestPipelineReport::test_pipeline_report_validation 
[gw4] [ 43%] PASSED tests/unit/test_models_new.py::TestPipelineReport::test_pipeline_report_validation 
tests/unit/test_models_new.py::TestPipelineReport::test_pipeline_report_invalid_pipeline_id 
[gw4] [ 44%] PASSED tests/unit/test_models_new.py::TestPipelineReport::test_pipeline_report_invalid_pipeline_id 
tests/unit/test_models_new.py::TestEnums::test_pipeline_status_enum 
[gw4] [ 44%] PASSED tests/unit/test_models_new.py::TestEnums::test_pipeline_status_enum 
tests/unit/test_models_new.py::TestEnums::test_pipeline_mode_enum 
[gw4] [ 44%] PASSED tests/unit/test_models_new.py::TestEnums::test_pipeline_mode_enum 
tests/unit/test_models_new.py::TestEnums::test_step_status_enum 
[gw4] [ 44%] PASSED tests/unit/test_models_new.py::TestEnums::test_step_status_enum 
tests/unit/test_models_new.py::TestEnums::test_step_type_enum 
[gw4] [ 44%] PASSED tests/unit/test_models_new.py::TestEnums::test_step_type_enum 
tests/unit/test_models_new.py::TestStepResult::test_step_result_creation 
[gw4] [ 44%] PASSED tests/unit/test_models_new.py::TestStepResult::test_step_result_creation 
tests/unit/test_models_new.py::TestStepResult::test_step_result_validation 
[gw4] [ 44%] PASSED tests/unit/test_models_new.py::TestStepResult::test_step_result_validation 
tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_with_failed_gold_step 
tests/unit/test_models_new.py::TestStepResult::test_step_result_invalid_step_name 
[gw4] [ 44%] PASSED tests/unit/test_models_new.py::TestStepResult::test_step_result_invalid_step_name 
tests/unit/test_models_simple.py::TestBaseModel::test_validate_default 
[gw4] [ 44%] PASSED tests/unit/test_models_simple.py::TestBaseModel::test_validate_default 
tests/unit/test_models_simple.py::TestBaseModel::test_to_dict_simple 
[gw4] [ 44%] PASSED tests/unit/test_models_simple.py::TestBaseModel::test_to_dict_simple 
[gw9] [ 44%] PASSED tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_with_failed_gold_step 
tests/unit/test_models_simple.py::TestBaseModel::test_to_dict_nested_objects 
[gw4] [ 44%] PASSED tests/unit/test_models_simple.py::TestBaseModel::test_to_dict_nested_objects 
tests/unit/test_models_simple.py::TestBaseModel::test_to_json 
[gw4] [ 44%] PASSED tests/unit/test_models_simple.py::TestBaseModel::test_to_json 
tests/unit/test_models_simple.py::TestBaseModel::test_str_representation 
[gw4] [ 44%] PASSED tests/unit/test_models_simple.py::TestBaseModel::test_str_representation 
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_creation 
[gw4] [ 44%] PASSED tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_creation 
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_validation 
[gw4] [ 44%] PASSED tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_validation 
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_invalid_bronze 
[gw4] [ 44%] PASSED tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_invalid_bronze 
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_invalid_silver 
[gw4] [ 44%] PASSED tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_invalid_silver 
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_invalid_gold 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_invalid_gold 
tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_silver_step_without_schema 
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_hierarchy 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_hierarchy 
tests/unit/test_models_simple.py::TestParallelConfig::test_parallel_config_creation 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestParallelConfig::test_parallel_config_creation 
tests/unit/test_models_simple.py::TestParallelConfig::test_parallel_config_validation 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestParallelConfig::test_parallel_config_validation 
tests/unit/test_models_simple.py::TestParallelConfig::test_parallel_config_invalid_max_workers 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestParallelConfig::test_parallel_config_invalid_max_workers 
tests/unit/test_models_simple.py::TestPipelineConfig::test_pipeline_config_creation 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestPipelineConfig::test_pipeline_config_creation 
tests/unit/test_models_simple.py::TestPipelineConfig::test_pipeline_config_validation 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestPipelineConfig::test_pipeline_config_validation 
tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_creation 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_creation 
tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_validation 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_validation 
tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_invalid_name 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_invalid_name 
tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_invalid_rules 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_invalid_rules 
[gw9] [ 45%] PASSED tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_silver_step_without_schema 
[gw8] [ 45%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestEdgeCases::test_pipeline_all_invalid_data 
tests/system/test_full_pipeline_with_logging_variations.py::TestExecutionModes::test_pipeline_sequential_execution_with_logging 
tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_creation 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_creation 
tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_validation 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_validation 
tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_invalid_source_bronze 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_invalid_source_bronze 
tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_invalid_transform 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_invalid_transform 
tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_invalid_table_name 
[gw4] [ 45%] PASSED tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_invalid_table_name 
tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_creation 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_creation 
tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_validation 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_validation 
tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_gold_step_without_schema 
tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_invalid_transform 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_invalid_transform 
tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_invalid_table_name 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_invalid_table_name 
tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_invalid_source_silvers 
[gw8] [ 46%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestExecutionModes::test_pipeline_sequential_execution_with_logging 
tests/system/test_full_pipeline_with_logging_variations.py::TestIncrementalScenarios::test_pipeline_multiple_incremental_runs 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_invalid_source_silvers 
tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_creation 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_creation 
tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_validation 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_validation 
tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_invalid_validation_rate 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_invalid_validation_rate 
tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_negative_values 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_negative_values 
tests/unit/test_models_simple.py::TestExecutionContext::test_execution_context_creation 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestExecutionContext::test_execution_context_creation 
tests/unit/test_models_simple.py::TestExecutionContext::test_execution_context_validation 
[gw9] [ 46%] PASSED tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_gold_step_without_schema 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestExecutionContext::test_execution_context_validation 
tests/unit/test_models_simple.py::TestExecutionContext::test_execution_context_invalid_execution_id 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestExecutionContext::test_execution_context_invalid_execution_id 
tests/unit/test_models_simple.py::TestPipelineMetrics::test_pipeline_metrics_creation 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestPipelineMetrics::test_pipeline_metrics_creation 
tests/unit/test_models_simple.py::TestPipelineMetrics::test_pipeline_metrics_validation 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestPipelineMetrics::test_pipeline_metrics_validation 
tests/unit/test_models_simple.py::TestPipelineMetrics::test_pipeline_metrics_invalid_values 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestPipelineMetrics::test_pipeline_metrics_invalid_values 
tests/unit/test_models_simple.py::TestPipelineReport::test_pipeline_report_creation 
[gw4] [ 46%] PASSED tests/unit/test_models_simple.py::TestPipelineReport::test_pipeline_report_creation 
tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_silver_step_success 
tests/unit/test_models_simple.py::TestPipelineReport::test_pipeline_report_validation 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestPipelineReport::test_pipeline_report_validation 
tests/unit/test_models_simple.py::TestPipelineReport::test_pipeline_report_invalid_pipeline_id 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestPipelineReport::test_pipeline_report_invalid_pipeline_id 
tests/unit/test_models_simple.py::TestStepResult::test_step_result_creation 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestStepResult::test_step_result_creation 
tests/unit/test_models_simple.py::TestStepResult::test_step_result_validation 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestStepResult::test_step_result_validation 
tests/unit/test_models_simple.py::TestStepResult::test_step_result_invalid_step_name 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestStepResult::test_step_result_invalid_step_name 
tests/unit/test_models_simple.py::TestEnums::test_pipeline_phase_enum 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestEnums::test_pipeline_phase_enum 
tests/unit/test_models_simple.py::TestEnums::test_execution_mode_enum 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestEnums::test_execution_mode_enum 
tests/unit/test_models_simple.py::TestEnums::test_write_mode_enum 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestEnums::test_write_mode_enum 
tests/unit/test_models_simple.py::TestEnums::test_validation_result_enum 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestEnums::test_validation_result_enum 
tests/unit/test_models_simple.py::TestEnums::test_step_status_enum 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestEnums::test_step_status_enum 
tests/unit/test_models_simple.py::TestEnums::test_step_type_enum 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestEnums::test_step_type_enum 
[gw9] [ 47%] PASSED tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_silver_step_success 
tests/unit/test_models_simple.py::TestEnums::test_pipeline_status_enum 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestEnums::test_pipeline_status_enum 
tests/unit/test_models_simple.py::TestEnums::test_pipeline_mode_enum 
[gw4] [ 47%] PASSED tests/unit/test_models_simple.py::TestEnums::test_pipeline_mode_enum 
tests/unit/test_performance.py::TestNowDt::test_now_dt_returns_datetime 
[gw4] [ 47%] PASSED tests/unit/test_performance.py::TestNowDt::test_now_dt_returns_datetime 
tests/unit/test_performance.py::TestNowDt::test_now_dt_returns_utc 
[gw4] [ 47%] PASSED tests/unit/test_performance.py::TestNowDt::test_now_dt_returns_utc 
tests/unit/test_performance.py::TestNowDt::test_now_dt_recent_time 
[gw4] [ 47%] PASSED tests/unit/test_performance.py::TestNowDt::test_now_dt_recent_time 
tests/unit/test_performance.py::TestFormatDuration::test_format_duration_seconds 
[gw4] [ 47%] PASSED tests/unit/test_performance.py::TestFormatDuration::test_format_duration_seconds 
tests/unit/test_performance.py::TestFormatDuration::test_format_duration_minutes 
[gw4] [ 48%] PASSED tests/unit/test_performance.py::TestFormatDuration::test_format_duration_minutes 
tests/unit/test_performance.py::TestFormatDuration::test_format_duration_hours 
[gw4] [ 48%] PASSED tests/unit/test_performance.py::TestFormatDuration::test_format_duration_hours 
tests/unit/test_performance.py::TestFormatDuration::test_format_duration_zero 
[gw4] [ 48%] PASSED tests/unit/test_performance.py::TestFormatDuration::test_format_duration_zero 
tests/unit/test_performance.py::TestFormatDuration::test_format_duration_negative 
[gw4] [ 48%] PASSED tests/unit/test_performance.py::TestFormatDuration::test_format_duration_negative 
tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_silver_step_missing_source 
tests/unit/test_performance.py::TestTimeOperation::test_time_operation_success 
[gw4] [ 48%] PASSED tests/unit/test_performance.py::TestTimeOperation::test_time_operation_success 
tests/unit/test_performance.py::TestTimeOperation::test_time_operation_failure 
[gw4] [ 48%] PASSED tests/unit/test_performance.py::TestTimeOperation::test_time_operation_failure 
tests/unit/test_performance.py::TestTimeOperation::test_time_operation_preserves_function_metadata 
[gw4] [ 48%] PASSED tests/unit/test_performance.py::TestTimeOperation::test_time_operation_preserves_function_metadata 
tests/unit/test_performance.py::TestTimeOperation::test_time_operation_with_args_and_kwargs 
[gw4] [ 48%] PASSED tests/unit/test_performance.py::TestTimeOperation::test_time_operation_with_args_and_kwargs 
tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_success 
[gw9] [ 48%] PASSED tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_silver_step_missing_source 
[gw2] [ 48%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_logger_creation_with_file 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_basic_logging_methods 
[gw2] [ 48%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_basic_logging_methods 
tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_set_level 
[gw2] [ 48%] PASSED tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_set_level 
[gw4] [ 48%] PASSED tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_success 
tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_failure 
[gw4] [ 48%] PASSED tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_failure 
tests/unit/test_logging.py::TestTimerContextManager::test_timer_context_manager_success 
[gw2] [ 48%] PASSED tests/unit/test_logging.py::TestTimerContextManager::test_timer_context_manager_success 
tests/unit/test_logging.py::TestTimerContextManager::test_timer_context_manager_exception 
[gw2] [ 48%] PASSED tests/unit/test_logging.py::TestTimerContextManager::test_timer_context_manager_exception 
tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_schema_and_table_name 
[gw2] [ 48%] PASSED tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_schema_and_table_name 
tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_config_shows_deprecation_warning 
[gw2] [ 48%] PASSED tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_config_shows_deprecation_warning 
[gw5] [ 49%] PASSED tests/integration/test_validation_integration.py::TestAssessDataQuality::test_dataframe_with_rules 
tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_with_max_duration_warning 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_with_max_duration_warning 
tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_with_max_duration_no_warning 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_with_max_duration_no_warning 
tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_invalid_mode 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_invalid_mode 
tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_imports_table_operations 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_imports_table_operations 
tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_append_mode 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_append_mode 
tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_with_options 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_with_options 
tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_failure 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_failure 
tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_success 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_success 
tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_failure 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_failure 
tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_with_max_duration 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_with_max_duration 
tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_preserves_function_metadata 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_preserves_function_metadata 
tests/unit/test_performance.py::TestPerformanceIntegration::test_all_functions_work_together 
[gw4] [ 49%] PASSED tests/unit/test_performance.py::TestPerformanceIntegration::test_all_functions_work_together 
tests/unit/test_performance.py::TestPerformanceIntegration::test_duration_formatting_integration 
tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_without_required_params_raises_error 
[gw2] [ 49%] PASSED tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_without_required_params_raises_error 
tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_only_schema_raises_error 
[gw2] [ 49%] PASSED tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_only_schema_raises_error 
tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_only_table_name_raises_error 
[gw2] [ 49%] PASSED tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_only_table_name_raises_error 
tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_creates_log_row 
[gw7] [ 49%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_security_thresholds_integration 
tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_gold_step_success 
[gw9] [ 50%] PASSED tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_gold_step_success 
tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_gold_step_missing_source 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_creates_log_row 
tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_populates_table_total_rows 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_populates_table_total_rows 
tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_with_errors 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_with_errors 
tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_generates_run_id_if_not_provided 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_generates_run_id_if_not_provided 
tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_includes_metadata 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_includes_metadata 
tests/unit/test_logwriter_new_api.py::TestCreateTableMethod::test_create_table_calls_storage_with_overwrite 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestCreateTableMethod::test_create_table_calls_storage_with_overwrite 
tests/unit/test_logwriter_new_api.py::TestCreateTableMethod::test_create_table_returns_success_result 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestCreateTableMethod::test_create_table_returns_success_result 
tests/unit/test_logwriter_new_api.py::TestCreateTableMethod::test_create_table_generates_run_id_if_not_provided 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestCreateTableMethod::test_create_table_generates_run_id_if_not_provided 
tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_calls_storage_with_append_mode 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_calls_storage_with_append_mode 
tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_returns_success_result 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_returns_success_result 
tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_multiple_times 
[gw9] [ 50%] PASSED tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_gold_step_missing_source 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_multiple_times 
tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_refreshes_table_totals_between_runs 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_refreshes_table_totals_between_runs 
tests/unit/test_logwriter_new_api.py::TestLogWriterNewAPIIntegration::test_complete_workflow_create_and_append 
[gw2] [ 50%] PASSED tests/unit/test_logwriter_new_api.py::TestLogWriterNewAPIIntegration::test_complete_workflow_create_and_append 
tests/unit/test_models.py::TestExceptions::test_pipeline_configuration_error 
[gw2] [ 50%] PASSED tests/unit/test_models.py::TestExceptions::test_pipeline_configuration_error 
tests/unit/test_models.py::TestExceptions::test_pipeline_execution_error 
[gw2] [ 50%] PASSED tests/unit/test_models.py::TestExceptions::test_pipeline_execution_error 
tests/unit/test_models.py::TestEnums::test_pipeline_phase_enum 
[gw2] [ 50%] PASSED tests/unit/test_models.py::TestEnums::test_pipeline_phase_enum 
tests/unit/test_models.py::TestEnums::test_execution_mode_enum 
[gw2] [ 51%] PASSED tests/unit/test_models.py::TestEnums::test_execution_mode_enum 
tests/unit/test_models.py::TestEnums::test_write_mode_enum 
[gw2] [ 51%] PASSED tests/unit/test_models.py::TestEnums::test_write_mode_enum 
tests/unit/test_models.py::TestEnums::test_validation_result_enum 
[gw2] [ 51%] PASSED tests/unit/test_models.py::TestEnums::test_validation_result_enum 
tests/unit/test_models.py::TestTypeDefinitions::test_model_value_types 
tests/security/test_security_integration.py::TestSecurityIntegration::test_security_configuration_integration 
[gw2] [ 51%] PASSED tests/unit/test_models.py::TestTypeDefinitions::test_model_value_types 
tests/unit/test_models.py::TestTypeDefinitions::test_column_rule_types 
[gw2] [ 51%] PASSED tests/unit/test_models.py::TestTypeDefinitions::test_column_rule_types 
tests/unit/test_models.py::TestTypeDefinitions::test_resource_value_types 
[gw2] [ 51%] PASSED tests/unit/test_models.py::TestTypeDefinitions::test_resource_value_types 
tests/unit/test_models.py::TestBaseModel::test_base_model_abstract 
[gw2] [ 51%] PASSED tests/unit/test_models.py::TestBaseModel::test_base_model_abstract 
tests/unit/test_models.py::TestBaseModel::test_base_model_validation_abstract 
[gw2] [ 51%] PASSED tests/unit/test_models.py::TestBaseModel::test_base_model_validation_abstract 
tests/unit/test_models.py::TestBronzeStep::test_bronze_step_creation 
[gw2] [ 51%] PASSED tests/unit/test_models.py::TestBronzeStep::test_bronze_step_creation 
tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_schema_property 
[gw2] [ 51%] PASSED tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_schema_property 
tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_validators_property 
[gw2] [ 51%] PASSED tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_validators_property 
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_basic 
[gw2] [ 51%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_basic 
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_with_quality_rates 
[gw2] [ 51%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_with_quality_rates 
[gw7] [ 51%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_security_configuration_integration 
tests/security/test_security_integration.py::TestSecurityIntegration::test_security_performance_integration 
tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_gold_step_with_none_source_silvers 
[gw9] [ 51%] PASSED tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_gold_step_with_none_source_silvers 
tests/unit/test_execution_comprehensive.py::TestExecutionMode::test_execution_mode_values 
[gw9] [ 51%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutionMode::test_execution_mode_values 
tests/unit/test_execution_comprehensive.py::TestExecutionMode::test_execution_mode_enumeration 
[gw9] [ 51%] PASSED tests/unit/test_execution_comprehensive.py::TestExecutionMode::test_execution_mode_enumeration 
tests/unit/test_execution_comprehensive.py::TestStepStatus::test_step_status_values 
[gw9] [ 51%] PASSED tests/unit/test_execution_comprehensive.py::TestStepStatus::test_step_status_values 
tests/unit/test_execution_comprehensive.py::TestStepStatus::test_step_status_enumeration 
[gw9] [ 52%] PASSED tests/unit/test_execution_comprehensive.py::TestStepStatus::test_step_status_enumeration 
tests/unit/test_execution_comprehensive.py::TestStepType::test_step_type_values 
[gw9] [ 52%] PASSED tests/unit/test_execution_comprehensive.py::TestStepType::test_step_type_values 
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_invalid_spark 
[gw2] [ 52%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_invalid_spark 
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_empty_schema 
[gw2] [ 52%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_empty_schema 
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_pipeline_id 
[gw2] [ 52%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_pipeline_id 
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_validators 
[gw2] [ 52%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_validators 
tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_basic 
tests/integration/test_validation_integration.py::TestAssessDataQuality::test_error_handling 
[gw4] [ 52%] PASSED tests/unit/test_performance.py::TestPerformanceIntegration::test_duration_formatting_integration 
tests/unit/test_performance.py::TestPerformanceIntegration::test_now_dt_consistency 
[gw4] [ 52%] PASSED tests/unit/test_performance.py::TestPerformanceIntegration::test_now_dt_consistency 
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_basic 
[gw4] [ 52%] PASSED tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_basic 
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_with_quality_rates 
[gw4] [ 52%] PASSED tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_with_quality_rates 
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_invalid_spark 
[gw4] [ 52%] PASSED tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_invalid_spark 
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_empty_schema 
[gw4] [ 52%] PASSED tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_empty_schema 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_filter_uses_mock_fallback_when_needed 
[gw9] [ 52%] SKIPPED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_filter_uses_mock_fallback_when_needed 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_validation_only_mode_has_no_write_mode_for_gold_step 
[gw9] [ 52%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_validation_only_mode_has_no_write_mode_for_gold_step 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_spark_write_mode_matches_result_write_mode 
[gw9] [ 52%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_spark_write_mode_matches_result_write_mode 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_all_execution_modes_covered 
[gw9] [ 52%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_all_execution_modes_covered 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_write_mode_consistency_across_step_types 
[gw2] [ 52%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_basic 
tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_with_incremental_col 
[gw2] [ 52%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_with_incremental_col 
tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_with_schema 
[gw2] [ 53%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_with_schema 
tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_duplicate_name 
[gw2] [ 53%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_duplicate_name 
tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_empty_name 
[gw2] [ 53%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_empty_name 
tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_pyspark_rules 
[gw2] [ 53%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_pyspark_rules 
tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_basic 
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_pipeline_id 
[gw4] [ 53%] PASSED tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_pipeline_id 
[gw5] [ 53%] PASSED tests/integration/test_validation_integration.py::TestAssessDataQuality::test_error_handling 
tests/integration/test_validation_integration.py::TestValidationResult::test_validation_result_creation 
[gw5] [ 53%] PASSED tests/integration/test_validation_integration.py::TestValidationResult::test_validation_result_creation 
[gw2] [ 53%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_basic 
tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_with_watermark 
[gw2] [ 53%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_with_watermark 
[gw8] [ 53%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestIncrementalScenarios::test_pipeline_multiple_incremental_runs 
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_validators 
[gw9] [ 53%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_write_mode_consistency_across_step_types 
[gw4] [ 53%] PASSED tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_validators 
tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_bronze_step_has_no_write_mode 
[gw9] [ 53%] PASSED tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_bronze_step_has_no_write_mode 
tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_duplicate_name 
[gw2] [ 53%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_duplicate_name 
tests/system/test_full_pipeline_with_logging_variations.py::TestIncrementalScenarios::test_pipeline_incremental_with_gaps 
tests/unit/test_execution_write_mode.py::TestWriteModeRegression::test_incremental_mode_uses_append_for_silver_steps 
[gw9] [ 53%] PASSED tests/unit/test_execution_write_mode.py::TestWriteModeRegression::test_incremental_mode_uses_append_for_silver_steps 
tests/integration/test_validation_integration.py::TestValidationResult::test_validation_result_defaults 
[gw5] [ 53%] PASSED tests/integration/test_validation_integration.py::TestValidationResult::test_validation_result_defaults 
tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_empty_rules_validation_success 
tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_empty_name 
[gw2] [ 53%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_empty_name 
tests/unit/test_pipeline_builder_basic.py::TestValidatorManagement::test_add_validator 
[gw5] [ 53%] PASSED tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_empty_rules_validation_success 
tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_bronze_step_with_provided_data 
[gw1] [ 54%] PASSED tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_anomaly_detection_pipeline 
tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_basic 
tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_performance_monitoring 
tests/unit/test_execution_write_mode.py::TestWriteModeRegression::test_gold_incremental_mode_uses_overwrite 
[gw9] [ 54%] PASSED tests/unit/test_execution_write_mode.py::TestWriteModeRegression::test_gold_incremental_mode_uses_overwrite 
tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_write_mode_field 
[gw9] [ 54%] PASSED tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_write_mode_field 
tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_validation_rate_field 
[gw4] [ 54%] PASSED tests/unit/test_pipeline_builder_basic.py::TestValidatorManagement::test_add_validator 
tests/unit/test_pipeline_builder_basic.py::TestValidatorManagement::test_add_multiple_validators 
[gw4] [ 54%] PASSED tests/unit/test_pipeline_builder_basic.py::TestValidatorManagement::test_add_multiple_validators 
tests/unit/test_pipeline_builder_basic.py::TestPipelineValidation::test_validate_pipeline_empty 
[gw4] [ 54%] PASSED tests/unit/test_pipeline_builder_basic.py::TestPipelineValidation::test_validate_pipeline_empty 
tests/unit/test_pipeline_builder_basic.py::TestPipelineValidation::test_validate_pipeline_invalid_config 
[gw4] [ 54%] PASSED tests/unit/test_pipeline_builder_basic.py::TestPipelineValidation::test_validate_pipeline_invalid_config 
tests/unit/test_pipeline_builder_basic.py::TestToPipeline::test_to_pipeline_empty 
[gw4] [ 54%] PASSED tests/unit/test_pipeline_builder_basic.py::TestToPipeline::test_to_pipeline_empty 
tests/unit/test_pipeline_builder_basic.py::TestHelperMethods::test_get_effective_schema 
[gw2] [ 54%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_basic 
tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_auto_inference 
[gw2] [ 54%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_auto_inference 
tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_no_bronze_steps 
[gw2] [ 54%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_no_bronze_steps 
tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_invalid_source 
[gw2] [ 54%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_invalid_source 
tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_duplicate_name 
[gw2] [ 54%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_duplicate_name 
[gw5] [ 54%] PASSED tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_bronze_step_with_provided_data 
tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_pipeline_builder_with_missing_columns 
[gw5] [ 54%] PASSED tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_pipeline_builder_with_missing_columns 
[gw4] [ 54%] PASSED tests/unit/test_pipeline_builder_basic.py::TestHelperMethods::test_get_effective_schema 
tests/unit/test_pipeline_builder_basic.py::TestHelperMethods::test_create_schema_if_not_exists 
[gw4] [ 54%] PASSED tests/unit/test_pipeline_builder_basic.py::TestHelperMethods::test_create_schema_if_not_exists 
tests/unit/test_pipeline_builder_basic.py::TestHelperMethods::test_create_schema_if_not_exists_failure 
[gw4] [ 54%] PASSED tests/unit/test_pipeline_builder_basic.py::TestHelperMethods::test_create_schema_if_not_exists_failure 
[gw9] [ 55%] PASSED tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_validation_rate_field 
tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_rows_written_field 
[gw9] [ 55%] PASSED tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_rows_written_field 
tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_basic 
[gw2] [ 55%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_basic 
tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_auto_inference 
[gw2] [ 55%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_auto_inference 
tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_no_silver_steps 
tests/unit/test_pipeline_builder_basic.py::TestClassMethods::test_for_development 
[gw4] [ 55%] PASSED tests/unit/test_pipeline_builder_basic.py::TestClassMethods::test_for_development 
tests/unit/test_pipeline_builder_basic.py::TestClassMethods::test_for_production 
[gw4] [ 55%] PASSED tests/unit/test_pipeline_builder_basic.py::TestClassMethods::test_for_production 
tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_with_bronze_rules_empty_name 
[gw4] [ 55%] PASSED tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_with_bronze_rules_empty_name 
tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_with_silver_rules_empty_name 
[gw4] [ 55%] PASSED tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_with_silver_rules_empty_name 
tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_add_silver_transform_no_bronze_steps 
[gw4] [ 55%] PASSED tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_add_silver_transform_no_bronze_steps 
tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_add_gold_transform_no_silver_steps 
[gw4] [ 55%] PASSED tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_add_gold_transform_no_silver_steps 
tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_bronze_steps_storage 
[gw4] [ 55%] PASSED tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_bronze_steps_storage 
[gw2] [ 55%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_no_silver_steps 
tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_invalid_sources 
[gw2] [ 55%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_invalid_sources 
tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_duplicate_name 
[gw2] [ 55%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_duplicate_name 
tests/unit/test_pipeline_builder_comprehensive.py::TestValidatorManagement::test_add_validator 
[gw2] [ 55%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestValidatorManagement::test_add_validator 
tests/unit/test_pipeline_builder_comprehensive.py::TestValidatorManagement::test_add_multiple_validators 
[gw2] [ 55%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestValidatorManagement::test_add_multiple_validators 
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineValidation::test_validate_pipeline_empty 
[gw2] [ 55%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineValidation::test_validate_pipeline_empty 
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineValidation::test_validate_pipeline_with_steps 
tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_bronze_step_missing_data_error 
[gw2] [ 55%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineValidation::test_validate_pipeline_with_steps 
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineValidation::test_validate_pipeline_invalid_config 
[gw2] [ 56%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineValidation::test_validate_pipeline_invalid_config 
tests/unit/test_pipeline_builder_comprehensive.py::TestToPipeline::test_to_pipeline_basic 
[gw2] [ 56%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestToPipeline::test_to_pipeline_basic 
tests/unit/test_pipeline_builder_comprehensive.py::TestToPipeline::test_to_pipeline_validation_failure 
[gw2] [ 56%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestToPipeline::test_to_pipeline_validation_failure 
tests/unit/test_pipeline_builder_comprehensive.py::TestToPipeline::test_to_pipeline_empty 
[gw2] [ 56%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestToPipeline::test_to_pipeline_empty 
tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_get_effective_schema 
[gw2] [ 56%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_get_effective_schema 
tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_validate_schema_existing 
[gw2] [ 56%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_validate_schema_existing 
tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_validate_schema_nonexistent 
[gw5] [ 56%] PASSED tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_bronze_step_missing_data_error 
tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_silver_steps_storage 
[gw4] [ 56%] PASSED tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_silver_steps_storage 
tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_input_rows_field 
[gw9] [ 56%] PASSED tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_input_rows_field 
tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_gold_steps_storage 
[gw4] [ 56%] PASSED tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_gold_steps_storage 
tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_pipeline_configuration 
[gw4] [ 56%] PASSED tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_pipeline_configuration 
tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_dict_data 
[gw5] [ 56%] PASSED tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_dict_data 
tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_tuple_data 
[gw5] [ 56%] PASSED tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_tuple_data 
tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_structtype_schema 
[gw5] [ 56%] PASSED tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_structtype_schema 
tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_tuple_and_structtype 
[gw5] [ 56%] PASSED tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_tuple_and_structtype 
[gw2] [ 56%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_validate_schema_nonexistent 
tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_create_schema_if_not_exists 
[gw2] [ 56%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_create_schema_if_not_exists 
tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_create_schema_if_not_exists_failure 
[gw2] [ 56%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_create_schema_if_not_exists_failure 
tests/unit/test_pipeline_builder_comprehensive.py::TestClassMethods::test_for_development 
[gw2] [ 57%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestClassMethods::test_for_development 
tests/unit/test_pipeline_builder_comprehensive.py::TestClassMethods::test_for_production 
[gw2] [ 57%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestClassMethods::test_for_production 
tests/unit/test_pipeline_builder_comprehensive.py::TestIntegration::test_complete_pipeline_workflow 
[gw2] [ 57%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestIntegration::test_complete_pipeline_workflow 
tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_with_watermark 
[gw2] [ 57%] PASSED tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_with_watermark 
tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_duplicate_name 
[gw2] [ 57%] PASSED tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_duplicate_name 
tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_pyspark_dataframe 
[gw5] [ 57%] PASSED tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_pyspark_dataframe 
[gw1] [ 57%] PASSED tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_performance_monitoring 
tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_default_values 
[gw9] [ 57%] PASSED tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_default_values 
tests/unit/test_log_row_fields.py::TestPipelineReportFieldPropagation::test_pipeline_report_includes_write_mode 
[gw9] [ 57%] PASSED tests/unit/test_log_row_fields.py::TestPipelineReportFieldPropagation::test_pipeline_report_includes_write_mode 
tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_write_mode_populated_from_step_info 
[gw9] [ 57%] PASSED tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_write_mode_populated_from_step_info 
tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_fields_calculated_correctly 
[gw9] [ 57%] PASSED tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_fields_calculated_correctly 
tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_perfect_rate 
[gw9] [ 57%] PASSED tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_perfect_rate 
tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_low_rate 
tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_pipeline_logger 
[gw4] [ 57%] PASSED tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_pipeline_logger 
tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_pipeline_id_generation 
[gw4] [ 57%] PASSED tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_pipeline_id_generation 
tests/unit/test_pipeline_builder_comprehensive.py::TestIntegration::test_pipeline_with_custom_validator 
[gw4] [ 57%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestIntegration::test_pipeline_with_custom_validator 
tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_empty_name 
[gw2] [ 57%] PASSED tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_empty_name 
tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_basic 
[gw2] [ 57%] PASSED tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_basic 
tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_auto_inference 
[gw2] [ 57%] PASSED tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_auto_inference 
tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_no_bronze_steps 
[gw2] [ 58%] PASSED tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_no_bronze_steps 
tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_invalid_source 
[gw2] [ 58%] PASSED tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_invalid_source 
tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_basic 
[gw2] [ 58%] PASSED tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_basic 
tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_auto_inference 
[gw2] [ 58%] PASSED tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_auto_inference 
tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_no_silver_steps 
[gw2] [ 58%] PASSED tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_no_silver_steps 
tests/unit/test_pipeline_builder_comprehensive.py::TestIntegration::test_pipeline_with_multiple_schemas 
[gw4] [ 58%] PASSED tests/unit/test_pipeline_builder_comprehensive.py::TestIntegration::test_pipeline_with_multiple_schemas 
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_basic 
[gw4] [ 58%] PASSED tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_basic 
tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_invalid_sources 
[gw2] [ 58%] PASSED tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_invalid_sources 
tests/unit/test_pipeline_builder_simple.py::TestValidatorManagement::test_add_validator 
[gw2] [ 58%] PASSED tests/unit/test_pipeline_builder_simple.py::TestValidatorManagement::test_add_validator 
tests/unit/test_pipeline_builder_simple.py::TestValidatorManagement::test_add_multiple_validators 
[gw2] [ 58%] PASSED tests/unit/test_pipeline_builder_simple.py::TestValidatorManagement::test_add_multiple_validators 
tests/builder_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_complete_marketing_pipeline_execution 
tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_mock_spark_dataframe 
[gw5] [ 58%] PASSED tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_mock_spark_dataframe 
tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_non_dataframe_object 
[gw5] [ 58%] PASSED tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_non_dataframe_object 
tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_object_with_some_methods 
[gw5] [ 58%] PASSED tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_object_with_some_methods 
tests/unit/test_compat_helpers.py::TestDetectSparkType::test_detect_mock_spark 
[gw5] [ 58%] PASSED tests/unit/test_compat_helpers.py::TestDetectSparkType::test_detect_mock_spark 
tests/unit/test_compat_helpers.py::TestDetectSparkType::test_detect_pyspark 
[gw5] [ 58%] SKIPPED tests/unit/test_compat_helpers.py::TestDetectSparkType::test_detect_pyspark 
tests/unit/test_compat_helpers.py::TestCreateTestDataframe::test_create_test_dataframe_with_dict 
[gw5] [ 58%] PASSED tests/unit/test_compat_helpers.py::TestCreateTestDataframe::test_create_test_dataframe_with_dict 
tests/unit/test_compat_helpers.py::TestCreateTestDataframe::test_create_test_dataframe_with_schema 
[gw5] [ 58%] PASSED tests/unit/test_compat_helpers.py::TestCreateTestDataframe::test_create_test_dataframe_with_schema 
tests/unit/test_compat_helpers.py::TestCreateTestDataframe::test_create_test_dataframe_with_tuples 
[gw5] [ 58%] PASSED tests/unit/test_compat_helpers.py::TestCreateTestDataframe::test_create_test_dataframe_with_tuples 
tests/unit/test_constants.py::TestMemoryConstants::test_bytes_per_kb 
[gw5] [ 59%] PASSED tests/unit/test_constants.py::TestMemoryConstants::test_bytes_per_kb 
tests/unit/test_constants.py::TestMemoryConstants::test_bytes_per_mb 
[gw5] [ 59%] PASSED tests/unit/test_constants.py::TestMemoryConstants::test_bytes_per_mb 
tests/unit/test_constants.py::TestMemoryConstants::test_bytes_per_gb 
[gw5] [ 59%] PASSED tests/unit/test_constants.py::TestMemoryConstants::test_bytes_per_gb 
[gw9] [ 59%] PASSED tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_low_rate 
tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_rows_written_vs_rows_processed 
[gw9] [ 59%] PASSED tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_rows_written_vs_rows_processed 
tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_all_phases_have_correct_fields 
[gw9] [ 59%] PASSED tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_all_phases_have_correct_fields 
tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_failed_step_has_zero_validation 
[gw9] [ 59%] PASSED tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_failed_step_has_zero_validation 
tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_calculation_edge_cases 
[gw9] [ 59%] PASSED tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_calculation_edge_cases 
tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_different_write_modes 
[gw9] [ 59%] PASSED tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_different_write_modes 
tests/unit/test_pipeline_builder_simple.py::TestPipelineValidation::test_validate_pipeline_with_steps 
[gw9] [ 59%] PASSED tests/unit/test_pipeline_builder_simple.py::TestPipelineValidation::test_validate_pipeline_with_steps 
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_with_quality_rates 
[gw4] [ 59%] PASSED tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_with_quality_rates 
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_invalid_spark 
[gw4] [ 59%] PASSED tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_invalid_spark 
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_empty_schema 
[gw4] [ 59%] PASSED tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_empty_schema 
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_pipeline_id 
[gw4] [ 59%] PASSED tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_pipeline_id 
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_validators 
[gw4] [ 59%] PASSED tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_validators 
tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_basic 
[gw4] [ 59%] PASSED tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_basic 
tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_with_incremental_col 
[gw4] [ 59%] PASSED tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_with_incremental_col 
tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_with_schema 
[gw4] [ 60%] PASSED tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_with_schema 
tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_duplicate_name 
[gw4] [ 60%] PASSED tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_duplicate_name 
tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_empty_name 
[gw4] [ 60%] PASSED tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_empty_name 
tests/unit/test_constants.py::TestDefaultMemoryLimits::test_default_max_memory_mb 
[gw5] [ 60%] PASSED tests/unit/test_constants.py::TestDefaultMemoryLimits::test_default_max_memory_mb 
tests/unit/test_constants.py::TestDefaultMemoryLimits::test_default_cache_memory_mb 
[gw5] [ 60%] PASSED tests/unit/test_constants.py::TestDefaultMemoryLimits::test_default_cache_memory_mb 
tests/unit/test_constants.py::TestFileSizeConstants::test_default_max_file_size_mb 
[gw5] [ 60%] PASSED tests/unit/test_constants.py::TestFileSizeConstants::test_default_max_file_size_mb 
tests/unit/test_constants.py::TestFileSizeConstants::test_default_backup_count 
[gw5] [ 60%] PASSED tests/unit/test_constants.py::TestFileSizeConstants::test_default_backup_count 
tests/unit/test_constants.py::TestPerformanceConstants::test_default_cache_partitions 
[gw5] [ 60%] PASSED tests/unit/test_constants.py::TestPerformanceConstants::test_default_cache_partitions 
tests/unit/test_pipeline_builder_simple.py::TestPipelineValidation::test_validate_pipeline_empty 
[gw2] [ 60%] PASSED tests/unit/test_pipeline_builder_simple.py::TestPipelineValidation::test_validate_pipeline_empty 
tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_basic 
[gw4] [ 60%] PASSED tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_basic 
tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_skipped 
[gw4] [ 60%] PASSED tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_skipped 
tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_rounding 
[gw4] [ 60%] PASSED tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_rounding 
tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_type_conversion 
[gw4] [ 60%] PASSED tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_type_conversion 
tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_basic 
[gw4] [ 60%] PASSED tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_basic 
tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_skipped 
[gw4] [ 60%] PASSED tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_skipped 
tests/unit/test_constants.py::TestPerformanceConstants::test_default_shuffle_partitions 
[gw5] [ 60%] PASSED tests/unit/test_constants.py::TestPerformanceConstants::test_default_shuffle_partitions 
tests/unit/test_constants.py::TestValidationConstants::test_default_bronze_threshold 
[gw5] [ 60%] PASSED tests/unit/test_constants.py::TestValidationConstants::test_default_bronze_threshold 
tests/unit/test_constants.py::TestValidationConstants::test_default_silver_threshold 
[gw5] [ 60%] PASSED tests/unit/test_constants.py::TestValidationConstants::test_default_silver_threshold 
tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_no_dict_type_annotations 
[gw8] [ 61%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestIncrementalScenarios::test_pipeline_incremental_with_gaps 
tests/system/test_full_pipeline_with_logging_variations.py::TestDataQuality::test_pipeline_null_handling_with_logging 
tests/unit/test_pipeline_builder_simple.py::TestPipelineValidation::test_validate_pipeline_invalid_config 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestPipelineValidation::test_validate_pipeline_invalid_config 
tests/unit/test_pipeline_builder_simple.py::TestToPipeline::test_to_pipeline_basic 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestToPipeline::test_to_pipeline_basic 
tests/unit/test_pipeline_builder_simple.py::TestToPipeline::test_to_pipeline_validation_failure 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestToPipeline::test_to_pipeline_validation_failure 
tests/unit/test_pipeline_builder_simple.py::TestToPipeline::test_to_pipeline_empty 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestToPipeline::test_to_pipeline_empty 
tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_get_effective_schema 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_get_effective_schema 
tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_validate_schema_existing 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_validate_schema_existing 
tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_validate_schema_nonexistent 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_validate_schema_nonexistent 
tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_create_schema_if_not_exists 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_create_schema_if_not_exists 
tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_create_schema_if_not_exists_failure 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_create_schema_if_not_exists_failure 
tests/unit/test_pipeline_builder_simple.py::TestClassMethods::test_for_development 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestClassMethods::test_for_development 
tests/unit/test_pipeline_builder_simple.py::TestClassMethods::test_for_production 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestClassMethods::test_for_production 
tests/unit/test_pipeline_builder_simple.py::TestIntegration::test_pipeline_with_custom_validator 
[gw2] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestIntegration::test_pipeline_with_custom_validator 
tests/unit/test_pipeline_builder_simple.py::TestIntegration::test_pipeline_with_multiple_schemas 
[gw2] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestIntegration::test_pipeline_with_multiple_schemas 
tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_incremental_sets_expected_write_modes 
[gw2] [ 61%] PASSED tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_incremental_sets_expected_write_modes 
tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_initial_load_uses_overwrite_mode 
tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_rounding 
[gw4] [ 61%] PASSED tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_rounding 
tests/unit/test_pipeline_builder_simple.py::TestIntegration::test_complete_pipeline_workflow 
[gw9] [ 61%] PASSED tests/unit/test_pipeline_builder_simple.py::TestIntegration::test_complete_pipeline_workflow 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_error_handling 
[gw9] [ 61%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_error_handling 
tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_type_conversion 
[gw4] [ 62%] PASSED tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_type_conversion 
tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_basic 
[gw4] [ 62%] PASSED tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_basic 
tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_zero_steps 
[gw4] [ 62%] PASSED tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_zero_steps 
tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_perfect_success 
[gw4] [ 62%] PASSED tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_perfect_success 
tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_rounding 
[gw4] [ 62%] PASSED tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_rounding 
tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_zero_division_handling 
[gw4] [ 62%] PASSED tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_zero_division_handling 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_module_reload 
tests/unit/test_reporting.py::TestReportingIntegration::test_all_functions_return_dicts 
[gw4] [ 62%] PASSED tests/unit/test_reporting.py::TestReportingIntegration::test_all_functions_return_dicts 
[gw2] [ 62%] PASSED tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_initial_load_uses_overwrite_mode 
tests/unit/test_reporting.py::TestReportingIntegration::test_consistent_datetime_handling 
tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_full_refresh_uses_overwrite_mode 
[gw4] [ 62%] PASSED tests/unit/test_reporting.py::TestReportingIntegration::test_consistent_datetime_handling 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_import 
[gw4] [ 62%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_import 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_functions 
[gw4] [ 62%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_functions 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_execution_report 
[gw4] [ 62%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_execution_report 
[gw2] [ 62%] PASSED tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_full_refresh_uses_overwrite_mode 
tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_pipeline_with_incremental_mode_sets_expected_write_modes 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_quality_report 
[gw4] [ 62%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_quality_report 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_performance_report 
[gw4] [ 62%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_performance_report 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_error_report 
[gw4] [ 62%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_error_report 
[gw2] [ 62%] PASSED tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_pipeline_with_incremental_mode_sets_expected_write_modes 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_format_report 
[gw8] [ 62%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestDataQuality::test_pipeline_null_handling_with_logging 
[gw4] [ 63%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_format_report 
tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_pipeline_with_initial_mode_uses_overwrite 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_save_report 
[gw4] [ 63%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_save_report 
tests/system/test_full_pipeline_with_logging_variations.py::TestDataQuality::test_pipeline_duplicate_data_with_logging 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_print_report 
[gw4] [ 63%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_print_report 
[gw2] [ 63%] PASSED tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_pipeline_with_initial_mode_uses_overwrite 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_module_attributes 
[gw4] [ 63%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_module_attributes 
tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_pipeline_mode_mapping_to_execution_mode 
[gw2] [ 63%] PASSED tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_pipeline_mode_mapping_to_execution_mode 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_step_result_validation_working 
[gw4] [ 63%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_step_result_validation_working 
tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_incremental_vs_initial_write_mode_difference 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_stage_stats_validation_working 
[gw4] [ 63%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_stage_stats_validation_working 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_comprehensive_coverage_working 
[gw8] [ 63%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestDataQuality::test_pipeline_duplicate_data_with_logging 
[gw4] [ 63%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_comprehensive_coverage_working 
[gw2] [ 63%] PASSED tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_incremental_vs_initial_write_mode_difference 
tests/system/test_full_pipeline_with_logging_variations.py::TestHighVolume::test_pipeline_high_volume_with_logging 
tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_no_data_loss_in_incremental_mode_for_silver_steps 
[gw2] [ 63%] PASSED tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_no_data_loss_in_incremental_mode_for_silver_steps 
tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_execution_engine_receives_correct_mode 
[gw2] [ 63%] PASSED tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_execution_engine_receives_correct_mode 
tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_all_files_parseable 
[gw5] [ 63%] PASSED tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_no_dict_type_annotations 
tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_no_legacy_typing_imports 
[gw2] [ 63%] PASSED tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_all_files_parseable 
[gw9] [ 63%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_module_reload 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_imports 
[gw9] [ 63%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_imports 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_function_signatures 
[gw9] [ 63%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_function_signatures 
tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_module_documentation 
[gw9] [ 64%] PASSED tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_module_documentation 
tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_dict_instantiation 
[gw9] [ 64%] PASSED tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_dict_instantiation 
tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_dict_type_annotation_works 
[gw9] [ 64%] PASSED tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_dict_type_annotation_works 
tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_dict_vs_Dict_equivalence 
[gw9] [ 64%] PASSED tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_dict_vs_Dict_equivalence 
tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_python_version 
[gw9] [ 64%] PASSED tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_python_version 
tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_typeddict_compatibility 
[gw9] [ 64%] PASSED tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_typeddict_compatibility 
tests/unit/test_table_operations.py::TestFqn::test_fqn_basic 
[gw4] [ 64%] PASSED tests/unit/test_table_operations.py::TestFqn::test_fqn_basic 
tests/unit/test_table_operations.py::TestFqn::test_fqn_different_names 
[gw4] [ 64%] PASSED tests/unit/test_table_operations.py::TestFqn::test_fqn_different_names 
tests/unit/test_table_operations.py::TestFqn::test_fqn_empty_schema 
[gw4] [ 64%] PASSED tests/unit/test_table_operations.py::TestFqn::test_fqn_empty_schema 
tests/unit/test_table_operations.py::TestFqn::test_fqn_empty_table 
[gw4] [ 64%] PASSED tests/unit/test_table_operations.py::TestFqn::test_fqn_empty_table 
tests/unit/test_table_operations.py::TestFqn::test_fqn_both_empty 
[gw4] [ 64%] PASSED tests/unit/test_table_operations.py::TestFqn::test_fqn_both_empty 
tests/unit/test_table_operations.py::TestFqn::test_fqn_none_schema 
[gw4] [ 64%] PASSED tests/unit/test_table_operations.py::TestFqn::test_fqn_none_schema 
tests/unit/test_table_operations.py::TestFqn::test_fqn_none_table 
[gw4] [ 64%] PASSED tests/unit/test_table_operations.py::TestFqn::test_fqn_none_table 
tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_union_with_dict_works 
[gw9] [ 64%] PASSED tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_union_with_dict_works 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_pipeline_builder_working 
[gw9] [ 64%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_pipeline_builder_working 
tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_with_options 
[gw9] [ 64%] PASSED tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_with_options 
tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_failure 
[gw9] [ 64%] PASSED tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_failure 
tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_zero_rows 
[gw9] [ 64%] PASSED tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_zero_rows 
tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_import_compatibility 
[gw2] [ 65%] PASSED tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_import_compatibility 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_execution_engine_working 
[gw2] [ 65%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_execution_engine_working 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_validation_system_working 
[gw2] [ 65%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_validation_system_working 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_writer_system_working 
[gw2] [ 65%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_writer_system_working 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_models_working 
[gw2] [ 65%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_models_working 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_logging_system_working 
[gw2] [ 65%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_logging_system_working 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_performance_system_working 
[gw2] [ 65%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_performance_system_working 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_table_operations_working 
[gw2] [ 65%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_table_operations_working 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_error_handling_working 
[gw2] [ 65%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_error_handling_working 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_validation_utils_working 
[gw2] [ 65%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_validation_utils_working 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_pipeline_validation_working 
[gw2] [ 65%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_pipeline_validation_working 
tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_success 
[gw9] [ 65%] PASSED tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_success 
tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_with_options 
[gw9] [ 65%] PASSED tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_with_options 
tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_failure 
[gw9] [ 65%] PASSED tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_failure 
tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_zero_rows 
[gw9] [ 65%] PASSED tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_zero_rows 
tests/unit/test_table_operations.py::TestReadTable::test_read_table_success 
[gw9] [ 65%] PASSED tests/unit/test_table_operations.py::TestReadTable::test_read_table_success 
tests/unit/test_table_operations.py::TestReadTable::test_read_table_analysis_exception 
[gw9] [ 65%] PASSED tests/unit/test_table_operations.py::TestReadTable::test_read_table_analysis_exception 
tests/unit/test_table_operations.py::TestReadTable::test_read_table_other_exception 
[gw9] [ 65%] PASSED tests/unit/test_table_operations.py::TestReadTable::test_read_table_other_exception 
tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_success 
[gw4] [ 66%] PASSED tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_success 
tests/unit/test_table_operations.py::TestTableExists::test_table_exists_false_analysis_exception 
[gw4] [ 66%] PASSED tests/unit/test_table_operations.py::TestTableExists::test_table_exists_false_analysis_exception 
tests/unit/test_table_operations.py::TestTableExists::test_table_exists_true 
[gw9] [ 66%] PASSED tests/unit/test_table_operations.py::TestTableExists::test_table_exists_true 
tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_import_compatibility 
[gw9] [ 66%] PASSED tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_import_compatibility 
tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_no_dict_type_annotations 
tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_edge_cases_working 
[gw2] [ 66%] PASSED tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_edge_cases_working 
tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_unexpected_error_is_logged_and_re_raised 
[gw2] [ 66%] PASSED tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_unexpected_error_is_logged_and_re_raised 
tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_successful_assessment_returns_correct_metrics 
[gw2] [ 66%] PASSED tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_successful_assessment_returns_correct_metrics 
tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_successful_assessment_with_rules_returns_correct_metrics 
tests/unit/test_table_operations.py::TestTableExists::test_table_exists_false_other_exception 
[gw4] [ 66%] PASSED tests/unit/test_table_operations.py::TestTableExists::test_table_exists_false_other_exception 
tests/unit/test_table_operations.py::TestDropTable::test_drop_table_success 
[gw4] [ 66%] PASSED tests/unit/test_table_operations.py::TestDropTable::test_drop_table_success 
tests/unit/test_table_operations.py::TestDropTable::test_drop_table_with_default_schema 
[gw4] [ 66%] PASSED tests/unit/test_table_operations.py::TestDropTable::test_drop_table_with_default_schema 
[gw2] [ 66%] PASSED tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_successful_assessment_with_rules_returns_correct_metrics 
tests/unit/test_table_operations.py::TestDropTable::test_drop_table_not_exists 
[gw4] [ 66%] PASSED tests/unit/test_table_operations.py::TestDropTable::test_drop_table_not_exists 
tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_empty_dataframe_returns_correct_metrics 
[gw2] [ 66%] PASSED tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_empty_dataframe_returns_correct_metrics 
tests/unit/test_table_operations.py::TestDropTable::test_drop_table_failure 
[gw4] [ 66%] PASSED tests/unit/test_table_operations.py::TestDropTable::test_drop_table_failure 
tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_no_fallback_response_for_errors 
[gw2] [ 66%] PASSED tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_no_fallback_response_for_errors 
tests/unit/test_table_operations.py::TestDropTable::test_drop_table_exception_during_check 
[gw4] [ 66%] PASSED tests/unit/test_table_operations.py::TestDropTable::test_drop_table_exception_during_check 
tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_execution_engine_creation_in_to_pipeline 
[gw2] [ 66%] PASSED tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_execution_engine_creation_in_to_pipeline 
tests/unit/test_table_operations.py::TestTableOperationsIntegration::test_fqn_with_table_operations 
tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_objects_are_not_garbage_collected 
[gw4] [ 66%] PASSED tests/unit/test_table_operations.py::TestTableOperationsIntegration::test_fqn_with_table_operations 
[gw2] [ 67%] PASSED tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_objects_are_not_garbage_collected 
tests/unit/test_table_operations.py::TestTableOperationsIntegration::test_write_and_read_workflow 
tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_pipeline_validation_before_object_creation 
[gw2] [ 67%] PASSED tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_pipeline_validation_before_object_creation 
[gw4] [ 67%] PASSED tests/unit/test_table_operations.py::TestTableOperationsIntegration::test_write_and_read_workflow 
tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_objects_are_accessible_after_creation 
tests/unit/test_table_operations.py::TestTableOperationsIntegration::test_table_lifecycle 
[gw2] [ 67%] PASSED tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_objects_are_accessible_after_creation 
tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_step_type 
[gw4] [ 67%] PASSED tests/unit/test_table_operations.py::TestTableOperationsIntegration::test_table_lifecycle 
[gw2] [ 67%] PASSED tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_step_type 
tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_table_info 
[gw2] [ 67%] PASSED tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_table_info 
tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_all_files_parseable 
tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_input_rows 
[gw2] [ 67%] PASSED tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_input_rows 
tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_fallback_for_missing_data 
[gw2] [ 67%] PASSED tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_fallback_for_missing_data 
tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_validation_metrics_are_calculated_correctly 
[gw2] [ 67%] PASSED tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_validation_metrics_are_calculated_correctly 
tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_execution_context_data 
[gw2] [ 67%] PASSED tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_execution_context_data 
tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_core_writer_raises_specific_exceptions 
[gw2] [ 67%] PASSED tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_core_writer_raises_specific_exceptions 
tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_core_writer_analytics_raises_specific_exceptions 
[gw2] [ 67%] PASSED tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_core_writer_analytics_raises_specific_exceptions 
tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_storage_manager_raises_specific_exceptions 
[gw2] [ 67%] PASSED tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_storage_manager_raises_specific_exceptions 
tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_analytics_raises_specific_exceptions 
[gw2] [ 67%] PASSED tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_analytics_raises_specific_exceptions 
tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_monitoring_raises_specific_exceptions 
[gw2] [ 67%] PASSED tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_monitoring_raises_specific_exceptions 
tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_execution_engine_rules_check_without_hasattr 
[gw2] [ 67%] PASSED tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_execution_engine_rules_check_without_hasattr 
tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_dependency_analyzer_source_bronze_without_hasattr 
[gw2] [ 67%] PASSED tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_dependency_analyzer_source_bronze_without_hasattr 
tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_dependency_analyzer_source_silvers_without_hasattr 
[gw2] [ 68%] PASSED tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_dependency_analyzer_source_silvers_without_hasattr 
tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_pipeline_validator_dependencies_hasattr_improved 
[gw2] [ 68%] PASSED tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_pipeline_validator_dependencies_hasattr_improved 
tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_logging_context_removes_redundant_hasattr 
[gw2] [ 68%] PASSED tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_logging_context_removes_redundant_hasattr 
tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_base_model_to_dict_keeps_appropriate_hasattr 
[gw2] [ 68%] PASSED tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_base_model_to_dict_keeps_appropriate_hasattr 
tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_execution_context_mode_handling_keeps_appropriate_hasattr 
[gw2] [ 68%] PASSED tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_execution_context_mode_handling_keeps_appropriate_hasattr 
tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_environment_variable_parsing 
[gw2] [ 68%] PASSED tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_environment_variable_parsing 
tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_environment_variable_parsing_basic_spark 
[gw2] [ 68%] PASSED tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_environment_variable_parsing_basic_spark 
tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_error_message_contains_helpful_guidance 
[gw2] [ 68%] PASSED tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_error_message_contains_helpful_guidance 
tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_isolated_session_error_message_contains_helpful_guidance 
[gw2] [ 68%] PASSED tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_isolated_session_error_message_contains_helpful_guidance 
tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_environment_variable_combination_logic 
[gw2] [ 68%] PASSED tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_environment_variable_combination_logic 
tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_helpful_error_message_format 
[gw2] [ 68%] PASSED tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_helpful_error_message_format 
tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_isolated_session_helpful_error_message_format 
[gw2] [ 68%] PASSED tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_isolated_session_helpful_error_message_format 
tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_start_operation_raises_specific_exception_on_failure 
[gw2] [ 68%] PASSED tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_start_operation_raises_specific_exception_on_failure 
tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_end_operation_raises_specific_exception_on_failure 
[gw2] [ 68%] PASSED tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_end_operation_raises_specific_exception_on_failure 
tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_check_performance_thresholds_raises_specific_exception_on_failure 
[gw2] [ 68%] PASSED tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_check_performance_thresholds_raises_specific_exception_on_failure 
tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_get_memory_usage_raises_specific_exception_on_failure 
[gw2] [ 68%] PASSED tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_get_memory_usage_raises_specific_exception_on_failure 
tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_analyze_execution_trends_raises_specific_exception_on_failure 
[gw2] [ 68%] PASSED tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_analyze_execution_trends_raises_specific_exception_on_failure 
tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_detect_anomalies_raises_specific_exception_on_failure 
[gw2] [ 68%] PASSED tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_detect_anomalies_raises_specific_exception_on_failure 
tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_generate_performance_report_raises_specific_exception_on_failure 
[gw2] [ 69%] PASSED tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_generate_performance_report_raises_specific_exception_on_failure 
tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_error_chaining_preserves_original_exception 
[gw2] [ 69%] PASSED tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_error_chaining_preserves_original_exception 
tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_logging_still_occurs_before_exception_raising 
[gw2] [ 69%] PASSED tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_logging_still_occurs_before_exception_raising 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_writer_config_generate_table_name_requires_parameters 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_writer_config_generate_table_name_requires_parameters 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_writer_config_generate_table_name_with_pattern_requires_parameters 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_writer_config_generate_table_name_with_pattern_requires_parameters 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_writer_config_generate_table_name_without_patterns_works_with_none 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_writer_config_generate_table_name_without_patterns_works_with_none 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_execution_engine_context_validation 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_execution_engine_context_validation 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_execution_engine_context_type_validation 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_execution_engine_context_type_validation 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_run_id_handling 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_run_id_handling 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_batch_run_ids_handling 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_batch_run_ids_handling 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_display_limit_handling 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_display_limit_handling 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_logger_initialization_explicit_none 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_logger_initialization_explicit_none 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_logger_initialization_with_logger 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_logger_initialization_with_logger 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_step_result_step_type_handling 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_step_result_step_type_handling 
tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_step_result_step_type_with_value 
[gw2] [ 69%] PASSED tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_step_result_step_type_with_value 
tests/unit/test_types.py::TestTypeAliases::test_string_type_aliases 
[gw2] [ 69%] PASSED tests/unit/test_types.py::TestTypeAliases::test_string_type_aliases 
tests/unit/test_types.py::TestTypeAliases::test_numeric_type_aliases 
[gw2] [ 69%] PASSED tests/unit/test_types.py::TestTypeAliases::test_numeric_type_aliases 
tests/unit/test_types.py::TestTypeAliases::test_dictionary_type_aliases 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestTypeAliases::test_dictionary_type_aliases 
tests/unit/test_types.py::TestTypeAliases::test_optional_type_aliases 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestTypeAliases::test_optional_type_aliases 
tests/unit/test_types.py::TestEnums::test_step_type_enum 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestEnums::test_step_type_enum 
tests/unit/test_types.py::TestEnums::test_step_status_enum 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestEnums::test_step_status_enum 
tests/unit/test_types.py::TestEnums::test_pipeline_mode_enum 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestEnums::test_pipeline_mode_enum 
tests/unit/test_types.py::TestFunctionTypes::test_transform_function_types 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestFunctionTypes::test_transform_function_types 
tests/unit/test_types.py::TestFunctionTypes::test_filter_function_type 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestFunctionTypes::test_filter_function_type 
tests/unit/test_types.py::TestDataTypeAliases::test_column_rules_type 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestDataTypeAliases::test_column_rules_type 
tests/unit/test_types.py::TestDataTypeAliases::test_result_type_aliases 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestDataTypeAliases::test_result_type_aliases 
[gw3] [ 70%] PASSED tests/integration/test_parallel_execution.py::test_parallel_execution 
tests/unit/test_types.py::TestDataTypeAliases::test_context_type_aliases 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestDataTypeAliases::test_context_type_aliases 
tests/integration/test_pipeline_builder.py::TestPipelineMode::test_pipeline_mode_values 
[gw3] [ 70%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineMode::test_pipeline_mode_values 
tests/unit/test_types.py::TestDataTypeAliases::test_config_type_aliases 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestDataTypeAliases::test_config_type_aliases 
tests/integration/test_pipeline_builder.py::TestPipelineStatus::test_pipeline_status_values 
[gw3] [ 70%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineStatus::test_pipeline_status_values 
tests/unit/test_types.py::TestDataTypeAliases::test_quality_thresholds_type 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestDataTypeAliases::test_quality_thresholds_type 
tests/integration/test_pipeline_builder.py::TestPipelineMetrics::test_pipeline_metrics_creation 
[gw3] [ 70%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineMetrics::test_pipeline_metrics_creation 
tests/unit/test_types.py::TestDataTypeAliases::test_error_type_aliases 
[gw2] [ 70%] PASSED tests/unit/test_types.py::TestDataTypeAliases::test_error_type_aliases 
tests/integration/test_pipeline_builder.py::TestPipelineReport::test_pipeline_report_creation 
[gw3] [ 70%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineReport::test_pipeline_report_creation 
tests/unit/test_types.py::TestProtocols::test_validatable_protocol 
[gw2] [ 71%] PASSED tests/unit/test_types.py::TestProtocols::test_validatable_protocol 
tests/integration/test_pipeline_builder.py::TestPipelineReport::test_pipeline_report_to_dict 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineReport::test_pipeline_report_to_dict 
tests/unit/test_types.py::TestProtocols::test_serializable_protocol 
[gw2] [ 71%] PASSED tests/unit/test_types.py::TestProtocols::test_serializable_protocol 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_add_gold_transform 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_add_gold_transform 
tests/unit/test_types.py::TestBackwardCompatibility::test_backward_compatibility_aliases 
[gw2] [ 71%] PASSED tests/unit/test_types.py::TestBackwardCompatibility::test_backward_compatibility_aliases 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_add_silver_transform 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_add_silver_transform 
tests/unit/test_types.py::TestTypeUsage::test_pipeline_configuration_usage 
[gw2] [ 71%] PASSED tests/unit/test_types.py::TestTypeUsage::test_pipeline_configuration_usage 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_builder_creation 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_builder_creation 
tests/unit/test_types.py::TestTypeUsage::test_step_result_usage 
[gw2] [ 71%] PASSED tests/unit/test_types.py::TestTypeUsage::test_step_result_usage 
tests/unit/test_types.py::TestTypeUsage::test_validation_context_usage 
[gw2] [ 71%] PASSED tests/unit/test_types.py::TestTypeUsage::test_validation_context_usage 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_builder_creation_with_custom_params 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_builder_creation_with_custom_params 
tests/unit/test_types.py::TestTypeUsage::test_error_handling_usage 
[gw2] [ 71%] PASSED tests/unit/test_types.py::TestTypeUsage::test_error_handling_usage 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_to_pipeline_success 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_to_pipeline_success 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_to_pipeline_validation_error 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_to_pipeline_validation_error 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_error_concatenation 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_error_concatenation 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_errors 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_errors 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_return_type 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_return_type 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_success 
[gw3] [ 71%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_success 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validator_return_types 
[gw3] [ 72%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validator_return_types 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_with_bronze_rules 
[gw3] [ 72%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_with_bronze_rules 
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_with_silver_rules 
[gw3] [ 72%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_with_silver_rules 
tests/integration/test_pipeline_builder.py::TestPipelineBuilderIntegration::test_complex_pipeline_construction 
[gw3] [ 72%] PASSED tests/integration/test_pipeline_builder.py::TestPipelineBuilderIntegration::test_complex_pipeline_construction 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_creation 
tests/unit/test_validation.py::TestAndAllRules::test_empty_rules 
[gw2] [ 72%] PASSED tests/unit/test_validation.py::TestAndAllRules::test_empty_rules 
[gw3] [ 72%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_creation 
tests/unit/test_validation.py::TestAndAllRules::test_single_rule 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_bronze_step_creation 
[gw2] [ 72%] PASSED tests/unit/test_validation.py::TestAndAllRules::test_single_rule 
[gw3] [ 72%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_bronze_step_creation 
tests/unit/test_validation.py::TestAndAllRules::test_multiple_rules 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_silver_step_creation 
[gw2] [ 72%] PASSED tests/unit/test_validation.py::TestAndAllRules::test_multiple_rules 
[gw3] [ 72%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_silver_step_creation 
tests/unit/test_validation.py::TestValidateDataframeSchema::test_valid_schema 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_gold_step_creation 
[gw5] [ 72%] PASSED tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_no_legacy_typing_imports 
tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_python_version 
[gw5] [ 72%] PASSED tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_python_version 
tests/unit/test_python38_compatibility.py::DictTypeAnnotationTest::test_dict_vs_Dict_compatibility 
[gw5] [ 72%] PASSED tests/unit/test_python38_compatibility.py::DictTypeAnnotationTest::test_dict_vs_Dict_compatibility 
tests/unit/test_python38_compatibility.py::DictTypeAnnotationTest::test_typeddict_compatibility 
[gw5] [ 72%] PASSED tests/unit/test_python38_compatibility.py::DictTypeAnnotationTest::test_typeddict_compatibility 
tests/unit/test_python38_compatibility.py::DictTypeAnnotationTest::test_union_type_compatibility 
[gw5] [ 72%] PASSED tests/unit/test_python38_compatibility.py::DictTypeAnnotationTest::test_union_type_compatibility 
[gw3] [ 72%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_gold_step_creation 
[gw2] [ 72%] PASSED tests/unit/test_validation.py::TestValidateDataframeSchema::test_valid_schema 
tests/unit/test_python38_compatibility.py::ImportCompatibilityTest::test_core_imports 
[gw5] [ 72%] PASSED tests/unit/test_python38_compatibility.py::ImportCompatibilityTest::test_core_imports 
tests/unit/test_python38_compatibility.py::ImportCompatibilityTest::test_models_imports 
[gw5] [ 73%] PASSED tests/unit/test_python38_compatibility.py::ImportCompatibilityTest::test_models_imports 
tests/unit/test_python38_compatibility.py::ImportCompatibilityTest::test_writer_imports 
[gw5] [ 73%] PASSED tests/unit/test_python38_compatibility.py::ImportCompatibilityTest::test_writer_imports 
tests/unit/test_reporting.py::TestCreateValidationDict::test_create_validation_dict_with_stats 
[gw5] [ 73%] PASSED tests/unit/test_reporting.py::TestCreateValidationDict::test_create_validation_dict_with_stats 
tests/unit/test_reporting.py::TestCreateValidationDict::test_create_validation_dict_without_stats 
[gw5] [ 73%] PASSED tests/unit/test_reporting.py::TestCreateValidationDict::test_create_validation_dict_without_stats 
tests/unit/test_reporting.py::TestCreateValidationDict::test_create_validation_dict_rounding 
[gw5] [ 73%] PASSED tests/unit/test_reporting.py::TestCreateValidationDict::test_create_validation_dict_rounding 
tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_basic 
[gw5] [ 73%] PASSED tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_basic 
[gw4] [ 73%] PASSED tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_all_files_parseable 
[gw9] [ 73%] PASSED tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_no_dict_type_annotations 
tests/unit/test_validation.py::TestValidateDataframeSchema::test_missing_columns 
tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_no_legacy_typing_imports 
[gw2] [ 73%] PASSED tests/unit/test_validation.py::TestValidateDataframeSchema::test_missing_columns 
tests/unit/test_validation.py::TestApplyColumnRules::test_none_rules_raises_error 
[gw5] [ 73%] PASSED tests/unit/test_validation.py::TestApplyColumnRules::test_none_rules_raises_error 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_validation 
tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_exception_chaining_preserves_original_error 
[gw3] [ 73%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_validation 
tests/unit/test_validation.py::TestValidateDataframeSchema::test_extra_columns 
[gw4] [ 73%] PASSED tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_exception_chaining_preserves_original_error 
[gw9] [ 73%] PASSED tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_no_legacy_typing_imports 
[gw2] [ 73%] PASSED tests/unit/test_validation.py::TestValidateDataframeSchema::test_extra_columns 
tests/unit/test_validation.py::TestApplyColumnRules::test_empty_rules 
tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_python_version 
[gw9] [ 73%] PASSED tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_python_version 
[gw5] [ 73%] PASSED tests/unit/test_validation.py::TestApplyColumnRules::test_empty_rules 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_to_pipeline 
tests/unit/test_validation.py::TestValidateDataframeSchema::test_empty_expected_columns 
tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_no_generic_error_responses_returned 
[gw3] [ 73%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_to_pipeline 
[gw2] [ 73%] PASSED tests/unit/test_validation.py::TestValidateDataframeSchema::test_empty_expected_columns 
tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_parsing_errors_are_logged_and_tracked 
[gw4] [ 74%] PASSED tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_no_generic_error_responses_returned 
tests/unit/test_validation.py::TestApplyColumnRules::test_complex_rules 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_execution_with_mock_data 
[gw9] [ 74%] PASSED tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_parsing_errors_are_logged_and_tracked 
tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_error_logging_before_raising 
tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_parsing_errors_in_dict_syntax_are_logged_and_tracked 
[gw9] [ 74%] PASSED tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_parsing_errors_in_dict_syntax_are_logged_and_tracked 
tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_valid_files_are_processed_normally 
[gw9] [ 74%] PASSED tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_valid_files_are_processed_normally 
tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_multiple_parsing_errors_are_all_tracked 
[gw4] [ 74%] PASSED tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_error_logging_before_raising 
tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_silver_step_without_schema_raises_error 
[gw4] [ 74%] PASSED tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_silver_step_without_schema_raises_error 
tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_gold_step_without_schema_raises_error 
[gw4] [ 74%] PASSED tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_gold_step_without_schema_raises_error 
tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_silver_step_with_schema_works_correctly 
[gw4] [ 74%] PASSED tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_silver_step_with_schema_works_correctly 
tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_gold_step_with_schema_works_correctly 
[gw4] [ 74%] PASSED tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_gold_step_with_schema_works_correctly 
tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_pipeline_execution_logs_missing_schema_warnings 
[gw3] [ 74%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_execution_with_mock_data 
[gw4] [ 74%] PASSED tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_pipeline_execution_logs_missing_schema_warnings 
tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_no_silent_fallback_to_default_schema 
[gw4] [ 74%] PASSED tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_no_silent_fallback_to_default_schema 
tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_validation_mode_skips_schema_validation 
[gw4] [ 74%] PASSED tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_validation_mode_skips_schema_validation 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_no_column_expressions 
[gw4] [ 74%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_no_column_expressions 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_apply_column_rules_validation_predicate_true 
[gw4] [ 74%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_apply_column_rules_validation_predicate_true 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_apply_column_rules_with_rules 
[gw4] [ 74%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_apply_column_rules_with_rules 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_safe_divide_edge_cases 
[gw4] [ 74%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_safe_divide_edge_cases 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_validate_dataframe_schema_edge_cases 
[gw4] [ 74%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_validate_dataframe_schema_edge_cases 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_get_dataframe_info_edge_cases 
[gw4] [ 75%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_get_dataframe_info_edge_cases 
tests/unit/test_validation.py::TestGetDataframeInfo::test_basic_info 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_get_dataframe_info_error_handling 
[gw4] [ 75%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_get_dataframe_info_error_handling 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_assess_data_quality_edge_cases 
[gw4] [ 75%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_assess_data_quality_edge_cases 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_apply_column_rules_edge_cases 
[gw4] [ 75%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_apply_column_rules_edge_cases 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_convert_rules_to_expressions_complex_cases 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_configuration_creation 
[gw4] [ 75%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_convert_rules_to_expressions_complex_cases 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_convert_rule_to_expression_edge_cases 
[gw4] [ 75%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_convert_rule_to_expression_edge_cases 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_single_expression 
[gw4] [ 75%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_single_expression 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_multiple_expressions 
[gw4] [ 75%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_multiple_expressions 
[gw2] [ 75%] PASSED tests/unit/test_validation.py::TestGetDataframeInfo::test_basic_info 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_string_rule_conversion_edge_cases 
[gw4] [ 75%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_string_rule_conversion_edge_cases 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_validation_error_handling 
[gw4] [ 75%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_validation_error_handling 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_convert_rule_to_expression_with_mock_functions 
[gw4] [ 75%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_convert_rule_to_expression_with_mock_functions 
[gw5] [ 75%] PASSED tests/unit/test_validation.py::TestApplyColumnRules::test_complex_rules 
[gw3] [ 75%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_configuration_creation 
tests/unit/test_validation.py::TestSafeDivide::test_normal_division 
[gw5] [ 75%] PASSED tests/unit/test_validation.py::TestSafeDivide::test_normal_division 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_execution_engine_with_pipeline_config 
tests/unit/test_validation.py::TestGetDataframeInfo::test_empty_dataframe 
[gw2] [ 75%] PASSED tests/unit/test_validation.py::TestGetDataframeInfo::test_empty_dataframe 
[gw3] [ 75%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_execution_engine_with_pipeline_config 
[gw1] [ 75%] FAILED tests/builder_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_complete_marketing_pipeline_execution 
[gw9] [ 76%] PASSED tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_multiple_parsing_errors_are_all_tracked 
tests/unit/test_validation.py::TestSafeDivide::test_division_by_zero 
tests/unit/test_validation.py::TestGetDataframeInfo::test_error_handling 
tests/builder_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_incremental_marketing_processing 
tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_logging_uses_correct_module_name 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_step_execution_with_real_data 
[gw2] [ 76%] PASSED tests/unit/test_validation.py::TestGetDataframeInfo::test_error_handling 
[gw9] [ 76%] PASSED tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_logging_uses_correct_module_name 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_convert_rule_to_expression_with_default_functions 
tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_validation_error_is_re_raised 
[gw9] [ 76%] PASSED tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_validation_error_is_re_raised 
tests/unit/test_validation.py::TestConvertRulesToExpressions::test_mixed_rules_conversion 
[gw5] [ 76%] PASSED tests/unit/test_validation.py::TestSafeDivide::test_division_by_zero 
[gw3] [ 76%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_step_execution_with_real_data 
[gw9] [ 76%] PASSED tests/unit/test_validation.py::TestConvertRulesToExpressions::test_mixed_rules_conversion 
tests/unit/test_validation.py::TestApplyColumnRules::test_basic_validation 
[gw4] [ 76%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_convert_rule_to_expression_with_default_functions 
tests/unit/test_validation.py::TestSafeDivide::test_division_by_zero_custom_default 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_step_validation_with_real_data 
tests/unit/test_validation.py::TestAssessDataQuality::test_basic_data_quality_assessment 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_convert_rules_to_expressions_with_mock_functions 
[gw3] [ 76%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_step_validation_with_real_data 
[gw2] [ 76%] PASSED tests/unit/test_validation.py::TestApplyColumnRules::test_basic_validation 
[gw5] [ 76%] PASSED tests/unit/test_validation.py::TestSafeDivide::test_division_by_zero_custom_default 
[gw9] [ 76%] PASSED tests/unit/test_validation.py::TestAssessDataQuality::test_basic_data_quality_assessment 
[gw1] [ 76%] PASSED tests/builder_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_incremental_marketing_processing 
tests/unit/test_validation.py::TestAssessDataQuality::test_data_quality_with_rules 
tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_execution_flow_integration 
[gw3] [ 76%] PASSED tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_execution_flow_integration 
[gw4] [ 76%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_convert_rules_to_expressions_with_mock_functions 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_and_all_rules_with_mock_functions 
[gw9] [ 76%] PASSED tests/unit/test_validation.py::TestAssessDataQuality::test_data_quality_with_rules 
tests/unit/test_validation.py::TestSafeDivide::test_zero_numerator 
[gw2] [ 76%] PASSED tests/unit/test_validation.py::TestSafeDivide::test_zero_numerator 
tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_complete_multi_source_integration_pipeline_execution 
tests/unit/test_validation.py::TestSafeDivide::test_float_division 
[gw5] [ 76%] PASSED tests/unit/test_validation.py::TestSafeDivide::test_float_division 
[gw1] [ 77%] PASSED tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_complete_multi_source_integration_pipeline_execution 
tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_schema_evolution_handling 
tests/unit/test_validation.py::TestSafeDivide::test_negative_numbers 
[gw4] [ 77%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_and_all_rules_with_mock_functions 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_monitor_initialization_with_logger 
[gw3] [ 77%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_monitor_initialization_with_logger 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_monitor_initialization_without_logger 
[gw3] [ 77%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_monitor_initialization_without_logger 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_start_execution 
[gw3] [ 77%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_start_execution 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_start_execution_with_empty_steps 
[gw3] [ 77%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_start_execution_with_empty_steps 
tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_start_execution_with_mocked_time 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_apply_column_rules_with_mock_functions 
[gw5] [ 77%] PASSED tests/unit/test_validation.py::TestSafeDivide::test_negative_numbers 
tests/unit/test_validation.py::TestApplyValidationRules::test_apply_column_rules_basic 
tests/unit/test_validation.py::TestConvertRuleToExpression::test_not_null_rule 
[gw2] [ 77%] PASSED tests/unit/test_validation.py::TestConvertRuleToExpression::test_not_null_rule 
[gw3] [ 77%] PASSED tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_start_execution_with_mocked_time 
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_error_handling 
tests/unit/test_validation.py::TestConvertRuleToExpression::test_positive_rule 
[gw3] [ 77%] PASSED tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_error_handling 
[gw1] [ 77%] PASSED tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_schema_evolution_handling 
tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_complex_dependency_handling 
[gw4] [ 77%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_apply_column_rules_with_mock_functions 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validate_dataframe_schema_with_mock_functions 
[gw9] [ 77%] PASSED tests/unit/test_validation.py::TestApplyValidationRules::test_apply_column_rules_basic 
[gw5] [ 77%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validate_dataframe_schema_with_mock_functions 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_functions_backward_compatibility 
[gw8] [ 77%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestHighVolume::test_pipeline_high_volume_with_logging 
tests/system/test_full_pipeline_with_logging_variations.py::TestComplexDependencies::test_pipeline_complex_dependencies_with_logging 
tests/unit/test_validation.py::TestApplyValidationRules::test_apply_column_rules_empty 
[gw5] [ 77%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_functions_backward_compatibility 
[gw9] [ 77%] PASSED tests/unit/test_validation.py::TestApplyValidationRules::test_apply_column_rules_empty 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_assess_data_quality_with_mock_functions 
[gw2] [ 77%] PASSED tests/unit/test_validation.py::TestConvertRuleToExpression::test_positive_rule 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_mock_functions_protocol_compliance 
[gw5] [ 78%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_mock_functions_protocol_compliance 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_convert_rule_to_expression_string_handling 
[gw9] [ 78%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_convert_rule_to_expression_string_handling 
tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_empty_expressions 
[gw9] [ 78%] PASSED tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_empty_expressions 
tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_static_methods_with_mock_functions 
[gw9] [ 78%] PASSED tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_static_methods_with_mock_functions 
[gw4] [ 78%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_assess_data_quality_with_mock_functions 
tests/unit/test_validation.py::TestConvertRuleToExpression::test_non_negative_rule 
[gw2] [ 78%] PASSED tests/unit/test_validation.py::TestConvertRuleToExpression::test_non_negative_rule 
tests/unit/test_validation.py::TestConvertRuleToExpression::test_non_zero_rule 
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_functions_protocol_type_checking 
[gw3] [ 78%] PASSED tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_functions_protocol_type_checking 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rule_to_expression_with_mock_functions 
[gw3] [ 78%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rule_to_expression_with_mock_functions 
[gw1] [ 78%] PASSED tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_complex_dependency_handling 
tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_multi_source_logging 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_with_complex_rules 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_and_all_rules_with_mock_functions 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rule_in_not_in_like 
tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_backward_compatibility 
[gw2] [ 78%] PASSED tests/unit/test_validation.py::TestConvertRuleToExpression::test_non_zero_rule 
[gw4] [ 78%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_and_all_rules_with_mock_functions 
[gw3] [ 78%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rule_in_not_in_like 
[gw9] [ 78%] PASSED tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_backward_compatibility 
[gw5] [ 78%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_with_complex_rules 
tests/unit/test_validation.py::TestConvertRuleToExpression::test_custom_expression_rule 
[gw1] [ 78%] PASSED tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_multi_source_logging 
tests/builder_tests/test_simple.py::test_simple_pipeline_creation 
[gw1] [ 78%] PASSED tests/builder_tests/test_simple.py::test_simple_pipeline_creation 
tests/builder_tests/test_simple_pipeline.py::TestSimplePipeline::test_simple_pipeline_execution 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rule_in_requires_iterable 
tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_class_methods_with_mock_functions 
[gw2] [ 78%] PASSED tests/unit/test_validation.py::TestConvertRuleToExpression::test_custom_expression_rule 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_error_handling_with_mock_functions 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_apply_column_rules_with_mock_functions 
[gw3] [ 78%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rule_in_requires_iterable 
[gw5] [ 79%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_error_handling_with_mock_functions 
[gw9] [ 79%] PASSED tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_class_methods_with_mock_functions 
tests/unit/test_validation.py::TestConvertRulesToExpressions::test_string_rules_conversion 
[gw8] [ 79%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestComplexDependencies::test_pipeline_complex_dependencies_with_logging 
tests/system/test_full_pipeline_with_logging_variations.py::TestParallelStress::test_pipeline_parallel_execution_stress 
[gw2] [ 79%] PASSED tests/unit/test_validation.py::TestConvertRulesToExpressions::test_string_rules_conversion 
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_behavior 
tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_performance_with_mock_functions 
[gw4] [ 79%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_apply_column_rules_with_mock_functions 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rules_to_expressions_with_mock_functions 
[gw3] [ 79%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rules_to_expressions_with_mock_functions 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_assess_data_quality_with_mock_functions 
[gw9] [ 79%] PASSED tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_behavior 
[gw1] [ 79%] PASSED tests/builder_tests/test_simple_pipeline.py::TestSimplePipeline::test_simple_pipeline_execution 
tests/builder_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_complete_streaming_hybrid_pipeline_execution 
[gw5] [ 79%] PASSED tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_performance_with_mock_functions 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_performance_with_mock_functions 
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_validation_with_mock_functions_end_to_end 
[gw4] [ 79%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_assess_data_quality_with_mock_functions 
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_validation_with_mock_functions_end_to_end 
tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_with_mock_functions 
[gw3] [ 79%] PASSED tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_validation_with_mock_functions_end_to_end 
[gw2] [ 79%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_performance_with_mock_functions 
[gw5] [ 79%] PASSED tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_with_mock_functions 
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_performance 
[gw9] [ 79%] PASSED tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_validation_with_mock_functions_end_to_end 
tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_positive_rule 
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_with_mock_functions 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validate_dataframe_schema_with_mock_functions 
[gw4] [ 79%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validate_dataframe_schema_with_mock_functions 
[gw3] [ 79%] PASSED tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_performance 
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_performance 
[gw2] [ 79%] PASSED tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_with_mock_functions 
[gw5] [ 80%] PASSED tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_positive_rule 
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_error_handling 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_functions_backward_compatibility 
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_static_methods_with_mock_functions 
tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_non_negative_rule 
[gw9] [ 80%] PASSED tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_performance 
[gw3] [ 80%] PASSED tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_error_handling 
[gw4] [ 80%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_functions_backward_compatibility 
[gw2] [ 80%] PASSED tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_static_methods_with_mock_functions 
[gw5] [ 80%] PASSED tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_non_negative_rule 
tests/unit/test_validation_mock.py::TestSafeDivide::test_none_numerator 
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_functions_protocol_compatibility 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_mock_functions_basic_operations 
tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_non_zero_rule 
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_backward_compatibility 
[gw9] [ 80%] PASSED tests/unit/test_validation_mock.py::TestSafeDivide::test_none_numerator 
[gw8] [ 80%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestParallelStress::test_pipeline_parallel_execution_stress 
tests/system/test_full_pipeline_with_logging_variations.py::TestSchemaEvolution::test_pipeline_with_schema_evolution_logging 
[gw3] [ 80%] PASSED tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_functions_protocol_compatibility 
[gw4] [ 80%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_mock_functions_basic_operations 
[gw5] [ 80%] PASSED tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_non_zero_rule 
tests/unit/test_validation_mock.py::TestSafeDivide::test_both_none 
[gw2] [ 80%] PASSED tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_backward_compatibility 
tests/unit/test_validation_mock.py::TestSafeDivide::test_normal_division 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_with_complex_rules 
tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_custom_expression 
[gw9] [ 80%] PASSED tests/unit/test_validation_mock.py::TestSafeDivide::test_both_none 
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_class_methods_with_mock_functions 
[gw3] [ 80%] PASSED tests/unit/test_validation_mock.py::TestSafeDivide::test_normal_division 
[gw5] [ 80%] PASSED tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_custom_expression 
tests/unit/test_validation_mock.py::TestGetDataframeInfo::test_basic_info 
[gw4] [ 80%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_with_complex_rules 
[gw2] [ 80%] PASSED tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_class_methods_with_mock_functions 
tests/unit/test_validation_mock.py::TestSafeDivide::test_division_by_zero 
tests/unit/test_validation_mock.py::TestConvertRulesToExpressions::test_single_rule 
[gw9] [ 80%] PASSED tests/unit/test_validation_mock.py::TestGetDataframeInfo::test_basic_info 
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_error_handling_with_mock_functions 
[gw3] [ 81%] PASSED tests/unit/test_validation_mock.py::TestSafeDivide::test_division_by_zero 
[gw5] [ 81%] PASSED tests/unit/test_validation_mock.py::TestConvertRulesToExpressions::test_single_rule 
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_behavior 
[gw4] [ 81%] PASSED tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_error_handling_with_mock_functions 
[gw2] [ 81%] PASSED tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_behavior 
tests/unit/test_validation_mock.py::TestGetDataframeInfo::test_empty_dataframe 
tests/unit/test_validation_mock.py::TestSafeDivide::test_division_by_none 
tests/unit/test_validation_mock.py::TestConvertRulesToExpressions::test_multiple_rules 
[gw9] [ 81%] PASSED tests/unit/test_validation_mock.py::TestGetDataframeInfo::test_empty_dataframe 
tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_valid_schema 
[gw3] [ 81%] PASSED tests/unit/test_validation_mock.py::TestSafeDivide::test_division_by_none 
tests/unit/test_validation_mock.py::TestConvertRulesToExpressions::test_empty_rules 
[gw5] [ 81%] PASSED tests/unit/test_validation_mock.py::TestConvertRulesToExpressions::test_multiple_rules 
[gw8] [ 81%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestSchemaEvolution::test_pipeline_with_schema_evolution_logging 
tests/system/test_full_pipeline_with_logging_variations.py::TestDataTypes::test_pipeline_data_type_variations 
tests/unit/test_validation_mock.py::TestGetDataframeInfo::test_error_handling 
[gw4] [ 81%] PASSED tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_valid_schema 
tests/unit/test_validation_mock.py::TestApplyColumnRules::test_multiple_columns 
[gw2] [ 81%] PASSED tests/unit/test_validation_mock.py::TestConvertRulesToExpressions::test_empty_rules 
tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_safe_divide_properties 
[gw9] [ 81%] PASSED tests/unit/test_validation_mock.py::TestGetDataframeInfo::test_error_handling 
[gw3] [ 81%] PASSED tests/unit/test_validation_mock.py::TestApplyColumnRules::test_multiple_columns 
[gw8] [ 81%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestDataTypes::test_pipeline_data_type_variations 
tests/system/test_full_pipeline_with_logging_variations.py::TestValidationThresholds::test_pipeline_validation_thresholds_logging 
tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_missing_columns 
tests/unit/test_validation_mock.py::TestAndAllRules::test_empty_rules 
tests/unit/test_validation_mock.py::TestApplyColumnRules::test_empty_rules 
tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_not_null_rule 
[gw4] [ 81%] PASSED tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_missing_columns 
[gw8] [ 81%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestValidationThresholds::test_pipeline_validation_thresholds_logging 
[gw2] [ 81%] PASSED tests/unit/test_validation_mock.py::TestAndAllRules::test_empty_rules 
tests/system/test_full_pipeline_with_logging_variations.py::TestWriteModes::test_pipeline_write_mode_variations 
[gw9] [ 81%] PASSED tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_not_null_rule 
[gw3] [ 81%] PASSED tests/unit/test_validation_mock.py::TestApplyColumnRules::test_empty_rules 
tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_extra_columns 
tests/unit/test_validation_mock.py::TestAndAllRules::test_single_rule 
tests/unit/test_validation_mock.py::TestAssessDataQuality::test_basic_quality_assessment 
tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_by_zero 
[gw2] [ 82%] PASSED tests/unit/test_validation_mock.py::TestAndAllRules::test_single_rule 
[gw4] [ 82%] PASSED tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_extra_columns 
[gw8] [ 82%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestWriteModes::test_pipeline_write_mode_variations 
tests/system/test_full_pipeline_with_logging_variations.py::TestMixedSuccessFailure::test_pipeline_mixed_success_failure 
[gw3] [ 82%] PASSED tests/unit/test_validation_mock.py::TestAssessDataQuality::test_basic_quality_assessment 
[gw9] [ 82%] PASSED tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_by_zero 
tests/unit/test_validation_mock.py::TestAndAllRules::test_multiple_rules 
tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_empty_expected_columns 
tests/unit/test_validation_mock.py::TestAssessDataQuality::test_multiple_quality_rules 
tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_none_values 
[gw2] [ 82%] PASSED tests/unit/test_validation_mock.py::TestAndAllRules::test_multiple_rules 
[gw4] [ 82%] PASSED tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_empty_expected_columns 
[gw3] [ 82%] PASSED tests/unit/test_validation_mock.py::TestAssessDataQuality::test_multiple_quality_rules 
[gw8] [ 82%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestMixedSuccessFailure::test_pipeline_mixed_success_failure 
tests/system/test_full_pipeline_with_logging_variations.py::TestLongRunning::test_pipeline_long_running_with_logging 
[gw9] [ 82%] PASSED tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_none_values 
tests/unit/test_validation_mock.py::TestApplyColumnRules::test_basic_validation 
tests/unit/test_validation_mock.py::TestAssessDataQuality::test_empty_rules 
tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_edge_cases 
tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_none_dataframe 
[gw2] [ 82%] PASSED tests/unit/test_validation_mock.py::TestApplyColumnRules::test_basic_validation 
[gw3] [ 82%] PASSED tests/unit/test_validation_mock.py::TestAssessDataQuality::test_empty_rules 
[gw4] [ 82%] PASSED tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_none_dataframe 
[gw9] [ 82%] PASSED tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_edge_cases 
tests/unit/test_validation_simple.py::TestValidationUtils::test_get_dataframe_info_error_handling 
tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_pipeline_validation 
tests/unit/test_validation_simple.py::TestValidationUtils::test_get_dataframe_info 
tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_none_expected_columns 
[gw3] [ 82%] PASSED tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_pipeline_validation 
[gw2] [ 82%] PASSED tests/unit/test_validation_simple.py::TestValidationUtils::test_get_dataframe_info_error_handling 
tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_step_validation 
[gw4] [ 82%] PASSED tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_none_expected_columns 
[gw9] [ 82%] PASSED tests/unit/test_validation_simple.py::TestValidationUtils::test_get_dataframe_info 
tests/unit/test_validation_simple.py::TestPipelineValidation::test_validation_result_creation 
[gw3] [ 83%] PASSED tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_step_validation 
tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_workflow_with_mock_data 
[gw2] [ 83%] PASSED tests/unit/test_validation_simple.py::TestPipelineValidation::test_validation_result_creation 
tests/unit/test_validation_simple.py::TestValidationUtils::test_get_dataframe_info_empty 
tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_custom_validators 
[gw4] [ 83%] PASSED tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_workflow_with_mock_data 
[gw9] [ 83%] PASSED tests/unit/test_validation_simple.py::TestValidationUtils::test_get_dataframe_info_empty 
tests/unit/test_validation_simple.py::TestPipelineValidation::test_validation_result_false 
[gw3] [ 83%] PASSED tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_custom_validators 
tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_with_pipeline_config 
tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_invalid_config 
[gw2] [ 83%] PASSED tests/unit/test_validation_simple.py::TestPipelineValidation::test_validation_result_false 
tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_empty_pipeline 
[gw4] [ 83%] PASSED tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_with_pipeline_config 
[gw9] [ 83%] PASSED tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_invalid_config 
tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_initialization 
[gw3] [ 83%] PASSED tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_empty_pipeline 
tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_with_complex_pipeline 
tests/unit/test_validation_simple.py::TestValidationErrorHandling::test_validation_error_creation 
[gw2] [ 83%] PASSED tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_initialization 
tests/unit/test_validation_standalone.py::TestSafeDivide::test_division_by_zero 
[gw9] [ 83%] PASSED tests/unit/test_validation_simple.py::TestValidationErrorHandling::test_validation_error_creation 
[gw4] [ 83%] PASSED tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_with_complex_pipeline 
tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_add_validator 
[gw3] [ 83%] PASSED tests/unit/test_validation_standalone.py::TestSafeDivide::test_division_by_zero 
tests/unit/test_validation_simple.py::TestValidationErrorHandling::test_validation_error_with_context 
tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_error_scenarios 
[gw8] [ 83%] PASSED tests/system/test_full_pipeline_with_logging_variations.py::TestLongRunning::test_pipeline_long_running_with_logging 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_auto_infer_gold_source_silvers 
[gw8] [ 83%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_auto_infer_gold_source_silvers 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_auto_infer_gold_source_silvers_explicit 
[gw8] [ 83%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_auto_infer_gold_source_silvers_explicit 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_auto_infer_gold_no_silver_steps_error 
[gw8] [ 83%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_auto_infer_gold_no_silver_steps_error 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_preset_configurations_development 
[gw8] [ 83%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_preset_configurations_development 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_preset_configurations_production 
[gw8] [ 84%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_preset_configurations_production 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_preset_configurations_testing 
[gw8] [ 84%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_preset_configurations_testing 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_not_null_rules 
[gw2] [ 84%] PASSED tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_add_validator 
[gw9] [ 84%] PASSED tests/unit/test_validation_simple.py::TestValidationErrorHandling::test_validation_error_with_context 
tests/unit/test_validation_standalone.py::TestGetDataframeInfo::test_empty_dataframe 
[gw2] [ 84%] PASSED tests/unit/test_validation_standalone.py::TestGetDataframeInfo::test_empty_dataframe 
[gw8] [ 84%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_not_null_rules 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_positive_number_rules 
[gw8] [ 84%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_positive_number_rules 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_string_not_empty_rules 
[gw8] [ 84%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_string_not_empty_rules 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_timestamp_rules 
[gw8] [ 84%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_timestamp_rules 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_detect_timestamp_columns 
[gw8] [ 84%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_detect_timestamp_columns 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_detect_timestamp_columns_list 
[gw8] [ 84%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_detect_timestamp_columns_list 
tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_chaining_with_auto_inference 
[gw8] [ 84%] PASSED tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_chaining_with_auto_inference 
tests/system/test_logger.py::TestPipelineLogger::test_basic_logging_methods 
[gw8] [ 84%] PASSED tests/system/test_logger.py::TestPipelineLogger::test_basic_logging_methods 
[gw4] [ 84%] PASSED tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_error_scenarios 
tests/unit/test_validation_standalone.py::TestSafeDivide::test_normal_division_float 
[gw3] [ 84%] PASSED tests/unit/test_validation_standalone.py::TestSafeDivide::test_normal_division_float 
tests/unit/test_validation_standalone.py::TestSafeDivide::test_division_with_default 
tests/system/test_logger.py::TestPipelineLogger::test_log_level_management 
[gw8] [ 84%] PASSED tests/system/test_logger.py::TestPipelineLogger::test_log_level_management 
tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_non_negative_rule 
tests/unit/test_validation_standalone.py::TestSafeDivide::test_normal_division 
tests/unit/test_validation_simple.py::TestValidationErrorHandling::test_validation_error_attributes 
[gw3] [ 84%] PASSED tests/unit/test_validation_standalone.py::TestSafeDivide::test_division_with_default 
tests/unit/test_validation_standalone.py::TestGetDataframeInfo::test_error_handling 
[gw8] [ 84%] PASSED tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_non_negative_rule 
[gw4] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestSafeDivide::test_normal_division 
[gw9] [ 85%] PASSED tests/unit/test_validation_simple.py::TestValidationErrorHandling::test_validation_error_attributes 
[gw2] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestGetDataframeInfo::test_error_handling 
tests/unit/test_validation_standalone.py::TestGetDataframeInfo::test_basic_info 
tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_non_zero_rule 
tests/unit/test_validation_standalone.py::TestAndAllRules::test_multiple_rules 
tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_multiple_rules 
[gw3] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestGetDataframeInfo::test_basic_info 
tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_not_null_rule 
[gw8] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_non_zero_rule 
[gw9] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestAndAllRules::test_multiple_rules 
tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_basic_quality_assessment 
[gw4] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_multiple_rules 
[gw2] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_not_null_rule 
tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_custom_expression 
tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_basic_validation 
tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_empty_rules 
[gw3] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_basic_quality_assessment 
[gw8] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_custom_expression 
tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_positive_rule 
[gw9] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_basic_validation 
[gw4] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_empty_rules 
[gw2] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_positive_rule 
tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_multiple_quality_rules 
tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_single_rule 
tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_multiple_columns 
tests/unit/test_validation_standalone.py::TestAndAllRules::test_empty_rules 
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_missing_columns 
[gw3] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_multiple_quality_rules 
[gw8] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_single_rule 
[gw9] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_multiple_columns 
[gw4] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestAndAllRules::test_empty_rules 
tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_empty_rules 
[gw2] [ 85%] PASSED tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_missing_columns 
tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_empty_rules 
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_none_expected_columns 
[gw3] [ 86%] PASSED tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_empty_rules 
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_extra_columns 
tests/unit/test_validation_standalone.py::TestAndAllRules::test_single_rule 
[gw8] [ 86%] PASSED tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_none_expected_columns 
[gw9] [ 86%] PASSED tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_empty_rules 
[gw4] [ 86%] PASSED tests/unit/test_validation_standalone.py::TestAndAllRules::test_single_rule 
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_valid_schema 
[gw2] [ 86%] PASSED tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_extra_columns 
tests/unit/test_working_examples.py::TestWorkingExamples::test_pipeline_builder_basic 
[gw8] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_pipeline_builder_basic 
tests/unit/test_working_examples.py::TestWorkingExamples::test_execution_engine_with_config 
[gw9] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_execution_engine_with_config 
tests/unit/test_working_examples.py::TestWorkingExamples::test_unified_validator_basic 
[gw9] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_unified_validator_basic 
tests/unit/test_working_examples.py::TestWorkingExamples::test_validation_result_creation 
[gw9] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_validation_result_creation 
tests/unit/test_working_examples.py::TestWorkingExamples::test_parallel_config_creation 
[gw9] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_parallel_config_creation 
tests/unit/test_working_examples.py::TestWorkingExamples::test_mock_spark_integration 
[gw9] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_mock_spark_integration 
tests/unit/test_working_examples.py::TestWorkingExamples::test_pipeline_builder_with_quality_rates 
[gw8] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_pipeline_builder_with_quality_rates 
tests/unit/test_working_examples.py::TestWorkingExamples::test_writer_config_with_custom_values 
[gw8] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_writer_config_with_custom_values 
tests/unit/test_working_examples.py::TestWorkingExamples::test_pipeline_config_creation 
[gw8] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_pipeline_config_creation 
tests/unit/test_working_examples.py::TestWorkingExamples::test_validation_result_with_errors 
[gw4] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_validation_result_with_errors 
tests/unit/test_working_examples.py::TestWorkingExamples::test_log_writer_with_config 
[gw4] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_log_writer_with_config 
[gw3] [ 86%] PASSED tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_valid_schema 
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_empty_expected_columns 
tests/unit/test_working_examples.py::TestWorkingExamples::test_error_handling 
[gw9] [ 86%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_error_handling 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_table_exists_function 
tests/unit/test_working_examples.py::TestWorkingExamples::test_validation_thresholds_creation 
[gw8] [ 87%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_validation_thresholds_creation 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_config_defaults 
[gw2] [ 87%] PASSED tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_empty_expected_columns 
tests/unit/test_working_examples.py::TestWorkingExamples::test_step_execution_result_creation 
[gw3] [ 87%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_step_execution_result_creation 
tests/unit/test_working_examples.py::TestWorkingExamples::test_execution_result_creation 
[gw3] [ 87%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_execution_result_creation 
tests/unit/test_working_examples.py::TestWorkingExamples::test_writer_config_creation 
[gw3] [ 87%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_writer_config_creation 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_with_custom_logger 
tests/unit/test_working_examples.py::TestWorkingExamples::test_enum_values 
[gw4] [ 87%] PASSED tests/unit/test_working_examples.py::TestWorkingExamples::test_enum_values 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result 
[gw8] [ 87%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_config_defaults 
[gw9] [ 87%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_table_exists_function 
[gw3] [ 87%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_with_custom_logger 
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_none_dataframe 
[gw2] [ 87%] PASSED tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_none_dataframe 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_time_write_operation_function 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_initialization 
[gw4] [ 87%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result 
[gw5] [ 87%] FAILED tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_safe_divide_properties 
tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_safe_divide_zero_denominator_properties 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_invalid_config 
[gw9] [ 87%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_time_write_operation_function 
[gw8] [ 87%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_initialization 
[gw5] [ 87%] PASSED tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_safe_divide_zero_denominator_properties 
[gw3] [ 87%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_invalid_config 
tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_validate_dataframe_schema_properties 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_step_results 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result_batch 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result_with_metadata 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_config_creation 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_write_modes 
[gw2] [ 87%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_step_results 
[gw8] [ 87%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result_batch 
[gw9] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_config_creation 
[gw3] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_write_modes 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_partition_settings 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_metrics_tracking 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_log_rows 
[gw9] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_partition_settings 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_log_levels 
[gw4] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result_with_metadata 
[gw5] [ 88%] PASSED tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_validate_dataframe_schema_properties 
tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_dataframe_schema_edge_cases_properties 
[gw8] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_metrics_tracking 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_custom_batch_size 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_schema_evolution_settings 
[gw2] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_log_rows 
[gw5] [ 88%] PASSED tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_dataframe_schema_edge_cases_properties 
tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_normal 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_schema_creation 
[gw9] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_schema_evolution_settings 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_error_handling 
[gw8] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_schema_creation 
[gw5] [ 88%] PASSED tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_normal 
[gw3] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_log_levels 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_initialization 
[gw2] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_error_handling 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_invalid_spark_session 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_initialization_with_config 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_components_initialization 
[gw4] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_custom_batch_size 
[gw9] [ 88%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_initialization 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_table_fqn 
[gw8] [ 88%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_invalid_spark_session 
[gw5] [ 88%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_initialization_with_config 
[gw3] [ 88%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_table_fqn 
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_compression_settings 
[gw2] [ 89%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_components_initialization 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_get_spark 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_get_config 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_table_exists_function_invalid_parameters 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_table_exists_function 
[gw9] [ 89%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_get_spark 
[gw8] [ 89%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_get_config 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_write_mode_enum 
[gw5] [ 89%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_table_exists_function 
[gw3] [ 89%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_table_exists_function_invalid_parameters 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_writer_config_default_values 
[gw2] [ 89%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_write_mode_enum 
[gw4] [ 89%] PASSED tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_compression_settings 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_writer_config_creation 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_error_handling 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_level_enum 
[gw8] [ 89%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_writer_config_default_values 
[gw9] [ 89%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_writer_config_creation 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_with_sample_data 
[gw5] [ 89%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_error_handling 
[gw4] [ 89%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_level_enum 
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_metrics_collection 
[gw2] [ 89%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_metrics_collection 
tests/unit/writer/test_core.py::TestLogWriter::test_init_default_logger 
[gw5] [ 89%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_init_default_logger 
tests/unit/writer/test_core.py::TestLogWriter::test_init_valid_config 
[gw8] [ 89%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_init_valid_config 
tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_validation_failure 
[gw2] [ 89%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_validation_failure 
tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_invalid_input 
[gw4] [ 89%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_invalid_input 
tests/unit/writer/test_core.py::TestLogWriter::test_init_invalid_config 
[gw9] [ 89%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_init_invalid_config 
[gw3] [ 90%] PASSED tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_with_sample_data 
tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_success 
[gw3] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_success 
tests/unit/writer/test_core.py::TestLogWriter::test_reset_metrics 
[gw2] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_reset_metrics 
tests/unit/writer/test_core.py::TestLogWriter::test_get_metrics 
[gw8] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_get_metrics 
tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_success 
[gw4] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_success 
tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_batch_with_failures 
tests/unit/writer/test_core.py::TestLogWriter::test_get_memory_usage_success 
tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_batch_success 
[gw2] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_get_memory_usage_success 
[gw8] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_batch_with_failures 
tests/unit/writer/test_core.py::TestLogWriter::test_show_logs 
[gw3] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_show_logs 
tests/unit/writer/test_core.py::TestLogWriter::test_write_step_results 
[gw5] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_write_step_results 
tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_validation_failure 
[gw9] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_validation_failure 
[gw4] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_batch_success 
tests/unit/writer/test_core.py::TestLogWriter::test_get_memory_usage_exception 
[gw8] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_get_memory_usage_exception 
tests/unit/writer/test_core.py::TestLogWriter::test_get_table_info 
[gw3] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_get_table_info 
tests/unit/writer/test_core.py::TestLogWriter::test_get_memory_usage_psutil_not_available 
[gw2] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_get_memory_usage_psutil_not_available 
tests/unit/writer/test_core.py::TestLogWriter::test_show_logs_no_limit 
[gw5] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_show_logs_no_limit 
tests/unit/writer/test_core.py::TestLogWriter::test_validate_log_data_quality_failure 
[gw8] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_validate_log_data_quality_failure 
tests/unit/writer/test_core.py::TestLogWriter::test_detect_anomalies_success 
tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_batch 
tests/unit/writer/test_core.py::TestLogWriter::test_detect_anomalies_disabled 
tests/unit/writer/test_core.py::TestLogWriter::test_validate_log_data_quality_success 
tests/unit/writer/test_core.py::TestLogWriter::test_vacuum_table_success 
[gw9] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_batch 
[gw3] [ 90%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_detect_anomalies_success 
[gw5] [ 91%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_detect_anomalies_disabled 
[gw2] [ 91%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_vacuum_table_success 
[gw4] [ 91%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_validate_log_data_quality_success 
tests/unit/writer/test_core.py::TestLogWriter::test_optimize_table_success 
[gw9] [ 91%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_optimize_table_success 
tests/unit/writer/test_core.py::TestLogWriter::test_analyze_execution_trends_success 
[gw3] [ 91%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_analyze_execution_trends_success 
tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_success 
[gw5] [ 91%] PASSED tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_success 
tests/unit/writer/test_core.py::TestLogWriter::test_optimize_table_not_exists 
[gw4] [ 91%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_optimize_table_not_exists 
tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_empty_table_name 
[gw9] [ 91%] PASSED tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_empty_table_name 
tests/unit/writer/test_core.py::TestLogWriter::test_analyze_quality_trends_success 
[gw8] [ 91%] PASSED tests/unit/writer/test_core.py::TestLogWriter::test_analyze_quality_trends_success 
tests/unit/writer/test_models.py::TestLogSchema::test_create_log_schema 
[gw3] [ 91%] PASSED tests/unit/writer/test_models.py::TestLogSchema::test_create_log_schema 
tests/unit/writer/test_models.py::TestWriterConfig::test_valid_config 
[gw2] [ 91%] PASSED tests/unit/writer/test_models.py::TestWriterConfig::test_valid_config 
tests/unit/writer/test_models.py::TestLogRowCreation::test_create_log_row_from_step_result 
[gw5] [ 91%] PASSED tests/unit/writer/test_models.py::TestLogRowCreation::test_create_log_row_from_step_result 
tests/unit/writer/test_models.py::TestLogRowCreation::test_create_log_rows_from_execution_result 
[gw4] [ 91%] PASSED tests/unit/writer/test_models.py::TestLogRowCreation::test_create_log_rows_from_execution_result 
tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_empty_schema 
[gw8] [ 91%] PASSED tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_empty_schema 
tests/unit/writer/test_models.py::TestLogRowCreation::test_process_execution_result_populates_table_total_rows 
[gw9] [ 91%] PASSED tests/unit/writer/test_models.py::TestLogRowCreation::test_process_execution_result_populates_table_total_rows 
tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_row_empty_run_id 
tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_valid_log_row 
[gw5] [ 91%] PASSED tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_row_empty_run_id 
tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_data_valid 
[gw9] [ 91%] PASSED tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_data_valid 
tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_row_negative_duration 
[gw4] [ 91%] PASSED tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_row_negative_duration 
tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_data_invalid_row 
[gw8] [ 92%] PASSED tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_data_invalid_row 
tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_invalid_batch_size 
[gw2] [ 92%] PASSED tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_invalid_batch_size 
[gw3] [ 92%] PASSED tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_valid_log_row 
[gw6] [ 92%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_security_test_suite_integration 
tests/security/test_security_integration.py::TestSecurityIntegration::test_vulnerability_scanner_integration 
[gw6] [ 92%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_vulnerability_scanner_integration 
[gw7] [ 92%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_security_performance_integration 
tests/security/test_security_integration.py::TestSecurityIntegration::test_compliance_checker_integration 
tests/security/test_security_integration.py::TestSecurityMarkers::test_security_marker_works 
[gw7] [ 92%] PASSED tests/security/test_security_integration.py::TestSecurityMarkers::test_security_marker_works 
tests/security/test_security_integration.py::TestSecurityMarkers::test_slow_security_test 
[gw7] [ 92%] PASSED tests/security/test_security_integration.py::TestSecurityMarkers::test_slow_security_test 
tests/security/test_security_integration.py::test_security_cicd_integration 
[gw7] [ 92%] PASSED tests/security/test_security_integration.py::test_security_cicd_integration 
tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_auto_infer_single_bronze_step 
[gw7] [ 92%] PASSED tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_auto_infer_single_bronze_step 
tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_auto_infer_multiple_bronze_steps 
[gw7] [ 92%] PASSED tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_auto_infer_multiple_bronze_steps 
tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_explicit_source_bronze_still_works 
[gw7] [ 92%] PASSED tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_explicit_source_bronze_still_works 
tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_no_bronze_steps_raises_error 
[gw7] [ 92%] PASSED tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_no_bronze_steps_raises_error 
tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_invalid_source_bronze_raises_error 
[gw7] [ 92%] PASSED tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_invalid_source_bronze_raises_error 
tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_logging_auto_inference 
[gw7] [ 92%] PASSED tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_logging_auto_inference 
tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_chaining_works_with_auto_inference 
[gw7] [ 92%] PASSED tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_chaining_works_with_auto_inference 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_bronze_step_without_incremental_col 
[gw7] [ 92%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_bronze_step_without_incremental_col 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_bronze_step_with_incremental_col 
[gw7] [ 92%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_bronze_step_with_incremental_col 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_silver_step_creation 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_silver_step_creation 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_gold_step_creation 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_gold_step_creation 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_pipeline_validation 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_pipeline_validation 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_pipeline_creation 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_pipeline_creation 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_dataframe_operations 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_dataframe_operations 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_execution_engine_initialization 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_execution_engine_initialization 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_step_type_detection 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_step_type_detection 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_pipeline_configuration 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_pipeline_configuration 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_execution_mode_enum 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_execution_mode_enum 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_step_status_enum 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_step_status_enum 
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_step_type_enum 
[gw7] [ 93%] PASSED tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_step_type_enum 
tests/system/test_complete_pipeline.py::TestCompletePipeline::test_bronze_to_silver_to_gold_pipeline 
[gw7] [ 93%] PASSED tests/system/test_complete_pipeline.py::TestCompletePipeline::test_bronze_to_silver_to_gold_pipeline 
tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_with_data_validation 
[gw7] [ 93%] PASSED tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_with_data_validation 
tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_with_logging_and_monitoring 
[gw7] [ 93%] PASSED tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_with_logging_and_monitoring 
tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_error_recovery 
[gw7] [ 93%] PASSED tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_error_recovery 
tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_with_different_data_sizes 
[gw7] [ 93%] PASSED tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_with_different_data_sizes 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_bronze_step_creation 
[gw7] [ 93%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_bronze_step_creation 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_silver_step_creation 
[gw7] [ 93%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_silver_step_creation 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_gold_step_creation 
[gw7] [ 94%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_gold_step_creation 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_pipeline_builder_validation 
[gw7] [ 94%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_pipeline_builder_validation 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_pipeline_creation 
[gw7] [ 94%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_pipeline_creation 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_dataframe_operations 
[gw7] [ 94%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_dataframe_operations 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_execution_engine_initialization 
[gw7] [ 94%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_execution_engine_initialization 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_step_type_detection 
[gw7] [ 94%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_step_type_detection 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_pipeline_configuration 
[gw7] [ 94%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_pipeline_configuration 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_execution_mode_enum 
[gw7] [ 94%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_execution_mode_enum 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_step_status_enum 
[gw7] [ 94%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_step_status_enum 
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_step_type_enum 
[gw7] [ 94%] PASSED tests/system/test_dataframe_access.py::TestDataFrameAccess::test_step_type_enum 
tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_acid_transactions 
[gw7] [ 94%] SKIPPED tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_acid_transactions 
[gw1] [ 94%] FAILED tests/builder_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_complete_streaming_hybrid_pipeline_execution 
tests/builder_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_incremental_streaming_processing 
[gw1] [ 94%] PASSED tests/builder_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_incremental_streaming_processing 
tests/builder_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_complete_supply_chain_pipeline_execution 
[gw1] [ 94%] FAILED tests/builder_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_complete_supply_chain_pipeline_execution 
tests/builder_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_incremental_supply_chain_processing 
[gw1] [ 94%] PASSED tests/builder_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_incremental_supply_chain_processing 
tests/builder_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_supply_chain_logging 
[gw1] [ 94%] PASSED tests/builder_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_supply_chain_logging 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_engine_detection 
[gw1] [ 94%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_engine_detection 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_imports 
[gw1] [ 94%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_imports 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_dataframe_operations 
[gw1] [ 95%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_dataframe_operations 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_pipeline_building 
[gw1] [ 95%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_pipeline_building 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_validation 
[gw1] [ 95%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_validation 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_delta_lake_operations 
[gw1] [ 95%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_delta_lake_operations 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_error_handling 
[gw1] [ 95%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_error_handling 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_performance_monitoring 
[gw1] [ 95%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_performance_monitoring 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_table_operations 
[gw1] [ 95%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkCompatibility::test_pyspark_table_operations 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkEngineSwitching::test_switch_to_pyspark 
[gw1] [ 95%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkEngineSwitching::test_switch_to_pyspark 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkEngineSwitching::test_switch_to_mock 
[gw1] [ 95%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkEngineSwitching::test_switch_to_mock 
tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkEngineSwitching::test_auto_detection 
[gw1] [ 95%] SKIPPED tests/compat_pyspark/test_pyspark_compatibility.py::TestPySparkEngineSwitching::test_auto_detection 
tests/debug/test_delta_minimal.py::test_delta_minimal_write 
[gw1] [ 95%] PASSED tests/debug/test_delta_minimal.py::test_delta_minimal_write 
tests/debug/test_delta_minimal.py::test_delta_minimal_direct_session 
[gw1] [ 95%] PASSED tests/debug/test_delta_minimal.py::test_delta_minimal_direct_session 
tests/integration/test_execution_engine.py::TestExecutionMode::test_execution_mode_values 
[gw1] [ 95%] PASSED tests/integration/test_execution_engine.py::TestExecutionMode::test_execution_mode_values 
tests/integration/test_execution_engine.py::TestExecutionMode::test_execution_mode_enumeration 
[gw1] [ 95%] PASSED tests/integration/test_execution_engine.py::TestExecutionMode::test_execution_mode_enumeration 
tests/integration/test_execution_engine.py::TestStepStatus::test_step_status_values 
[gw1] [ 95%] PASSED tests/integration/test_execution_engine.py::TestStepStatus::test_step_status_values 
tests/integration/test_execution_engine.py::TestStepStatus::test_step_status_enumeration 
[gw1] [ 95%] PASSED tests/integration/test_execution_engine.py::TestStepStatus::test_step_status_enumeration 
tests/integration/test_execution_engine.py::TestStepType::test_step_type_values 
[gw1] [ 95%] PASSED tests/integration/test_execution_engine.py::TestStepType::test_step_type_values 
tests/integration/test_execution_engine.py::TestStepType::test_step_type_enumeration 
[gw1] [ 95%] PASSED tests/integration/test_execution_engine.py::TestStepType::test_step_type_enumeration 
[gw0] [ 96%] FAILED tests/builder_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_complete_data_quality_pipeline_execution 
tests/builder_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_incremental_data_quality_processing 
[gw0] [ 96%] PASSED tests/builder_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_incremental_data_quality_processing 
tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_complete_ecommerce_pipeline_execution 
[gw0] [ 96%] PASSED tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_complete_ecommerce_pipeline_execution 
tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_incremental_order_processing 
[gw0] [ 96%] PASSED tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_incremental_order_processing 
tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_validation_failures 
[gw0] [ 96%] PASSED tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_validation_failures 
tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_logging_and_monitoring 
[gw0] [ 96%] PASSED tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_logging_and_monitoring 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_silver_valid_dependency 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_silver_valid_dependency 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_detect_conflicts_duplicate_names 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_detect_conflicts_duplicate_names 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_no_issues 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_no_issues 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_with_cycles 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_with_cycles 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_with_conflicts 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_with_conflicts 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_high_dependencies 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_high_dependencies 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_large_pipeline 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_large_pipeline 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_create_cache_key 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_create_cache_key 
tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_clear_cache 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_clear_cache 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestAnalysisStrategy::test_strategy_values 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestAnalysisStrategy::test_strategy_values 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestExecutionMode::test_execution_mode_values 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestExecutionMode::test_execution_mode_values 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalysisResult::test_analysis_result_creation 
[gw0] [ 96%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalysisResult::test_analysis_result_creation 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalysisResult::test_get_parallelization_ratio 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalysisResult::test_get_parallelization_ratio 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalysisResult::test_get_total_execution_time 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalysisResult::test_get_total_execution_time 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_basic 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_basic 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_caching 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_caching 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_force_refresh 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_force_refresh 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_with_bronze_steps 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_with_bronze_steps 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_with_gold_steps 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_with_gold_steps 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyzer_creation 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyzer_creation 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyzer_creation_with_custom_params 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyzer_creation_with_custom_params 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzerIntegration::test_complex_pipeline_analysis 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzerIntegration::test_complex_pipeline_analysis 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzerIntegration::test_different_strategies_comparison 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzerIntegration::test_different_strategies_comparison 
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzerIntegration::test_error_handling 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzerIntegration::test_error_handling 
tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_basic 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_basic 
tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_with_step_name 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_with_step_name 
tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_inheritance 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_inheritance 
tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_with_empty_message 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_with_empty_message 
tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_with_none_step_name 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_with_none_step_name 
tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_basic 
[gw0] [ 97%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_basic 
tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_with_step_name 
[gw0] [ 98%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_with_step_name 
tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_with_analysis_step 
[gw0] [ 98%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_with_analysis_step 
tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_with_both_steps 
[gw0] [ 98%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_with_both_steps 
tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_inheritance 
[gw0] [ 98%] PASSED tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_inheritance 
[gw6] [ 98%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_compliance_checker_integration 
tests/security/test_security_integration.py::TestSecurityIntegration::test_security_monitor_integration 
[gw6] [ 98%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_security_monitor_integration 
tests/security/test_security_integration.py::TestSecurityIntegration::test_security_components_workflow 
[gw6] [ 98%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_security_components_workflow 
tests/security/test_security_integration.py::TestSecurityIntegration::test_security_reporting_integration 
[gw6] [ 98%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_security_reporting_integration 
tests/security/test_security_integration.py::TestSecurityIntegration::test_security_alerting_integration 
[gw6] [ 98%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_security_alerting_integration 
tests/security/test_security_integration.py::TestSecurityIntegration::test_security_metrics_integration 
[gw6] [ 98%] PASSED tests/security/test_security_integration.py::TestSecurityIntegration::test_security_metrics_integration 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_initialization 
[gw6] [ 98%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_initialization 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_invalid_spark_session 
[gw6] [ 98%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_invalid_spark_session 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_get_spark 
[gw6] [ 98%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_get_spark 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_creation 
[gw6] [ 98%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_creation 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_failed 
[gw6] [ 98%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_failed 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_enum 
[gw6] [ 98%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_enum 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_with_sample_data 
[gw6] [ 98%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_with_sample_data 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_error_handling 
[gw6] [ 98%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_error_handling 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_metrics_collection 
[gw6] [ 99%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_metrics_collection 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_with_errors 
[gw6] [ 99%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_with_errors 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_with_warnings_only 
[gw6] [ 99%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_with_warnings_only 
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_empty 
[gw6] [ 99%] PASSED tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_empty 
tests/unit/test_dataframe_writer_modes.py::test_delta_writer_preserves_overwrite_mode 
[gw6] [ 99%] PASSED tests/unit/test_dataframe_writer_modes.py::test_delta_writer_preserves_overwrite_mode 
tests/unit/test_dataframe_writer_modes.py::test_delta_writer_append_mode 
[gw6] [ 99%] PASSED tests/unit/test_dataframe_writer_modes.py::test_delta_writer_append_mode 
tests/unit/test_dataframe_writer_modes.py::test_delta_writer_respects_explicit_overwrite_schema 
[gw6] [ 99%] PASSED tests/unit/test_dataframe_writer_modes.py::test_delta_writer_respects_explicit_overwrite_schema 
tests/unit/test_dict_annotations.py::test_no_dict_annotations 
[gw6] [ 99%] PASSED tests/unit/test_dict_annotations.py::test_no_dict_annotations 
tests/unit/test_dict_annotations.py::test_python_version 
[gw6] [ 99%] PASSED tests/unit/test_dict_annotations.py::test_python_version 
tests/unit/test_dict_annotations.py::test_dict_vs_Dict_equivalence 
[gw6] [ 99%] PASSED tests/unit/test_dict_annotations.py::test_dict_vs_Dict_equivalence 
tests/unit/test_dict_annotations.py::test_typeddict_compatibility 
[gw6] [ 99%] PASSED tests/unit/test_dict_annotations.py::test_typeddict_compatibility 
tests/unit/test_dict_annotations.py::test_import_compatibility 
[gw6] [ 99%] PASSED tests/unit/test_dict_annotations.py::test_import_compatibility 
tests/unit/test_dict_annotations.py::test_writer_imports 
[gw6] [ 99%] PASSED tests/unit/test_dict_annotations.py::test_writer_imports 
tests/unit/test_dict_annotations.py::test_models_imports 
[gw6] [ 99%] PASSED tests/unit/test_dict_annotations.py::test_models_imports 
tests/unit/test_edge_cases.py::TestEdgeCases::test_empty_dataframe_operations 
[gw6] [ 99%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_empty_dataframe_operations 
tests/unit/test_edge_cases.py::TestEdgeCases::test_null_value_handling 
[gw6] [ 99%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_null_value_handling 
tests/unit/test_edge_cases.py::TestEdgeCases::test_large_dataset_operations 
[gw6] [ 99%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_large_dataset_operations 
tests/unit/test_edge_cases.py::TestEdgeCases::test_complex_schema_operations 
[gw6] [100%] PASSED tests/unit/test_edge_cases.py::TestEdgeCases::test_complex_schema_operations 

=================================== FAILURES ===================================
______ TestHealthcarePipeline.test_complete_healthcare_pipeline_execution ______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python
tests/builder_tests/test_healthcare_pipeline.py:498: in test_complete_healthcare_pipeline_execution
    assert result.status.value == "completed" or result.success
E   assert ('failed' == 'completed'
E     
E     - completed
E     + failed or False)
E    +  where False = PipelineReport(pipeline_id='pipeline_20251218_184022', execution_id='194402de-3f7d-4fbd-963d-fb7a1975b784', mode=<PipelineMode.INITIAL: 'initial'>, status=<PipelineStatus.FAILED: 'failed'>, start_time=datetime.datetime(2025, 12, 18, 18, 40, 22, 518603), end_time=datetime.datetime(2025, 12, 18, 18, 40, 23, 466239), duration_seconds=0.947636, metrics=PipelineMetrics(total_steps=9, successful_steps=8, failed_steps=1, skipped_steps=0, total_duration=0.947636, bronze_duration=0.8924859999999999, silver_duration=1.7238390000000001, gold_duration=0.004051, total_rows_processed=510, total_rows_written=40, avg_validation_rate=0.0, parallel_efficiency=69.13512235688445, cache_hit_rate=0.0, error_count=0, retry_count=0), bronze_results={'raw_patients': {'status': 'completed', 'duration': 0.19685, 'rows_processed': 40, 'output_table': None, 'start_time': '2025-12-18T18:40:22.529383', 'end_time': '2025-12-18T18:40:22.726233', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': 40}, 'raw_diagnoses': {'status': 'completed', 'duration': 0.208916, 'rows_processed': 120, 'output_table': None, 'start_time': '2025-12-18T18:40:22.534089', 'end_time': '2025-12-18T18:40:22...status': 'failed', 'duration': 1e-06, 'rows_processed': None, 'output_table': None, 'start_time': '2025-12-18T18:40:23.460307', 'end_time': '2025-12-18T18:40:23.460308', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': None, 'error': "Step execution failed: 'DataFrame' object has no attribute 'risk_score_sum'. Available columns: patient_id, full_name, age, age_group, gender, insurance_provider, total_labs, abnormal_labs, critical_labs, patient_id, total_labs, abnormal_labs, critical_labs"}, 'population_health_metrics': {'status': 'completed', 'duration': 0.00405, 'rows_processed': 0, 'output_table': 'bronze.population_health_metrics', 'start_time': '2025-12-18T18:40:23.455874', 'end_time': '2025-12-18T18:40:23.459924', 'write_mode': 'overwrite', 'validation_rate': 100.0, 'rows_written': 0, 'input_rows': 0}}, errors=["Step execution failed: 'DataFrame' object has no attribute 'risk_score_sum'. Available columns: patient_id, full_name, age, age_group, gender, insurance_provider, total_labs, abnormal_labs, critical_labs, patient_id, total_labs, abnormal_labs, critical_labs"], warnings=[], recommendations=[], execution_groups_count=3, max_group_size=4).success
---------------------------- Captured stdout setup -----------------------------
 Creating Mock Spark session for all tests
 Test database created successfully
----------------------------- Captured stdout call -----------------------------
18:40:22 - PipelineRunner - INFO -  PipelineBuilder initialized (schema: bronze)
18:40:22 - PipelineRunner - INFO -  Added Bronze step: raw_patients
18:40:22 - PipelineRunner - INFO -  Added Bronze step: raw_labs
18:40:22 - PipelineRunner - INFO -  Added Bronze step: raw_diagnoses
18:40:22 - PipelineRunner - INFO -  Added Bronze step: raw_medications
18:40:22 - PipelineRunner - INFO -  Added Silver step: clean_patients (source: raw_patients)
18:40:22 - PipelineRunner - INFO -  Added Silver step: normalized_labs (source: raw_labs)
18:40:22 - PipelineRunner - INFO -  Added Silver step: processed_diagnoses (source: raw_diagnoses)
18:40:22 - PipelineRunner - INFO -  Added Gold step: patient_risk_scores (sources: ['clean_patients', 'normalized_labs', 'processed_diagnoses'])
18:40:22 - PipelineRunner - INFO -  Added Gold step: population_health_metrics (sources: ['clean_patients', 'normalized_labs', 'processed_diagnoses'])
18:40:22 - PipelineRunner - INFO -  Pipeline validation passed
18:40:22 - PipelineRunner - INFO -  Pipeline built successfully with 4 bronze, 3 silver, 2 gold steps
18:40:22 - PipelineRunner - INFO - Starting pipeline execution: pipeline_20251218_184022
18:40:22 - PipelineRunner - INFO - Starting dependency analysis with strategy: hybrid
18:40:22 - PipelineRunner - INFO - Dependency analysis completed in 0.00s
18:40:22 - PipelineRunner - INFO - Dependency analysis complete: 3 execution groups, max group size: 4
18:40:22 - PipelineRunner - INFO - Parallel execution enabled with 4 workers
18:40:22 - PipelineRunner - INFO - Executing group 1/3: 4 steps - raw_patients, raw_labs, raw_diagnoses, raw_medications
18:40:22 - PipelineRunner - INFO -  Starting BRONZE step: raw_patients
18:40:22 - PipelineRunner - INFO -  Starting BRONZE step: raw_labs
18:40:22 - PipelineRunner - INFO -  Starting BRONZE step: raw_diagnoses
18:40:22 - PipelineRunner - INFO -  Starting BRONZE step: raw_medications
18:40:22 - DataValidation - INFO - Validation completed for pipeline.raw_patients: 100.0% valid
18:40:22 - DataValidation - INFO - Validation completed for pipeline.raw_diagnoses: 100.0% valid
18:40:22 - PipelineRunner - INFO -  Completed BRONZE step: raw_patients (0.20s) - 40 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:22 - PipelineRunner - INFO -  Completed BRONZE step: raw_diagnoses (0.21s) - 120 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:22 - DataValidation - INFO - Validation completed for pipeline.raw_labs: 100.0% valid
18:40:22 - PipelineRunner - INFO -  Completed BRONZE step: raw_labs (0.23s) - 150 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:22 - DataValidation - INFO - Validation completed for pipeline.raw_medications: 100.0% valid
18:40:22 - PipelineRunner - INFO -  Completed BRONZE step: raw_medications (0.25s) - 160 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:22 - PipelineRunner - INFO - Group 1 completed in 0.32s
18:40:22 - PipelineRunner - INFO - Executing group 2/3: 3 steps - clean_patients, normalized_labs, processed_diagnoses
18:40:22 - PipelineRunner - INFO -  Starting SILVER step: clean_patients
18:40:22 - PipelineRunner - INFO -  Starting SILVER step: normalized_labs
18:40:22 - PipelineRunner - INFO -  Starting SILVER step: processed_diagnoses
18:40:23 - DataValidation - INFO - Validation completed for pipeline.normalized_labs: 0.0% valid
18:40:23 - PipelineRunner - INFO -  Completed SILVER step: normalized_labs (0.57s) - 0 rows processed, 0 rows written, 150 invalid, 0.0% valid
18:40:23 - DataValidation - INFO - Validation completed for pipeline.processed_diagnoses: 0.0% valid
18:40:23 - PipelineRunner - INFO -  Completed SILVER step: processed_diagnoses (0.55s) - 0 rows processed, 0 rows written, 120 invalid, 0.0% valid
18:40:23 - DataValidation - INFO - Validation completed for pipeline.clean_patients: 100.0% valid
18:40:23 - PipelineRunner - INFO -  Completed SILVER step: clean_patients (0.61s) - 40 rows processed, 40 rows written, 0 invalid, 100.0% valid
18:40:23 - PipelineRunner - INFO - Group 2 completed in 0.61s
18:40:23 - PipelineRunner - INFO - Executing group 3/3: 2 steps - patient_risk_scores, population_health_metrics
18:40:23 - PipelineRunner - INFO -  Starting GOLD step: patient_risk_scores
18:40:23 - PipelineRunner - INFO -  Starting GOLD step: population_health_metrics
18:40:23 - PipelineRunner - ERROR -  Failed GOLD step: patient_risk_scores (0.00s) - 'DataFrame' object has no attribute 'risk_score_sum'. Available columns: patient_id, full_name, age, age_group, gender, insurance_provider, total_labs, abnormal_labs, critical_labs, patient_id, total_labs, abnormal_labs, critical_labs
18:40:23 - DataValidation - INFO - Validation completed for pipeline.population_health_metrics: 100.0% valid
18:40:23 - PipelineRunner - INFO -  Completed GOLD step: population_health_metrics (0.00s) - 0 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:23 - PipelineRunner - ERROR - Exception executing step patient_risk_scores: Step execution failed: 'DataFrame' object has no attribute 'risk_score_sum'. Available columns: patient_id, full_name, age, age_group, gender, insurance_provider, total_labs, abnormal_labs, critical_labs, patient_id, total_labs, abnormal_labs, critical_labs
18:40:23 - PipelineRunner - INFO - Group 3 completed in 0.01s
18:40:23 - PipelineRunner - ERROR - Pipeline execution failed: 1 steps failed
18:40:23 - PipelineRunner - INFO - Completed pipeline execution: pipeline_20251218_184022
------------------------------ Captured log call -------------------------------
INFO     PipelineRunner:logging.py:82  PipelineBuilder initialized (schema: bronze)
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_patients
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_labs
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_diagnoses
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_medications
INFO     PipelineRunner:logging.py:82  Added Silver step: clean_patients (source: raw_patients)
INFO     PipelineRunner:logging.py:82  Added Silver step: normalized_labs (source: raw_labs)
INFO     PipelineRunner:logging.py:82  Added Silver step: processed_diagnoses (source: raw_diagnoses)
INFO     PipelineRunner:logging.py:82  Added Gold step: patient_risk_scores (sources: ['clean_patients', 'normalized_labs', 'processed_diagnoses'])
INFO     PipelineRunner:logging.py:82  Added Gold step: population_health_metrics (sources: ['clean_patients', 'normalized_labs', 'processed_diagnoses'])
INFO     PipelineRunner:logging.py:82  Pipeline validation passed
INFO     PipelineRunner:logging.py:82  Pipeline built successfully with 4 bronze, 3 silver, 2 gold steps
INFO     PipelineRunner:logging.py:82 Starting pipeline execution: pipeline_20251218_184022
INFO     PipelineRunner:logging.py:82 Starting dependency analysis with strategy: hybrid
INFO     PipelineRunner:logging.py:82 Dependency analysis completed in 0.00s
INFO     PipelineRunner:logging.py:82 Dependency analysis complete: 3 execution groups, max group size: 4
INFO     PipelineRunner:logging.py:82 Parallel execution enabled with 4 workers
INFO     PipelineRunner:logging.py:82 Executing group 1/3: 4 steps - raw_patients, raw_labs, raw_diagnoses, raw_medications
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_patients
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_labs
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_diagnoses
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_medications
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_patients: 100.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_diagnoses: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_patients (0.20s) - 40 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_diagnoses (0.21s) - 120 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_labs: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_labs (0.23s) - 150 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_medications: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_medications (0.25s) - 160 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82 Group 1 completed in 0.32s
INFO     PipelineRunner:logging.py:82 Executing group 2/3: 3 steps - clean_patients, normalized_labs, processed_diagnoses
INFO     PipelineRunner:logging.py:82  Starting SILVER step: clean_patients
INFO     PipelineRunner:logging.py:82  Starting SILVER step: normalized_labs
INFO     PipelineRunner:logging.py:82  Starting SILVER step: processed_diagnoses
INFO     DataValidation:logging.py:82 Validation completed for pipeline.normalized_labs: 0.0% valid
INFO     PipelineRunner:logging.py:82  Completed SILVER step: normalized_labs (0.57s) - 0 rows processed, 0 rows written, 150 invalid, 0.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.processed_diagnoses: 0.0% valid
INFO     PipelineRunner:logging.py:82  Completed SILVER step: processed_diagnoses (0.55s) - 0 rows processed, 0 rows written, 120 invalid, 0.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.clean_patients: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed SILVER step: clean_patients (0.61s) - 40 rows processed, 40 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82 Group 2 completed in 0.61s
INFO     PipelineRunner:logging.py:82 Executing group 3/3: 2 steps - patient_risk_scores, population_health_metrics
INFO     PipelineRunner:logging.py:82  Starting GOLD step: patient_risk_scores
INFO     PipelineRunner:logging.py:82  Starting GOLD step: population_health_metrics
ERROR    PipelineRunner:logging.py:92  Failed GOLD step: patient_risk_scores (0.00s) - 'DataFrame' object has no attribute 'risk_score_sum'. Available columns: patient_id, full_name, age, age_group, gender, insurance_provider, total_labs, abnormal_labs, critical_labs, patient_id, total_labs, abnormal_labs, critical_labs
INFO     DataValidation:logging.py:82 Validation completed for pipeline.population_health_metrics: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed GOLD step: population_health_metrics (0.00s) - 0 rows processed, 0 rows written, 0 invalid, 100.0% valid
ERROR    PipelineRunner:logging.py:92 Exception executing step patient_risk_scores: Step execution failed: 'DataFrame' object has no attribute 'risk_score_sum'. Available columns: patient_id, full_name, age, age_group, gender, insurance_provider, total_labs, abnormal_labs, critical_labs, patient_id, total_labs, abnormal_labs, critical_labs
INFO     PipelineRunner:logging.py:82 Group 3 completed in 0.01s
ERROR    PipelineRunner:logging.py:92 Pipeline execution failed: 1 steps failed
INFO     PipelineRunner:logging.py:82 Completed pipeline execution: pipeline_20251218_184022
--------------------------- Captured stdout teardown ---------------------------
 Mock Spark session cleanup completed
_______ TestMarketingPipeline.test_complete_marketing_pipeline_execution _______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python
tests/builder_tests/test_marketing_pipeline.py:529: in test_complete_marketing_pipeline_execution
    assert result.status.value == "completed" or result.success
E   AssertionError: assert ('failed' == 'completed'
E     
E     - completed
E     + failed or False)
E    +  where False = PipelineReport(pipeline_id='pipeline_20251218_184026', execution_id='8b8f8f13-52a4-47d6-89c9-aa24fa62fd5b', mode=<PipelineMode.INITIAL: 'initial'>, status=<PipelineStatus.FAILED: 'failed'>, start_time=datetime.datetime(2025, 12, 18, 18, 40, 26, 135334), end_time=datetime.datetime(2025, 12, 18, 18, 40, 27, 300666), duration_seconds=1.165332, metrics=PipelineMetrics(total_steps=8, successful_steps=5, failed_steps=3, skipped_steps=0, total_duration=1.165332, bronze_duration=0.19214399999999998, silver_duration=1.6490299999999998, gold_duration=1e-06, total_rows_processed=250, total_rows_written=0, avg_validation_rate=0.0, parallel_efficiency=39.50107228459694, cache_hit_rate=0.0, error_count=0, retry_count=0), bronze_results={'raw_clicks': {'status': 'completed', 'duration': 0.063292, 'rows_processed': 60, 'output_table': None, 'start_time': '2025-12-18T18:40:26.140496', 'end_time': '2025-12-18T18:40:26.203788', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': 60}, 'raw_impressions': {'status': 'completed', 'duration': 0.066198, 'rows_processed': 150, 'output_table': None, 'start_time': '2025-12-18T18:40:26.139299', 'end_time': '2025-12-18T18:40:26.2...on_rate': 0.0, 'rows_written': 0, 'input_rows': 0}}, gold_results={'campaign_performance': {'status': 'failed', 'duration': 0.0, 'rows_processed': None, 'output_table': None, 'start_time': '2025-12-18T18:40:27.300553', 'end_time': '2025-12-18T18:40:27.300553', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': None, 'error': 'Step execution failed: Source silver processed_impressions not found in context'}, 'customer_journey': {'status': 'failed', 'duration': 1e-06, 'rows_processed': None, 'output_table': None, 'start_time': '2025-12-18T18:40:27.300584', 'end_time': '2025-12-18T18:40:27.300585', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': None, 'error': 'Step execution failed: Source silver processed_impressions not found in context'}}, errors=['Step execution failed: invalid series dtype: expected `String`, got `datetime[s]` for series with name `impression_date_parsed`', 'Step execution failed: Source silver processed_impressions not found in context', 'Step execution failed: Source silver processed_impressions not found in context'], warnings=[], recommendations=[], execution_groups_count=3, max_group_size=3).success
---------------------------- Captured stdout setup -----------------------------
 Creating Mock Spark session for all tests
 Test database created successfully
----------------------------- Captured stdout call -----------------------------
18:40:26 - PipelineRunner - INFO -  PipelineBuilder initialized (schema: bronze)
18:40:26 - PipelineRunner - INFO -  Added Bronze step: raw_impressions
18:40:26 - PipelineRunner - INFO -  Added Bronze step: raw_clicks
18:40:26 - PipelineRunner - INFO -  Added Bronze step: raw_conversions
18:40:26 - PipelineRunner - INFO -  Added Silver step: processed_impressions (source: raw_impressions)
18:40:26 - PipelineRunner - INFO -  Added Silver step: processed_clicks (source: raw_clicks)
18:40:26 - PipelineRunner - INFO -  Added Silver step: processed_conversions (source: raw_conversions)
18:40:26 - PipelineRunner - INFO -  Added Gold step: campaign_performance (sources: ['processed_impressions', 'processed_clicks', 'processed_conversions'])
18:40:26 - PipelineRunner - INFO -  Added Gold step: customer_journey (sources: ['processed_impressions', 'processed_clicks', 'processed_conversions'])
18:40:26 - PipelineRunner - INFO -  Pipeline validation passed
18:40:26 - PipelineRunner - INFO -  Pipeline built successfully with 3 bronze, 3 silver, 2 gold steps
18:40:26 - PipelineRunner - INFO - Starting pipeline execution: pipeline_20251218_184026
18:40:26 - PipelineRunner - INFO - Starting dependency analysis with strategy: hybrid
18:40:26 - PipelineRunner - INFO - Dependency analysis completed in 0.00s
18:40:26 - PipelineRunner - INFO - Dependency analysis complete: 3 execution groups, max group size: 3
18:40:26 - PipelineRunner - INFO - Parallel execution enabled with 4 workers
18:40:26 - PipelineRunner - INFO - Executing group 1/3: 3 steps - raw_impressions, raw_clicks, raw_conversions
18:40:26 - PipelineRunner - INFO -  Starting BRONZE step: raw_impressions
18:40:26 - PipelineRunner - INFO -  Starting BRONZE step: raw_clicks
18:40:26 - PipelineRunner - INFO -  Starting BRONZE step: raw_conversions
18:40:26 - DataValidation - INFO - Validation completed for pipeline.raw_clicks: 100.0% valid
18:40:26 - DataValidation - INFO - Validation completed for pipeline.raw_impressions: 100.0% valid
18:40:26 - DataValidation - INFO - Validation completed for pipeline.raw_conversions: 100.0% valid
18:40:26 - PipelineRunner - INFO -  Completed BRONZE step: raw_clicks (0.06s) - 60 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:26 - PipelineRunner - INFO -  Completed BRONZE step: raw_impressions (0.07s) - 150 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:26 - PipelineRunner - INFO -  Completed BRONZE step: raw_conversions (0.06s) - 40 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:26 - PipelineRunner - INFO - Group 1 completed in 0.08s
18:40:26 - PipelineRunner - INFO - Executing group 2/3: 3 steps - processed_impressions, processed_clicks, processed_conversions
18:40:26 - PipelineRunner - INFO -  Starting SILVER step: processed_impressions
18:40:26 - PipelineRunner - INFO -  Starting SILVER step: processed_clicks
18:40:26 - PipelineRunner - INFO -  Starting SILVER step: processed_conversions
18:40:26 - DataValidation - INFO - Validation completed for pipeline.processed_clicks: 0.0% valid
18:40:26 - PipelineRunner - INFO -  Completed SILVER step: processed_clicks (0.65s) - 0 rows processed, 0 rows written, 60 invalid, 0.0% valid
18:40:27 - PipelineRunner - ERROR -  Failed SILVER step: processed_impressions (0.78s) - invalid series dtype: expected `String`, got `datetime[s]` for series with name `impression_date_parsed`
18:40:27 - PipelineRunner - ERROR - Exception executing step processed_impressions: Step execution failed: invalid series dtype: expected `String`, got `datetime[s]` for series with name `impression_date_parsed`
18:40:27 - DataValidation - INFO - Validation completed for pipeline.processed_conversions: 0.0% valid
18:40:27 - PipelineRunner - INFO -  Completed SILVER step: processed_conversions (1.00s) - 0 rows processed, 0 rows written, 40 invalid, 0.0% valid
18:40:27 - PipelineRunner - INFO - Group 2 completed in 1.09s
18:40:27 - PipelineRunner - INFO - Executing group 3/3: 2 steps - campaign_performance, customer_journey
18:40:27 - PipelineRunner - INFO -  Starting GOLD step: campaign_performance
18:40:27 - PipelineRunner - ERROR -  Failed GOLD step: campaign_performance (0.00s) - Source silver processed_impressions not found in context
18:40:27 - PipelineRunner - INFO -  Starting GOLD step: customer_journey
18:40:27 - PipelineRunner - ERROR -  Failed GOLD step: customer_journey (0.00s) - Source silver processed_impressions not found in context
18:40:27 - PipelineRunner - ERROR - Exception executing step campaign_performance: Step execution failed: Source silver processed_impressions not found in context
18:40:27 - PipelineRunner - ERROR - Exception executing step customer_journey: Step execution failed: Source silver processed_impressions not found in context
18:40:27 - PipelineRunner - INFO - Group 3 completed in 0.00s
18:40:27 - PipelineRunner - ERROR - Pipeline execution failed: 3 steps failed
18:40:27 - PipelineRunner - INFO - Completed pipeline execution: pipeline_20251218_184026
------------------------------ Captured log call -------------------------------
INFO     PipelineRunner:logging.py:82  PipelineBuilder initialized (schema: bronze)
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_impressions
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_clicks
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_conversions
INFO     PipelineRunner:logging.py:82  Added Silver step: processed_impressions (source: raw_impressions)
INFO     PipelineRunner:logging.py:82  Added Silver step: processed_clicks (source: raw_clicks)
INFO     PipelineRunner:logging.py:82  Added Silver step: processed_conversions (source: raw_conversions)
INFO     PipelineRunner:logging.py:82  Added Gold step: campaign_performance (sources: ['processed_impressions', 'processed_clicks', 'processed_conversions'])
INFO     PipelineRunner:logging.py:82  Added Gold step: customer_journey (sources: ['processed_impressions', 'processed_clicks', 'processed_conversions'])
INFO     PipelineRunner:logging.py:82  Pipeline validation passed
INFO     PipelineRunner:logging.py:82  Pipeline built successfully with 3 bronze, 3 silver, 2 gold steps
INFO     PipelineRunner:logging.py:82 Starting pipeline execution: pipeline_20251218_184026
INFO     PipelineRunner:logging.py:82 Starting dependency analysis with strategy: hybrid
INFO     PipelineRunner:logging.py:82 Dependency analysis completed in 0.00s
INFO     PipelineRunner:logging.py:82 Dependency analysis complete: 3 execution groups, max group size: 3
INFO     PipelineRunner:logging.py:82 Parallel execution enabled with 4 workers
INFO     PipelineRunner:logging.py:82 Executing group 1/3: 3 steps - raw_impressions, raw_clicks, raw_conversions
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_impressions
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_clicks
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_conversions
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_clicks: 100.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_impressions: 100.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_conversions: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_clicks (0.06s) - 60 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_impressions (0.07s) - 150 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_conversions (0.06s) - 40 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82 Group 1 completed in 0.08s
INFO     PipelineRunner:logging.py:82 Executing group 2/3: 3 steps - processed_impressions, processed_clicks, processed_conversions
INFO     PipelineRunner:logging.py:82  Starting SILVER step: processed_impressions
INFO     PipelineRunner:logging.py:82  Starting SILVER step: processed_clicks
INFO     PipelineRunner:logging.py:82  Starting SILVER step: processed_conversions
INFO     DataValidation:logging.py:82 Validation completed for pipeline.processed_clicks: 0.0% valid
INFO     PipelineRunner:logging.py:82  Completed SILVER step: processed_clicks (0.65s) - 0 rows processed, 0 rows written, 60 invalid, 0.0% valid
ERROR    PipelineRunner:logging.py:92  Failed SILVER step: processed_impressions (0.78s) - invalid series dtype: expected `String`, got `datetime[s]` for series with name `impression_date_parsed`
ERROR    PipelineRunner:logging.py:92 Exception executing step processed_impressions: Step execution failed: invalid series dtype: expected `String`, got `datetime[s]` for series with name `impression_date_parsed`
INFO     DataValidation:logging.py:82 Validation completed for pipeline.processed_conversions: 0.0% valid
INFO     PipelineRunner:logging.py:82  Completed SILVER step: processed_conversions (1.00s) - 0 rows processed, 0 rows written, 40 invalid, 0.0% valid
INFO     PipelineRunner:logging.py:82 Group 2 completed in 1.09s
INFO     PipelineRunner:logging.py:82 Executing group 3/3: 2 steps - campaign_performance, customer_journey
INFO     PipelineRunner:logging.py:82  Starting GOLD step: campaign_performance
ERROR    PipelineRunner:logging.py:92  Failed GOLD step: campaign_performance (0.00s) - Source silver processed_impressions not found in context
INFO     PipelineRunner:logging.py:82  Starting GOLD step: customer_journey
ERROR    PipelineRunner:logging.py:92  Failed GOLD step: customer_journey (0.00s) - Source silver processed_impressions not found in context
ERROR    PipelineRunner:logging.py:92 Exception executing step campaign_performance: Step execution failed: Source silver processed_impressions not found in context
ERROR    PipelineRunner:logging.py:92 Exception executing step customer_journey: Step execution failed: Source silver processed_impressions not found in context
INFO     PipelineRunner:logging.py:82 Group 3 completed in 0.00s
ERROR    PipelineRunner:logging.py:92 Pipeline execution failed: 3 steps failed
INFO     PipelineRunner:logging.py:82 Completed pipeline execution: pipeline_20251218_184026
--------------------------- Captured stdout teardown ---------------------------
 Mock Spark session cleanup completed
___________ TestValidationPropertyBased.test_safe_divide_properties ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python
tests/unit/test_validation_property_based.py:22: in test_safe_divide_properties
    numerator=st.floats(
           ^^^^^^^
E   hypothesis.errors.FailedHealthCheck: Input generation is slow: Hypothesis only generated 2 valid inputs after 1.28 seconds.
E   
E                     count | fraction |    slowest draws (seconds)
E     default_value |    2  |    100%  |      --      --      --      --   1.282
E       numerator   |    2  |      0%  |      --      --      --      --      -- 
E      denominator  |    2  |      0%  |      --      --      --      --      -- 
E   
E   This could be for a few reasons:
E   1. This strategy could be generating too much data per input. Try decreasing the amount of data generated, for example by decreasing the minimum size of collection strategies like st.lists().
E   2. Some other expensive computation could be running during input generation. For example, if @st.composite or st.data() is interspersed with an expensive computation, HealthCheck.too_slow is likely to trigger. If this computation is unrelated to input generation, move it elsewhere. Otherwise, try making it more efficient, or disable this health check if that is not possible.
E   
E   If you expect input generation to take this long, you can disable this health check with @settings(suppress_health_check=[HealthCheck.too_slow]). See https://hypothesis.readthedocs.io/en/latest/reference/api.html#hypothesis.HealthCheck for details.
---------------------------------- Hypothesis ----------------------------------
You can add @seed(155316133055221154274359500140549499527) to this test or run pytest with --hypothesis-seed=155316133055221154274359500140549499527 to reproduce this failure.
_ TestStreamingHybridPipeline.test_complete_streaming_hybrid_pipeline_execution _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python
tests/builder_tests/test_streaming_hybrid_pipeline.py:509: in test_complete_streaming_hybrid_pipeline_execution
    assert result.status.value == "completed" or result.success
E   AssertionError: assert ('failed' == 'completed'
E     
E     - completed
E     + failed or False)
E    +  where False = PipelineReport(pipeline_id='pipeline_20251218_184028', execution_id='cdf87675-0dc4-47f5-be7e-cbaed00ff951', mode=<PipelineMode.INITIAL: 'initial'>, status=<PipelineStatus.FAILED: 'failed'>, start_time=datetime.datetime(2025, 12, 18, 18, 40, 28, 338971), end_time=datetime.datetime(2025, 12, 18, 18, 40, 34, 74676), duration_seconds=5.735705, metrics=PipelineMetrics(total_steps=6, successful_steps=2, failed_steps=4, skipped_steps=0, total_duration=5.735705, bronze_duration=0.100022, silver_duration=1e-06, gold_duration=1e-06, total_rows_processed=180, total_rows_written=0, avg_validation_rate=0.0, parallel_efficiency=0.435975986625374, cache_hit_rate=0.0, error_count=0, retry_count=0), bronze_results={'raw_streaming_events': {'status': 'completed', 'duration': 0.040012, 'rows_processed': 80, 'output_table': None, 'start_time': '2025-12-18T18:40:28.366683', 'end_time': '2025-12-18T18:40:28.406695', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': 80}, 'raw_batch_history': {'status': 'completed', 'duration': 0.06001, 'rows_processed': 100, 'output_table': None, 'start_time': '2025-12-18T18:40:28.349165', 'end_time': '2025-12-18T18:40:28.409175', 'write...cessed': None, 'output_table': None, 'start_time': '2025-12-18T18:40:34.074499', 'end_time': '2025-12-18T18:40:34.074499', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': None, 'error': 'Step execution failed: Source silver unified_batch_events not found in context'}, 'real_time_sessions': {'status': 'failed', 'duration': 1e-06, 'rows_processed': None, 'output_table': None, 'start_time': '2025-12-18T18:40:34.074604', 'end_time': '2025-12-18T18:40:34.074605', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': None, 'error': 'Step execution failed: Source silver unified_streaming_events not found in context'}}, errors=['Step execution failed: invalid series dtype: expected `String`, got `datetime[s]` for series with name `event_timestamp_parsed`', 'Step execution failed: invalid series dtype: expected `String`, got `datetime[s]` for series with name `event_timestamp_parsed`', 'Step execution failed: Source silver unified_batch_events not found in context', 'Step execution failed: Source silver unified_streaming_events not found in context'], warnings=[], recommendations=[], execution_groups_count=3, max_group_size=2).success
---------------------------- Captured stdout setup -----------------------------
 Creating Mock Spark session for all tests
 Test database created successfully
----------------------------- Captured stdout call -----------------------------
18:40:28 - PipelineRunner - INFO -  PipelineBuilder initialized (schema: bronze)
18:40:28 - PipelineRunner - INFO -  Added Bronze step: raw_batch_history
18:40:28 - PipelineRunner - INFO -  Added Bronze step: raw_streaming_events
18:40:28 - PipelineRunner - INFO -  Added Silver step: unified_batch_events (source: raw_batch_history)
18:40:28 - PipelineRunner - INFO -  Added Silver step: unified_streaming_events (source: raw_streaming_events)
18:40:28 - PipelineRunner - INFO -  Added Gold step: unified_analytics (sources: ['unified_batch_events', 'unified_streaming_events'])
18:40:28 - PipelineRunner - INFO -  Added Gold step: real_time_sessions (sources: ['unified_streaming_events'])
18:40:28 - PipelineRunner - INFO -  Pipeline validation passed
18:40:28 - PipelineRunner - INFO -  Pipeline built successfully with 2 bronze, 2 silver, 2 gold steps
18:40:28 - PipelineRunner - INFO - Starting pipeline execution: pipeline_20251218_184028
18:40:28 - PipelineRunner - INFO - Starting dependency analysis with strategy: hybrid
18:40:28 - PipelineRunner - INFO - Dependency analysis completed in 0.00s
18:40:28 - PipelineRunner - INFO - Dependency analysis complete: 3 execution groups, max group size: 2
18:40:28 - PipelineRunner - INFO - Parallel execution enabled with 4 workers
18:40:28 - PipelineRunner - INFO - Executing group 1/3: 2 steps - raw_batch_history, raw_streaming_events
18:40:28 - PipelineRunner - INFO -  Starting BRONZE step: raw_batch_history
18:40:28 - PipelineRunner - INFO -  Starting BRONZE step: raw_streaming_events
18:40:28 - DataValidation - INFO - Validation completed for pipeline.raw_streaming_events: 100.0% valid
18:40:28 - DataValidation - INFO - Validation completed for pipeline.raw_batch_history: 100.0% valid
18:40:28 - PipelineRunner - INFO -  Completed BRONZE step: raw_streaming_events (0.04s) - 80 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:28 - PipelineRunner - INFO -  Completed BRONZE step: raw_batch_history (0.06s) - 100 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:28 - PipelineRunner - INFO - Group 1 completed in 0.07s
18:40:28 - PipelineRunner - INFO - Executing group 2/3: 2 steps - unified_batch_events, unified_streaming_events
18:40:28 - PipelineRunner - INFO -  Starting SILVER step: unified_batch_events
18:40:28 - PipelineRunner - INFO -  Starting SILVER step: unified_streaming_events
18:40:34 - PipelineRunner - ERROR -  Failed SILVER step: unified_batch_events (5.66s) - invalid series dtype: expected `String`, got `datetime[s]` for series with name `event_timestamp_parsed`
18:40:34 - PipelineRunner - ERROR -  Failed SILVER step: unified_streaming_events (5.66s) - invalid series dtype: expected `String`, got `datetime[s]` for series with name `event_timestamp_parsed`
18:40:34 - PipelineRunner - ERROR - Exception executing step unified_batch_events: Step execution failed: invalid series dtype: expected `String`, got `datetime[s]` for series with name `event_timestamp_parsed`
18:40:34 - PipelineRunner - ERROR - Exception executing step unified_streaming_events: Step execution failed: invalid series dtype: expected `String`, got `datetime[s]` for series with name `event_timestamp_parsed`
18:40:34 - PipelineRunner - INFO - Group 2 completed in 5.66s
18:40:34 - PipelineRunner - INFO - Executing group 3/3: 2 steps - unified_analytics, real_time_sessions
18:40:34 - PipelineRunner - INFO -  Starting GOLD step: unified_analytics
18:40:34 - PipelineRunner - ERROR -  Failed GOLD step: unified_analytics (0.00s) - Source silver unified_batch_events not found in context
18:40:34 - PipelineRunner - ERROR - Exception executing step unified_analytics: Step execution failed: Source silver unified_batch_events not found in context
18:40:34 - PipelineRunner - INFO -  Starting GOLD step: real_time_sessions
18:40:34 - PipelineRunner - ERROR -  Failed GOLD step: real_time_sessions (0.00s) - Source silver unified_streaming_events not found in context
18:40:34 - PipelineRunner - ERROR - Exception executing step real_time_sessions: Step execution failed: Source silver unified_streaming_events not found in context
18:40:34 - PipelineRunner - INFO - Group 3 completed in 0.00s
18:40:34 - PipelineRunner - ERROR - Pipeline execution failed: 4 steps failed
18:40:34 - PipelineRunner - INFO - Completed pipeline execution: pipeline_20251218_184028
------------------------------ Captured log call -------------------------------
INFO     PipelineRunner:logging.py:82  PipelineBuilder initialized (schema: bronze)
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_batch_history
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_streaming_events
INFO     PipelineRunner:logging.py:82  Added Silver step: unified_batch_events (source: raw_batch_history)
INFO     PipelineRunner:logging.py:82  Added Silver step: unified_streaming_events (source: raw_streaming_events)
INFO     PipelineRunner:logging.py:82  Added Gold step: unified_analytics (sources: ['unified_batch_events', 'unified_streaming_events'])
INFO     PipelineRunner:logging.py:82  Added Gold step: real_time_sessions (sources: ['unified_streaming_events'])
INFO     PipelineRunner:logging.py:82  Pipeline validation passed
INFO     PipelineRunner:logging.py:82  Pipeline built successfully with 2 bronze, 2 silver, 2 gold steps
INFO     PipelineRunner:logging.py:82 Starting pipeline execution: pipeline_20251218_184028
INFO     PipelineRunner:logging.py:82 Starting dependency analysis with strategy: hybrid
INFO     PipelineRunner:logging.py:82 Dependency analysis completed in 0.00s
INFO     PipelineRunner:logging.py:82 Dependency analysis complete: 3 execution groups, max group size: 2
INFO     PipelineRunner:logging.py:82 Parallel execution enabled with 4 workers
INFO     PipelineRunner:logging.py:82 Executing group 1/3: 2 steps - raw_batch_history, raw_streaming_events
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_batch_history
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_streaming_events
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_streaming_events: 100.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_batch_history: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_streaming_events (0.04s) - 80 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_batch_history (0.06s) - 100 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82 Group 1 completed in 0.07s
INFO     PipelineRunner:logging.py:82 Executing group 2/3: 2 steps - unified_batch_events, unified_streaming_events
INFO     PipelineRunner:logging.py:82  Starting SILVER step: unified_batch_events
INFO     PipelineRunner:logging.py:82  Starting SILVER step: unified_streaming_events
ERROR    PipelineRunner:logging.py:92  Failed SILVER step: unified_batch_events (5.66s) - invalid series dtype: expected `String`, got `datetime[s]` for series with name `event_timestamp_parsed`
ERROR    PipelineRunner:logging.py:92  Failed SILVER step: unified_streaming_events (5.66s) - invalid series dtype: expected `String`, got `datetime[s]` for series with name `event_timestamp_parsed`
ERROR    PipelineRunner:logging.py:92 Exception executing step unified_batch_events: Step execution failed: invalid series dtype: expected `String`, got `datetime[s]` for series with name `event_timestamp_parsed`
ERROR    PipelineRunner:logging.py:92 Exception executing step unified_streaming_events: Step execution failed: invalid series dtype: expected `String`, got `datetime[s]` for series with name `event_timestamp_parsed`
INFO     PipelineRunner:logging.py:82 Group 2 completed in 5.66s
INFO     PipelineRunner:logging.py:82 Executing group 3/3: 2 steps - unified_analytics, real_time_sessions
INFO     PipelineRunner:logging.py:82  Starting GOLD step: unified_analytics
ERROR    PipelineRunner:logging.py:92  Failed GOLD step: unified_analytics (0.00s) - Source silver unified_batch_events not found in context
ERROR    PipelineRunner:logging.py:92 Exception executing step unified_analytics: Step execution failed: Source silver unified_batch_events not found in context
INFO     PipelineRunner:logging.py:82  Starting GOLD step: real_time_sessions
ERROR    PipelineRunner:logging.py:92  Failed GOLD step: real_time_sessions (0.00s) - Source silver unified_streaming_events not found in context
ERROR    PipelineRunner:logging.py:92 Exception executing step real_time_sessions: Step execution failed: Source silver unified_streaming_events not found in context
INFO     PipelineRunner:logging.py:82 Group 3 completed in 0.00s
ERROR    PipelineRunner:logging.py:92 Pipeline execution failed: 4 steps failed
INFO     PipelineRunner:logging.py:82 Completed pipeline execution: pipeline_20251218_184028
--------------------------- Captured stdout teardown ---------------------------
 Mock Spark session cleanup completed
____ TestSupplyChainPipeline.test_complete_supply_chain_pipeline_execution _____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python
tests/builder_tests/test_supply_chain_pipeline.py:445: in test_complete_supply_chain_pipeline_execution
    assert result.status.value == "completed" or result.success
E   assert ('failed' == 'completed'
E     
E     - completed
E     + failed or False)
E    +  where False = PipelineReport(pipeline_id='pipeline_20251218_184034', execution_id='1706fbe8-b641-401b-8cbf-fcadaa9be620', mode=<PipelineMode.INITIAL: 'initial'>, status=<PipelineStatus.FAILED: 'failed'>, start_time=datetime.datetime(2025, 12, 18, 18, 40, 34, 96189), end_time=datetime.datetime(2025, 12, 18, 18, 40, 34, 506232), duration_seconds=0.410043, metrics=PipelineMetrics(total_steps=8, successful_steps=6, failed_steps=2, skipped_steps=0, total_duration=0.410043, bronze_duration=0.030508, silver_duration=0.552578, gold_duration=0.000686, total_rows_processed=330, total_rows_written=0, avg_validation_rate=0.0, parallel_efficiency=35.596982343342596, cache_hit_rate=0.0, error_count=0, retry_count=0), bronze_results={'raw_shipments': {'status': 'completed', 'duration': 0.00978, 'rows_processed': 100, 'output_table': None, 'start_time': '2025-12-18T18:40:34.097279', 'end_time': '2025-12-18T18:40:34.107059', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': 100}, 'raw_orders': {'status': 'completed', 'duration': 0.010914, 'rows_processed': 80, 'output_table': None, 'start_time': '2025-12-18T18:40:34.096460', 'end_time': '2025-12-18T18:40:34.107374', 'write_mode'...': 0.0, 'rows_written': 0, 'input_rows': 0}}, gold_results={'delivery_performance': {'status': 'completed', 'duration': 0.000685, 'rows_processed': 0, 'output_table': 'bronze.delivery_performance', 'start_time': '2025-12-18T18:40:34.505279', 'end_time': '2025-12-18T18:40:34.505964', 'write_mode': 'overwrite', 'validation_rate': 100.0, 'rows_written': 0, 'input_rows': 0}, 'inventory_turnover': {'status': 'failed', 'duration': 1e-06, 'rows_processed': None, 'output_table': None, 'start_time': '2025-12-18T18:40:34.506170', 'end_time': '2025-12-18T18:40:34.506171', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': None, 'error': 'Step execution failed: Source silver processed_inventory not found in context'}}, errors=["Step execution failed: 'DataFrame' object has no attribute 'snapshot_date'. Available columns: inventory_id, product_id, warehouse_id, snapshot_date_parsed, quantity_on_hand, quantity_reserved, available_quantity, reorder_point, max_stock, is_low_stock, is_overstocked, stock_level", 'Step execution failed: Source silver processed_inventory not found in context'], warnings=[], recommendations=[], execution_groups_count=3, max_group_size=3).success
---------------------------- Captured stdout setup -----------------------------
 Creating Mock Spark session for all tests
 Test database created successfully
----------------------------- Captured stdout call -----------------------------
18:40:34 - PipelineRunner - INFO -  PipelineBuilder initialized (schema: bronze)
18:40:34 - PipelineRunner - INFO -  Added Bronze step: raw_orders
18:40:34 - PipelineRunner - INFO -  Added Bronze step: raw_shipments
18:40:34 - PipelineRunner - INFO -  Added Bronze step: raw_inventory
18:40:34 - PipelineRunner - INFO -  Added Silver step: processed_orders (source: raw_orders)
18:40:34 - PipelineRunner - INFO -  Added Silver step: processed_shipments (source: raw_shipments)
18:40:34 - PipelineRunner - INFO -  Added Silver step: processed_inventory (source: raw_inventory)
18:40:34 - PipelineRunner - INFO -  Added Gold step: delivery_performance (sources: ['processed_orders', 'processed_shipments'])
18:40:34 - PipelineRunner - INFO -  Added Gold step: inventory_turnover (sources: ['processed_orders', 'processed_inventory'])
18:40:34 - PipelineRunner - INFO -  Pipeline validation passed
18:40:34 - PipelineRunner - INFO -  Pipeline built successfully with 3 bronze, 3 silver, 2 gold steps
18:40:34 - PipelineRunner - INFO - Starting pipeline execution: pipeline_20251218_184034
18:40:34 - PipelineRunner - INFO - Starting dependency analysis with strategy: hybrid
18:40:34 - PipelineRunner - INFO - Dependency analysis completed in 0.00s
18:40:34 - PipelineRunner - INFO - Dependency analysis complete: 3 execution groups, max group size: 3
18:40:34 - PipelineRunner - INFO - Parallel execution enabled with 4 workers
18:40:34 - PipelineRunner - INFO - Executing group 1/3: 3 steps - raw_orders, raw_shipments, raw_inventory
18:40:34 - PipelineRunner - INFO -  Starting BRONZE step: raw_orders
18:40:34 - PipelineRunner - INFO -  Starting BRONZE step: raw_shipments
18:40:34 - PipelineRunner - INFO -  Starting BRONZE step: raw_inventory
18:40:34 - DataValidation - INFO - Validation completed for pipeline.raw_orders: 100.0% valid
18:40:34 - DataValidation - INFO - Validation completed for pipeline.raw_shipments: 100.0% valid
18:40:34 - DataValidation - INFO - Validation completed for pipeline.raw_inventory: 100.0% valid
18:40:34 - PipelineRunner - INFO -  Completed BRONZE step: raw_shipments (0.01s) - 100 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:34 - PipelineRunner - INFO -  Completed BRONZE step: raw_orders (0.01s) - 80 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:34 - PipelineRunner - INFO -  Completed BRONZE step: raw_inventory (0.01s) - 150 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:34 - PipelineRunner - INFO - Group 1 completed in 0.01s
18:40:34 - PipelineRunner - INFO - Executing group 2/3: 3 steps - processed_orders, processed_shipments, processed_inventory
18:40:34 - PipelineRunner - INFO -  Starting SILVER step: processed_orders
18:40:34 - PipelineRunner - INFO -  Starting SILVER step: processed_shipments
18:40:34 - PipelineRunner - INFO -  Starting SILVER step: processed_inventory
18:40:34 - DataValidation - INFO - Validation completed for pipeline.processed_orders: 0.0% valid
18:40:34 - PipelineRunner - INFO -  Completed SILVER step: processed_orders (0.16s) - 0 rows processed, 0 rows written, 80 invalid, 0.0% valid
18:40:34 - PipelineRunner - ERROR -  Failed SILVER step: processed_inventory (0.22s) - 'DataFrame' object has no attribute 'snapshot_date'. Available columns: inventory_id, product_id, warehouse_id, snapshot_date_parsed, quantity_on_hand, quantity_reserved, available_quantity, reorder_point, max_stock, is_low_stock, is_overstocked, stock_level
18:40:34 - PipelineRunner - ERROR - Exception executing step processed_inventory: Step execution failed: 'DataFrame' object has no attribute 'snapshot_date'. Available columns: inventory_id, product_id, warehouse_id, snapshot_date_parsed, quantity_on_hand, quantity_reserved, available_quantity, reorder_point, max_stock, is_low_stock, is_overstocked, stock_level
18:40:34 - DataValidation - INFO - Validation completed for pipeline.processed_shipments: 0.0% valid
18:40:34 - PipelineRunner - INFO -  Completed SILVER step: processed_shipments (0.40s) - 0 rows processed, 0 rows written, 100 invalid, 0.0% valid
18:40:34 - PipelineRunner - INFO - Group 2 completed in 0.40s
18:40:34 - PipelineRunner - INFO - Executing group 3/3: 2 steps - delivery_performance, inventory_turnover
18:40:34 - PipelineRunner - INFO -  Starting GOLD step: delivery_performance
18:40:34 - DataValidation - INFO - Validation completed for pipeline.delivery_performance: 100.0% valid
18:40:34 - PipelineRunner - INFO -  Completed GOLD step: delivery_performance (0.00s) - 0 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:34 - PipelineRunner - INFO -  Starting GOLD step: inventory_turnover
18:40:34 - PipelineRunner - ERROR -  Failed GOLD step: inventory_turnover (0.00s) - Source silver processed_inventory not found in context
18:40:34 - PipelineRunner - ERROR - Exception executing step inventory_turnover: Step execution failed: Source silver processed_inventory not found in context
18:40:34 - PipelineRunner - INFO - Group 3 completed in 0.00s
18:40:34 - PipelineRunner - ERROR - Pipeline execution failed: 2 steps failed
18:40:34 - PipelineRunner - INFO - Completed pipeline execution: pipeline_20251218_184034
------------------------------ Captured log call -------------------------------
INFO     PipelineRunner:logging.py:82  PipelineBuilder initialized (schema: bronze)
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_orders
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_shipments
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_inventory
INFO     PipelineRunner:logging.py:82  Added Silver step: processed_orders (source: raw_orders)
INFO     PipelineRunner:logging.py:82  Added Silver step: processed_shipments (source: raw_shipments)
INFO     PipelineRunner:logging.py:82  Added Silver step: processed_inventory (source: raw_inventory)
INFO     PipelineRunner:logging.py:82  Added Gold step: delivery_performance (sources: ['processed_orders', 'processed_shipments'])
INFO     PipelineRunner:logging.py:82  Added Gold step: inventory_turnover (sources: ['processed_orders', 'processed_inventory'])
INFO     PipelineRunner:logging.py:82  Pipeline validation passed
INFO     PipelineRunner:logging.py:82  Pipeline built successfully with 3 bronze, 3 silver, 2 gold steps
INFO     PipelineRunner:logging.py:82 Starting pipeline execution: pipeline_20251218_184034
INFO     PipelineRunner:logging.py:82 Starting dependency analysis with strategy: hybrid
INFO     PipelineRunner:logging.py:82 Dependency analysis completed in 0.00s
INFO     PipelineRunner:logging.py:82 Dependency analysis complete: 3 execution groups, max group size: 3
INFO     PipelineRunner:logging.py:82 Parallel execution enabled with 4 workers
INFO     PipelineRunner:logging.py:82 Executing group 1/3: 3 steps - raw_orders, raw_shipments, raw_inventory
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_orders
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_shipments
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_inventory
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_orders: 100.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_shipments: 100.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_inventory: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_shipments (0.01s) - 100 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_orders (0.01s) - 80 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_inventory (0.01s) - 150 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82 Group 1 completed in 0.01s
INFO     PipelineRunner:logging.py:82 Executing group 2/3: 3 steps - processed_orders, processed_shipments, processed_inventory
INFO     PipelineRunner:logging.py:82  Starting SILVER step: processed_orders
INFO     PipelineRunner:logging.py:82  Starting SILVER step: processed_shipments
INFO     PipelineRunner:logging.py:82  Starting SILVER step: processed_inventory
INFO     DataValidation:logging.py:82 Validation completed for pipeline.processed_orders: 0.0% valid
INFO     PipelineRunner:logging.py:82  Completed SILVER step: processed_orders (0.16s) - 0 rows processed, 0 rows written, 80 invalid, 0.0% valid
ERROR    PipelineRunner:logging.py:92  Failed SILVER step: processed_inventory (0.22s) - 'DataFrame' object has no attribute 'snapshot_date'. Available columns: inventory_id, product_id, warehouse_id, snapshot_date_parsed, quantity_on_hand, quantity_reserved, available_quantity, reorder_point, max_stock, is_low_stock, is_overstocked, stock_level
ERROR    PipelineRunner:logging.py:92 Exception executing step processed_inventory: Step execution failed: 'DataFrame' object has no attribute 'snapshot_date'. Available columns: inventory_id, product_id, warehouse_id, snapshot_date_parsed, quantity_on_hand, quantity_reserved, available_quantity, reorder_point, max_stock, is_low_stock, is_overstocked, stock_level
INFO     DataValidation:logging.py:82 Validation completed for pipeline.processed_shipments: 0.0% valid
INFO     PipelineRunner:logging.py:82  Completed SILVER step: processed_shipments (0.40s) - 0 rows processed, 0 rows written, 100 invalid, 0.0% valid
INFO     PipelineRunner:logging.py:82 Group 2 completed in 0.40s
INFO     PipelineRunner:logging.py:82 Executing group 3/3: 2 steps - delivery_performance, inventory_turnover
INFO     PipelineRunner:logging.py:82  Starting GOLD step: delivery_performance
INFO     DataValidation:logging.py:82 Validation completed for pipeline.delivery_performance: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed GOLD step: delivery_performance (0.00s) - 0 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82  Starting GOLD step: inventory_turnover
ERROR    PipelineRunner:logging.py:92  Failed GOLD step: inventory_turnover (0.00s) - Source silver processed_inventory not found in context
ERROR    PipelineRunner:logging.py:92 Exception executing step inventory_turnover: Step execution failed: Source silver processed_inventory not found in context
INFO     PipelineRunner:logging.py:82 Group 3 completed in 0.00s
ERROR    PipelineRunner:logging.py:92 Pipeline execution failed: 2 steps failed
INFO     PipelineRunner:logging.py:82 Completed pipeline execution: pipeline_20251218_184034
--------------------------- Captured stdout teardown ---------------------------
 Mock Spark session cleanup completed
____ TestDataQualityPipeline.test_complete_data_quality_pipeline_execution _____
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python
tests/builder_tests/test_data_quality_pipeline.py:450: in test_complete_data_quality_pipeline_execution
    assert result.status.value == "completed" or result.success
E   assert ('failed' == 'completed'
E     
E     - completed
E     + failed or False)
E    +  where False = PipelineReport(pipeline_id='pipeline_20251218_184022', execution_id='e0f8644a-22a3-4592-a3a1-97464d0e299a', mode=<PipelineMode.INITIAL: 'initial'>, status=<PipelineStatus.FAILED: 'failed'>, start_time=datetime.datetime(2025, 12, 18, 18, 40, 22, 507045), end_time=datetime.datetime(2025, 12, 18, 18, 40, 49, 906227), duration_seconds=27.399182, metrics=PipelineMetrics(total_steps=6, successful_steps=3, failed_steps=3, skipped_steps=0, total_duration=27.399182, bronze_duration=0.26632100000000003, silver_duration=27.237913000000002, gold_duration=2e-06, total_rows_processed=180, total_rows_written=0, avg_validation_rate=0.0, parallel_efficiency=25.09591641919822, cache_hit_rate=0.0, error_count=0, retry_count=0), bronze_results={'raw_source_b': {'status': 'completed', 'duration': 0.124492, 'rows_processed': 100, 'output_table': None, 'start_time': '2025-12-18T18:40:22.532481', 'end_time': '2025-12-18T18:40:22.656973', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': 100}, 'raw_source_a': {'status': 'completed', 'duration': 0.141829, 'rows_processed': 80, 'output_table': None, 'start_time': '2025-12-18T18:40:22.524883', 'end_time': '2025-12-18T18:40:22...6, 'rows_processed': None, 'output_table': None, 'start_time': '2025-12-18T18:40:49.906044', 'end_time': '2025-12-18T18:40:49.906045', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': None, 'error': 'Step execution failed: Source silver normalized_source_b not found in context'}, 'data_quality_metrics': {'status': 'failed', 'duration': 1e-06, 'rows_processed': None, 'output_table': None, 'start_time': '2025-12-18T18:40:49.906166', 'end_time': '2025-12-18T18:40:49.906167', 'write_mode': None, 'validation_rate': 100.0, 'rows_written': None, 'input_rows': None, 'error': 'Step execution failed: Source silver normalized_source_b not found in context'}}, errors=['Step execution failed: unable to find column "transaction_date_parsed"; valid columns: ["id", "customer_id", "date", "amount", "status", "category", "region", "quality_score", "quality_status", "has_null_customer", "has_invalid_amount", "has_empty_category"]', 'Step execution failed: Source silver normalized_source_b not found in context', 'Step execution failed: Source silver normalized_source_b not found in context'], warnings=[], recommendations=[], execution_groups_count=3, max_group_size=2).success
---------------------------- Captured stdout setup -----------------------------
 Creating Mock Spark session for all tests
 Test database created successfully
----------------------------- Captured stdout call -----------------------------
18:40:22 - PipelineRunner - INFO -  PipelineBuilder initialized (schema: bronze)
18:40:22 - PipelineRunner - INFO -  Added Bronze step: raw_source_a
18:40:22 - PipelineRunner - INFO -  Added Bronze step: raw_source_b
18:40:22 - PipelineRunner - INFO -  Added Silver step: normalized_source_a (source: raw_source_a)
18:40:22 - PipelineRunner - INFO -  Added Silver step: normalized_source_b (source: raw_source_b)
18:40:22 - PipelineRunner - INFO -  Added Gold step: data_quality_metrics (sources: ['normalized_source_a', 'normalized_source_b'])
18:40:22 - PipelineRunner - INFO -  Added Gold step: source_reconciliation (sources: ['normalized_source_a', 'normalized_source_b'])
18:40:22 - PipelineRunner - INFO -  Pipeline validation passed
18:40:22 - PipelineRunner - INFO -  Pipeline built successfully with 2 bronze, 2 silver, 2 gold steps
18:40:22 - PipelineRunner - INFO - Starting pipeline execution: pipeline_20251218_184022
18:40:22 - PipelineRunner - INFO - Starting dependency analysis with strategy: hybrid
18:40:22 - PipelineRunner - INFO - Dependency analysis completed in 0.00s
18:40:22 - PipelineRunner - INFO - Dependency analysis complete: 3 execution groups, max group size: 2
18:40:22 - PipelineRunner - INFO - Parallel execution enabled with 4 workers
18:40:22 - PipelineRunner - INFO - Executing group 1/3: 2 steps - raw_source_a, raw_source_b
18:40:22 - PipelineRunner - INFO -  Starting BRONZE step: raw_source_a
18:40:22 - PipelineRunner - INFO -  Starting BRONZE step: raw_source_b
18:40:22 - DataValidation - INFO - Validation completed for pipeline.raw_source_b: 100.0% valid
18:40:22 - PipelineRunner - INFO -  Completed BRONZE step: raw_source_b (0.12s) - 100 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:22 - DataValidation - INFO - Validation completed for pipeline.raw_source_a: 100.0% valid
18:40:22 - PipelineRunner - INFO -  Completed BRONZE step: raw_source_a (0.14s) - 80 rows processed, 0 rows written, 0 invalid, 100.0% valid
18:40:22 - PipelineRunner - INFO - Group 1 completed in 0.16s
18:40:22 - PipelineRunner - INFO - Executing group 2/3: 2 steps - normalized_source_a, normalized_source_b
18:40:22 - PipelineRunner - INFO -  Starting SILVER step: normalized_source_a
18:40:22 - PipelineRunner - INFO -  Starting SILVER step: normalized_source_b
18:40:33 - PipelineRunner - ERROR -  Failed SILVER step: normalized_source_b (10.77s) - unable to find column "transaction_date_parsed"; valid columns: ["id", "customer_id", "date", "amount", "status", "category", "region", "quality_score", "quality_status", "has_null_customer", "has_invalid_amount", "has_empty_category"]
18:40:33 - PipelineRunner - ERROR - Exception executing step normalized_source_b: Step execution failed: unable to find column "transaction_date_parsed"; valid columns: ["id", "customer_id", "date", "amount", "status", "category", "region", "quality_score", "quality_status", "has_null_customer", "has_invalid_amount", "has_empty_category"]
18:40:49 - DataValidation - INFO - Validation completed for pipeline.normalized_source_a: 0.0% valid
18:40:49 - PipelineRunner - INFO -  Completed SILVER step: normalized_source_a (27.24s) - 0 rows processed, 0 rows written, 80 invalid, 0.0% valid
18:40:49 - PipelineRunner - INFO - Group 2 completed in 27.24s
18:40:49 - PipelineRunner - INFO - Executing group 3/3: 2 steps - source_reconciliation, data_quality_metrics
18:40:49 - PipelineRunner - INFO -  Starting GOLD step: source_reconciliation
18:40:49 - PipelineRunner - ERROR -  Failed GOLD step: source_reconciliation (0.00s) - Source silver normalized_source_b not found in context
18:40:49 - PipelineRunner - ERROR - Exception executing step source_reconciliation: Step execution failed: Source silver normalized_source_b not found in context
18:40:49 - PipelineRunner - INFO -  Starting GOLD step: data_quality_metrics
18:40:49 - PipelineRunner - ERROR -  Failed GOLD step: data_quality_metrics (0.00s) - Source silver normalized_source_b not found in context
18:40:49 - PipelineRunner - ERROR - Exception executing step data_quality_metrics: Step execution failed: Source silver normalized_source_b not found in context
18:40:49 - PipelineRunner - INFO - Group 3 completed in 0.00s
18:40:49 - PipelineRunner - ERROR - Pipeline execution failed: 3 steps failed
18:40:49 - PipelineRunner - INFO - Completed pipeline execution: pipeline_20251218_184022
------------------------------ Captured log call -------------------------------
INFO     PipelineRunner:logging.py:82  PipelineBuilder initialized (schema: bronze)
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_source_a
INFO     PipelineRunner:logging.py:82  Added Bronze step: raw_source_b
INFO     PipelineRunner:logging.py:82  Added Silver step: normalized_source_a (source: raw_source_a)
INFO     PipelineRunner:logging.py:82  Added Silver step: normalized_source_b (source: raw_source_b)
INFO     PipelineRunner:logging.py:82  Added Gold step: data_quality_metrics (sources: ['normalized_source_a', 'normalized_source_b'])
INFO     PipelineRunner:logging.py:82  Added Gold step: source_reconciliation (sources: ['normalized_source_a', 'normalized_source_b'])
INFO     PipelineRunner:logging.py:82  Pipeline validation passed
INFO     PipelineRunner:logging.py:82  Pipeline built successfully with 2 bronze, 2 silver, 2 gold steps
INFO     PipelineRunner:logging.py:82 Starting pipeline execution: pipeline_20251218_184022
INFO     PipelineRunner:logging.py:82 Starting dependency analysis with strategy: hybrid
INFO     PipelineRunner:logging.py:82 Dependency analysis completed in 0.00s
INFO     PipelineRunner:logging.py:82 Dependency analysis complete: 3 execution groups, max group size: 2
INFO     PipelineRunner:logging.py:82 Parallel execution enabled with 4 workers
INFO     PipelineRunner:logging.py:82 Executing group 1/3: 2 steps - raw_source_a, raw_source_b
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_source_a
INFO     PipelineRunner:logging.py:82  Starting BRONZE step: raw_source_b
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_source_b: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_source_b (0.12s) - 100 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     DataValidation:logging.py:82 Validation completed for pipeline.raw_source_a: 100.0% valid
INFO     PipelineRunner:logging.py:82  Completed BRONZE step: raw_source_a (0.14s) - 80 rows processed, 0 rows written, 0 invalid, 100.0% valid
INFO     PipelineRunner:logging.py:82 Group 1 completed in 0.16s
INFO     PipelineRunner:logging.py:82 Executing group 2/3: 2 steps - normalized_source_a, normalized_source_b
INFO     PipelineRunner:logging.py:82  Starting SILVER step: normalized_source_a
INFO     PipelineRunner:logging.py:82  Starting SILVER step: normalized_source_b
ERROR    PipelineRunner:logging.py:92  Failed SILVER step: normalized_source_b (10.77s) - unable to find column "transaction_date_parsed"; valid columns: ["id", "customer_id", "date", "amount", "status", "category", "region", "quality_score", "quality_status", "has_null_customer", "has_invalid_amount", "has_empty_category"]
ERROR    PipelineRunner:logging.py:92 Exception executing step normalized_source_b: Step execution failed: unable to find column "transaction_date_parsed"; valid columns: ["id", "customer_id", "date", "amount", "status", "category", "region", "quality_score", "quality_status", "has_null_customer", "has_invalid_amount", "has_empty_category"]
INFO     DataValidation:logging.py:82 Validation completed for pipeline.normalized_source_a: 0.0% valid
INFO     PipelineRunner:logging.py:82  Completed SILVER step: normalized_source_a (27.24s) - 0 rows processed, 0 rows written, 80 invalid, 0.0% valid
INFO     PipelineRunner:logging.py:82 Group 2 completed in 27.24s
INFO     PipelineRunner:logging.py:82 Executing group 3/3: 2 steps - source_reconciliation, data_quality_metrics
INFO     PipelineRunner:logging.py:82  Starting GOLD step: source_reconciliation
ERROR    PipelineRunner:logging.py:92  Failed GOLD step: source_reconciliation (0.00s) - Source silver normalized_source_b not found in context
ERROR    PipelineRunner:logging.py:92 Exception executing step source_reconciliation: Step execution failed: Source silver normalized_source_b not found in context
INFO     PipelineRunner:logging.py:82  Starting GOLD step: data_quality_metrics
ERROR    PipelineRunner:logging.py:92  Failed GOLD step: data_quality_metrics (0.00s) - Source silver normalized_source_b not found in context
ERROR    PipelineRunner:logging.py:92 Exception executing step data_quality_metrics: Step execution failed: Source silver normalized_source_b not found in context
INFO     PipelineRunner:logging.py:82 Group 3 completed in 0.00s
ERROR    PipelineRunner:logging.py:92 Pipeline execution failed: 3 steps failed
INFO     PipelineRunner:logging.py:82 Completed pipeline execution: pipeline_20251218_184022
--------------------------- Captured stdout teardown ---------------------------
 Mock Spark session cleanup completed
=============================== warnings summary ===============================
tests/builder_pyspark_tests/test_healthcare_pipeline.py:590: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/builder_pyspark_tests/test_healthcare_pipeline.py:590: PytestUnknownMarkWarning: Unknown pytest.mark.pyspark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.pyspark

tests/builder_pyspark_tests/test_supply_chain_pipeline.py:524: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/builder_pyspark_tests/test_supply_chain_pipeline.py:524: PytestUnknownMarkWarning: Unknown pytest.mark.pyspark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.pyspark

tests/compat_pyspark/test_pyspark_compatibility.py:15: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/compat_pyspark/test_pyspark_compatibility.py:15: PytestUnknownMarkWarning: Unknown pytest.mark.pyspark_compat - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    pytestmark = pytest.mark.pyspark_compat

tests/security/test_security_integration.py:498: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/security/test_security_integration.py:498: PytestUnknownMarkWarning: Unknown pytest.mark.security - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.security

tests/system/test_delta_lake.py:78: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_delta_lake.py:78: PytestUnknownMarkWarning: Unknown pytest.mark.delta - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.delta

tests/system/test_simple_real_spark.py:75: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_simple_real_spark.py:75: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_simple_real_spark.py:94: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_simple_real_spark.py:94: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_simple_real_spark.py:115: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_simple_real_spark.py:115: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_simple_real_spark.py:131: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_simple_real_spark.py:131: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_simple_real_spark.py:145: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_simple_real_spark.py:145: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_simple_real_spark.py:161: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_simple_real_spark.py:161: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_simple_real_spark.py:186: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_simple_real_spark.py:186: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_simple_real_spark.py:201: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_simple_real_spark.py:201: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_simple_real_spark.py:219: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_simple_real_spark.py:219: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_simple_real_spark.py:220: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_simple_real_spark.py:220: PytestUnknownMarkWarning: Unknown pytest.mark.pyspark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.pyspark

tests/system/test_utils.py:81: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:81: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:95: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:95: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:104: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:104: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:125: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:125: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:139: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:139: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:152: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:152: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:162: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:162: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:205: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:205: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:222: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:222: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:250: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:250: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:276: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:276: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:304: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:304: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_utils.py:329: 10 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_utils.py:329: PytestUnknownMarkWarning: Unknown pytest.mark.spark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.spark

tests/system/test_logger.py::TestPipelineLogger::test_logger_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logger_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_update_step_execution_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_update_step_execution_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_without_active_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_update_step_execution_without_active_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_update_step_execution_failure_without_error_message
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_update_step_execution_failure_without_error_message' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_finish_execution_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_finish_execution_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_without_active_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_finish_execution_without_active_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_with_zero_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_finish_execution_with_zero_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_with_mocked_time
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_finish_execution_with_mocked_time' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_finish_execution_mixed_results
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_finish_execution_mixed_results' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_pipeline_monitor_alias
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_monitor_alias' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_monitor_logging_calls
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_monitor_logging_calls' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_runner_initialization_with_all_parameters
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_runner_initialization_with_all_parameters' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_runner_initialization_with_minimal_parameters
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_runner_initialization_with_minimal_parameters' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_runner_initialization_with_none_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_runner_initialization_with_none_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_initial
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_mode_initial' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_incremental
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_mode_incremental' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_full_refresh
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_mode_full_refresh' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_validation_only
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_mode_validation_only' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_convert_mode_unknown
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_mode_unknown' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_logger.py::TestPipelineLogger::test_logger_with_file
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logger_with_file' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_execution_engine_with_mock_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_with_mock_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_bronze_rules_with_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_rules_with_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_execution_engine_error_handling
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEnginePerformance::test_execution_engine_memory_usage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_memory_usage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEnginePerformance::test_execution_engine_concurrent_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_concurrent_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_bronze_rules_without_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_rules_without_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngineLogging::test_execution_engine_logging_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_logging_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngineLogging::test_execution_engine_default_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_default_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_silver_rules_with_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_rules_with_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngineLogging::test_execution_engine_logging_methods
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_logging_methods' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_silver_transform_with_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_transform_with_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_gold_transform_with_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_transform_with_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_validation_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_schema_validation_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_validation_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_schema_validation_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_get_effective_schema
tests/unit/test_pipeline_builder_basic.py::TestHelperMethods::test_get_effective_schema
tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_get_effective_schema
tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_get_effective_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_effective_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_schema_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_creation_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_schema_creation_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_cross_schema_pipeline
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_cross_schema_pipeline' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_mixed_schema_usage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_mixed_schema_usage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_schema_validation_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_schema_validation_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_multi_schema_support.py::TestMultiSchemaSupport::test_backward_compatibility
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_backward_compatibility' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_schema_evolution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_lake_schema_evolution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_time_travel
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_lake_time_travel' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_merge_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_lake_merge_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_optimization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_lake_optimization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_pipeline_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_with_bronze_sources
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_pipeline_with_bronze_sources' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_without_bronze_sources
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_pipeline_without_bronze_sources' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_pipeline_execution_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_pipeline_execution_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_initial_load_with_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_initial_load_with_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_initial_load_without_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_initial_load_without_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_incremental
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_incremental' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_full_refresh
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_full_refresh' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_run_validation_only
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_validation_only' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_pipeline_report_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_pipeline_report_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_without_end_time
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_pipeline_report_without_end_time' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_history_and_metadata
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_lake_history_and_metadata' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_concurrent_writes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_lake_concurrent_writes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_performance_characteristics
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_lake_performance_characteristics' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_data_quality_constraints
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_lake_data_quality_constraints' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_error_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_error_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_pipeline_runner_alias
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_runner_alias' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_create_pipeline_report_with_empty_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_pipeline_report_with_empty_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_row_counts_accuracy
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_report_metrics_row_counts_accuracy' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_duration_by_layer_accuracy
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_report_metrics_duration_by_layer_accuracy' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_with_failed_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_report_metrics_with_failed_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_with_no_rows_processed
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_report_metrics_with_no_rows_processed' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_runner.py::TestSimplePipelineRunner::test_report_metrics_mixed_layers_comprehensive
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_report_metrics_mixed_layers_comprehensive' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_unified_validator_initialization
tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_initialization
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_creation
tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_execution_result_creation
tests/unit/test_execution_comprehensive.py::TestStepExecutionResult::test_step_execution_result_creation
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_step_execution_result_creation
tests/unit/test_working_examples.py::TestWorkingExamples::test_step_execution_result_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_bronze_step_execution_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_execution_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_type_detection_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_type_detection_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_unified_validator_with_custom_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_with_custom_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_with_all_fields
tests/unit/test_execution_comprehensive.py::TestStepExecutionResult::test_step_execution_result_with_all_fields
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_with_all_fields' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_silver_step_execution_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_execution_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_add_validator
tests/unit/test_pipeline_builder_basic.py::TestValidatorManagement::test_add_validator
tests/unit/test_pipeline_builder_comprehensive.py::TestValidatorManagement::test_add_validator
tests/unit/test_pipeline_builder_simple.py::TestValidatorManagement::test_add_validator
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_validator' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_execution_context_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_context_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_duration_calculation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_duration_calculation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_gold_step_execution_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_execution_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_execution_result_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_step_with_custom_validators
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_with_custom_validators' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestStepExecutionResult::test_step_execution_result_no_duration_without_end_time
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_no_duration_without_end_time' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_validation_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_validation_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestDataValidation::test_and_all_rules_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_and_all_rules_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_execution_mode_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_mode_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_complete_financial_transaction_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_financial_transaction_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_step_validator_exception
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_validator_exception' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_creation
tests/unit/test_execution_comprehensive.py::TestExecutionResult::test_execution_result_creation
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_result_creation
tests/unit/test_working_examples.py::TestWorkingExamples::test_execution_result_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_result_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_complete_customer_360_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_customer_360_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestDataValidation::test_apply_column_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_apply_column_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_status_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_status_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_churn_prediction
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_customer_churn_prediction' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestDataValidation::test_apply_column_rules_none_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_apply_column_rules_none_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestDataValidation::test_assess_data_quality
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_assess_data_quality' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestDataValidation::test_get_dataframe_info
tests/unit/test_validation_simple.py::TestValidationUtils::test_get_dataframe_info
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dataframe_info' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestDataValidation::test_validate_dataframe_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_dataframe_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestDataTransformationUtilities::test_basic_dataframe_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_basic_dataframe_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestDataTransformationUtilities::test_dataframe_filtering
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dataframe_filtering' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestFactoryFunctions::test_create_validation_dict
tests/unit/pipeline_builder_base/test_reporting.py::TestReportUtilities::test_create_validation_dict
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_validation_dict' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestFactoryFunctions::test_create_write_dict
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_write_dict' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_pipeline_config_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_config_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_with_all_fields
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_result_with_all_fields' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestPerformanceWithRealData::test_large_dataset_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_large_dataset_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_fraud_detection_scenarios
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_fraud_detection_scenarios' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_pipeline_configuration_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_configuration_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_lifetime_value_analysis
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_customer_lifetime_value_analysis' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_compliance_monitoring
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_compliance_monitoring' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_pipeline_success
tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_silver_schema_evolution_on_initial_load_rerun
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_schema_evolution_on_initial_load_rerun' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_execution_engine_initialization_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_initialization_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_duration_calculation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_result_duration_calculation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_bronze_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_bronze_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestPerformanceWithRealData::test_complex_transformations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complex_transformations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestAnalysisStrategy::test_analysis_strategy_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analysis_strategy_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalysisResult::test_dependency_analysis_result_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analysis_result_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_dependency_analyzer_creation_default
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analyzer_creation_default' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_dependency_analyzer_creation_custom
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analyzer_creation_custom' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_bronze_only
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_bronze_only' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_silver_with_bronze
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_silver_with_bronze' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_execution_error_handling_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_error_handling_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionResult::test_execution_result_steps_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_result_steps_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_silver_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_silver_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_gold_with_silver
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_gold_with_silver' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_missing_bronze_dependency
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_missing_bronze_dependency' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_warning_scenarios
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_warning_scenarios' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_silver_depends_on_warning
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_silver_depends_on_warning' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_missing_silver_dependency
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_missing_silver_dependency' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execution_engine_initialization_with_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_initialization_with_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_step_execution.py::TestStepExecutionFlow::test_step_execution_with_mock_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_with_mock_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_force_refresh
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_force_refresh
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_force_refresh' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_cached
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_cached' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_exception
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_exception' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_dependency_graph_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_bronze_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_dependency_graph_bronze_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_customer_analytics_pipeline.py::TestCustomerAnalyticsPipeline::test_customer_analytics_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_customer_analytics_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_silver_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_dependency_graph_silver_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_build_dependency_graph_gold_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_dependency_graph_gold_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_resolve_cycles
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_resolve_cycles' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_detect_conflicts
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_detect_conflicts' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_cycle_warning
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_cycle_warning' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_conflict_warning
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_conflict_warning' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_validate_missing_dependencies
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_missing_dependencies' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_execution_groups
tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_execution_groups
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_execution_groups' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_stats
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_stats' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execution_engine_initialization_without_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_initialization_without_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_financial_pipeline.py::TestFinancialPipeline::test_financial_audit_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_financial_audit_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_gold_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_gold_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_not_null_rule
tests/unit/test_validation.py::TestConvertRuleToExpression::test_not_null_rule
tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_not_null_rule
tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_not_null_rule
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_not_null_rule' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestUnifiedValidator::test_validate_dependencies
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_dependencies' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_parallel_candidates
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_parallel_candidates' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_base_builder_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_builder_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_base_builder_default_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_builder_default_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_bronze
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_check_duplicate_step_name_bronze' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_silver
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_check_duplicate_step_name_silver' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_gold
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_check_duplicate_step_name_gold' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_check_duplicate_step_name_no_duplicate
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_check_duplicate_step_name_no_duplicate' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_silver_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_dependencies_silver_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_bronze_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_bronze_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_silver_missing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_dependencies_silver_missing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_positive_rule
tests/unit/test_validation.py::TestConvertRuleToExpression::test_positive_rule
tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_positive_rule
tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_positive_rule
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_positive_rule' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_gold_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_dependencies_gold_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_gold_missing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_dependencies_gold_missing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_gold_invalid_list
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_dependencies_gold_invalid_list' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_step_dependencies_auto_inference
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_dependencies_auto_inference' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestApplyValidationRules::test_apply_column_rules_deprecated
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_apply_column_rules_deprecated' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_schema_valid
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_schema_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_schema_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_schema_invalid
tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_schema_invalid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_schema_invalid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestBasePipelineBuilder::test_validate_pipeline
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_bronze
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_classify_step_type_bronze' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_silver_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_silver
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_classify_step_type_silver' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_gold
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_classify_step_type_gold' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_non_negative_rule
tests/unit/test_validation.py::TestConvertRuleToExpression::test_non_negative_rule
tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_non_negative_rule
tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_non_negative_rule
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_non_negative_rule' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_from_attribute
tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_classify_step_type_from_attribute
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_classify_step_type_from_attribute' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_classify_step_type_unknown
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_classify_step_type_unknown' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_extract_step_dependencies_silver
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_extract_step_dependencies_silver' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_extract_step_dependencies_gold
tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_extract_step_dependencies_gold
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_extract_step_dependencies_gold' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_extract_step_dependencies_none
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_extract_step_dependencies_none' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_group_steps_by_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_group_steps_by_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_get_all_step_names
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_all_step_names' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_build_dependency_graph
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_dependency_graph' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_gold_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestStepClassifier::test_get_execution_order
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_execution_order' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_bronze_step_dict
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_bronze_step_dict' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_bronze_step_dict_with_metadata
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_bronze_step_dict_with_metadata' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_silver_step_dict
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_silver_step_dict' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_silver_step_dict_with_watermark
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_silver_step_dict_with_watermark' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_gold_step_dict
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_gold_step_dict' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_builder.py::TestHelperFunctions::test_create_gold_step_dict_no_sources
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_gold_step_dict_no_sources' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_development_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_development_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_development_config_overrides
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_development_config_overrides' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_production_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_production_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_production_config_overrides
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_production_config_overrides' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_non_zero_rule
tests/unit/test_validation.py::TestConvertRuleToExpression::test_non_zero_rule
tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_non_zero_rule
tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_non_zero_rule
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_non_zero_rule' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_test_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_test_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationFactories::test_create_test_config_overrides
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_test_config_overrides' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_pipeline_config_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_config_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_unknown_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_unknown_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_silver_schema_evolution_incremental_should_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_schema_evolution_incremental_should_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_incremental_pipeline_preserves_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_pipeline_preserves_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_pipeline_config_invalid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_config_invalid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_parallel_config_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_parallel_config_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_parallel_config_invalid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_parallel_config_invalid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_parallel_config_too_large
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_parallel_config_too_large' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_thresholds_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_invalid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_thresholds_invalid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_range
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_thresholds_range' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_config.py::TestConfigurationValidators::test_validate_thresholds_order
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_thresholds_order' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestConvertRuleToExpression::test_unknown_rule
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unknown_rule' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_bronze_without_source_path
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_bronze_without_source_path' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_dependency_graph_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_graph_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_add_node
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_node' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_add_dependency
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_dependency' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_add_dependency_missing_node
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_dependency_missing_node' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_node
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_node' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_node_missing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_node_missing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_initial_pipeline_overwrites_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_initial_pipeline_overwrites_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_dependencies
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dependencies' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestConvertRulesToExpressions::test_string_rules_conversion
tests/unit/test_validation.py::TestConvertRulesToExpressions::test_string_rules_conversion
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_string_rules_conversion' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging.py::TestFullPipelineWithLogging::test_full_pipeline_with_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_full_pipeline_with_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_dependents
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dependents' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_has_cycle
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_has_cycle' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_has_cycle_no_cycle
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_has_cycle_no_cycle' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_topological_sort
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_topological_sort' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_topological_sort_cycle
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_topological_sort_cycle' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyGraph::test_get_execution_groups_parallel
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_execution_groups_parallel' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestStepNode::test_step_node_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_node_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_bronze_step_not_in_context
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_bronze_step_not_in_context' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestStepNode::test_step_node_with_dependencies
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_node_with_dependencies' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestStepNode::test_step_node_with_metadata
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_node_with_metadata' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_dependency_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_cycle_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_cycle_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_missing_dependency_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_missing_dependency_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestConvertRulesToExpressions::test_mixed_rules_conversion
tests/unit/test_validation.py::TestConvertRulesToExpressions::test_mixed_rules_conversion
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_mixed_rules_conversion' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_dependency_analysis_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analysis_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_dependencies.py::TestDependencyExceptions::test_dependency_conflict_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_conflict_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_context_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_to_dict
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_context_to_dict' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_add
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_context_add' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestErrorContext::test_error_context_merge
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_context_merge' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_suggestion_generator_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_suggestion_generator_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_bronze_step_with_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_bronze_step_with_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_validation_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_suggestions_validation_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_dependency_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_suggestions_dependency_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_config_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_suggestions_config_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestSuggestionGenerator::test_generate_suggestions_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_suggestions_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py: 2 warnings
tests/unit/test_validation.py: 2 warnings
tests/unit/test_validation_mock.py: 4 warnings
tests/unit/test_validation_standalone.py: 4 warnings
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_empty_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_execution_context
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_execution_context' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_execution_context_with_metadata
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_execution_context_with_metadata' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_validation_context
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_validation_context' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_errors.py::TestErrorContextBuilders::test_build_validation_context_gold
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_validation_context_gold' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_builder_runner_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_builder_runner_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_validator_builder_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validator_builder_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_config_factory_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_config_factory_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_without_dependencies
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_silver_without_dependencies' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_write_mode_consistency_across_pipeline_runs
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_mode_consistency_across_pipeline_runs' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_dependency_graph_builder
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_graph_builder' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_integration.py::TestBuilderRunnerIntegration::test_error_context_full_flow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_context_full_flow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_validation_report_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_report_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_validation_report_to_dict
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_report_to_dict' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_transform_report_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_transform_report_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_write_report_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_report_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_execution_summary_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_summary_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_performance_metrics_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_metrics_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestMinimalPipelines::test_minimal_pipeline_with_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_minimal_pipeline_with_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_data_metrics_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_data_metrics_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_reporting.py::TestReportClasses::test_summary_report_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_summary_report_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_reporting.py::TestReportUtilities::test_create_validation_dict_none_stats
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_validation_dict_none_stats' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_base_runner_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_runner_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_missing_dependency
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_silver_missing_dependency' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestAndAllRules::test_single_column_single_rule
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_single_column_single_rule' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_base_runner_default_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_runner_default_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_handle_step_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_handle_step_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_handle_step_error_with_context
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_handle_step_error_with_context' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_collect_step_results
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_collect_step_results' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_collect_step_results_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_collect_step_results_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_collect_step_results_with_errors
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_collect_step_results_with_errors' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_create_pipeline_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_pipeline_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_aggregate_step_reports
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_aggregate_step_reports' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestBaseRunner::test_aggregate_step_reports_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_aggregate_step_reports_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_determine_execution_mode_initial
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_determine_execution_mode_initial' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_determine_execution_mode_initial_empty_sources
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_determine_execution_mode_initial_empty_sources' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_determine_execution_mode_incremental
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_determine_execution_mode_incremental' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_should_run_incremental_with_last_run
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_should_run_incremental_with_last_run' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_silver_without_transform
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_silver_without_transform' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_should_run_incremental_no_last_run
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_should_run_incremental_no_last_run' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_prepare_sources_for_execution_bronze
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_prepare_sources_for_execution_bronze' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_prepare_sources_for_execution_silver
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_prepare_sources_for_execution_silver' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_prepare_sources_for_execution_gold
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_prepare_sources_for_execution_gold' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_bronze_sources_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_missing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_bronze_sources_missing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_unexpected
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_bronze_sources_unexpected' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_with_validator
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_bronze_sources_with_validator' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_mixed_pipeline_modes_have_correct_write_modes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_mixed_pipeline_modes_have_correct_write_modes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestAndAllRules::test_single_column_multiple_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_single_column_multiple_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_pipeline_structure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_structure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_step_validator_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_validator_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_step_name_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_name_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_without_dependencies
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_gold_without_dependencies' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_step_name_invalid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_name_invalid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_step_name_reserved
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_name_reserved' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_schema_name_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_schema_name_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestStepValidator::test_validate_schema_name_invalid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_schema_name_invalid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_check_duplicate_names
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_check_duplicate_names' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_check_duplicate_names_no_duplicates
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_check_duplicate_names_no_duplicates' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestAndAllRules::test_multiple_columns
tests/unit/test_validation_mock.py::TestApplyColumnRules::test_multiple_columns
tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_multiple_columns
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_multiple_columns' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_validate_dependency_chain
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_dependency_chain' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_validate_schema_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_schema_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_validate_step_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_safe_divide
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_safe_divide' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestValidationUtils::test_safe_divide_by_zero
tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_by_zero
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_safe_divide_by_zero' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestBaseWriter::test_base_writer_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_writer_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestBaseWriter::test_base_writer_abstract_methods
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_writer_abstract_methods' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestBaseWriter::test_base_writer_table_fqn
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_writer_table_fqn' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestWriterModels::test_write_result_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_result_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestWriterModels::test_writer_metrics_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_metrics_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestWriterModels::test_log_row_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_write_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_table_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_table_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_silver_schema_evolution_with_multiple_new_columns
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_schema_evolution_with_multiple_new_columns' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_validation_error_creation
tests/system/test_system_exceptions.py::TestValidationError::test_validation_error_creation
tests/unit/test_validation_simple.py::TestValidationErrorHandling::test_validation_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_configuration_error_creation
tests/system/test_system_exceptions.py::TestConfigurationError::test_configuration_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_configuration_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_data_quality_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_data_quality_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_writer.py::TestWriterExceptions::test_performance_error_creation
tests/system/test_system_exceptions.py::TestPerformanceError::test_performance_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_missing_dependency
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_gold_missing_dependency' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_write_mode_regression_prevention
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_mode_regression_prevention' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestAndAllRules::test_complex_rules
tests/unit/test_validation.py::TestApplyColumnRules::test_complex_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complex_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_missing_columns_validation_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_missing_columns_validation_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_complete_healthcare_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_healthcare_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_gold_without_transform
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_gold_without_transform' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_schema_evolution_without_override.py::TestSchemaEvolutionWithoutOverride::test_gold_schema_evolution_without_override
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_schema_evolution_without_override' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_dataframe_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_real_spark_dataframe_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestAndAllRules::test_empty_rules_returns_true
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_empty_rules_returns_true' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestAndAllRules::test_no_valid_expressions_returns_true
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_valid_expressions_returns_true' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_write_mode_integration.py::TestWriteModeIntegration::test_log_writer_receives_correct_write_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_receives_correct_write_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestValidationPerformance::test_safe_divide_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_safe_divide_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestValidationPerformance::test_safe_divide_zero_denominator_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_safe_divide_zero_denominator_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestValidationPerformance::test_validate_dataframe_schema_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_dataframe_schema_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_existing_columns_validation_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_existing_columns_validation_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestValidationConstants::test_default_gold_threshold
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_gold_threshold' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_validation_only_mode
tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_validation_only_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_validation_only_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestValidationPerformance::test_assess_data_quality_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_assess_data_quality_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_valid_schema
tests/unit/test_validation.py::TestValidateDataframeSchema::test_valid_schema
tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_valid_schema
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_valid_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_valid_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestValidationConstants::test_threshold_ordering
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_threshold_ordering' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_transformations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_real_spark_transformations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_step_exception_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_exception_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_missing_columns
tests/unit/test_validation.py::TestValidateDataframeSchema::test_missing_columns
tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_missing_columns
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_missing_columns
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_missing_columns' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_validation_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_real_spark_validation_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestTimeoutConstants::test_default_timeout_seconds
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_timeout_seconds' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_data_quality
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_real_spark_data_quality' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestTimeoutConstants::test_default_retry_timeout_seconds
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_retry_timeout_seconds' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestValidationPerformance::test_get_dataframe_info_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dataframe_info_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_metadata_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_real_spark_metadata_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_real_spark_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_real_spark_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_schema_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_real_spark_schema_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_simple_real_spark.py::TestRealSparkOperations::test_real_spark_joins
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_real_spark_joins' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestValidationError::test_validation_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestTableOperationError::test_table_operation_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_table_operation_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestTableOperationError::test_table_operation_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_table_operation_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestPerformanceError::test_performance_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestPipelineValidationError::test_pipeline_validation_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_validation_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestPipelineValidationError::test_pipeline_validation_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_validation_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestExecutionError::test_execution_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestTimeoutConstants::test_timeout_ordering
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_timeout_ordering' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestLoggingConstants::test_default_log_level
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_log_level' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestLoggingConstants::test_default_verbose
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_verbose' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestModelCreationPerformance::test_validation_thresholds_creation_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_creation_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_extra_columns
tests/unit/test_validation.py::TestValidateDataframeSchema::test_extra_columns
tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_extra_columns
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_extra_columns
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_extra_columns' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestExecutionError::test_execution_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestModelCreationPerformance::test_parallel_config_creation_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_config_creation_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestSchemaConstants::test_default_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestSchemaConstants::test_test_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_test_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestErrorConstants::test_max_error_message_length
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_max_error_message_length' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestErrorConstants::test_max_stack_trace_lines
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_max_stack_trace_lines' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestPerformanceMonitoringConstants::test_default_metrics_interval_seconds
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_metrics_interval_seconds' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestModelCreationPerformance::test_pipeline_config_creation_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_creation_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestConfigurationError::test_configuration_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_configuration_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestExceptionChaining::test_exception_with_cause
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_exception_with_cause' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_system_exceptions.py::TestExceptionChaining::test_exception_context
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_exception_context' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_utils.py::TestDataValidation::test_and_all_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_and_all_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_constructor_parameters
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analysis_error_constructor_parameters' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestPerformanceMonitoringConstants::test_default_alert_threshold_percent
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_alert_threshold_percent' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestConstantsIntegration::test_memory_calculations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_memory_calculations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestConstantsIntegration::test_threshold_percentages
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_threshold_percentages' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestConstantsIntegration::test_positive_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_positive_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestConstantsIntegration::test_string_constants_not_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_string_constants_not_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_import
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_constants_import' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_constants_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_constants_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_ranges
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_constants_ranges' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_consistency
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_constants_consistency' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_immutability
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_constants_immutability' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_documentation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_constants_documentation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_usage_examples
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_constants_usage_examples' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_constants_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants_coverage.py::TestConstantsCoverage::test_constants_module_attributes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_constants_module_attributes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_error_conditions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_conditions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_boundary_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_boundary_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_concurrent_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_concurrent_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_circular_dependency_error_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestModelCreationPerformance::test_bronze_step_creation_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_creation_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_empty_expected_columns
tests/unit/test_validation.py::TestValidateDataframeSchema::test_empty_expected_columns
tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_empty_expected_columns
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_empty_expected_columns
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_empty_expected_columns' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_with_step_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_circular_dependency_error_with_step_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_empty_cycle
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_circular_dependency_error_empty_cycle' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_single_step_cycle
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_circular_dependency_error_single_step_cycle' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_circular_dependency_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestValidateDataframeSchema::test_empty_dataframe
tests/integration/test_validation_integration.py::TestGetDataframeInfo::test_empty_dataframe
tests/integration/test_validation_integration.py::TestAssessDataQuality::test_empty_dataframe
tests/unit/test_validation.py::TestGetDataframeInfo::test_empty_dataframe
tests/unit/test_validation_mock.py::TestGetDataframeInfo::test_empty_dataframe
tests/unit/test_validation_standalone.py::TestGetDataframeInfo::test_empty_dataframe
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_empty_dataframe' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestSafeDivide::test_normal_division
tests/unit/test_validation.py::TestSafeDivide::test_normal_division
tests/unit/test_validation_mock.py::TestSafeDivide::test_normal_division
tests/unit/test_validation_standalone.py::TestSafeDivide::test_normal_division
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_normal_division' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestCircularDependencyError::test_circular_dependency_error_cycle_immutability
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_circular_dependency_error_cycle_immutability' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_invalid_dependency_error_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_with_step_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_invalid_dependency_error_with_step_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_empty_list
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_invalid_dependency_error_empty_list' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_single_dependency
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_invalid_dependency_error_single_dependency' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_invalid_dependency_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestInvalidDependencyError::test_invalid_dependency_error_list_immutability
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_invalid_dependency_error_list_immutability' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_conflict_error_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_with_step_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_conflict_error_with_step_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_with_different_step_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_with_different_step_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_memory_management
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_memory_management' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_schema_evolution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_schema_evolution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_pipeline_builder_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_execution_engine_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestModelCreationPerformance::test_silver_step_creation_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_creation_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestSafeDivide::test_division_by_zero
tests/unit/test_validation.py::TestSafeDivide::test_division_by_zero
tests/unit/test_validation_mock.py::TestSafeDivide::test_division_by_zero
tests/unit/test_validation_standalone.py::TestSafeDivide::test_division_by_zero
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_division_by_zero' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_validation_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_writer_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_writer_edge_cases
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_edge_cases.py:416: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=minimal_config)

tests/unit/test_edge_cases.py::TestEdgeCases::test_writer_edge_cases
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_edge_cases.py:432: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer_max = LogWriter(spark=mock_spark_session, config=max_config)

tests/unit/test_edge_cases.py::TestEdgeCases::test_storage_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_storage_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_function_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_function_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_dataframe_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dataframe_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_session_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_session_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_has_all_required_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_mode_has_all_required_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_models_matches_base
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_mode_models_matches_base' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestModelCreationPerformance::test_gold_step_creation_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_creation_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestSerializationPerformance::test_model_to_dict_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_model_to_dict_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_empty_list
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_conflict_error_empty_list' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_matches_pipeline_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_mode_matches_pipeline_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestExecutionModeConsistency::test_execution_mode_enum_values_exist
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_mode_enum_values_exist' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_models_has_basic_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_mode_models_has_basic_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_writer_has_all_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_mode_writer_has_all_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_consistency_across_locations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_mode_consistency_across_locations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestSerializationPerformance::test_model_to_json_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_model_to_json_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestWriteModeConsistency::test_write_mode_enum_values_exist
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_mode_enum_values_exist' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestStepTypeConsistency::test_step_type_has_all_required_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_type_has_all_required_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_single_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_conflict_error_single_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_conflict_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestStepTypeConsistency::test_step_type_consistency_across_locations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_type_consistency_across_locations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_with_max_workers
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_with_max_workers' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_empty_steps
tests/unit/test_execution_comprehensive.py::TestExecutePipeline::test_execute_pipeline_empty_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_empty_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyConflictError::test_dependency_conflict_error_list_immutability
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_conflict_error_list_immutability' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestExceptionChaining::test_dependency_error_chaining
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_error_chaining' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestExceptionChaining::test_circular_dependency_error_chaining
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_circular_dependency_error_chaining' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestExceptionChaining::test_exception_attributes_preserved
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_exception_attributes_preserved' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_dependency_error_str
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_error_str' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_dependency_analysis_error_str
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analysis_error_str' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_circular_dependency_error_str
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_circular_dependency_error_str' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_invalid_dependency_error_str
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_invalid_dependency_error_str' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestExceptionStringRepresentation::test_dependency_conflict_error_str
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_conflict_error_str' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_add_dependency_missing_nodes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_dependency_missing_nodes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestSerializationPerformance::test_model_validation_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_model_validation_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestSafeDivide::test_division_by_zero_custom_default
tests/unit/test_validation.py::TestSafeDivide::test_division_by_zero_custom_default
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_division_by_zero_custom_default' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestSafeDivide::test_float_division
tests/unit/test_validation.py::TestSafeDivide::test_float_division
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_float_division' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_execute_pipeline_step_failure_continues
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_step_failure_continues' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_dependencies_missing_node
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dependencies_missing_node' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_dependents_missing_node
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dependents_missing_node' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_detect_cycles
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_detect_cycles' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_get_execution_groups_missing_dependency
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_execution_groups_missing_dependency' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_graph.py::TestDependencyGraph::test_validate_cycles
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_cycles' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestStepStatusConsistency::test_step_status_has_all_required_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_status_has_all_required_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestStepStatusConsistency::test_step_status_consistency_across_locations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_status_consistency_across_locations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestPipelineModeExecutionModeMapping::test_pipeline_mode_to_execution_mode_mapping
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_mode_to_execution_mode_mapping' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_incremental_healthcare_processing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_healthcare_processing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestPipelineModeExecutionModeMapping::test_all_pipeline_modes_have_execution_mode_equivalents
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_all_pipeline_modes_have_execution_mode_equivalents' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_gold_step_success
tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_gold_step_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_gold_step_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestEnumCompleteness::test_execution_mode_completeness
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_mode_completeness' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_enum_consistency.py::TestEnumCompleteness::test_pipeline_mode_completeness
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_mode_completeness' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestMemoryUsagePerformance::test_model_creation_memory_usage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_model_creation_memory_usage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::TestMemoryUsagePerformance::test_serialization_memory_usage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_serialization_memory_usage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::test_performance_summary
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_summary' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/performance/test_performance.py::test_update_baselines
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_update_baselines' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine.py::TestExecutionEngine::test_backward_compatibility_aliases
tests/unit/test_types.py::TestBackwardCompatibility::test_backward_compatibility_aliases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_backward_compatibility_aliases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_engine_initialization
tests/unit/test_execution_comprehensive.py::TestExecutionEngineInitialization::test_execution_engine_initialization
tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_initialization
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_execution_engine_initialization
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_execution_engine_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_engine_without_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_without_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestSafeDivide::test_negative_numbers
tests/unit/test_validation.py::TestSafeDivide::test_negative_numbers
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_negative_numbers' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestSafeDivide::test_zero_numerator
tests/unit/test_validation.py::TestSafeDivide::test_zero_numerator
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_zero_numerator' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_error_context_value_type_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_context_value_type_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_type_detection
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_step_type_detection
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_step_type_detection
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_type_detection' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_context_creation
tests/unit/test_models_new.py::TestExecutionContext::test_execution_context_creation
tests/unit/test_models_simple.py::TestExecutionContext::test_execution_context_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_context_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_execution_mode_enum
tests/unit/test_models_simple.py::TestEnums::test_execution_mode_enum
tests/unit/test_models.py::TestEnums::test_execution_mode_enum
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_execution_mode_enum
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_execution_mode_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_mode_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_with_rules_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_with_rules_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_error_context_type_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_context_type_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_error_suggestions_type_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_suggestions_type_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_base_error_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_error_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestGetDataframeInfo::test_basic_info
tests/unit/test_validation.py::TestGetDataframeInfo::test_basic_info
tests/unit/test_validation_mock.py::TestGetDataframeInfo::test_basic_info
tests/unit/test_validation_standalone.py::TestGetDataframeInfo::test_basic_info
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_basic_info' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_configuration_error_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_configuration_error_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_status_enum
tests/unit/test_models_new.py::TestEnums::test_step_status_enum
tests/unit/test_models_simple.py::TestEnums::test_step_status_enum
tests/unit/test_types.py::TestEnums::test_step_status_enum
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_step_status_enum
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_step_status_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_status_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngine::test_step_type_enum
tests/unit/test_models_new.py::TestEnums::test_step_type_enum
tests/unit/test_models_simple.py::TestEnums::test_step_type_enum
tests/unit/test_types.py::TestEnums::test_step_type_enum
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_step_type_enum
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_step_type_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_type_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_bronze_step_validation
tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_validation
tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_silver_step_validation
tests/unit/test_models_new.py::TestSilverStep::test_silver_step_validation
tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_data_error_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_data_error_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_pipeline_error_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_error_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_step_error_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_error_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_execution_error_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_error_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_gold_step_validation
tests/unit/test_models_new.py::TestGoldStep::test_gold_step_validation
tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_execution_engine_new.py::TestExecutionEngineIntegration::test_pipeline_config_validation
tests/unit/test_models_new.py::TestPipelineConfig::test_pipeline_config_validation
tests/unit/test_models_simple.py::TestPipelineConfig::test_pipeline_config_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_runner.py::TestExecutionHelpers::test_validate_bronze_sources_with_invalid_validator
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_bronze_sources_with_invalid_validator' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_step_manager_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_manager_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_add_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_add_step_duplicate
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_step_duplicate' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_system_error_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_system_error_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_performance_error_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_error_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_error_serialization_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_serialization_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_error_context_manipulation_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_context_manipulation_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_step_missing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_step_missing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_step_all_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_step_all_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_steps_by_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_steps_by_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_remove_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_remove_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_error_suggestion_manipulation_explicit_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_suggestion_manipulation_explicit_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_no_any_types_in_error_classes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_any_types_in_error_classes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorTypeSafety::test_no_args_kwargs_in_error_constructors
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_args_kwargs_in_error_constructors' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_clear_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_clear_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_get_all_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_all_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepManager::test_validate_all_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_all_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_classify_step_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_classify_step_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_extract_step_dependencies
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_extract_step_dependencies' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_get_step_target
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_step_target' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_existing_error_usage_still_works
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_existing_error_usage_still_works' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_get_step_target_missing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_step_target_missing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_normalize_step_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_normalize_step_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_steps.py::TestStepUtils::test_normalize_step_name_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_normalize_step_name_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_pipeline_validator_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_validator_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_error_inheritance_still_works
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_inheritance_still_works' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_error_context_manipulation_still_works
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_context_manipulation_still_works' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_error_serialization_still_works
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_serialization_still_works' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_errors.py::TestErrorBackwardCompatibility::test_resource_error_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_resource_error_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_pipeline_validator_default_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_validator_default_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_step_names_unique
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_names_unique' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_step_names_duplicate
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_names_duplicate' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_step_names_invalid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_step_names_invalid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestLargePipelines::test_large_pipeline_with_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_large_pipeline_with_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestGetDataframeInfo::test_error_handling
tests/integration/test_validation_integration.py::TestAssessDataQuality::test_error_handling
tests/unit/test_validation.py::TestGetDataframeInfo::test_error_handling
tests/unit/test_validation_mock.py::TestGetDataframeInfo::test_error_handling
tests/unit/test_validation_standalone.py::TestGetDataframeInfo::test_error_handling
tests/unit/test_working_examples.py::TestWorkingExamples::test_error_handling
tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzerIntegration::test_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_silver_missing_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_silver_missing_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_silver_step_success
tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_silver_step_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_silver_step_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestStepType::test_step_type_enumeration
tests/integration/test_execution_engine.py::TestStepType::test_step_type_enumeration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_type_enumeration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestStepExecutionResult::test_step_execution_result_with_end_time
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_with_end_time' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestEdgeCases::test_pipeline_with_empty_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_with_empty_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecutionResult::test_execution_result_with_end_time
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_result_with_end_time' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecutionResult::test_execution_result_with_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_result_with_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecutionEngineInitialization::test_execution_engine_with_custom_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_with_custom_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecutionEngineInitialization::test_execution_engine_with_none_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_with_none_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecuteStep::test_execute_bronze_step_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_bronze_step_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecuteStep::test_execute_step_unknown_step_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_unknown_step_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecuteStep::test_execute_bronze_step_missing_context
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_bronze_step_missing_context' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_dependency_chain_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_dependency_chain_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/pipeline_builder_base/test_validation.py::TestPipelineValidator::test_validate_dependency_chain_cycle
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_dependency_chain_cycle' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestAssessDataQuality::test_dataframe_without_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dataframe_without_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_healthcare_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_healthcare_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecutePipeline::test_execute_pipeline_with_none_context
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_with_none_context' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecutePipeline::test_execute_pipeline_invalid_context_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_invalid_context_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestPrivateMethods::test_execute_bronze_step_empty_dataframe
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_bronze_step_empty_dataframe' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestBackwardCompatibility::test_unified_execution_engine_alias
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_execution_engine_alias' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestBackwardCompatibility::test_unified_step_execution_result_alias
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_step_execution_result_alias' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_gold_missing_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_gold_missing_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_get_spark
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_get_spark' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_get_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_get_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_default_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_default_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_step_status_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_step_status_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_step_type_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_step_type_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_execution_mode_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_execution_mode_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_with_empty_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_with_empty_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_with_sample_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_with_sample_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_metrics_collection
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_metrics_collection' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_final_coverage.py::TestExecutionFinalCoverage::test_execute_pipeline_with_none_steps_result
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_with_none_steps_result' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_final_coverage.py::TestExecutionFinalCoverage::test_execute_pipeline_silver_step_no_schema_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_silver_step_no_schema_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_final_coverage.py::TestExecutionFinalCoverage::test_execute_pipeline_gold_step_no_schema_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_gold_step_no_schema_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecutionIntegration::test_different_execution_modes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_different_execution_modes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecutionIntegration::test_logging_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logging_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_mode_uses_append_for_silver_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_mode_uses_append_for_silver_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_mode_uses_overwrite_for_gold_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_mode_uses_overwrite_for_gold_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_initial_mode_uses_overwrite_for_silver_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_initial_mode_uses_overwrite_for_silver_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_initial_mode_uses_overwrite_for_gold_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_initial_mode_uses_overwrite_for_gold_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_full_refresh_mode_uses_overwrite_for_silver_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_full_refresh_mode_uses_overwrite_for_silver_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_full_refresh_mode_uses_overwrite_for_gold_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_full_refresh_mode_uses_overwrite_for_gold_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_validation_only_mode_has_no_write_mode_for_silver_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_only_mode_has_no_write_mode_for_silver_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_incremental_filter_excludes_existing_rows
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_filter_excludes_existing_rows' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_context_manager
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_timer_context_manager' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_context_manager_exception
tests/unit/test_logging.py::TestTimerContextManager::test_timer_context_manager_exception
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_timer_context_manager_exception' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_setup_handlers_console_only
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_setup_handlers_console_only' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_silver_missing_source
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_silver_missing_source' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_gold_missing_source
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_gold_missing_source' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_initialization_with_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_initialization_with_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_engine_simple.py::TestExecutionEngineSimple::test_execution_engine_invalid_spark_session
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_invalid_spark_session' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestMultiStepLogRowFields::test_multiple_steps_each_have_correct_fields
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_multiple_steps_each_have_correct_fields' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_format_message_with_kwargs
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_format_message_with_kwargs' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_format_message_without_kwargs
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_format_message_without_kwargs' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_context_manager
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_context_manager' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_start
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_start' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_start_different_stage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_start_different_stage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_complete
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_complete' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_step_complete_no_rows
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_complete_no_rows' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_start
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_timer_start' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_end
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_timer_end' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_timer_end_nonexistent
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_timer_end_nonexistent' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestBronzeStep::test_bronze_step_creation_minimal
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_creation_minimal' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_validation_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_empty_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_validation_empty_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_none_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_validation_none_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestBronzeStep::test_bronze_step_validation_invalid_rules_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_validation_invalid_rules_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestBronzeStep::test_bronze_step_has_incremental_capability
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_has_incremental_capability' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverStep::test_silver_step_creation
tests/unit/test_models_new.py::TestSilverStep::test_silver_step_creation
tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_creation
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_silver_step_creation
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_silver_step_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverStep::test_silver_step_creation_minimal
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_creation_minimal' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_validation_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_empty_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_validation_empty_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_empty_source_bronze
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_validation_empty_source_bronze' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_none_transform
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_validation_none_transform' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_invalid_rules_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_validation_invalid_rules_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverStep::test_silver_step_validation_empty_table_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_validation_empty_table_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestGoldStep::test_gold_step_creation
tests/unit/test_models_new.py::TestGoldStep::test_gold_step_creation
tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_creation
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_gold_step_creation
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_gold_step_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestGoldStep::test_gold_step_creation_minimal
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_creation_minimal' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_validation_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_empty_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_validation_empty_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecuteStepComplete::test_execute_step_transform_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_step_transform_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_none_transform
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_validation_none_transform' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_invalid_rules_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_validation_invalid_rules_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestGoldStep::test_gold_step_validation_empty_table_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_validation_empty_table_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestStepResult::test_step_result_creation
tests/unit/test_models_new.py::TestStepResult::test_step_result_creation
tests/unit/test_models_simple.py::TestStepResult::test_step_result_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_result_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestStepResult::test_step_result_is_high_quality
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_result_is_high_quality' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestStepResult::test_step_result_create_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_result_create_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestStepResult::test_step_result_create_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_result_create_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestPipelineMetrics::test_pipeline_metrics_creation_default
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_metrics_creation_default' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestPipelineMetrics::test_pipeline_metrics_creation_custom
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_metrics_creation_custom' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestPipelineConfig::test_pipeline_config_creation_default
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_creation_default' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestPipelineConfig::test_pipeline_config_creation_custom
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_creation_custom' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_dependency_info_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_validation_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_dependency_info_validation_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_validation_empty_step_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_dependency_info_validation_empty_step_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestSilverDependencyInfo::test_silver_dependency_info_validation_empty_source_bronze
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_dependency_info_validation_empty_source_bronze' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_parallel_config_creation
tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_creation
tests/unit/test_models_simple.py::TestParallelConfig::test_parallel_config_creation
tests/unit/test_working_examples.py::TestWorkingExamples::test_parallel_config_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_config_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_parallel_config_creation_minimal
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_config_creation_minimal' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_config_validation_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_negative_max_workers
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_config_validation_negative_max_workers' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_negative_worker_timeout
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_config_validation_negative_worker_timeout' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_base_model_to_dict_with_nested_objects
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_model_to_dict_with_nested_objects' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_base_model_to_dict_without_nested_objects
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_model_to_dict_without_nested_objects' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_validation_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_validation_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_get_threshold
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_get_threshold' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_validation_invalid_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_validation_invalid_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_create_default
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_create_default' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_success_with_silver_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_success_with_silver_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_create_high_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_create_high_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_base_model_to_json
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_model_to_json' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_complete_iot_sensor_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_iot_sensor_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_incremental_sensor_processing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_sensor_processing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_base_model_str_representation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_model_str_representation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_create_loose
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_create_loose' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_validation_thresholds_create_strict
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_create_strict' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_parallel_config_validation_max_workers_exceeded
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_config_validation_max_workers_exceeded' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_properties
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_properties' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestParallelConfig::test_pipeline_config_create_conservative
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_create_conservative' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestBaseModel::test_validate_default
tests/unit/test_models_simple.py::TestBaseModel::test_validate_default
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_default' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestBaseModel::test_to_dict_simple
tests/unit/test_models_simple.py::TestBaseModel::test_to_dict_simple
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_to_dict_simple' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestBaseModel::test_to_dict_nested_objects
tests/unit/test_models_simple.py::TestBaseModel::test_to_dict_nested_objects
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_to_dict_nested_objects' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_setup_handlers_with_file
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_setup_handlers_with_file' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_setup_handlers_verbose_false
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_setup_handlers_verbose_false' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_logger_creation_with_custom_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logger_creation_with_custom_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestEdgeCases::test_pipeline_with_partial_validation_failures
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_with_partial_validation_failures' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestBaseModel::test_to_json
tests/unit/test_models_simple.py::TestBaseModel::test_to_json
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_to_json' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestBaseModel::test_str_representation
tests/unit/test_models_simple.py::TestBaseModel::test_str_representation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_str_representation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_creation
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_creation
tests/unit/test_working_examples.py::TestWorkingExamples::test_validation_thresholds_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_defaults
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_defaults' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_validation
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_invalid_bronze
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_invalid_bronze
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_invalid_bronze' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_invalid_silver
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_invalid_silver
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_invalid_silver' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_invalid_gold
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_invalid_gold
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_invalid_gold' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestValidationThresholds::test_validation_thresholds_hierarchy
tests/unit/test_models_simple.py::TestValidationThresholds::test_validation_thresholds_hierarchy
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_thresholds_hierarchy' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_logger_creation_with_custom_level
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logger_creation_with_custom_level' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_defaults
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_config_defaults' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_validation
tests/unit/test_models_simple.py::TestParallelConfig::test_parallel_config_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_config_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestParallelConfig::test_parallel_config_invalid_max_workers
tests/unit/test_models_simple.py::TestParallelConfig::test_parallel_config_invalid_max_workers
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_config_invalid_max_workers' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestPipelineConfig::test_pipeline_config_creation
tests/unit/test_models_simple.py::TestPipelineConfig::test_pipeline_config_creation
tests/unit/test_working_examples.py::TestWorkingExamples::test_pipeline_config_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestPipelineConfig::test_pipeline_config_invalid_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_config_invalid_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_success_with_gold_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_success_with_gold_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_creation
tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_creation
tests/unit/test_models.py::TestBronzeStep::test_bronze_step_creation
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_bronze_step_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_invalid_name
tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_invalid_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_invalid_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestBronzeStep::test_bronze_step_invalid_rules
tests/unit/test_models_simple.py::TestBronzeStep::test_bronze_step_invalid_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_invalid_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestSilverStep::test_silver_step_invalid_source_bronze
tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_invalid_source_bronze
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_invalid_source_bronze' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestSilverStep::test_silver_step_invalid_transform
tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_invalid_transform
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_invalid_transform' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestSilverStep::test_silver_step_invalid_table_name
tests/unit/test_models_simple.py::TestSilverStep::test_silver_step_invalid_table_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_invalid_table_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestGoldStep::test_gold_step_invalid_transform
tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_invalid_transform
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_invalid_transform' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestGoldStep::test_gold_step_invalid_table_name
tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_invalid_table_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_invalid_table_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestGoldStep::test_gold_step_invalid_source_silvers
tests/unit/test_models_simple.py::TestGoldStep::test_gold_step_invalid_source_silvers
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_invalid_source_silvers' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestStageStats::test_stage_stats_creation
tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_stage_stats_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestStageStats::test_stage_stats_validation
tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_stage_stats_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestStageStats::test_stage_stats_invalid_validation_rate
tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_invalid_validation_rate
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_stage_stats_invalid_validation_rate' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestStageStats::test_stage_stats_negative_values
tests/unit/test_models_simple.py::TestStageStats::test_stage_stats_negative_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_stage_stats_negative_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestExecutionContext::test_execution_context_validation
tests/unit/test_models_simple.py::TestExecutionContext::test_execution_context_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_context_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestExecutionContext::test_execution_context_invalid_pipeline_id
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_context_invalid_pipeline_id' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestPipelineMetrics::test_pipeline_metrics_creation
tests/unit/test_models_simple.py::TestPipelineMetrics::test_pipeline_metrics_creation
tests/integration/test_pipeline_builder.py::TestPipelineMetrics::test_pipeline_metrics_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_metrics_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestPipelineMetrics::test_pipeline_metrics_validation
tests/unit/test_models_simple.py::TestPipelineMetrics::test_pipeline_metrics_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_metrics_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestPipelineMetrics::test_pipeline_metrics_invalid_values
tests/unit/test_models_simple.py::TestPipelineMetrics::test_pipeline_metrics_invalid_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_metrics_invalid_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestPipelineReport::test_pipeline_report_creation
tests/unit/test_models_simple.py::TestPipelineReport::test_pipeline_report_creation
tests/integration/test_pipeline_builder.py::TestPipelineReport::test_pipeline_report_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_report_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestPipelineReport::test_pipeline_report_validation
tests/unit/test_models_simple.py::TestPipelineReport::test_pipeline_report_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_report_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestPipelineReport::test_pipeline_report_invalid_pipeline_id
tests/unit/test_models_simple.py::TestPipelineReport::test_pipeline_report_invalid_pipeline_id
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_report_invalid_pipeline_id' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestEnums::test_pipeline_status_enum
tests/unit/test_models_simple.py::TestEnums::test_pipeline_status_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_status_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestEnums::test_pipeline_mode_enum
tests/unit/test_models_simple.py::TestEnums::test_pipeline_mode_enum
tests/unit/test_types.py::TestEnums::test_pipeline_mode_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_mode_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestStepResult::test_step_result_validation
tests/unit/test_models_simple.py::TestStepResult::test_step_result_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_result_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_with_failed_silver_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_with_failed_silver_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_new.py::TestStepResult::test_step_result_invalid_step_name
tests/unit/test_models_simple.py::TestStepResult::test_step_result_invalid_step_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_result_invalid_step_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_with_failed_gold_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_with_failed_gold_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestEdgeCases::test_pipeline_all_invalid_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_all_invalid_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_silver_step_without_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_silver_step_without_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestExecutionModes::test_pipeline_sequential_execution_with_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_sequential_execution_with_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_simple.py::TestExecutionContext::test_execution_context_invalid_execution_id
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_context_invalid_execution_id' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestExecutePipelineComplete::test_execute_pipeline_gold_step_without_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_pipeline_gold_step_without_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_simple.py::TestEnums::test_pipeline_phase_enum
tests/unit/test_models.py::TestEnums::test_pipeline_phase_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_phase_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_simple.py::TestEnums::test_write_mode_enum
tests/unit/test_models.py::TestEnums::test_write_mode_enum
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_write_mode_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_mode_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models_simple.py::TestEnums::test_validation_result_enum
tests/unit/test_models.py::TestEnums::test_validation_result_enum
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_result_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestNowDt::test_now_dt_returns_datetime
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_now_dt_returns_datetime' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestNowDt::test_now_dt_returns_utc
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_now_dt_returns_utc' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestNowDt::test_now_dt_recent_time
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_now_dt_recent_time' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestFormatDuration::test_format_duration_seconds
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_format_duration_seconds' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestFormatDuration::test_format_duration_minutes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_format_duration_minutes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestFormatDuration::test_format_duration_hours
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_format_duration_hours' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestFormatDuration::test_format_duration_zero
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_format_duration_zero' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestFormatDuration::test_format_duration_negative
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_format_duration_negative' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestTimeOperation::test_time_operation_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_time_operation_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestTimeOperation::test_time_operation_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_time_operation_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestTimeOperation::test_time_operation_preserves_function_metadata
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_time_operation_preserves_function_metadata' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestTimeOperation::test_time_operation_with_args_and_kwargs
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_time_operation_with_args_and_kwargs' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_logger_creation_with_file
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logger_creation_with_file' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_basic_logging_methods
tests/system/test_logger.py::TestPipelineLogger::test_basic_logging_methods
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_basic_logging_methods' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestPipelineLoggerComprehensive::test_set_level
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_set_level' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_monitor_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logging.py::TestTimerContextManager::test_timer_context_manager_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_timer_context_manager_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_schema_and_table_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_init_with_schema_and_table_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_monitor_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_with_max_duration_warning
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_monitor_with_max_duration_warning' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestPerformanceMonitor::test_performance_monitor_with_max_duration_no_warning
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_monitor_with_max_duration_no_warning' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_invalid_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_time_write_operation_invalid_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_imports_table_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_time_write_operation_imports_table_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_append_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_time_write_operation_append_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_with_options
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_time_write_operation_with_options' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestTimeWriteOperation::test_time_write_operation_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_time_write_operation_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_monitor_performance_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_monitor_performance_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_with_max_duration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_monitor_performance_with_max_duration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestMonitorPerformance::test_monitor_performance_preserves_function_metadata
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_monitor_performance_preserves_function_metadata' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestPerformanceIntegration::test_all_functions_work_together
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_all_functions_work_together' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_config_shows_deprecation_warning
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_init_with_config_shows_deprecation_warning' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_without_required_params_raises_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_init_without_required_params_raises_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_only_schema_raises_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_init_with_only_schema_raises_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestLogWriterSimplifiedInit::test_init_with_only_table_name_raises_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_init_with_only_table_name_raises_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_silver_step_missing_source
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_silver_step_missing_source' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_creates_log_row
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_report_creates_log_row' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_populates_table_total_rows
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_report_populates_table_total_rows' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_with_errors
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_report_with_errors' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_generates_run_id_if_not_provided
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_report_generates_run_id_if_not_provided' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestConvertReportToLogRows::test_convert_report_includes_metadata
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_report_includes_metadata' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestCreateTableMethod::test_create_table_calls_storage_with_overwrite
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_table_calls_storage_with_overwrite' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestCreateTableMethod::test_create_table_returns_success_result
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_table_returns_success_result' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestCreateTableMethod::test_create_table_generates_run_id_if_not_provided
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_table_generates_run_id_if_not_provided' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_calls_storage_with_append_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_append_calls_storage_with_append_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_returns_success_result
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_append_returns_success_result' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_multiple_times
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_append_multiple_times' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestAppendMethod::test_append_refreshes_table_totals_between_runs
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_append_refreshes_table_totals_between_runs' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_logwriter_new_api.py::TestLogWriterNewAPIIntegration::test_complete_workflow_create_and_append
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_workflow_create_and_append' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestExceptions::test_pipeline_configuration_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_configuration_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestExceptions::test_pipeline_execution_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_execution_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_security_thresholds_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_thresholds_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_gold_step_missing_source
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_gold_step_missing_source' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestTypeDefinitions::test_model_value_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_model_value_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestTypeDefinitions::test_column_rule_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_column_rule_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestTypeDefinitions::test_resource_value_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_resource_value_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestBaseModel::test_base_model_abstract
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_model_abstract' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_models.py::TestBaseModel::test_base_model_validation_abstract
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_model_validation_abstract' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_schema_property
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_schema_property' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_validators_property
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validators_property' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_basic
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_basic
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_initialization_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_with_quality_rates
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_with_quality_rates
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_with_quality_rates
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_initialization_with_quality_rates' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_security_configuration_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_configuration_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_100_coverage.py::TestPrivateMethodsComplete::test_execute_gold_step_with_none_source_silvers
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execute_gold_step_with_none_source_silvers' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecutionMode::test_execution_mode_values
tests/integration/test_execution_engine.py::TestExecutionMode::test_execution_mode_values
tests/unit/dependencies/test_analyzer_comprehensive.py::TestExecutionMode::test_execution_mode_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_mode_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestExecutionMode::test_execution_mode_enumeration
tests/integration/test_execution_engine.py::TestExecutionMode::test_execution_mode_enumeration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_mode_enumeration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestStepStatus::test_step_status_values
tests/integration/test_execution_engine.py::TestStepStatus::test_step_status_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_status_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestStepStatus::test_step_status_enumeration
tests/integration/test_execution_engine.py::TestStepStatus::test_step_status_enumeration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_status_enumeration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_comprehensive.py::TestStepType::test_step_type_values
tests/integration/test_execution_engine.py::TestStepType::test_step_type_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_type_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_invalid_spark
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_invalid_spark
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_invalid_spark
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_initialization_invalid_spark' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_empty_schema
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_empty_schema
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_empty_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_initialization_empty_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_pipeline_id
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_pipeline_id
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_pipeline_id
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_initialization_pipeline_id' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_validators
tests/unit/test_pipeline_builder_basic.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_validators
tests/unit/test_pipeline_builder_simple.py::TestPipelineBuilderInitialization::test_pipeline_builder_initialization_validators
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_initialization_validators' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestAssessDataQuality::test_dataframe_with_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dataframe_with_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestPerformanceIntegration::test_duration_formatting_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_duration_formatting_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_performance.py::TestPerformanceIntegration::test_now_dt_consistency
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_now_dt_consistency' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_validation_only_mode_has_no_write_mode_for_gold_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_only_mode_has_no_write_mode_for_gold_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_spark_write_mode_matches_result_write_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_spark_write_mode_matches_result_write_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_all_execution_modes_covered
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_all_execution_modes_covered' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_basic
tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_bronze_rules_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_with_incremental_col
tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_with_incremental_col
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_bronze_rules_with_incremental_col' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_with_schema
tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_with_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_bronze_rules_with_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_duplicate_name
tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_duplicate_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_bronze_rules_duplicate_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_empty_name
tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_with_bronze_rules_empty_name
tests/unit/test_pipeline_builder_simple.py::TestBronzeRules::test_with_bronze_rules_empty_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_bronze_rules_empty_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestBronzeRules::test_with_bronze_rules_pyspark_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_bronze_rules_pyspark_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_basic
tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_silver_rules_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_with_watermark
tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_with_watermark
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_silver_rules_with_watermark' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_write_mode_consistency_across_step_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_mode_consistency_across_step_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestValidationResult::test_validation_result_creation
tests/unit/test_validation_simple.py::TestPipelineValidation::test_validation_result_creation
tests/unit/test_working_examples.py::TestWorkingExamples::test_validation_result_creation
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_result_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestExecutionEngineWriteMode::test_bronze_step_has_no_write_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_has_no_write_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestIncrementalScenarios::test_pipeline_multiple_incremental_runs
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_multiple_incremental_runs' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_duplicate_name
tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_duplicate_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_silver_rules_duplicate_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_validation_integration.py::TestValidationResult::test_validation_result_defaults
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_result_defaults' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_empty_rules_validation_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_empty_rules_validation_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestWriteModeRegression::test_incremental_mode_uses_append_for_silver_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_mode_uses_append_for_silver_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestSilverRules::test_with_silver_rules_empty_name
tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_with_silver_rules_empty_name
tests/unit/test_pipeline_builder_simple.py::TestSilverRules::test_with_silver_rules_empty_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_silver_rules_empty_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_anomaly_detection_pipeline
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_anomaly_detection_pipeline' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_execution_write_mode.py::TestWriteModeRegression::test_gold_incremental_mode_uses_overwrite
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_incremental_mode_uses_overwrite' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_write_mode_field
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_has_write_mode_field' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestValidatorManagement::test_add_multiple_validators
tests/unit/test_pipeline_builder_comprehensive.py::TestValidatorManagement::test_add_multiple_validators
tests/unit/test_pipeline_builder_simple.py::TestValidatorManagement::test_add_multiple_validators
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_multiple_validators' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestPipelineValidation::test_validate_pipeline_empty
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineValidation::test_validate_pipeline_empty
tests/unit/test_pipeline_builder_simple.py::TestPipelineValidation::test_validate_pipeline_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestPipelineValidation::test_validate_pipeline_invalid_config
tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineValidation::test_validate_pipeline_invalid_config
tests/unit/test_pipeline_builder_simple.py::TestPipelineValidation::test_validate_pipeline_invalid_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_invalid_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestToPipeline::test_to_pipeline_empty
tests/unit/test_pipeline_builder_comprehensive.py::TestToPipeline::test_to_pipeline_empty
tests/unit/test_pipeline_builder_simple.py::TestToPipeline::test_to_pipeline_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_to_pipeline_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_basic
tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_silver_transform_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_auto_inference
tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_auto_inference
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_silver_transform_auto_inference' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_no_bronze_steps
tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_add_silver_transform_no_bronze_steps
tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_no_bronze_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_silver_transform_no_bronze_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_invalid_source
tests/unit/test_pipeline_builder_simple.py::TestSilverTransform::test_add_silver_transform_invalid_source
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_silver_transform_invalid_source' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestSilverTransform::test_add_silver_transform_duplicate_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_silver_transform_duplicate_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_bronze_step_with_provided_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_with_provided_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestHelperMethods::test_create_schema_if_not_exists
tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_create_schema_if_not_exists
tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_create_schema_if_not_exists
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_schema_if_not_exists' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_validation_rate_field
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_has_validation_rate_field' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_basic
tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_gold_transform_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_auto_inference
tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_auto_inference
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_gold_transform_auto_inference' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestHelperMethods::test_create_schema_if_not_exists_failure
tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_create_schema_if_not_exists_failure
tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_create_schema_if_not_exists_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_schema_if_not_exists_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestClassMethods::test_for_development
tests/unit/test_pipeline_builder_comprehensive.py::TestClassMethods::test_for_development
tests/unit/test_pipeline_builder_simple.py::TestClassMethods::test_for_development
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_for_development' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestClassMethods::test_for_production
tests/unit/test_pipeline_builder_comprehensive.py::TestClassMethods::test_for_production
tests/unit/test_pipeline_builder_simple.py::TestClassMethods::test_for_production
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_for_production' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestErrorHandling::test_add_gold_transform_no_silver_steps
tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_no_silver_steps
tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_no_silver_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_gold_transform_no_silver_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_invalid_sources
tests/unit/test_pipeline_builder_simple.py::TestGoldTransform::test_add_gold_transform_invalid_sources
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_gold_transform_invalid_sources' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestGoldTransform::test_add_gold_transform_duplicate_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_gold_transform_duplicate_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_pipeline_builder_with_missing_columns
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_with_missing_columns' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestPipelineValidation::test_validate_pipeline_with_steps
tests/unit/test_pipeline_builder_simple.py::TestPipelineValidation::test_validate_pipeline_with_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_with_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestToPipeline::test_to_pipeline_basic
tests/unit/test_pipeline_builder_simple.py::TestToPipeline::test_to_pipeline_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_to_pipeline_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestToPipeline::test_to_pipeline_validation_failure
tests/unit/test_pipeline_builder_simple.py::TestToPipeline::test_to_pipeline_validation_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_to_pipeline_validation_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_validate_schema_existing
tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_validate_schema_existing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_schema_existing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_bronze_steps_storage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_steps_storage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_rows_written_field
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_has_rows_written_field' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_silver_steps_storage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_steps_storage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_gold_steps_storage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_steps_storage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_bronze_rules_column_validation.py::TestBronzeRulesColumnValidation::test_bronze_step_missing_data_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_missing_data_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_dict_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_dataframe_with_dict_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_tuple_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_dataframe_with_tuple_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_structtype_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_dataframe_with_structtype_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestHelperMethods::test_validate_schema_nonexistent
tests/unit/test_pipeline_builder_simple.py::TestHelperMethods::test_validate_schema_nonexistent
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_schema_nonexistent' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestIntegration::test_complete_pipeline_workflow
tests/unit/test_pipeline_builder_simple.py::TestIntegration::test_complete_pipeline_workflow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_pipeline_workflow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestCreateDataframeCompat::test_create_dataframe_with_tuple_and_structtype
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_dataframe_with_tuple_and_structtype' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_pyspark_dataframe
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pyspark_dataframe' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_has_input_rows_field
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_has_input_rows_field' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestStepExecutionResultFields::test_step_execution_result_default_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_result_default_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestPipelineReportFieldPropagation::test_pipeline_report_includes_write_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_report_includes_write_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_write_mode_populated_from_step_info
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_write_mode_populated_from_step_info' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_fields_calculated_correctly
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_validation_fields_calculated_correctly' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_perfect_rate
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_validation_perfect_rate' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_pipeline_configuration
tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_pipeline_configuration
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_pipeline_configuration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_configuration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_pipeline_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_basic.py::TestStepManagement::test_pipeline_id_generation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_id_generation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestIntegration::test_pipeline_with_custom_validator
tests/unit/test_pipeline_builder_simple.py::TestIntegration::test_pipeline_with_custom_validator
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_with_custom_validator' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_builder_comprehensive.py::TestIntegration::test_pipeline_with_multiple_schemas
tests/unit/test_pipeline_builder_simple.py::TestIntegration::test_pipeline_with_multiple_schemas
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_with_multiple_schemas' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_iot_pipeline.py::TestIotPipeline::test_performance_monitoring
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_monitoring' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_mock_spark_dataframe
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_mock_spark_dataframe' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_non_dataframe_object
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_non_dataframe_object' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestIsDataframeLike::test_object_with_some_methods
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_object_with_some_methods' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestDetectSparkType::test_detect_mock_spark
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_detect_mock_spark' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestDetectSparkType::test_detect_pyspark
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_detect_pyspark' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestCreateTestDataframe::test_create_test_dataframe_with_dict
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_test_dataframe_with_dict' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestCreateTestDataframe::test_create_test_dataframe_with_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_test_dataframe_with_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_compat_helpers.py::TestCreateTestDataframe::test_create_test_dataframe_with_tuples
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_test_dataframe_with_tuples' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestMemoryConstants::test_bytes_per_kb
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bytes_per_kb' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestMemoryConstants::test_bytes_per_mb
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bytes_per_mb' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_low_rate
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_validation_low_rate' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_rows_written_vs_rows_processed
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_rows_written_vs_rows_processed' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_all_phases_have_correct_fields
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_all_phases_have_correct_fields' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_failed_step_has_zero_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_failed_step_has_zero_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_validation_calculation_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_validation_calculation_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_log_row_fields.py::TestLogRowFieldCalculations::test_log_row_different_write_modes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_different_write_modes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestMemoryConstants::test_bytes_per_gb
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bytes_per_gb' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestDefaultMemoryLimits::test_default_max_memory_mb
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_max_memory_mb' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestDefaultMemoryLimits::test_default_cache_memory_mb
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_cache_memory_mb' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestFileSizeConstants::test_default_max_file_size_mb
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_max_file_size_mb' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestFileSizeConstants::test_default_backup_count
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_backup_count' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_skipped
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_transform_dict_skipped' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_rounding
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_transform_dict_rounding' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_type_conversion
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_transform_dict_type_conversion' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_write_dict_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_skipped
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_write_dict_skipped' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestPerformanceConstants::test_default_cache_partitions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_cache_partitions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestPerformanceConstants::test_default_shuffle_partitions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_shuffle_partitions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestValidationConstants::test_default_bronze_threshold
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_bronze_threshold' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_constants.py::TestValidationConstants::test_default_silver_threshold
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_default_silver_threshold' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestIncrementalScenarios::test_pipeline_incremental_with_gaps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_incremental_with_gaps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_incremental_sets_expected_write_modes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_incremental_sets_expected_write_modes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_rounding
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_write_dict_rounding' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_reporting_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateWriteDict::test_create_write_dict_type_conversion
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_write_dict_type_conversion' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_summary_report_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_zero_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_summary_report_zero_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_perfect_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_summary_report_perfect_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_rounding
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_summary_report_rounding' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateSummaryReport::test_create_summary_report_zero_division_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_summary_report_zero_division_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestReportingIntegration::test_all_functions_return_dicts
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_all_functions_return_dicts' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_initial_load_uses_overwrite_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_initial_load_uses_overwrite_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestReportingIntegration::test_consistent_datetime_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_consistent_datetime_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_import
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_reporting_import' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_reporting_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_execution_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_execution_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_full_refresh_uses_overwrite_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_full_refresh_uses_overwrite_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_quality_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_quality_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_performance_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_performance_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_generate_error_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_error_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_pipeline_with_incremental_mode_sets_expected_write_modes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_pipeline_with_incremental_mode_sets_expected_write_modes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_format_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_format_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestDataQuality::test_pipeline_null_handling_with_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_null_handling_with_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_save_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_save_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_print_report
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_print_report' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_run_pipeline_with_initial_mode_uses_overwrite
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_run_pipeline_with_initial_mode_uses_overwrite' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_module_attributes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_reporting_module_attributes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_pipeline_mode_mapping_to_execution_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_mode_mapping_to_execution_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_step_result_validation_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_result_validation_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_stage_stats_validation_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_stage_stats_validation_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_comprehensive_coverage_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_comprehensive_coverage_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestDataQuality::test_pipeline_duplicate_data_with_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_duplicate_data_with_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_incremental_vs_initial_write_mode_difference
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_vs_initial_write_mode_difference' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_no_data_loss_in_incremental_mode_for_silver_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_data_loss_in_incremental_mode_for_silver_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_pipeline_runner_write_mode.py::TestPipelineRunnerWriteMode::test_execution_engine_receives_correct_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_receives_correct_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_no_dict_type_annotations
tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_no_dict_type_annotations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_dict_type_annotations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_module_reload
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_reporting_module_reload' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_imports
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_reporting_imports' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_function_signatures
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_reporting_function_signatures' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting_coverage.py::TestReportingCoverage::test_reporting_module_documentation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_reporting_module_documentation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_dict_instantiation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dict_instantiation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_dict_type_annotation_works
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dict_type_annotation_works' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_dict_vs_Dict_equivalence
tests/unit/test_dict_annotations.py::test_dict_vs_Dict_equivalence
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dict_vs_Dict_equivalence' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_python_version
tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_python_version
tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_python_version
tests/unit/test_dict_annotations.py::test_python_version
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_python_version' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_comprehensive_coverage_working
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_sparkforge_working.py:590: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=writer_config)

tests/unit/test_table_operations.py::TestFqn::test_fqn_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_fqn_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestFqn::test_fqn_different_names
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_fqn_different_names' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestFqn::test_fqn_empty_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_fqn_empty_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestFqn::test_fqn_empty_table
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_fqn_empty_table' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestFqn::test_fqn_both_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_fqn_both_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestFqn::test_fqn_none_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_fqn_none_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestFqn::test_fqn_none_table
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_fqn_none_table' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_typeddict_compatibility
tests/unit/test_python38_compatibility.py::DictTypeAnnotationTest::test_typeddict_compatibility
tests/unit/test_dict_annotations.py::test_typeddict_compatibility
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_typeddict_compatibility' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_simple_dict_check.py::SimpleDictCheckTest::test_union_with_dict_works
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_union_with_dict_works' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_pipeline_builder_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_with_options
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_overwrite_table_with_options' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_overwrite_table_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_zero_rows
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_overwrite_table_zero_rows' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_all_files_parseable
tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_all_files_parseable
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_all_files_parseable' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_import_compatibility
tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_import_compatibility
tests/unit/test_dict_annotations.py::test_import_compatibility
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_import_compatibility' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_execution_engine_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_validation_system_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_system_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_writer_system_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_system_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_writer_system_working
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_sparkforge_working.py:210: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_models_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_models_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_logging_system_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logging_system_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_performance_system_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_performance_system_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_table_operations_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_table_operations_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_error_handling_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_handling_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_validation_utils_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_utils_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_pipeline_validation_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_validation_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_append_table_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_with_options
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_append_table_with_options' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_append_table_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestWriteAppendTable::test_write_append_table_zero_rows
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_append_table_zero_rows' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestReadTable::test_read_table_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_read_table_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestReadTable::test_read_table_analysis_exception
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_read_table_analysis_exception' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestReadTable::test_read_table_other_exception
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_read_table_other_exception' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestWriteOverwriteTable::test_write_overwrite_table_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_overwrite_table_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestTableExists::test_table_exists_false_analysis_exception
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_table_exists_false_analysis_exception' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestTableExists::test_table_exists_true
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_table_exists_true' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_sparkforge_working.py::TestSparkForgeWorking::test_edge_cases_working
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_edge_cases_working' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_unexpected_error_is_logged_and_re_raised
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unexpected_error_is_logged_and_re_raised' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_successful_assessment_returns_correct_metrics
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_successful_assessment_returns_correct_metrics' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestTableExists::test_table_exists_false_other_exception
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_table_exists_false_other_exception' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestDropTable::test_drop_table_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_drop_table_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestDropTable::test_drop_table_with_default_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_drop_table_with_default_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_successful_assessment_with_rules_returns_correct_metrics
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_successful_assessment_with_rules_returns_correct_metrics' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestDropTable::test_drop_table_not_exists
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_drop_table_not_exists' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_empty_dataframe_returns_correct_metrics
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_empty_dataframe_returns_correct_metrics' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestDropTable::test_drop_table_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_drop_table_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_no_fallback_response_for_errors
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_fallback_response_for_errors' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestDropTable::test_drop_table_exception_during_check
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_drop_table_exception_during_check' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_execution_engine_creation_in_to_pipeline
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_creation_in_to_pipeline' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestTableOperationsIntegration::test_fqn_with_table_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_fqn_with_table_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_objects_are_not_garbage_collected
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_objects_are_not_garbage_collected' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_pipeline_validation_before_object_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_validation_before_object_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestTableOperationsIntegration::test_write_and_read_workflow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_and_read_workflow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_2_missing_object_creation.py::TestTrap2MissingObjectCreation::test_objects_are_accessible_after_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_objects_are_accessible_after_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_table_operations.py::TestTableOperationsIntegration::test_table_lifecycle
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_table_lifecycle' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_step_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_uses_actual_step_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_table_info
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_uses_actual_table_info' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_input_rows
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_uses_actual_input_rows' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_fallback_for_missing_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_fallback_for_missing_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_validation_metrics_are_calculated_correctly
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_validation_metrics_are_calculated_correctly' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_3_hardcoded_fallback_values.py::TestTrap3HardcodedFallbackValues::test_log_row_uses_actual_execution_context_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_row_uses_actual_execution_context_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_core_writer_raises_specific_exceptions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_core_writer_raises_specific_exceptions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_core_writer_raises_specific_exceptions
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_trap_4_broad_exception_catching.py:31: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_core_writer_analytics_raises_specific_exceptions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_core_writer_analytics_raises_specific_exceptions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_core_writer_analytics_raises_specific_exceptions
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_trap_4_broad_exception_catching.py:57: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_storage_manager_raises_specific_exceptions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_storage_manager_raises_specific_exceptions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_analytics_raises_specific_exceptions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analytics_raises_specific_exceptions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_monitoring_raises_specific_exceptions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_monitoring_raises_specific_exceptions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_execution_engine_rules_check_without_hasattr
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_rules_check_without_hasattr' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_dependency_analyzer_source_bronze_without_hasattr
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analyzer_source_bronze_without_hasattr' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_dependency_analyzer_source_silvers_without_hasattr
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analyzer_source_silvers_without_hasattr' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_pipeline_validator_dependencies_hasattr_improved
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_validator_dependencies_hasattr_improved' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_logging_context_removes_redundant_hasattr
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logging_context_removes_redundant_hasattr' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_base_model_to_dict_keeps_appropriate_hasattr
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_base_model_to_dict_keeps_appropriate_hasattr' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_6_hasattr_checks.py::TestTrap6HasattrChecks::test_execution_context_mode_handling_keeps_appropriate_hasattr
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_context_mode_handling_keeps_appropriate_hasattr' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_environment_variable_parsing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_environment_variable_parsing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_environment_variable_parsing_basic_spark
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_environment_variable_parsing_basic_spark' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_error_message_contains_helpful_guidance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_message_contains_helpful_guidance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_isolated_session_error_message_contains_helpful_guidance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_isolated_session_error_message_contains_helpful_guidance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_environment_variable_combination_logic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_environment_variable_combination_logic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_helpful_error_message_format
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_helpful_error_message_format' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_7_silent_fallback_test_config.py::TestTrap7SilentFallbackTestConfig::test_isolated_session_helpful_error_message_format
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_isolated_session_helpful_error_message_format' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_start_operation_raises_specific_exception_on_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_start_operation_raises_specific_exception_on_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_end_operation_raises_specific_exception_on_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_end_operation_raises_specific_exception_on_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_check_performance_thresholds_raises_specific_exception_on_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_check_performance_thresholds_raises_specific_exception_on_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_get_memory_usage_raises_specific_exception_on_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_memory_usage_raises_specific_exception_on_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_analyze_execution_trends_raises_specific_exception_on_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_execution_trends_raises_specific_exception_on_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_detect_anomalies_raises_specific_exception_on_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_detect_anomalies_raises_specific_exception_on_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_generate_performance_report_raises_specific_exception_on_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_performance_report_raises_specific_exception_on_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_error_chaining_preserves_original_exception
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_chaining_preserves_original_exception' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_8_generic_error_handling_performance.py::TestTrap8GenericErrorHandlingPerformance::test_logging_still_occurs_before_exception_raising
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logging_still_occurs_before_exception_raising' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_writer_config_generate_table_name_requires_parameters
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_config_generate_table_name_requires_parameters' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_writer_config_generate_table_name_with_pattern_requires_parameters
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_config_generate_table_name_with_pattern_requires_parameters' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_writer_config_generate_table_name_without_patterns_works_with_none
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_config_generate_table_name_without_patterns_works_with_none' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_execution_engine_context_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_context_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_execution_engine_context_type_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_context_type_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_run_id_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_run_id_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_run_id_handling
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_trap_9_default_value_fallbacks.py:146: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=spark_session, config=config)

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_batch_run_ids_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_batch_run_ids_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_batch_run_ids_handling
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_trap_9_default_value_fallbacks.py:185: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=spark_session, config=config)

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_display_limit_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_display_limit_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_log_writer_display_limit_handling
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_trap_9_default_value_fallbacks.py:223: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=spark_session, config=config)

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_logger_initialization_explicit_none
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logger_initialization_explicit_none' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_logger_initialization_with_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logger_initialization_with_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_step_result_step_type_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_result_step_type_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_9_default_value_fallbacks.py::TestTrap9DefaultValueFallbacks::test_step_result_step_type_with_value
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_result_step_type_with_value' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestTypeAliases::test_string_type_aliases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_string_type_aliases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestTypeAliases::test_numeric_type_aliases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_numeric_type_aliases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestTypeAliases::test_dictionary_type_aliases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dictionary_type_aliases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestTypeAliases::test_optional_type_aliases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_optional_type_aliases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestFunctionTypes::test_transform_function_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_transform_function_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestFunctionTypes::test_filter_function_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_filter_function_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestDataTypeAliases::test_column_rules_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_column_rules_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestDataTypeAliases::test_result_type_aliases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_result_type_aliases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_parallel_execution.py::test_parallel_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parallel_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestDataTypeAliases::test_context_type_aliases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_context_type_aliases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineMode::test_pipeline_mode_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_mode_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestDataTypeAliases::test_config_type_aliases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_config_type_aliases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineStatus::test_pipeline_status_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_status_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestDataTypeAliases::test_quality_thresholds_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_quality_thresholds_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestDataTypeAliases::test_error_type_aliases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_type_aliases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestProtocols::test_validatable_protocol
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validatable_protocol' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineReport::test_pipeline_report_to_dict
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_report_to_dict' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestProtocols::test_serializable_protocol
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_serializable_protocol' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_add_gold_transform
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_gold_transform' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_add_silver_transform
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_add_silver_transform' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestTypeUsage::test_pipeline_configuration_usage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_configuration_usage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_builder_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_builder_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestTypeUsage::test_step_result_usage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_result_usage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestTypeUsage::test_validation_context_usage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_context_usage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_builder_creation_with_custom_params
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_builder_creation_with_custom_params' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_types.py::TestTypeUsage::test_error_handling_usage
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_handling_usage' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_to_pipeline_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_to_pipeline_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_to_pipeline_validation_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_to_pipeline_validation_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_error_concatenation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_error_concatenation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_errors
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_errors' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validate_pipeline_return_type
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_pipeline_return_type' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_validator_return_types
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validator_return_types' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_with_bronze_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_bronze_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilder::test_with_silver_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_with_silver_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_builder.py::TestPipelineBuilderIntegration::test_complex_pipeline_construction
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complex_pipeline_construction' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation.py::TestAndAllRules::test_single_rule
tests/unit/test_validation_mock.py::TestConvertRulesToExpressions::test_single_rule
tests/unit/test_validation_mock.py::TestAndAllRules::test_single_rule
tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_single_rule
tests/unit/test_validation_standalone.py::TestAndAllRules::test_single_rule
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_single_rule' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_bronze_step_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_bronze_step_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation.py::TestAndAllRules::test_multiple_rules
tests/unit/test_validation_mock.py::TestConvertRulesToExpressions::test_multiple_rules
tests/unit/test_validation_mock.py::TestAndAllRules::test_multiple_rules
tests/unit/test_validation_standalone.py::TestAndAllRules::test_multiple_rules
tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_multiple_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_multiple_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_silver_step_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_silver_step_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_python38_compatibility.py::Python38CompatibilityTest::test_no_legacy_typing_imports
tests/unit/test_trap_10_silent_test_skip.py::Python38CompatibilityTest::test_no_legacy_typing_imports
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_legacy_typing_imports' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_python38_compatibility.py::DictTypeAnnotationTest::test_dict_vs_Dict_compatibility
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dict_vs_Dict_compatibility' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_python38_compatibility.py::DictTypeAnnotationTest::test_union_type_compatibility
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_union_type_compatibility' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_python38_compatibility.py::ImportCompatibilityTest::test_core_imports
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_core_imports' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_python38_compatibility.py::ImportCompatibilityTest::test_models_imports
tests/unit/test_dict_annotations.py::test_models_imports
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_models_imports' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_python38_compatibility.py::ImportCompatibilityTest::test_writer_imports
tests/unit/test_dict_annotations.py::test_writer_imports
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_imports' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateValidationDict::test_create_validation_dict_with_stats
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_validation_dict_with_stats' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateValidationDict::test_create_validation_dict_without_stats
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_validation_dict_without_stats' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateValidationDict::test_create_validation_dict_rounding
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_validation_dict_rounding' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_gold_step_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_gold_step_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_reporting.py::TestCreateTransformDict::test_create_transform_dict_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_transform_dict_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation.py::TestApplyColumnRules::test_none_rules_raises_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_none_rules_raises_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_exception_chaining_preserves_original_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_exception_chaining_preserves_original_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_validation
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_pipeline_builder_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_exception_chaining_preserves_original_error
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_trap_4_broad_exception_catching.py:155: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_builder_to_pipeline
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_to_pipeline' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_no_generic_error_responses_returned
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_generic_error_responses_returned' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_no_generic_error_responses_returned
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_trap_4_broad_exception_catching.py:178: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(

tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_parsing_errors_are_logged_and_tracked
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parsing_errors_are_logged_and_tracked' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_parsing_errors_in_dict_syntax_are_logged_and_tracked
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_parsing_errors_in_dict_syntax_are_logged_and_tracked' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_valid_files_are_processed_normally
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_valid_files_are_processed_normally' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_error_logging_before_raising
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_error_logging_before_raising' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_4_broad_exception_catching.py::TestTrap4BroadExceptionCatching::test_error_logging_before_raising
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_trap_4_broad_exception_catching.py:216: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(

tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_silver_step_without_schema_raises_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_without_schema_raises_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_gold_step_without_schema_raises_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_without_schema_raises_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_silver_step_with_schema_works_correctly
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_silver_step_with_schema_works_correctly' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_gold_step_with_schema_works_correctly
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_gold_step_with_schema_works_correctly' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_pipeline_execution_logs_missing_schema_warnings
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_execution_logs_missing_schema_warnings' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_no_silent_fallback_to_default_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_silent_fallback_to_default_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_5_default_schema_fallbacks.py::TestTrap5DefaultSchemaFallbacks::test_validation_mode_skips_schema_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_mode_skips_schema_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_no_column_expressions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_and_all_rules_no_column_expressions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_apply_column_rules_validation_predicate_true
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_apply_column_rules_validation_predicate_true' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_apply_column_rules_with_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_apply_column_rules_with_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_safe_divide_edge_cases
tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_safe_divide_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_validate_dataframe_schema_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_dataframe_schema_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_get_dataframe_info_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dataframe_info_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_get_dataframe_info_error_handling
tests/unit/test_validation_simple.py::TestValidationUtils::test_get_dataframe_info_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dataframe_info_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_assess_data_quality_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_assess_data_quality_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_apply_column_rules_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_apply_column_rules_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_execution_with_mock_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_execution_with_mock_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_convert_rules_to_expressions_complex_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_rules_to_expressions_complex_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_convert_rule_to_expression_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_rule_to_expression_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_single_expression
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_and_all_rules_single_expression' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_multiple_expressions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_and_all_rules_multiple_expressions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_string_rule_conversion_edge_cases
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_string_rule_conversion_edge_cases' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_validation_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_convert_rule_to_expression_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rule_to_expression_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_rule_to_expression_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_configuration_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_configuration_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_complete_marketing_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_marketing_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_multiple_parsing_errors_are_all_tracked
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_multiple_parsing_errors_are_all_tracked' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_execution_engine_with_pipeline_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_with_pipeline_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py: 12 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_enhanced.py:99: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    self.mock_functions = Functions()

tests/unit/test_trap_10_silent_test_skip.py::TestTrap10SilentTestSkip::test_logging_uses_correct_module_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logging_uses_correct_module_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_trap_1_silent_exception_handling.py::TestTrap1SilentExceptionHandling::test_validation_error_is_re_raised
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_error_is_re_raised' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_step_execution_with_real_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_step_execution_with_real_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_convert_rule_to_expression_with_default_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_rule_to_expression_with_default_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation.py::TestAssessDataQuality::test_basic_data_quality_assessment
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_basic_data_quality_assessment' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_step_validation_with_real_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_step_validation_with_real_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_convert_rules_to_expressions_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rules_to_expressions_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_rules_to_expressions_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation.py::TestApplyColumnRules::test_basic_validation
tests/unit/test_validation_mock.py::TestApplyColumnRules::test_basic_validation
tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_basic_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_basic_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_incremental_marketing_processing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_marketing_processing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_complete_multi_source_integration_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_multi_source_integration_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation.py::TestAssessDataQuality::test_data_quality_with_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_data_quality_with_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_execution.py::TestPipelineExecutionFlow::test_pipeline_execution_flow_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_execution_flow_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_monitor_initialization_with_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_monitor_initialization_with_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_monitor_initialization_without_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_monitor_initialization_without_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_start_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_start_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_start_execution_with_empty_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_start_execution_with_empty_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_and_all_rules_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_and_all_rules_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_and_all_rules_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/integration/test_pipeline_monitor.py::TestSimplePipelineMonitor::test_start_execution_with_mocked_time
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_start_execution_with_mocked_time' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_schema_evolution_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_schema_evolution_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validate_dataframe_schema_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validate_dataframe_schema_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_dataframe_schema_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestHighVolume::test_pipeline_high_volume_with_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_high_volume_with_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation.py::TestApplyValidationRules::test_apply_column_rules_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_apply_column_rules_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_error_handling
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_mock_functions_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_error_handling
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_functions_protocol_type_checking
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_behavior
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_validation_with_mock_functions_end_to_end
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_performance
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_enhanced.py:425: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    self.mock_functions = Functions()

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_apply_column_rules_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_apply_column_rules_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_apply_column_rules_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_functions_backward_compatibility
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_functions_backward_compatibility
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_functions_backward_compatibility' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation.py::TestApplyValidationRules::test_apply_column_rules_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_apply_column_rules_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_convert_rule_to_expression_string_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_rule_to_expression_string_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_additional_coverage.py::TestValidationEdgeCases::test_and_all_rules_empty_expressions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_and_all_rules_empty_expressions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_functions_protocol_type_checking
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_functions_protocol_type_checking' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_complex_dependency_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complex_dependency_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_mock_functions_protocol_compliance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_mock_functions_protocol_compliance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_assess_data_quality_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_assess_data_quality_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_assess_data_quality_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced_simple.py: 13 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_enhanced_simple.py:100: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    self.mock_functions = Functions()

tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_static_methods_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_static_methods_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_static_methods_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_static_methods_with_mock_functions
tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_backward_compatibility
tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_class_methods_with_mock_functions
tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_with_mock_functions
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_enhanced.py:328: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    self.mock_functions = Functions()

tests/builder_tests/test_multi_source_pipeline.py::TestMultiSourcePipeline::test_multi_source_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_multi_source_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_simple.py::test_simple_pipeline_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_simple_pipeline_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rule_in_not_in_like
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_rule_in_not_in_like' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_backward_compatibility
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_backward_compatibility
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_backward_compatibility' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_with_complex_rules
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_with_complex_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_with_complex_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation.py::TestConvertRuleToExpression::test_custom_expression_rule
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_custom_expression_rule' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_convert_rule_in_requires_iterable
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_convert_rule_in_requires_iterable' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestComplexDependencies::test_pipeline_complex_dependencies_with_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_complex_dependencies_with_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_class_methods_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_class_methods_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_class_methods_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_error_handling_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_error_handling_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_error_handling_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_simple_pipeline.py::TestSimplePipeline::test_simple_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_simple_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_behavior
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_behavior
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_mock_functions_behavior' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced.py::TestValidationWithFunctions::test_validation_performance_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_validation_performance_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_performance_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_validation_with_mock_functions_end_to_end
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_validation_with_mock_functions_end_to_end
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_with_mock_functions_end_to_end' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_validation_with_mock_functions_end_to_end
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_performance
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_error_handling
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_functions_protocol_compatibility
tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_behavior
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_enhanced_simple.py:435: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    self.mock_functions = Functions()

tests/unit/test_validation_enhanced.py::TestPipelineBuilderWithFunctions::test_pipeline_builder_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_with_mock_functions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_with_mock_functions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_mock_functions_performance
tests/unit/test_validation_enhanced.py::TestFunctionsIntegration::test_mock_functions_performance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_mock_functions_performance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_static_methods_with_mock_functions
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_backward_compatibility
tests/unit/test_validation_enhanced_simple.py::TestPipelineBuilderWithFunctionsSimple::test_pipeline_builder_class_methods_with_mock_functions
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_enhanced_simple.py:338: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    self.mock_functions = Functions()

tests/unit/test_validation_mock.py: 17 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_mock.py:107: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    return Functions()

tests/system/test_full_pipeline_with_logging_variations.py::TestParallelStress::test_pipeline_parallel_execution_stress
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_parallel_execution_stress' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_mock.py::TestSafeDivide::test_none_numerator
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_none_numerator' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced_simple.py::TestFunctionsIntegrationSimple::test_functions_protocol_compatibility
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_functions_protocol_compatibility' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_enhanced_simple.py::TestValidationWithFunctionsSimple::test_mock_functions_basic_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_mock_functions_basic_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_mock.py::TestSafeDivide::test_both_none
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_both_none' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_mock.py::TestConvertRuleToExpression::test_custom_expression
tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_custom_expression
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_custom_expression' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestSchemaEvolution::test_pipeline_with_schema_evolution_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_with_schema_evolution_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_mock.py::TestSafeDivide::test_division_by_none
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_division_by_none' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestDataTypes::test_pipeline_data_type_variations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_data_type_variations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestValidationThresholds::test_pipeline_validation_thresholds_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_validation_thresholds_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestWriteModes::test_pipeline_write_mode_variations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_write_mode_variations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_mock.py::TestAssessDataQuality::test_basic_quality_assessment
tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_basic_quality_assessment
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_basic_quality_assessment' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestMixedSuccessFailure::test_pipeline_mixed_success_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_mixed_success_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_mock.py::TestAssessDataQuality::test_multiple_quality_rules
tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_multiple_quality_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_multiple_quality_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_none_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_safe_divide_none_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_none_dataframe
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_none_dataframe
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_none_dataframe' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_pipeline_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_pipeline_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_mock.py::TestValidateDataframeSchema::test_none_expected_columns
tests/unit/test_validation_standalone.py::TestValidateDataframeSchema::test_none_expected_columns
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_none_expected_columns' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_step_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_step_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_workflow_with_mock_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_workflow_with_mock_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestValidationUtils::test_get_dataframe_info_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dataframe_info_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_custom_validators
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_custom_validators' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestPipelineValidation::test_validation_result_false
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_result_false' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_with_pipeline_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_with_pipeline_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_invalid_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_invalid_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_empty_pipeline
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_empty_pipeline' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_with_complex_pipeline
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_with_complex_pipeline' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_full_pipeline_with_logging_variations.py::TestLongRunning::test_pipeline_long_running_with_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_long_running_with_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_auto_infer_gold_source_silvers
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_auto_infer_gold_source_silvers' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_auto_infer_gold_source_silvers_explicit
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_auto_infer_gold_source_silvers_explicit' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_auto_infer_gold_no_silver_steps_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_auto_infer_gold_no_silver_steps_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_preset_configurations_development
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_preset_configurations_development' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_preset_configurations_production
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_preset_configurations_production' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_preset_configurations_testing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_preset_configurations_testing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestPipelineValidation::test_unified_validator_add_validator
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_add_validator' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_not_null_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_helper_not_null_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_positive_number_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_helper_positive_number_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_string_not_empty_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_helper_string_not_empty_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_validation_helper_timestamp_rules
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_helper_timestamp_rules' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_detect_timestamp_columns
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_detect_timestamp_columns' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_detect_timestamp_columns_list
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_detect_timestamp_columns_list' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_improved_user_experience.py::TestImprovedUserExperience::test_chaining_with_auto_inference
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_chaining_with_auto_inference' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestValidationIntegration::test_validation_error_scenarios
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_error_scenarios' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_standalone.py::TestSafeDivide::test_normal_division_float
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_normal_division_float' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_logger.py::TestPipelineLogger::test_log_level_management
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_level_management' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_simple.py::TestValidationErrorHandling::test_validation_error_with_context
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_error_with_context' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_standalone.py::TestSafeDivide::test_division_with_default
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_division_with_default' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_non_negative_rule
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:200: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_simple.py::TestValidationErrorHandling::test_validation_error_attributes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_error_attributes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_non_zero_rule
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:213: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestAndAllRules::test_multiple_rules
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:327: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_not_null_rule
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:173: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_multiple_rules
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:267: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_basic_quality_assessment
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:449: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_basic_validation
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:347: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestConvertRuleToExpression::test_positive_rule
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:187: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_empty_rules
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:283: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_multiple_quality_rules
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:484: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_multiple_columns
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:384: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestConvertRulesToExpressions::test_single_rule
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:252: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestAndAllRules::test_empty_rules
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:300: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_validation_standalone.py::TestAssessDataQuality::test_empty_rules
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:521: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_working_examples.py::TestWorkingExamples::test_pipeline_builder_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_standalone.py::TestApplyColumnRules::test_empty_rules
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:421: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_working_examples.py::TestWorkingExamples::test_execution_engine_with_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_execution_engine_with_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_working_examples.py::TestWorkingExamples::test_unified_validator_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_working_examples.py::TestWorkingExamples::test_mock_spark_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_mock_spark_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_working_examples.py::TestWorkingExamples::test_pipeline_builder_with_quality_rates
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_builder_with_quality_rates' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_working_examples.py::TestWorkingExamples::test_writer_config_with_custom_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_config_with_custom_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_validation_standalone.py::TestAndAllRules::test_single_rule
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_validation_standalone.py:313: DeprecationWarning: Functions() is deprecated. Use 'from sparkless.sql import functions as F' instead. This matches PySpark where functions is a module, not a class. Migration: Replace 'Functions()' with 'from sparkless.sql import functions as F'. Example: Instead of 'f = Functions(); f.col("name")', use 'from sparkless.sql import functions as F; F.col("name")'.
    mock_functions = Functions()

tests/unit/test_working_examples.py::TestWorkingExamples::test_validation_result_with_errors
tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_with_errors
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_result_with_errors' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_working_examples.py::TestWorkingExamples::test_log_writer_with_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_with_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_working_examples.py::TestWorkingExamples::test_log_writer_with_config
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_working_examples.py:107: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_working_examples.py::TestWorkingExamples::test_writer_config_creation
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_config_creation
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_writer_config_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_config_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_working_examples.py::TestWorkingExamples::test_enum_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_enum_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_table_exists_function
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_table_exists_function
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_table_exists_function' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_config_defaults
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_config_defaults' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_with_custom_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_with_custom_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_with_custom_logger
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:225: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(

tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_safe_divide_properties
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_safe_divide_properties' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_execution_result' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:254: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_safe_divide_zero_denominator_properties
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_safe_divide_zero_denominator_properties' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_time_write_operation_function
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_time_write_operation_function' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_initialization
tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_initialization
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:204: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_invalid_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_invalid_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_log_writer_invalid_config
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:242: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_step_results
tests/unit/writer/test_core.py::TestLogWriter::test_write_step_results
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_step_results' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_step_results
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:337: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result_batch
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_execution_result_batch' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result_batch
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:428: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_write_modes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_with_different_write_modes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_write_modes
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:489: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer_append = LogWriter(spark=mock_spark_session, config=config_append)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_write_modes
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:505: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer_overwrite = LogWriter(spark=mock_spark_session, config=config_overwrite)

tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_validate_dataframe_schema_properties
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_dataframe_schema_properties' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_partition_settings
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_with_partition_settings' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_partition_settings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:593: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result_with_metadata
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_execution_result_with_metadata' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_execution_result_with_metadata
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:311: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_dataframe_schema_edge_cases_properties
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dataframe_schema_edge_cases_properties' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_metrics_tracking
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_metrics_tracking' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_metrics_tracking
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:450: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_log_rows
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_log_rows' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_write_log_rows
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:379: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_schema_evolution_settings
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_schema_evolution_settings' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_schema_evolution_settings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:617: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_schema_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_schema_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_schema_creation
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:678: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_validation_simple.py::TestValidationUtils::test_safe_divide_normal
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_safe_divide_normal' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_log_levels
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_with_different_log_levels' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_log_levels
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_log_levels
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_log_levels
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_log_levels
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_different_log_levels
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:528: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_error_handling
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:638: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_custom_batch_size
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_with_custom_batch_size' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_custom_batch_size
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:547: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_initialization
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_core_simple.py:70: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=spark_session, config=config)

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_invalid_spark_session
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_invalid_spark_session' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_invalid_spark_session
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_core_simple.py:92: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=None, config=config)

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_initialization_with_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_initialization_with_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_initialization_with_config
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_core_simple.py:82: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_table_fqn
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_table_fqn' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_table_fqn
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:697: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_table_fqn
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:708: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer2 = LogWriter(spark=mock_spark_session, config=config2)

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_components_initialization
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_components_initialization' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_components_initialization
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:652: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_get_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_get_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_get_config
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_core_simple.py:114: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=spark_session, config=config)

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_get_spark
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_get_spark' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_get_spark
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_core_simple.py:102: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=spark_session, config=config)

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_table_exists_function_invalid_parameters
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_table_exists_function_invalid_parameters' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_compression_settings
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_with_compression_settings' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_compression_settings
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_compression_settings
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_compression_settings
tests/unit/test_writer_comprehensive.py::TestWriterComprehensive::test_writer_with_compression_settings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_comprehensive.py:571: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=config)

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_error_handling
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_core_simple.py:238: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    LogWriter(spark=spark_session, config=config)

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_level_enum
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_level_enum' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_writer_config_default_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_writer_config_default_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_metrics_collection
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_metrics_collection' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_metrics_collection
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_core_simple.py:247: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    LogWriter(spark=spark_session, config=config)

tests/unit/writer/test_core.py::TestLogWriter::test_init_default_logger
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_init_default_logger' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_init_valid_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_init_valid_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_validation_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_execution_result_validation_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_invalid_input
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_execution_result_invalid_input' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_init_invalid_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_init_invalid_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_with_sample_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_log_writer_with_sample_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_writer_core_simple.py::TestWriterCoreSimple::test_log_writer_with_sample_data
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/test_writer_core_simple.py:227: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    LogWriter(spark=spark_session, config=config)

tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_execution_result_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_init_default_logger
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:104: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config)

tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_success
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:127: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_invalid_input
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:166: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_init_valid_config
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:85: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_init_invalid_config
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:96: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    LogWriter(mock_spark, config=invalid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_validation_failure
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:186: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_reset_metrics
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_reset_metrics' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_reset_metrics
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:299: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_get_metrics
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_metrics' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_get_metrics
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:281: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_log_rows_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_success
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:240: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_get_memory_usage_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_memory_usage_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py: 15 warnings
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:66: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    return LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_batch_with_failures
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_execution_result_batch_with_failures' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_show_logs
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_show_logs' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_show_logs
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:319: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_write_step_results
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:216: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_validation_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_log_rows_validation_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_validation_failure
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:270: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_write_execution_result_batch_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_execution_result_batch_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_get_memory_usage_exception
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_memory_usage_exception' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_get_table_info
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_table_info' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_get_table_info
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:346: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_get_memory_usage_psutil_not_available
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_memory_usage_psutil_not_available' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_show_logs_no_limit
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_show_logs_no_limit' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_show_logs_no_limit
  /Users/odosmatthews/Documents/coding/sparkforge/tests/unit/writer/test_core.py:335: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(mock_spark, config=valid_config, logger=mock_logger)

tests/unit/writer/test_core.py::TestLogWriter::test_validate_log_data_quality_failure
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_log_data_quality_failure' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_write_log_rows_batch
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_write_log_rows_batch' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_detect_anomalies_disabled
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_detect_anomalies_disabled' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_vacuum_table_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_vacuum_table_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_detect_anomalies_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_detect_anomalies_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_validate_log_data_quality_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_log_data_quality_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_optimize_table_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_optimize_table_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_analyze_execution_trends_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_execution_trends_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_config_validation_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_optimize_table_not_exists
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_optimize_table_not_exists' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_empty_table_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_config_validation_empty_table_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_core.py::TestLogWriter::test_analyze_quality_trends_success
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_quality_trends_success' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestLogSchema::test_create_log_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_log_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestWriterConfig::test_valid_config
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_valid_config' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestLogRowCreation::test_create_log_row_from_step_result
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_log_row_from_step_result' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestLogRowCreation::test_create_log_rows_from_execution_result
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_log_rows_from_execution_result' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_empty_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_config_validation_empty_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestLogRowCreation::test_process_execution_result_populates_table_total_rows
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_process_execution_result_populates_table_total_rows' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_row_empty_run_id
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_log_row_empty_run_id' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_data_valid
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_log_data_valid' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_row_negative_duration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_log_row_negative_duration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_log_data_invalid_row
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_log_data_invalid_row' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestWriterConfig::test_config_validation_invalid_batch_size
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_config_validation_invalid_batch_size' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/writer/test_models.py::TestLogRowValidation::test_validate_valid_log_row
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validate_valid_log_row' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_security_test_suite_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_test_suite_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_vulnerability_scanner_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_vulnerability_scanner_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_security_performance_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_performance_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityMarkers::test_security_marker_works
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_marker_works' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityMarkers::test_slow_security_test
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_slow_security_test' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::test_security_cicd_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_cicd_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_auto_infer_single_bronze_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_auto_infer_single_bronze_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_auto_infer_multiple_bronze_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_auto_infer_multiple_bronze_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_explicit_source_bronze_still_works
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_explicit_source_bronze_still_works' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_no_bronze_steps_raises_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_bronze_steps_raises_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_invalid_source_bronze_raises_error
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_invalid_source_bronze_raises_error' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_logging_auto_inference
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logging_auto_inference' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_auto_infer_source_bronze.py::TestAutoInferSourceBronze::test_chaining_works_with_auto_inference
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_chaining_works_with_auto_inference' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_bronze_step_without_incremental_col
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_without_incremental_col' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_bronze_step_with_incremental_col
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_step_with_incremental_col' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_pipeline_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_pipeline_creation
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_pipeline_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_bronze_no_datetime.py::TestBronzeNoDatetime::test_dataframe_operations
tests/system/test_dataframe_access.py::TestDataFrameAccess::test_dataframe_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dataframe_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_complete_pipeline.py::TestCompletePipeline::test_bronze_to_silver_to_gold_pipeline
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_bronze_to_silver_to_gold_pipeline' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_complete_pipeline.py::TestCompletePipeline::test_bronze_to_silver_to_gold_pipeline
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_complete_pipeline.py:66: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=writer_config)

tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_with_data_validation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_with_data_validation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_with_logging_and_monitoring
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_with_logging_and_monitoring' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_with_logging_and_monitoring
  /Users/odosmatthews/Documents/coding/sparkforge/tests/system/test_complete_pipeline.py:211: DeprecationWarning: Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.
    writer = LogWriter(spark=mock_spark_session, config=writer_config)

tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_error_recovery
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_error_recovery' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_complete_pipeline.py::TestCompletePipeline::test_pipeline_with_different_data_sizes
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_pipeline_with_different_data_sizes' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/system/test_delta_lake.py::TestDeltaLakeComprehensive::test_delta_lake_acid_transactions
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_lake_acid_transactions' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_complete_streaming_hybrid_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_streaming_hybrid_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_incremental_streaming_processing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_streaming_processing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_complete_supply_chain_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_supply_chain_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_incremental_supply_chain_processing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_supply_chain_processing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_supply_chain_logging
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_supply_chain_logging' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/debug/test_delta_minimal.py::test_delta_minimal_write
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_minimal_write' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/debug/test_delta_minimal.py::test_delta_minimal_direct_session
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_minimal_direct_session' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_complete_data_quality_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_data_quality_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_incremental_data_quality_processing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_data_quality_processing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_complete_ecommerce_pipeline_execution
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complete_ecommerce_pipeline_execution' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_incremental_order_processing
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_incremental_order_processing' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_validation_failures
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_failures' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/builder_tests/test_ecommerce_pipeline.py::TestEcommercePipeline::test_logging_and_monitoring
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_logging_and_monitoring' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_analyze_dependencies_silver_valid_dependency
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_silver_valid_dependency' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_detect_conflicts_duplicate_names
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_detect_conflicts_duplicate_names' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_no_issues
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_recommendations_no_issues' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_with_cycles
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_recommendations_with_cycles' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_with_conflicts
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_recommendations_with_conflicts' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_high_dependencies
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_recommendations_high_dependencies' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_generate_recommendations_large_pipeline
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_generate_recommendations_large_pipeline' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_create_cache_key
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_create_cache_key' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer.py::TestDependencyAnalyzer::test_clear_cache
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_clear_cache' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestAnalysisStrategy::test_strategy_values
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_strategy_values' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalysisResult::test_analysis_result_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analysis_result_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalysisResult::test_get_parallelization_ratio
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_parallelization_ratio' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalysisResult::test_get_total_execution_time
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_total_execution_time' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_caching
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_caching' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_with_bronze_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_with_bronze_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyze_dependencies_with_gold_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyze_dependencies_with_gold_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyzer_creation
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyzer_creation' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzer::test_analyzer_creation_with_custom_params
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_analyzer_creation_with_custom_params' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzerIntegration::test_complex_pipeline_analysis
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complex_pipeline_analysis' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_analyzer_comprehensive.py::TestDependencyAnalyzerIntegration::test_different_strategies_comparison
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_different_strategies_comparison' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_error_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_with_step_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_error_with_step_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_with_empty_message
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_error_with_empty_message' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyError::test_dependency_error_with_none_step_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_error_with_none_step_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_basic
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analysis_error_basic' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_with_step_name
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analysis_error_with_step_name' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_with_analysis_step
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analysis_error_with_analysis_step' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_with_both_steps
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analysis_error_with_both_steps' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/dependencies/test_exceptions.py::TestDependencyAnalysisError::test_dependency_analysis_error_inheritance
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dependency_analysis_error_inheritance' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_compliance_checker_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_compliance_checker_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_security_monitor_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_monitor_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_security_components_workflow
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_components_workflow' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_security_reporting_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_reporting_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_security_alerting_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_alerting_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/security/test_security_integration.py::TestSecurityIntegration::test_security_metrics_integration
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_security_metrics_integration' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_invalid_spark_session
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_invalid_spark_session' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn( Set PYSPARK_SUBMIT_ARGS for Delta Lake: --packages io.delta:delta-spark_2.12:3.0.0 pyspark-shell


tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_get_spark
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_get_spark' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_failed
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_result_failed' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_with_sample_data
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_with_sample_data' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_error_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_error_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_unified_validator_metrics_collection
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_unified_validator_metrics_collection' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_with_warnings_only
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_result_with_warnings_only' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_data_validation_simple.py::TestDataValidationSimple::test_validation_result_empty
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_validation_result_empty' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_dataframe_writer_modes.py::test_delta_writer_preserves_overwrite_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_writer_preserves_overwrite_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_dataframe_writer_modes.py::test_delta_writer_append_mode
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_writer_append_mode' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_dataframe_writer_modes.py::test_delta_writer_respects_explicit_overwrite_schema
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_delta_writer_respects_explicit_overwrite_schema' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_dict_annotations.py::test_no_dict_annotations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_no_dict_annotations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_empty_dataframe_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_empty_dataframe_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_null_value_handling
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_null_value_handling' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_large_dataset_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_large_dataset_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

tests/unit/test_edge_cases.py::TestEdgeCases::test_complex_schema_operations
  /Users/odosmatthews/.local/lib/python3.11/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_complex_schema_operations' requested an async fixture 'ensure_greenlet_context' with autouse=True, with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/builder_tests/test_healthcare_pipeline.py::TestHealthcarePipeline::test_complete_healthcare_pipeline_execution
FAILED tests/builder_tests/test_marketing_pipeline.py::TestMarketingPipeline::test_complete_marketing_pipeline_execution
FAILED tests/unit/test_validation_property_based.py::TestValidationPropertyBased::test_safe_divide_properties
FAILED tests/builder_tests/test_streaming_hybrid_pipeline.py::TestStreamingHybridPipeline::test_complete_streaming_hybrid_pipeline_execution
FAILED tests/builder_tests/test_supply_chain_pipeline.py::TestSupplyChainPipeline::test_complete_supply_chain_pipeline_execution
FAILED tests/builder_tests/test_data_quality_pipeline.py::TestDataQualityPipeline::test_complete_data_quality_pipeline_execution
===== 6 failed, 1714 passed, 70 skipped, 2167 warnings in 83.37s (0:01:23) =====
