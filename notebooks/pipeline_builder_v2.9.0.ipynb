{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# PipelineBuilder & LogWriter v2.9.0 - Standalone Notebook\n",
        "#\n",
        "# This notebook contains the complete PipelineBuilder and LogWriter implementation\n",
        "# as a standalone, executable notebook. All dependencies are included as cells\n",
        "# in the correct order.\n",
        "#\n",
        "# Usage:\n",
        "# 1. Run all cells from top to bottom\n",
        "# 2. The PipelineBuilder and LogWriter classes will be available after all cells execute\n",
        "# 3. Use PipelineBuilder to build and execute data pipelines\n",
        "# 4. Use LogWriter to log and analyze pipeline execution results\n",
        "#\n",
        "# Note: This is generated from version 2.9.0. Module dependencies are\n",
        "# resolved automatically from source code analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# External imports (PySpark, standard library)\n",
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "import uuid\n",
        "from abc import ABC, abstractmethod\n",
        "from collections import defaultdict, deque\n",
        "from contextlib import contextmanager\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime, timedelta\n",
        "from enum import Enum\n",
        "from functools import wraps\n",
        "from pathlib import Path\n",
        "from typing import Any, Callable, Dict, Generator, List, Optional, Protocol, Set, Tuple, TypedDict, TypeVar, Union, cast\n",
        "\n",
        "# PySpark imports\n",
        "from pyspark.sql import Column, DataFrame, SparkSession, functions as F\n",
        "from pyspark.sql.types import (\n",
        "    BooleanType,\n",
        "    FloatType,\n",
        "    IntegerType,\n",
        "    StringType,\n",
        "    StructField,\n",
        "    StructType,\n",
        "    TimestampType,\n",
        ")\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Delta Lake imports\n",
        "try:\n",
        "    from delta.tables import DeltaTable\n",
        "except ImportError:\n",
        "    print(\"\u26a0\ufe0f  Delta Lake not available. Some features may not work.\")\n",
        "    DeltaTable = None\n",
        "\n",
        "# Optional imports\n",
        "try:\n",
        "    import psutil\n",
        "except ImportError:\n",
        "    print(\"\u26a0\ufe0f  psutil not available. Memory monitoring disabled.\")\n",
        "    psutil = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.logging (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Simplified logging system for the framework.\n",
        "\n",
        "This module provides a clean, focused logging system for pipeline operations\n",
        "without the complexity of the previous over-engineered system.\n",
        "\"\"\"\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "from contextlib import contextmanager\n",
        "from datetime import datetime, timezone\n",
        "from typing import Dict, Generator, Optional, Union\n",
        "\n",
        "class PipelineLogger:\n",
        "    \"\"\"\n",
        "    Simple, focused logging for pipeline operations.\n",
        "\n",
        "    Features:\n",
        "    - Basic logging levels (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
        "    - Console and file output\n",
        "    - Simple context management\n",
        "    - Performance timing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str = \"PipelineRunner\",\n",
        "        level: int = logging.INFO,\n",
        "        log_file: Optional[str] = None,\n",
        "        verbose: bool = True,\n",
        "    ):\n",
        "        self.name = name\n",
        "        self.level = level\n",
        "        self.log_file = log_file\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # Create logger\n",
        "        self.logger = logging.getLogger(name)\n",
        "        self.logger.setLevel(level)\n",
        "\n",
        "        # Clear existing handlers\n",
        "        self.logger.handlers.clear()\n",
        "\n",
        "        # Setup handlers\n",
        "        self._setup_handlers()\n",
        "\n",
        "        # Performance tracking\n",
        "        self._timers: Dict[str, datetime] = {}\n",
        "\n",
        "    def _setup_handlers(self) -> None:\n",
        "        \"\"\"Setup logging handlers.\"\"\"\n",
        "        # Console handler\n",
        "        if self.verbose:\n",
        "            console_handler = logging.StreamHandler(sys.stdout)\n",
        "            console_formatter = logging.Formatter(\n",
        "                \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
        "                datefmt=\"%H:%M:%S\",\n",
        "            )\n",
        "            console_handler.setFormatter(console_formatter)\n",
        "            console_handler.setLevel(self.level)\n",
        "            self.logger.addHandler(console_handler)\n",
        "\n",
        "        # File handler\n",
        "        if self.log_file:\n",
        "            file_handler = logging.FileHandler(self.log_file)\n",
        "            file_formatter = logging.Formatter(\n",
        "                \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
        "                datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "            )\n",
        "            file_handler.setFormatter(file_formatter)\n",
        "            file_handler.setLevel(self.level)\n",
        "            self.logger.addHandler(file_handler)\n",
        "\n",
        "    # Basic logging methods\n",
        "    def debug(self, message: str, **kwargs: Union[str, int, float, bool, None]) -> None:\n",
        "        \"\"\"Log debug message.\"\"\"\n",
        "        self.logger.debug(self._format_message(message, kwargs))\n",
        "\n",
        "    def info(self, message: str, **kwargs: Union[str, int, float, bool, None]) -> None:\n",
        "        \"\"\"Log info message.\"\"\"\n",
        "        self.logger.info(self._format_message(message, kwargs))\n",
        "\n",
        "    def warning(\n",
        "        self, message: str, **kwargs: Union[str, int, float, bool, None]\n",
        "    ) -> None:\n",
        "        \"\"\"Log warning message.\"\"\"\n",
        "        self.logger.warning(self._format_message(message, kwargs))\n",
        "\n",
        "    def error(self, message: str, **kwargs: Union[str, int, float, bool, None]) -> None:\n",
        "        \"\"\"Log error message.\"\"\"\n",
        "        self.logger.error(self._format_message(message, kwargs))\n",
        "\n",
        "    def critical(\n",
        "        self, message: str, **kwargs: Union[str, int, float, bool, None]\n",
        "    ) -> None:\n",
        "        \"\"\"Log critical message.\"\"\"\n",
        "        self.logger.critical(self._format_message(message, kwargs))\n",
        "\n",
        "    def _format_message(\n",
        "        self, message: str, kwargs: Dict[str, Union[str, int, float, bool, None]]\n",
        "    ) -> str:\n",
        "        \"\"\"Format message with keyword arguments.\"\"\"\n",
        "        if not kwargs:\n",
        "            return message\n",
        "        kwargs_str = \", \".join(f\"{k}={v}\" for k, v in kwargs.items())\n",
        "        return f\"{message} ({kwargs_str})\"\n",
        "\n",
        "    # Performance timing\n",
        "    @contextmanager\n",
        "    def time_operation(self, operation_name: str) -> Generator[None, None, None]:\n",
        "        \"\"\"Context manager for timing operations.\"\"\"\n",
        "        start_time = datetime.now(timezone.utc)\n",
        "        self._timers[operation_name] = start_time\n",
        "        try:\n",
        "            yield\n",
        "        finally:\n",
        "            end_time = datetime.now(timezone.utc)\n",
        "            duration = (end_time - start_time).total_seconds()\n",
        "            self.info(f\"Operation '{operation_name}' took {duration:.2f}s\")\n",
        "            # Clean up timer after operation completes\n",
        "            if operation_name in self._timers:\n",
        "                del self._timers[operation_name]\n",
        "\n",
        "    def start_timer(self, timer_name: str) -> None:\n",
        "        \"\"\"Start a named timer.\"\"\"\n",
        "        self._timers[timer_name] = datetime.now(timezone.utc)\n",
        "\n",
        "    def stop_timer(self, timer_name: str) -> float:\n",
        "        \"\"\"Stop a named timer and return duration in seconds.\"\"\"\n",
        "        if timer_name not in self._timers:\n",
        "            self.warning(f\"Timer '{timer_name}' was not started\")\n",
        "            return 0.0\n",
        "        start_time = self._timers[timer_name]\n",
        "        end_time = datetime.now(timezone.utc)\n",
        "        duration = (end_time - start_time).total_seconds()\n",
        "        del self._timers[timer_name]\n",
        "        return duration\n",
        "\n",
        "    def get_timer_duration(self, timer_name: str) -> float:\n",
        "        \"\"\"Get current duration of a running timer without stopping it.\"\"\"\n",
        "        if timer_name not in self._timers:\n",
        "            return 0.0\n",
        "        start_time = self._timers[timer_name]\n",
        "        end_time = datetime.now(timezone.utc)\n",
        "        return (end_time - start_time).total_seconds()\n",
        "\n",
        "    # Context management\n",
        "    @contextmanager\n",
        "    def log_context(self, context_name: str) -> Generator[None, None, None]:\n",
        "        \"\"\"Context manager for logging context.\"\"\"\n",
        "        self.info(f\"Starting: {context_name}\")\n",
        "        try:\n",
        "            yield\n",
        "            self.info(f\"Completed: {context_name}\")\n",
        "        except Exception as e:\n",
        "            self.error(f\"Failed: {context_name}\", error=str(e))\n",
        "            raise\n",
        "\n",
        "    # Step execution logging\n",
        "    def step_start(self, step_type: str, step_name: str) -> None:\n",
        "        \"\"\"Log step start.\"\"\"\n",
        "        self.info(f\"\u25b6\ufe0f Starting {step_type.upper()} step: {step_name}\")\n",
        "\n",
        "    def step_complete(\n",
        "        self,\n",
        "        step_type: str,\n",
        "        step_name: str,\n",
        "        duration: float,\n",
        "        rows_processed: int = 0,\n",
        "        rows_written: int = 0,\n",
        "        invalid_rows: int = 0,\n",
        "        validation_rate: float = 100.0,\n",
        "    ) -> None:\n",
        "        \"\"\"Log step completion.\"\"\"\n",
        "        self.info(\n",
        "            f\"\u2705 Completed {step_type.upper()} step: {step_name} ({duration:.2f}s) - \"\n",
        "            f\"{rows_processed} rows processed, {rows_written} rows written, \"\n",
        "            f\"{invalid_rows} invalid, {validation_rate:.1f}% valid\"\n",
        "        )\n",
        "\n",
        "    # Utility methods\n",
        "    def set_level(self, level: int) -> None:\n",
        "        \"\"\"Set logging level.\"\"\"\n",
        "        self.level = level\n",
        "        self.logger.setLevel(level)\n",
        "        for handler in self.logger.handlers:\n",
        "            handler.setLevel(level)\n",
        "\n",
        "    def add_handler(self, handler: logging.Handler) -> None:\n",
        "        \"\"\"Add a custom logging handler.\"\"\"\n",
        "        self.logger.addHandler(handler)\n",
        "\n",
        "    def remove_handler(self, handler: logging.Handler) -> None:\n",
        "        \"\"\"Remove a logging handler.\"\"\"\n",
        "        self.logger.removeHandler(handler)\n",
        "\n",
        "    def clear_handlers(self) -> None:\n",
        "        \"\"\"Clear all logging handlers.\"\"\"\n",
        "        self.logger.handlers.clear()\n",
        "\n",
        "    def close(self) -> None:\n",
        "        \"\"\"Close all logging handlers, especially file handlers.\"\"\"\n",
        "        for handler in self.logger.handlers[\n",
        "            :\n",
        "        ]:  # Copy list to avoid modification during iteration\n",
        "            handler.close()\n",
        "            self.logger.removeHandler(handler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.errors (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Simplified error handling system for the framework.\n",
        "\n",
        "This module provides a clean, consolidated error handling system\n",
        "with just the essential error types needed for the project.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "from enum import Enum\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "class ErrorSeverity(Enum):\n",
        "    \"\"\"Severity levels for errors.\"\"\"\n",
        "\n",
        "    LOW = \"low\"\n",
        "    MEDIUM = \"medium\"\n",
        "    HIGH = \"high\"\n",
        "    CRITICAL = \"critical\"\n",
        "\n",
        "class ErrorCategory(Enum):\n",
        "    \"\"\"Categories of errors.\"\"\"\n",
        "\n",
        "    CONFIGURATION = \"configuration\"\n",
        "    VALIDATION = \"validation\"\n",
        "    EXECUTION = \"execution\"\n",
        "    DATA = \"data\"\n",
        "    SYSTEM = \"system\"\n",
        "    PERFORMANCE = \"performance\"\n",
        "    RESOURCE = \"resource\"\n",
        "\n",
        "# Type definitions for error context\n",
        "ErrorContextValue = Union[str, int, float, bool, List[str], Dict[str, str], None]\n",
        "ErrorContext = Dict[str, ErrorContextValue]\n",
        "ErrorSuggestions = List[str]\n",
        "\n",
        "class SparkForgeError(Exception):\n",
        "    \"\"\"\n",
        "    Base exception for all framework errors.\n",
        "\n",
        "    This is the root exception class that all other framework exceptions\n",
        "    inherit from, providing consistent error handling patterns and rich context.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        *,\n",
        "        error_code: Optional[str] = None,\n",
        "        category: Optional[ErrorCategory] = None,\n",
        "        severity: ErrorSeverity = ErrorSeverity.MEDIUM,\n",
        "        context: Optional[ErrorContext] = None,\n",
        "        suggestions: Optional[ErrorSuggestions] = None,\n",
        "        timestamp: Optional[datetime] = None,\n",
        "        cause: Optional[Exception] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize a framework error.\n",
        "\n",
        "        Args:\n",
        "            message: Human-readable error message\n",
        "            error_code: Optional error code for programmatic handling\n",
        "            category: Error category for classification\n",
        "            severity: Error severity level\n",
        "            context: Additional context information\n",
        "            suggestions: Suggested actions to resolve the error\n",
        "            timestamp: When the error occurred (defaults to now)\n",
        "            cause: The underlying exception that caused this error\n",
        "        \"\"\"\n",
        "        super().__init__(message)\n",
        "        self.message = message\n",
        "        self.error_code = error_code\n",
        "        self.category = category\n",
        "        self.severity = severity\n",
        "        self.context = context or {}\n",
        "        self.suggestions = suggestions or []\n",
        "        self.timestamp = timestamp or datetime.now(timezone.utc)\n",
        "        self.cause = cause\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        \"\"\"Return string representation of the error.\"\"\"\n",
        "        parts = [self.message]\n",
        "\n",
        "        if self.error_code:\n",
        "            parts.append(f\"[{self.error_code}]\")\n",
        "\n",
        "        if self.context:\n",
        "            context_str = \", \".join(f\"{k}={v}\" for k, v in self.context.items())\n",
        "            parts.append(f\"Context: {context_str}\")\n",
        "\n",
        "        if self.suggestions:\n",
        "            parts.append(f\"Suggestions: {'; '.join(self.suggestions)}\")\n",
        "\n",
        "        return \" | \".join(parts)\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Convert error to dictionary for serialization.\"\"\"\n",
        "        return {\n",
        "            \"message\": self.message,\n",
        "            \"error_code\": self.error_code,\n",
        "            \"category\": self.category.value if self.category else None,\n",
        "            \"severity\": self.severity.value if self.severity else None,\n",
        "            \"context\": self.context,\n",
        "            \"suggestions\": self.suggestions,\n",
        "            \"timestamp\": self.timestamp.isoformat() if self.timestamp else None,\n",
        "            \"cause\": str(self.cause) if self.cause else None,\n",
        "        }\n",
        "\n",
        "class ValidationError(SparkForgeError):\n",
        "    \"\"\"Raised when validation fails.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        *,\n",
        "        field: Optional[str] = None,\n",
        "        value: Any = None,\n",
        "        **kwargs: Any,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            message,\n",
        "            category=ErrorCategory.VALIDATION,\n",
        "            severity=ErrorSeverity.MEDIUM,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.field = field\n",
        "        self.value = value\n",
        "        if field:\n",
        "            self.context[\"field\"] = field\n",
        "        if value is not None:\n",
        "            self.context[\"value\"] = str(value)\n",
        "\n",
        "class PipelineValidationError(ValidationError):\n",
        "    \"\"\"Raised when pipeline validation fails.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        *,\n",
        "        step_name: Optional[str] = None,\n",
        "        phase: Optional[str] = None,\n",
        "        **kwargs: Any,\n",
        "    ):\n",
        "        super().__init__(message, **kwargs)\n",
        "        self.step_name = step_name\n",
        "        self.phase = phase\n",
        "        if step_name:\n",
        "            self.context[\"step_name\"] = step_name\n",
        "        if phase:\n",
        "            self.context[\"phase\"] = phase\n",
        "\n",
        "class ConfigurationError(SparkForgeError):\n",
        "    \"\"\"Raised when configuration is invalid.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, **kwargs: Any):\n",
        "        # Only set default severity if not provided in kwargs\n",
        "        if \"severity\" not in kwargs:\n",
        "            kwargs[\"severity\"] = ErrorSeverity.MEDIUM\n",
        "        super().__init__(\n",
        "            message,\n",
        "            category=ErrorCategory.CONFIGURATION,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "class ExecutionError(SparkForgeError):\n",
        "    \"\"\"Raised when execution fails.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        *,\n",
        "        step_name: Optional[str] = None,\n",
        "        phase: Optional[str] = None,\n",
        "        **kwargs: Any,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            message,\n",
        "            category=ErrorCategory.EXECUTION,\n",
        "            severity=ErrorSeverity.HIGH,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.step_name = step_name\n",
        "        self.phase = phase\n",
        "        if step_name:\n",
        "            self.context[\"step_name\"] = step_name\n",
        "        if phase:\n",
        "            self.context[\"phase\"] = phase\n",
        "\n",
        "class DataError(SparkForgeError):\n",
        "    \"\"\"Raised when data operations fail.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, **kwargs: Any):\n",
        "        super().__init__(\n",
        "            message,\n",
        "            category=ErrorCategory.DATA,\n",
        "            severity=ErrorSeverity.MEDIUM,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "class SystemError(SparkForgeError):\n",
        "    \"\"\"Raised when system operations fail.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, **kwargs: Any):\n",
        "        super().__init__(\n",
        "            message,\n",
        "            category=ErrorCategory.SYSTEM,\n",
        "            severity=ErrorSeverity.CRITICAL,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "class PerformanceError(SparkForgeError):\n",
        "    \"\"\"Raised when performance issues are detected.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, **kwargs: Any):\n",
        "        super().__init__(\n",
        "            message,\n",
        "            category=ErrorCategory.PERFORMANCE,\n",
        "            severity=ErrorSeverity.LOW,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "class ResourceError(SparkForgeError):\n",
        "    \"\"\"Raised when resource operations fail.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, **kwargs: Any):\n",
        "        super().__init__(\n",
        "            message,\n",
        "            category=ErrorCategory.RESOURCE,\n",
        "            severity=ErrorSeverity.HIGH,\n",
        "            **kwargs,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.config.validators (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Configuration validation functions.\n",
        "\n",
        "This module provides validation functions for pipeline configurations.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import List\n",
        "\n",
        "# from ..models import PipelineConfig, ValidationThresholds  # Removed: defined in notebook cells above\n",
        "\n",
        "def validate_pipeline_config(config: PipelineConfig) -> List[str]:\n",
        "    \"\"\"\n",
        "    Validate pipeline configuration.\n",
        "\n",
        "    Args:\n",
        "        config: Pipeline configuration to validate\n",
        "\n",
        "    Returns:\n",
        "        List of validation errors (empty if valid)\n",
        "    \"\"\"\n",
        "    errors: List[str] = []\n",
        "\n",
        "    # Validate schema\n",
        "    # Note: config.schema is typed as str in PipelineConfig, but we validate at runtime\n",
        "    # The isinstance check is for runtime validation, even though mypy knows it's a str\n",
        "    if not isinstance(config.schema, str):  # type: ignore[unreachable]\n",
        "        errors.append(\"Pipeline schema must be a string\")\n",
        "        return errors  # Early return to avoid unreachable code\n",
        "    # After isinstance check, mypy knows it's a str\n",
        "    # The empty check is for runtime validation (empty strings are valid str types)\n",
        "    if not config.schema.strip():  # type: ignore[unreachable]\n",
        "        errors.append(\"Pipeline schema cannot be empty\")\n",
        "    if len(config.schema) > 128:\n",
        "        errors.append(\"Pipeline schema name is too long (max 128 characters)\")\n",
        "\n",
        "    # Validate thresholds\n",
        "    threshold_errors = validate_thresholds(config.thresholds)\n",
        "    errors.extend(threshold_errors)\n",
        "\n",
        "    return errors\n",
        "\n",
        "def validate_thresholds(thresholds: ValidationThresholds) -> List[str]:\n",
        "    \"\"\"\n",
        "    Validate validation thresholds.\n",
        "\n",
        "    Args:\n",
        "        thresholds: Validation thresholds to validate\n",
        "\n",
        "    Returns:\n",
        "        List of validation errors (empty if valid)\n",
        "    \"\"\"\n",
        "    errors: List[str] = []\n",
        "\n",
        "    # Check threshold ranges (0-100)\n",
        "    if not (0.0 <= thresholds.bronze <= 100.0):\n",
        "        errors.append(\n",
        "            f\"Bronze threshold must be between 0 and 100, got {thresholds.bronze}\"\n",
        "        )\n",
        "\n",
        "    if not (0.0 <= thresholds.silver <= 100.0):\n",
        "        errors.append(\n",
        "            f\"Silver threshold must be between 0 and 100, got {thresholds.silver}\"\n",
        "        )\n",
        "\n",
        "    if not (0.0 <= thresholds.gold <= 100.0):\n",
        "        errors.append(\n",
        "            f\"Gold threshold must be between 0 and 100, got {thresholds.gold}\"\n",
        "        )\n",
        "\n",
        "    # Check that thresholds are in ascending order (bronze <= silver <= gold)\n",
        "    if thresholds.bronze > thresholds.silver:\n",
        "        errors.append(\n",
        "            f\"Bronze threshold ({thresholds.bronze}) should not exceed silver threshold ({thresholds.silver})\"\n",
        "        )\n",
        "\n",
        "    if thresholds.silver > thresholds.gold:\n",
        "        errors.append(\n",
        "            f\"Silver threshold ({thresholds.silver}) should not exceed gold threshold ({thresholds.gold})\"\n",
        "        )\n",
        "\n",
        "    return errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.config.factories (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Configuration factory functions for creating preset configurations.\n",
        "\n",
        "This module provides factory functions for creating PipelineConfig instances\n",
        "with preset configurations for different environments.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any\n",
        "\n",
        "# from ..models import PipelineConfig, ValidationThresholds  # Removed: defined in notebook cells above\n",
        "\n",
        "def create_development_config(schema: str, **overrides: Any) -> PipelineConfig:\n",
        "    \"\"\"\n",
        "    Create a PipelineConfig optimized for development with relaxed validation.\n",
        "\n",
        "    Args:\n",
        "        schema: Database schema name\n",
        "        **overrides: Additional configuration parameters to override defaults\n",
        "\n",
        "    Returns:\n",
        "        PipelineConfig instance with development-optimized settings\n",
        "\n",
        "    Example:\n",
        "        >>> config = create_development_config(\"dev_schema\", verbose=True)\n",
        "    \"\"\"\n",
        "    thresholds = ValidationThresholds(\n",
        "        bronze=overrides.pop(\"min_bronze_rate\", 80.0),\n",
        "        silver=overrides.pop(\"min_silver_rate\", 85.0),\n",
        "        gold=overrides.pop(\"min_gold_rate\", 90.0),\n",
        "    )\n",
        "\n",
        "    return PipelineConfig(\n",
        "        schema=schema,\n",
        "        thresholds=thresholds,\n",
        "        verbose=overrides.pop(\"verbose\", True),\n",
        "        **overrides,\n",
        "    )\n",
        "\n",
        "def create_production_config(schema: str, **overrides: Any) -> PipelineConfig:\n",
        "    \"\"\"\n",
        "    Create a PipelineConfig optimized for production with strict validation.\n",
        "\n",
        "    Args:\n",
        "        schema: Database schema name\n",
        "        **overrides: Additional configuration parameters to override defaults\n",
        "\n",
        "    Returns:\n",
        "        PipelineConfig instance with production-optimized settings\n",
        "\n",
        "    Example:\n",
        "        >>> config = create_production_config(\"prod_schema\", verbose=False)\n",
        "    \"\"\"\n",
        "    thresholds = ValidationThresholds(\n",
        "        bronze=overrides.pop(\"min_bronze_rate\", 95.0),\n",
        "        silver=overrides.pop(\"min_silver_rate\", 98.0),\n",
        "        gold=overrides.pop(\"min_gold_rate\", 99.5),\n",
        "    )\n",
        "\n",
        "    return PipelineConfig(\n",
        "        schema=schema,\n",
        "        thresholds=thresholds,\n",
        "        verbose=overrides.pop(\"verbose\", False),\n",
        "        **overrides,\n",
        "    )\n",
        "\n",
        "def create_test_config(schema: str, **overrides: Any) -> PipelineConfig:\n",
        "    \"\"\"\n",
        "    Create a PipelineConfig optimized for testing with minimal validation.\n",
        "\n",
        "    Args:\n",
        "        schema: Database schema name\n",
        "        **overrides: Additional configuration parameters to override defaults\n",
        "\n",
        "    Returns:\n",
        "        PipelineConfig instance with test-optimized settings\n",
        "\n",
        "    Example:\n",
        "        >>> config = create_test_config(\"test_schema\")\n",
        "    \"\"\"\n",
        "    thresholds = ValidationThresholds(\n",
        "        bronze=overrides.pop(\"min_bronze_rate\", 50.0),\n",
        "        silver=overrides.pop(\"min_silver_rate\", 50.0),\n",
        "        gold=overrides.pop(\"min_gold_rate\", 50.0),\n",
        "    )\n",
        "\n",
        "    return PipelineConfig(\n",
        "        schema=schema,\n",
        "        thresholds=thresholds,\n",
        "        verbose=overrides.pop(\"verbose\", False),\n",
        "        **overrides,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.runner.execution_helpers (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Execution helper functions for pipeline runners.\n",
        "\n",
        "This module provides utility functions for execution mode determination,\n",
        "source validation, and execution preparation.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "# from ..models import ExecutionMode, PipelineConfig  # Removed: defined in notebook cells above\n",
        "\n",
        "def determine_execution_mode(\n",
        "    config: PipelineConfig,\n",
        "    bronze_sources: Optional[Dict[str, Any]] = None,\n",
        "    last_run: Optional[datetime] = None,\n",
        ") -> ExecutionMode:\n",
        "    \"\"\"\n",
        "    Determine execution mode based on configuration and context.\n",
        "\n",
        "    Args:\n",
        "        config: Pipeline configuration\n",
        "        bronze_sources: Optional dictionary of bronze sources\n",
        "        last_run: Optional datetime of last pipeline run\n",
        "\n",
        "    Returns:\n",
        "        ExecutionMode enum value\n",
        "    \"\"\"\n",
        "    # Check if this is an initial load (no bronze sources provided)\n",
        "    if not bronze_sources or len(bronze_sources) == 0:\n",
        "        return ExecutionMode.INITIAL\n",
        "\n",
        "    # Check if incremental mode should be used\n",
        "    if should_run_incremental(config, last_run):\n",
        "        return ExecutionMode.INCREMENTAL\n",
        "\n",
        "    # Default to initial if we can't determine\n",
        "    return ExecutionMode.INITIAL\n",
        "\n",
        "def should_run_incremental(\n",
        "    config: PipelineConfig, last_run: Optional[datetime] = None\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Determine if pipeline should run in incremental mode.\n",
        "\n",
        "    Args:\n",
        "        config: Pipeline configuration\n",
        "        last_run: Optional datetime of last pipeline run\n",
        "\n",
        "    Returns:\n",
        "        True if incremental mode should be used, False otherwise\n",
        "    \"\"\"\n",
        "    # If no last run time, must be initial load\n",
        "    if last_run is None:\n",
        "        return False\n",
        "\n",
        "    # Check if config has incremental settings\n",
        "    # This is a placeholder - actual logic depends on implementation\n",
        "    return True\n",
        "\n",
        "def validate_bronze_sources(\n",
        "    sources: Dict[str, Any],\n",
        "    expected_bronze_steps: Dict[str, Any],\n",
        "    source_validator: Optional[Any] = None,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Validate bronze sources match expected bronze steps.\n",
        "\n",
        "    Args:\n",
        "        sources: Dictionary of bronze sources\n",
        "        expected_bronze_steps: Dictionary of expected bronze steps\n",
        "        source_validator: Optional validator function to check source validity\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If sources don't match expected steps or are invalid\n",
        "    \"\"\"\n",
        "    # Check that all expected bronze steps have sources\n",
        "    missing_sources = set(expected_bronze_steps.keys()) - set(sources.keys())\n",
        "    if missing_sources:\n",
        "        raise ValueError(\n",
        "            f\"Missing bronze sources for steps: {', '.join(missing_sources)}\"\n",
        "        )\n",
        "\n",
        "    # Check that all sources have corresponding expected steps\n",
        "    unexpected_sources = set(sources.keys()) - set(expected_bronze_steps.keys())\n",
        "    if unexpected_sources:\n",
        "        raise ValueError(\n",
        "            f\"Unexpected bronze sources (no corresponding step): {', '.join(unexpected_sources)}\"\n",
        "        )\n",
        "\n",
        "    # Validate each source if validator provided\n",
        "    if source_validator:\n",
        "        for step_name, source in sources.items():\n",
        "            if not source_validator(source):\n",
        "                raise ValueError(\n",
        "                    f\"Invalid bronze source for step '{step_name}': {type(source)}\"\n",
        "                )\n",
        "\n",
        "def prepare_sources_for_execution(\n",
        "    sources: Dict[str, Any],\n",
        "    step_type: str,\n",
        "    step_name: Optional[str] = None,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Prepare sources for step execution.\n",
        "\n",
        "    Args:\n",
        "        sources: Dictionary of sources\n",
        "        step_type: Type of step (bronze/silver/gold)\n",
        "        step_name: Optional step name for filtering\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of prepared sources\n",
        "    \"\"\"\n",
        "    if step_type == \"bronze\":\n",
        "        # Bronze steps use all provided sources\n",
        "        return sources\n",
        "    elif step_type == \"silver\":\n",
        "        # Silver steps use bronze sources\n",
        "        return {k: v for k, v in sources.items() if k in sources}\n",
        "    elif step_type == \"gold\":\n",
        "        # Gold steps use silver sources\n",
        "        return {k: v for k, v in sources.items() if k in sources}\n",
        "\n",
        "    return sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.dependencies.graph (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Dependency graph representation for the framework pipelines.\n",
        "\n",
        "This module provides a clean, efficient representation of pipeline dependencies\n",
        "that can be used for analysis and optimization.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "from collections import defaultdict, deque\n",
        "from dataclasses import dataclass, field\n",
        "from enum import Enum\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class StepType(Enum):\n",
        "    \"\"\"Types of pipeline steps.\"\"\"\n",
        "\n",
        "    BRONZE = \"bronze\"\n",
        "    SILVER = \"silver\"\n",
        "    GOLD = \"gold\"\n",
        "\n",
        "@dataclass\n",
        "class StepNode:\n",
        "    \"\"\"Represents a single step in the dependency graph.\n",
        "\n",
        "    Attributes:\n",
        "        name: Unique identifier for this step.\n",
        "        step_type: Type of step (BRONZE, SILVER, or GOLD).\n",
        "        dependencies: Set of step names that this step depends on.\n",
        "        dependents: Set of step names that depend on this step.\n",
        "        execution_group: (Deprecated) Legacy field, no longer used. Execution\n",
        "            order is determined by topological sort.\n",
        "        estimated_duration: Estimated execution duration in seconds.\n",
        "        metadata: Dictionary for storing custom metadata about the step.\n",
        "    \"\"\"\n",
        "\n",
        "    name: str\n",
        "    step_type: StepType\n",
        "    dependencies: set[str] = field(default_factory=set)\n",
        "    dependents: set[str] = field(default_factory=set)\n",
        "    execution_group: int = 0\n",
        "    estimated_duration: float = 0.0\n",
        "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "class DependencyGraph:\n",
        "    \"\"\"\n",
        "    Represents the dependency graph of a pipeline.\n",
        "\n",
        "    This class provides efficient operations for dependency analysis,\n",
        "    cycle detection, and execution planning.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.nodes: Dict[str, StepNode] = {}\n",
        "        self._adjacency_list: Dict[str, set[str]] = defaultdict(set)\n",
        "        self._reverse_adjacency_list: Dict[str, set[str]] = defaultdict(set)\n",
        "\n",
        "    def add_node(self, node: StepNode) -> None:\n",
        "        \"\"\"Add a node to the dependency graph.\"\"\"\n",
        "        self.nodes[node.name] = node\n",
        "        self._adjacency_list[node.name] = set()\n",
        "        self._reverse_adjacency_list[node.name] = set()\n",
        "\n",
        "    def add_dependency(self, from_step: str, to_step: str) -> None:\n",
        "        \"\"\"Add a dependency from one step to another.\"\"\"\n",
        "        if from_step not in self.nodes or to_step not in self.nodes:\n",
        "            raise ValueError(f\"Steps {from_step} or {to_step} not found in graph\")\n",
        "\n",
        "        self._adjacency_list[from_step].add(to_step)\n",
        "        self._reverse_adjacency_list[to_step].add(from_step)\n",
        "\n",
        "        # Update node dependencies\n",
        "        self.nodes[from_step].dependencies.add(to_step)\n",
        "        self.nodes[to_step].dependents.add(from_step)\n",
        "\n",
        "    def get_dependencies(self, step_name: str) -> set[str]:\n",
        "        \"\"\"Get all dependencies for a step.\"\"\"\n",
        "        return self.nodes.get(\n",
        "            step_name, StepNode(\"\", StepType.BRONZE)\n",
        "        ).dependencies.copy()\n",
        "\n",
        "    def get_dependents(self, step_name: str) -> set[str]:\n",
        "        \"\"\"Get all dependents for a step.\"\"\"\n",
        "        return self.nodes.get(\n",
        "            step_name, StepNode(\"\", StepType.BRONZE)\n",
        "        ).dependents.copy()\n",
        "\n",
        "    def detect_cycles(self) -> list[list[str]]:\n",
        "        \"\"\"Detect cycles in the dependency graph using DFS.\"\"\"\n",
        "        visited = set()\n",
        "        rec_stack = set()\n",
        "        cycles = []\n",
        "\n",
        "        def dfs(node: str, path: list[str]) -> None:\n",
        "            if node in rec_stack:\n",
        "                # Found a cycle\n",
        "                cycle_start = path.index(node)\n",
        "                cycle = path[cycle_start:] + [node]\n",
        "                cycles.append(cycle)\n",
        "                return\n",
        "\n",
        "            if node in visited:\n",
        "                return\n",
        "\n",
        "            visited.add(node)\n",
        "            rec_stack.add(node)\n",
        "            path.append(node)\n",
        "\n",
        "            for neighbor in self._adjacency_list[node]:\n",
        "                dfs(neighbor, path)\n",
        "\n",
        "            rec_stack.remove(node)\n",
        "            path.pop()\n",
        "\n",
        "        for node in self.nodes:\n",
        "            if node not in visited:\n",
        "                dfs(node, [])\n",
        "\n",
        "        return cycles\n",
        "\n",
        "    def topological_sort(\n",
        "        self, creation_order: Optional[Dict[str, int]] = None\n",
        "    ) -> list[str]:\n",
        "        \"\"\"\n",
        "        Perform topological sort of the dependency graph.\n",
        "\n",
        "        Returns nodes in an order such that dependencies come before dependents.\n",
        "        Uses reverse adjacency list since add_dependency(A, B) means A depends on B,\n",
        "        so B must come before A in the sort.\n",
        "\n",
        "        **Explicit dependencies (e.g., source_silvers) always override creation order.**\n",
        "        When multiple nodes have the same in-degree, creation_order is used as a\n",
        "        tie-breaker for deterministic ordering based on step creation order.\n",
        "\n",
        "        Args:\n",
        "            creation_order: Optional dictionary mapping step names to creation order\n",
        "                (lower number = created earlier). Used as tie-breaker for deterministic\n",
        "                ordering when steps have no explicit dependencies. Explicit dependencies\n",
        "                (via source_silvers, source_bronze, etc.) always take precedence.\n",
        "        \"\"\"\n",
        "        in_degree = dict.fromkeys(self.nodes, 0)\n",
        "\n",
        "        # Calculate in-degrees using reverse adjacency\n",
        "        # If A depends on B, then B->A edge exists in reverse list\n",
        "        for node in self.nodes:\n",
        "            for dependent in self._reverse_adjacency_list[node]:\n",
        "                in_degree[dependent] += 1\n",
        "\n",
        "        # Helper function to get creation order for sorting\n",
        "        def get_sort_key(node_name: str) -> tuple[int, int]:\n",
        "            \"\"\"Return sort key: (in_degree, creation_order).\n",
        "\n",
        "            Lower creation_order (earlier created) comes first.\n",
        "            If creation_order not available, use a large number to sort to end.\n",
        "            \"\"\"\n",
        "            creation_ord: int = (\n",
        "                creation_order.get(node_name, 2**31 - 1)\n",
        "                if creation_order\n",
        "                else 2**31 - 1\n",
        "            )\n",
        "            return (in_degree[node_name], creation_ord)\n",
        "\n",
        "        # Find nodes with no incoming edges (no dependencies)\n",
        "        # Sort by creation order for deterministic ordering\n",
        "        ready_nodes = [node for node, degree in in_degree.items() if degree == 0]\n",
        "        if creation_order:\n",
        "            ready_nodes.sort(key=get_sort_key)\n",
        "        queue = deque(ready_nodes)\n",
        "        result = []\n",
        "\n",
        "        while queue:\n",
        "            node = queue.popleft()\n",
        "            result.append(node)\n",
        "\n",
        "            # Process nodes that depend on this one\n",
        "            for dependent in self._reverse_adjacency_list[node]:\n",
        "                in_degree[dependent] -= 1\n",
        "                if in_degree[dependent] == 0:\n",
        "                    queue.append(dependent)\n",
        "                    # Re-sort queue to maintain creation order when adding new nodes\n",
        "                    # Convert to list, sort, convert back to deque\n",
        "                    if creation_order and len(queue) > 1:\n",
        "                        queue_list = list(queue)\n",
        "                        queue_list.sort(key=get_sort_key)\n",
        "                        queue = deque(queue_list)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def validate(self) -> list[str]:\n",
        "        \"\"\"Validate the dependency graph and return any issues.\"\"\"\n",
        "        issues = []\n",
        "\n",
        "        # Check for cycles\n",
        "        cycles = self.detect_cycles()\n",
        "        if cycles:\n",
        "            for cycle in cycles:\n",
        "                issues.append(f\"Circular dependency detected: {' -> '.join(cycle)}\")\n",
        "\n",
        "        # Check for missing dependencies\n",
        "        for node_name, node in self.nodes.items():\n",
        "            for dep in node.dependencies:\n",
        "                if dep not in self.nodes:\n",
        "                    issues.append(f\"Node {node_name} depends on missing node {dep}\")\n",
        "\n",
        "        return issues\n",
        "\n",
        "    def get_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get statistics about the dependency graph.\"\"\"\n",
        "        total_nodes = len(self.nodes)\n",
        "        total_edges = sum(len(deps) for deps in self._adjacency_list.values())\n",
        "\n",
        "        # Count by step type\n",
        "        type_counts: Dict[str, int] = defaultdict(int)\n",
        "        for node in self.nodes.values():\n",
        "            type_counts[node.step_type.value] += 1\n",
        "\n",
        "        # Calculate average dependencies\n",
        "        avg_dependencies = total_edges / total_nodes if total_nodes > 0 else 0\n",
        "\n",
        "        return {\n",
        "            \"total_nodes\": total_nodes,\n",
        "            \"total_edges\": total_edges,\n",
        "            \"type_counts\": dict(type_counts),\n",
        "            \"average_dependencies\": avg_dependencies,\n",
        "            \"has_cycles\": len(self.detect_cycles()) > 0,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.dependencies.exceptions (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Dependency analysis exceptions for the framework.\n",
        "\n",
        "This module defines exceptions specific to dependency analysis operations.\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Optional\n",
        "\n",
        "class DependencyError(Exception):\n",
        "    \"\"\"Base exception for dependency-related errors.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, step_name: Optional[str] = None):\n",
        "        super().__init__(message)\n",
        "        self.step_name = step_name\n",
        "\n",
        "class DependencyAnalysisError(DependencyError):\n",
        "    \"\"\"Raised when dependency analysis fails.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, analysis_step: Optional[str] = None):\n",
        "        super().__init__(message, analysis_step)\n",
        "        self.analysis_step = analysis_step\n",
        "\n",
        "class CircularDependencyError(DependencyError):\n",
        "    \"\"\"Raised when circular dependencies are detected.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, cycle: List[str]):\n",
        "        super().__init__(message)\n",
        "        self.cycle = cycle\n",
        "\n",
        "class InvalidDependencyError(DependencyError):\n",
        "    \"\"\"Raised when invalid dependencies are detected.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, invalid_dependencies: List[str]):\n",
        "        super().__init__(message)\n",
        "        self.invalid_dependencies = invalid_dependencies\n",
        "\n",
        "class DependencyConflictError(DependencyError):\n",
        "    \"\"\"Raised when dependency conflicts are detected.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, conflicting_steps: List[str]):\n",
        "        super().__init__(message)\n",
        "        self.conflicting_steps = conflicting_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.models.steps (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Step model protocols for pipeline builders.\n",
        "\n",
        "This module defines Protocol classes that step implementations should follow.\n",
        "These protocols allow the base package to work with any step implementation\n",
        "without knowing the specific details of Spark or SQL steps.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Any, Dict, List, Optional, Protocol\n",
        "\n",
        "class StepProtocol(Protocol):\n",
        "    \"\"\"Protocol for all pipeline steps.\"\"\"\n",
        "\n",
        "    name: str\n",
        "    rules: Dict[str, Any]\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the step configuration.\"\"\"\n",
        "        ...\n",
        "\n",
        "class BronzeStepProtocol(StepProtocol, Protocol):\n",
        "    \"\"\"Protocol for bronze layer steps.\"\"\"\n",
        "\n",
        "    incremental_col: Optional[str]\n",
        "\n",
        "class SilverStepProtocol(StepProtocol, Protocol):\n",
        "    \"\"\"Protocol for silver layer steps.\"\"\"\n",
        "\n",
        "    source_bronze: str\n",
        "    table_name: str\n",
        "\n",
        "class GoldStepProtocol(StepProtocol, Protocol):\n",
        "    \"\"\"Protocol for gold layer steps.\"\"\"\n",
        "\n",
        "    source_silvers: Optional[List[str]]\n",
        "    table_name: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.models.enums (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Enums for the Pipeline Builder models.\n",
        "\"\"\"\n",
        "\n",
        "from enum import Enum\n",
        "\n",
        "class PipelinePhase(Enum):\n",
        "    \"\"\"Enumeration of pipeline phases.\"\"\"\n",
        "\n",
        "    BRONZE = \"bronze\"\n",
        "    SILVER = \"silver\"\n",
        "    GOLD = \"gold\"\n",
        "\n",
        "class ExecutionMode(Enum):\n",
        "    \"\"\"Enumeration of execution modes.\"\"\"\n",
        "\n",
        "    INITIAL = \"initial\"\n",
        "    INCREMENTAL = \"incremental\"\n",
        "    FULL_REFRESH = \"full_refresh\"\n",
        "    VALIDATION_ONLY = \"validation_only\"\n",
        "\n",
        "class WriteMode(Enum):\n",
        "    \"\"\"Enumeration of write modes.\"\"\"\n",
        "\n",
        "    OVERWRITE = \"overwrite\"\n",
        "    APPEND = \"append\"\n",
        "\n",
        "class ValidationResult(Enum):\n",
        "    \"\"\"Enumeration of validation results.\"\"\"\n",
        "\n",
        "    PASSED = \"passed\"\n",
        "    FAILED = \"failed\"\n",
        "    WARNING = \"warning\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.models.types (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Type definitions and protocols for the Pipeline Builder models.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, List, Protocol, TypeVar, Union\n",
        "\n",
        "# Specific types for model values instead of Any\n",
        "ModelValue = Union[str, int, float, bool, List[str], Dict[str, str], None]\n",
        "ResourceValue = Union[str, int, float, bool, List[str], Dict[str, str]]\n",
        "\n",
        "# Generic type for pipeline results\n",
        "T = TypeVar(\"T\")\n",
        "\n",
        "class Validatable(Protocol):\n",
        "    \"\"\"Protocol for objects that can be validated.\"\"\"\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the object and raise ValidationError if invalid.\"\"\"\n",
        "        ...\n",
        "\n",
        "class Serializable(Protocol):\n",
        "    \"\"\"Protocol for objects that can be serialized.\"\"\"\n",
        "\n",
        "    def to_dict(self) -> Dict[str, ModelValue]:\n",
        "        \"\"\"Convert object to dictionary.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def to_json(self) -> str:\n",
        "        \"\"\"Convert object to JSON string.\"\"\"\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.models.exceptions (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Custom exceptions for the Pipeline Builder models.\n",
        "\"\"\"\n",
        "\n",
        "class PipelineConfigurationError(ValueError):\n",
        "    \"\"\"Raised when pipeline configuration is invalid.\"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "class PipelineExecutionError(RuntimeError):\n",
        "    \"\"\"Raised when pipeline execution fails.\"\"\"\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.writer.models (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Writer-specific models and type definitions.\n",
        "\n",
        "This module contains all the TypedDict definitions and type aliases\n",
        "used by the writer module. It is engine-agnostic.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "from typing import Any, Dict, Literal, Optional, TypedDict\n",
        "\n",
        "# from ..models import ExecutionResult  # Removed: defined in notebook cells above\n",
        "\n",
        "# ============================================================================\n",
        "# Enums\n",
        "# ============================================================================\n",
        "\n",
        "class WriteMode(Enum):\n",
        "    \"\"\"Write mode for log operations.\"\"\"\n",
        "\n",
        "    OVERWRITE = \"overwrite\"\n",
        "    APPEND = \"append\"\n",
        "    MERGE = \"merge\"\n",
        "    IGNORE = \"ignore\"\n",
        "\n",
        "# ============================================================================\n",
        "# TypedDict Definitions\n",
        "# ============================================================================\n",
        "\n",
        "class LogRow(TypedDict):\n",
        "    \"\"\"\n",
        "    Enhanced log row with full type safety and framework integration.\n",
        "\n",
        "    This is an engine-agnostic log row structure that can be used\n",
        "    by both Spark and SQL implementations.\n",
        "    \"\"\"\n",
        "\n",
        "    # Run-level information\n",
        "    run_id: str\n",
        "    run_mode: Literal[\"initial\", \"incremental\", \"full_refresh\", \"validation_only\"]\n",
        "    run_started_at: Optional[datetime]\n",
        "    run_ended_at: Optional[datetime]\n",
        "\n",
        "    # Execution context\n",
        "    execution_id: str\n",
        "    pipeline_id: str\n",
        "    schema: str\n",
        "\n",
        "    # Step-level information\n",
        "    phase: Literal[\"bronze\", \"silver\", \"gold\", \"pipeline\"]\n",
        "    step_name: str\n",
        "    step_type: str\n",
        "\n",
        "    # Timing information\n",
        "    start_time: Optional[datetime]\n",
        "    end_time: Optional[datetime]\n",
        "    duration_secs: float\n",
        "\n",
        "    # Table information\n",
        "    table_fqn: Optional[str]\n",
        "    write_mode: Optional[Literal[\"overwrite\", \"append\"]]\n",
        "\n",
        "    # Data metrics\n",
        "    input_rows: Optional[int]\n",
        "    output_rows: Optional[int]\n",
        "    rows_written: Optional[int]\n",
        "    rows_processed: int\n",
        "    table_total_rows: Optional[int]  # Total rows in table after this write\n",
        "\n",
        "    # Validation metrics\n",
        "    valid_rows: int\n",
        "    invalid_rows: int\n",
        "    validation_rate: float\n",
        "\n",
        "    # Execution status\n",
        "    success: bool\n",
        "    error_message: Optional[str]\n",
        "\n",
        "    # Performance metrics\n",
        "    memory_usage_mb: Optional[float]\n",
        "    cpu_usage_percent: Optional[float]\n",
        "\n",
        "    # Metadata\n",
        "    metadata: Dict[str, Any]\n",
        "\n",
        "class WriterMetrics(TypedDict):\n",
        "    \"\"\"Metrics for writer operations.\"\"\"\n",
        "\n",
        "    total_writes: int\n",
        "    successful_writes: int\n",
        "    failed_writes: int\n",
        "    total_duration_secs: float\n",
        "    avg_write_duration_secs: float\n",
        "    total_rows_written: int\n",
        "    memory_usage_peak_mb: float\n",
        "\n",
        "# ============================================================================\n",
        "# Configuration Models\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class WriterConfig:\n",
        "    \"\"\"\n",
        "    Configuration for the LogWriter.\n",
        "\n",
        "    Provides comprehensive configuration options for the writer module\n",
        "    including table settings, performance tuning, and feature flags.\n",
        "    \"\"\"\n",
        "\n",
        "    table_schema: str\n",
        "    table_name: str\n",
        "    write_mode: WriteMode = WriteMode.APPEND\n",
        "    enable_analytics: bool = True\n",
        "    enable_monitoring: bool = True\n",
        "    enable_quality_checks: bool = True\n",
        "    batch_size: int = 1000\n",
        "    max_retries: int = 3\n",
        "    retry_delay_secs: float = 1.0\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the writer configuration.\"\"\"\n",
        "        if not self.table_schema or not isinstance(self.table_schema, str):\n",
        "            raise ValueError(\"table_schema must be a non-empty string\")\n",
        "        if not self.table_name or not isinstance(self.table_name, str):\n",
        "            raise ValueError(\"table_name must be a non-empty string\")\n",
        "        if self.batch_size < 1:\n",
        "            raise ValueError(\"batch_size must be at least 1\")\n",
        "        if self.max_retries < 0:\n",
        "            raise ValueError(\"max_retries must be non-negative\")\n",
        "        if self.retry_delay_secs < 0:\n",
        "            raise ValueError(\"retry_delay_secs must be non-negative\")\n",
        "\n",
        "# ============================================================================\n",
        "# Utility Functions\n",
        "# ============================================================================\n",
        "\n",
        "def create_log_rows_from_execution_result(\n",
        "    execution_result: ExecutionResult,\n",
        "    run_id: str,\n",
        "    run_mode: Literal[\n",
        "        \"initial\", \"incremental\", \"full_refresh\", \"validation_only\"\n",
        "    ] = \"initial\",\n",
        "    metadata: Optional[Dict[str, Any]] = None,\n",
        ") -> list[LogRow]:\n",
        "    \"\"\"\n",
        "    Create log rows from an execution result.\n",
        "\n",
        "    This is an engine-agnostic function that creates log rows from\n",
        "    execution results. Engine-specific implementations can use this\n",
        "    as a base and extend it as needed.\n",
        "\n",
        "    Args:\n",
        "        execution_result: The execution result\n",
        "        run_id: Run identifier\n",
        "        run_mode: Mode of the run\n",
        "        metadata: Additional metadata\n",
        "\n",
        "    Returns:\n",
        "        List of log rows\n",
        "    \"\"\"\n",
        "    log_rows = []\n",
        "\n",
        "    # Create a main log row for the execution\n",
        "    context = execution_result.context\n",
        "    main_row: LogRow = {\n",
        "        \"run_id\": run_id,\n",
        "        \"run_mode\": run_mode,\n",
        "        \"run_started_at\": context.start_time,\n",
        "        \"run_ended_at\": context.end_time,\n",
        "        \"execution_id\": context.execution_id,\n",
        "        \"pipeline_id\": context.pipeline_id,\n",
        "        \"schema\": context.schema,\n",
        "        \"phase\": \"pipeline\",\n",
        "        \"step_name\": \"pipeline_execution\",\n",
        "        \"step_type\": \"pipeline\",\n",
        "        \"start_time\": context.start_time,\n",
        "        \"end_time\": context.end_time,\n",
        "        \"duration_secs\": context.duration_secs or 0.0,\n",
        "        \"table_fqn\": None,\n",
        "        \"write_mode\": None,\n",
        "        \"input_rows\": None,\n",
        "        \"output_rows\": None,\n",
        "        \"rows_written\": None,\n",
        "        \"rows_processed\": 0,\n",
        "        \"table_total_rows\": None,\n",
        "        \"valid_rows\": 0,\n",
        "        \"invalid_rows\": 0,\n",
        "        \"validation_rate\": 100.0,\n",
        "        \"success\": execution_result.success,\n",
        "        \"error_message\": None,\n",
        "        \"memory_usage_mb\": None,\n",
        "        \"cpu_usage_percent\": None,\n",
        "        \"metadata\": metadata or {},\n",
        "    }\n",
        "\n",
        "    log_rows.append(main_row)\n",
        "\n",
        "    # Add step results\n",
        "    for step_result in execution_result.step_results:\n",
        "        step_row: LogRow = {\n",
        "            \"run_id\": run_id,\n",
        "            \"run_mode\": run_mode,\n",
        "            \"run_started_at\": context.start_time,\n",
        "            \"run_ended_at\": context.end_time,\n",
        "            \"execution_id\": context.execution_id,\n",
        "            \"pipeline_id\": context.pipeline_id,\n",
        "            \"schema\": context.schema,\n",
        "            \"phase\": step_result.phase.value,\n",
        "            \"step_name\": step_result.step_name,\n",
        "            \"step_type\": step_result.step_type or \"unknown\",\n",
        "            \"start_time\": step_result.start_time,\n",
        "            \"end_time\": step_result.end_time,\n",
        "            \"duration_secs\": step_result.duration_secs,\n",
        "            \"table_fqn\": step_result.table_fqn,\n",
        "            \"write_mode\": step_result.write_mode,  # type: ignore[typeddict-item]\n",
        "            \"input_rows\": step_result.input_rows,\n",
        "            \"output_rows\": step_result.rows_written,\n",
        "            \"rows_written\": step_result.rows_written,\n",
        "            \"rows_processed\": step_result.rows_processed,\n",
        "            \"table_total_rows\": None,\n",
        "            \"valid_rows\": step_result.rows_processed,\n",
        "            \"invalid_rows\": 0,\n",
        "            \"validation_rate\": step_result.validation_rate,\n",
        "            \"success\": step_result.success,\n",
        "            \"error_message\": step_result.error_message,\n",
        "            \"memory_usage_mb\": None,\n",
        "            \"cpu_usage_percent\": None,\n",
        "            \"metadata\": {},\n",
        "        }\n",
        "        log_rows.append(step_row)\n",
        "\n",
        "    return log_rows\n",
        "\n",
        "def validate_log_data(log_rows: list[LogRow]) -> None:\n",
        "    \"\"\"\n",
        "    Validate log data for quality and consistency.\n",
        "\n",
        "    Args:\n",
        "        log_rows: List of log rows to validate\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If validation fails\n",
        "    \"\"\"\n",
        "    if not log_rows:\n",
        "        return\n",
        "\n",
        "    # Basic validation - check required fields\n",
        "    required_fields = {\"run_id\", \"phase\", \"step_name\"}\n",
        "    for i, row in enumerate(log_rows):\n",
        "        missing_fields = required_fields - set(row.keys())\n",
        "        if missing_fields:\n",
        "            raise ValueError(f\"Log row {i} missing required fields: {missing_fields}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.steps.utils (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Step utility functions.\n",
        "\n",
        "This module provides utility functions for working with pipeline steps.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, List\n",
        "\n",
        "def classify_step_type(step: Any) -> str:\n",
        "    \"\"\"\n",
        "    Classify step type from step object.\n",
        "\n",
        "    Args:\n",
        "        step: Step object to classify\n",
        "\n",
        "    Returns:\n",
        "        Step type: 'bronze', 'silver', 'gold', or 'unknown'\n",
        "    \"\"\"\n",
        "    # Check if step has type attribute\n",
        "    if hasattr(step, \"type\") and step.type:\n",
        "        step_type = str(step.type).lower()\n",
        "        if step_type in (\"bronze\", \"silver\", \"gold\"):\n",
        "            return step_type\n",
        "\n",
        "    # Determine type from class name\n",
        "    class_name = step.__class__.__name__\n",
        "    if \"Bronze\" in class_name:\n",
        "        return \"bronze\"\n",
        "    elif \"Silver\" in class_name:\n",
        "        return \"silver\"\n",
        "    elif \"Gold\" in class_name:\n",
        "        return \"gold\"\n",
        "\n",
        "    return \"unknown\"\n",
        "\n",
        "def extract_step_dependencies(step: Any) -> List[str]:\n",
        "    \"\"\"\n",
        "    Extract dependencies from a step.\n",
        "\n",
        "    Args:\n",
        "        step: Step object to analyze\n",
        "\n",
        "    Returns:\n",
        "        List of dependency step names\n",
        "    \"\"\"\n",
        "    dependencies: List[str] = []\n",
        "\n",
        "    # Check for source_bronze (silver steps)\n",
        "    source_bronze = getattr(step, \"source_bronze\", None)\n",
        "    if source_bronze:\n",
        "        dependencies.append(source_bronze)\n",
        "\n",
        "    # Check for source_silvers (gold steps)\n",
        "    source_silvers = getattr(step, \"source_silvers\", None)\n",
        "    if source_silvers:\n",
        "        if isinstance(source_silvers, list):\n",
        "            dependencies.extend(source_silvers)\n",
        "        elif isinstance(source_silvers, str):\n",
        "            dependencies.append(source_silvers)\n",
        "\n",
        "    # Check for source attribute (backward compatibility)\n",
        "    source = getattr(step, \"source\", None)\n",
        "    if source and source not in dependencies:\n",
        "        if isinstance(source, str):\n",
        "            dependencies.append(source)\n",
        "        elif isinstance(source, list):\n",
        "            dependencies.extend(source)\n",
        "\n",
        "    return dependencies\n",
        "\n",
        "def get_step_target(step: Any) -> str:\n",
        "    \"\"\"\n",
        "    Get target table name from a step.\n",
        "\n",
        "    Args:\n",
        "        step: Step object\n",
        "\n",
        "    Returns:\n",
        "        Target table name, or empty string if not found\n",
        "    \"\"\"\n",
        "    # Check for table_name attribute\n",
        "    table_name = getattr(step, \"table_name\", None)\n",
        "    if table_name:\n",
        "        return str(table_name)\n",
        "\n",
        "    # Check for target attribute\n",
        "    target = getattr(step, \"target\", None)\n",
        "    if target:\n",
        "        return str(target)\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "def normalize_step_name(name: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalize step name (trim whitespace, convert to lowercase).\n",
        "\n",
        "    Args:\n",
        "        name: Step name to normalize\n",
        "\n",
        "    Returns:\n",
        "        Normalized step name\n",
        "    \"\"\"\n",
        "    if not name:\n",
        "        return \"\"\n",
        "    return name.strip().lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.errors.context (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Error context builders and suggestion generators.\n",
        "\n",
        "This module provides utilities for building structured error context\n",
        "and generating helpful error suggestions.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "# Type alias for error context\n",
        "ErrorContextType = Dict[\n",
        "    str, Union[str, int, float, bool, List[str], Dict[str, str], None]\n",
        "]\n",
        "\n",
        "class ErrorContext:\n",
        "    \"\"\"\n",
        "    Structured error context for better error messages.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs: Any):\n",
        "        \"\"\"\n",
        "        Initialize error context with key-value pairs.\n",
        "\n",
        "        Args:\n",
        "            **kwargs: Context key-value pairs\n",
        "        \"\"\"\n",
        "        self.context: ErrorContextType = dict(kwargs)\n",
        "\n",
        "    def add(self, key: str, value: Any) -> None:\n",
        "        \"\"\"\n",
        "        Add a context value.\n",
        "\n",
        "        Args:\n",
        "            key: Context key\n",
        "            value: Context value\n",
        "        \"\"\"\n",
        "        self.context[key] = value\n",
        "\n",
        "    def to_dict(self) -> ErrorContextType:\n",
        "        \"\"\"\n",
        "        Convert context to dictionary.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary representation of context\n",
        "        \"\"\"\n",
        "        return self.context.copy()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        \"\"\"Return string representation.\"\"\"\n",
        "        return f\"ErrorContext({self.context})\"\n",
        "\n",
        "class SuggestionGenerator:\n",
        "    \"\"\"\n",
        "    Generator for helpful error suggestions.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def suggest_fix_for_missing_dependency(\n",
        "        step_name: str, missing: str, step_type: str = \"step\"\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate suggestions for missing dependency.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step with missing dependency\n",
        "            missing: Name of the missing dependency\n",
        "            step_type: Type of step (bronze/silver/gold)\n",
        "\n",
        "        Returns:\n",
        "            List of suggestion strings\n",
        "        \"\"\"\n",
        "        suggestions = [\n",
        "            f\"Add {step_type} step '{missing}' before '{step_name}'\",\n",
        "            f\"Check spelling of '{missing}'\",\n",
        "            f\"Ensure '{missing}' is defined in the pipeline\",\n",
        "        ]\n",
        "\n",
        "        if step_type == \"silver\":\n",
        "            suggestions.append(\n",
        "                f\"Bronze step '{missing}' must be added with with_bronze_rules()\"\n",
        "            )\n",
        "        elif step_type == \"gold\":\n",
        "            suggestions.append(\n",
        "                f\"Silver step '{missing}' must be added with add_silver_transform()\"\n",
        "            )\n",
        "\n",
        "        return suggestions\n",
        "\n",
        "    @staticmethod\n",
        "    def suggest_fix_for_duplicate_name(name: str, step_type: str = \"step\") -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate suggestions for duplicate step name.\n",
        "\n",
        "        Args:\n",
        "            name: Duplicate step name\n",
        "            step_type: Type of step (bronze/silver/gold)\n",
        "\n",
        "        Returns:\n",
        "            List of suggestion strings\n",
        "        \"\"\"\n",
        "        return [\n",
        "            f\"Use a different name for this {step_type} step\",\n",
        "            f\"Remove the existing {step_type} step '{name}' first\",\n",
        "            f\"Check if '{name}' was already added to the pipeline\",\n",
        "        ]\n",
        "\n",
        "    @staticmethod\n",
        "    def suggest_fix_for_invalid_schema(schema: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate suggestions for invalid schema name.\n",
        "\n",
        "        Args:\n",
        "            schema: Invalid schema name\n",
        "\n",
        "        Returns:\n",
        "            List of suggestion strings\n",
        "        \"\"\"\n",
        "        return [\n",
        "            \"Schema name must be a non-empty string\",\n",
        "            \"Schema name must be 128 characters or less\",\n",
        "            \"Schema name cannot contain only whitespace\",\n",
        "            f\"Check the schema name: '{schema}'\",\n",
        "        ]\n",
        "\n",
        "    @staticmethod\n",
        "    def suggest_fix_for_missing_rules(\n",
        "        step_name: str, step_type: str = \"step\"\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate suggestions for missing validation rules.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of step missing rules\n",
        "            step_type: Type of step (bronze/silver/gold)\n",
        "\n",
        "        Returns:\n",
        "            List of suggestion strings\n",
        "        \"\"\"\n",
        "        return [\n",
        "            f\"{step_type.capitalize()} step '{step_name}' requires validation rules\",\n",
        "            \"Add rules dictionary with column validation rules\",\n",
        "            \"Rules cannot be empty\",\n",
        "        ]\n",
        "\n",
        "def build_validation_context(step: Any, step_type: str) -> ErrorContextType:\n",
        "    \"\"\"\n",
        "    Build error context for validation errors.\n",
        "\n",
        "    Args:\n",
        "        step: Step object\n",
        "        step_type: Type of step (bronze/silver/gold)\n",
        "\n",
        "    Returns:\n",
        "        Error context dictionary\n",
        "    \"\"\"\n",
        "    context: ErrorContextType = {\n",
        "        \"step_type\": step_type,\n",
        "    }\n",
        "\n",
        "    step_name = getattr(step, \"name\", None)\n",
        "    if step_name:\n",
        "        context[\"step_name\"] = step_name\n",
        "\n",
        "    # Add step-specific context\n",
        "    if step_type == \"silver\":\n",
        "        source_bronze = getattr(step, \"source_bronze\", None)\n",
        "        if source_bronze:\n",
        "            context[\"source_bronze\"] = source_bronze\n",
        "    elif step_type == \"gold\":\n",
        "        source_silvers = getattr(step, \"source_silvers\", None)\n",
        "        if source_silvers:\n",
        "            context[\"source_silvers\"] = (\n",
        "                source_silvers if isinstance(source_silvers, list) else [source_silvers]\n",
        "            )\n",
        "\n",
        "    return context\n",
        "\n",
        "def build_execution_context(step: Any, error: Exception) -> ErrorContextType:\n",
        "    \"\"\"\n",
        "    Build error context for execution errors.\n",
        "\n",
        "    Args:\n",
        "        step: Step object that failed\n",
        "        error: Exception that occurred\n",
        "\n",
        "    Returns:\n",
        "        Error context dictionary\n",
        "    \"\"\"\n",
        "    context: ErrorContextType = {\n",
        "        \"error_type\": error.__class__.__name__,\n",
        "        \"error_message\": str(error),\n",
        "    }\n",
        "\n",
        "    step_name = getattr(step, \"name\", None)\n",
        "    if step_name:\n",
        "        context[\"step_name\"] = step_name\n",
        "\n",
        "    step_type = getattr(step, \"type\", None)\n",
        "    if step_type:\n",
        "        context[\"step_type\"] = step_type\n",
        "\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.builder.helpers (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Builder helper functions for creating step dictionaries.\n",
        "\n",
        "This module provides helper functions for creating step configuration dictionaries.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "def create_bronze_step_dict(\n",
        "    name: str,\n",
        "    rules: Dict[str, Any],\n",
        "    incremental_col: Optional[str] = None,\n",
        "    schema: Optional[str] = None,\n",
        "    **kwargs: Any,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Create a dictionary representing a bronze step configuration.\n",
        "\n",
        "    Args:\n",
        "        name: Step name\n",
        "        rules: Validation rules dictionary\n",
        "        incremental_col: Optional incremental column name\n",
        "        schema: Optional schema name\n",
        "        **kwargs: Additional step attributes\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with bronze step configuration\n",
        "\n",
        "    Example:\n",
        "        >>> step_dict = create_bronze_step_dict(\n",
        "        ...     name=\"events\",\n",
        "        ...     rules={\"user_id\": [\"not_null\"]},\n",
        "        ...     incremental_col=\"timestamp\"\n",
        "        ... )\n",
        "    \"\"\"\n",
        "    step_dict: Dict[str, Any] = {\n",
        "        \"name\": name,\n",
        "        \"rules\": rules,\n",
        "        \"incremental_col\": incremental_col,\n",
        "        \"schema\": schema,\n",
        "        **kwargs,\n",
        "    }\n",
        "    return step_dict\n",
        "\n",
        "def create_silver_step_dict(\n",
        "    name: str,\n",
        "    source_bronze: str,\n",
        "    transform: Any,\n",
        "    rules: Dict[str, Any],\n",
        "    table_name: str,\n",
        "    watermark_col: Optional[str] = None,\n",
        "    schema: Optional[str] = None,\n",
        "    **kwargs: Any,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Create a dictionary representing a silver step configuration.\n",
        "\n",
        "    Args:\n",
        "        name: Step name\n",
        "        source_bronze: Source bronze step name\n",
        "        transform: Transformation function\n",
        "        rules: Validation rules dictionary\n",
        "        table_name: Target table name\n",
        "        watermark_col: Optional watermark column name\n",
        "        schema: Optional schema name\n",
        "        **kwargs: Additional step attributes\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with silver step configuration\n",
        "\n",
        "    Example:\n",
        "        >>> step_dict = create_silver_step_dict(\n",
        "        ...     name=\"clean_events\",\n",
        "        ...     source_bronze=\"events\",\n",
        "        ...     transform=clean_func,\n",
        "        ...     rules={\"user_id\": [\"not_null\"]},\n",
        "        ...     table_name=\"clean_events\"\n",
        "        ... )\n",
        "    \"\"\"\n",
        "    step_dict: Dict[str, Any] = {\n",
        "        \"name\": name,\n",
        "        \"source_bronze\": source_bronze,\n",
        "        \"transform\": transform,\n",
        "        \"rules\": rules,\n",
        "        \"table_name\": table_name,\n",
        "        \"watermark_col\": watermark_col,\n",
        "        \"schema\": schema,\n",
        "        **kwargs,\n",
        "    }\n",
        "    return step_dict\n",
        "\n",
        "def create_gold_step_dict(\n",
        "    name: str,\n",
        "    transform: Any,\n",
        "    rules: Dict[str, Any],\n",
        "    table_name: str,\n",
        "    source_silvers: Optional[List[str]] = None,\n",
        "    schema: Optional[str] = None,\n",
        "    **kwargs: Any,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Create a dictionary representing a gold step configuration.\n",
        "\n",
        "    Args:\n",
        "        name: Step name\n",
        "        transform: Transformation function\n",
        "        rules: Validation rules dictionary\n",
        "        table_name: Target table name\n",
        "        source_silvers: Optional list of source silver step names\n",
        "        schema: Optional schema name\n",
        "        **kwargs: Additional step attributes\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with gold step configuration\n",
        "\n",
        "    Example:\n",
        "        >>> step_dict = create_gold_step_dict(\n",
        "        ...     name=\"daily_metrics\",\n",
        "        ...     transform=metrics_func,\n",
        "        ...     rules={\"metric\": [\"not_null\"]},\n",
        "        ...     table_name=\"daily_metrics\",\n",
        "        ...     source_silvers=[\"clean_events\"]\n",
        "        ... )\n",
        "    \"\"\"\n",
        "    step_dict: Dict[str, Any] = {\n",
        "        \"name\": name,\n",
        "        \"transform\": transform,\n",
        "        \"rules\": rules,\n",
        "        \"table_name\": table_name,\n",
        "        \"source_silvers\": source_silvers or [],\n",
        "        \"schema\": schema,\n",
        "        **kwargs,\n",
        "    }\n",
        "    return step_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.validation.protocols (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Protocol definitions for validator interfaces.\n",
        "\n",
        "This module defines Protocol classes that specify the expected interfaces\n",
        "for validators, ensuring consistent return types and method signatures\n",
        "across different validator implementations.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, List, Protocol\n",
        "\n",
        "# from ..models import PipelineConfig  # Removed: defined in notebook cells above\n",
        "\n",
        "class PipelineValidatorProtocol(Protocol):\n",
        "    \"\"\"\n",
        "    Protocol defining the interface for pipeline validators.\n",
        "\n",
        "    This protocol ensures that all pipeline validators have consistent\n",
        "    method signatures and return types, preventing type mismatch bugs.\n",
        "\n",
        "    Note: Different implementations may return different types:\n",
        "    - UnifiedValidator returns List[str]\n",
        "    - UnifiedValidator returns ValidationResult\n",
        "    \"\"\"\n",
        "\n",
        "    def validate_pipeline(\n",
        "        self,\n",
        "        config: PipelineConfig,\n",
        "        bronze_steps: Dict[str, Any],\n",
        "        silver_steps: Dict[str, Any],\n",
        "        gold_steps: Dict[str, Any],\n",
        "    ) -> List[str] | Any:\n",
        "        \"\"\"\n",
        "        Validate entire pipeline configuration.\n",
        "\n",
        "        Args:\n",
        "            config: Pipeline configuration\n",
        "            bronze_steps: Dictionary of bronze steps\n",
        "            silver_steps: Dictionary of silver steps\n",
        "            gold_steps: Dictionary of gold steps\n",
        "\n",
        "        Returns:\n",
        "            List[str] or ValidationResult depending on implementation\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "    def validate_schema(self, schema: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate schema name.\n",
        "\n",
        "        Args:\n",
        "            schema: Schema name to validate\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "class ValidationResultProtocol(Protocol):\n",
        "    \"\"\"\n",
        "    Protocol defining the interface for validation results.\n",
        "\n",
        "    This protocol ensures that ValidationResult objects have consistent\n",
        "    attributes that can be safely accessed.\n",
        "    \"\"\"\n",
        "\n",
        "    @property\n",
        "    def errors(self) -> List[str]:\n",
        "        \"\"\"List of validation error messages.\"\"\"\n",
        "        ...\n",
        "\n",
        "    @property\n",
        "    def warnings(self) -> List[str]:\n",
        "        \"\"\"List of validation warnings.\"\"\"\n",
        "        ...\n",
        "\n",
        "    @property\n",
        "    def is_valid(self) -> bool:\n",
        "        \"\"\"Whether validation passed.\"\"\"\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.validation.utils (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Utility functions for the framework validation.\n",
        "\n",
        "This module provides utility functions for data analysis and validation operations.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, List, Set\n",
        "\n",
        "def safe_divide(numerator: float, denominator: float, default: float = 0.0) -> float:\n",
        "    \"\"\"\n",
        "    Safely divide two numbers, returning default if denominator is zero or None.\n",
        "\n",
        "    Args:\n",
        "        numerator: The numerator\n",
        "        denominator: The denominator\n",
        "        default: Default value to return if denominator is zero or None\n",
        "\n",
        "    Returns:\n",
        "        The division result or default value\n",
        "    \"\"\"\n",
        "    if denominator is None or numerator is None or denominator == 0:\n",
        "        return default\n",
        "    return numerator / denominator\n",
        "\n",
        "def validate_step_name(name: str) -> bool:\n",
        "    \"\"\"\n",
        "    Validate step name format.\n",
        "\n",
        "    Args:\n",
        "        name: Step name to validate\n",
        "\n",
        "    Returns:\n",
        "        True if valid, False otherwise\n",
        "    \"\"\"\n",
        "    if not name:\n",
        "        return False\n",
        "    if not isinstance(name, str):\n",
        "        return False  # type: ignore[unreachable]\n",
        "    if not name.strip():\n",
        "        return False\n",
        "    if len(name) > 128:  # Reasonable limit\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def validate_schema_name(schema: str) -> bool:\n",
        "    \"\"\"\n",
        "    Validate schema name format.\n",
        "\n",
        "    Args:\n",
        "        schema: Schema name to validate\n",
        "\n",
        "    Returns:\n",
        "        True if valid, False otherwise\n",
        "    \"\"\"\n",
        "    if not schema:\n",
        "        return False\n",
        "    if not isinstance(schema, str):\n",
        "        return False  # type: ignore[unreachable]\n",
        "    if not schema.strip():\n",
        "        return False\n",
        "    if len(schema) > 128:  # Reasonable limit\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def check_duplicate_names(items: List[Any], name_attr: str = \"name\") -> List[str]:\n",
        "    \"\"\"\n",
        "    Check for duplicate names in a list of items.\n",
        "\n",
        "    Args:\n",
        "        items: List of items to check\n",
        "        name_attr: Attribute name to use for getting the name\n",
        "\n",
        "    Returns:\n",
        "        List of duplicate names found\n",
        "    \"\"\"\n",
        "    seen: Dict[str, int] = {}\n",
        "    duplicates: List[str] = []\n",
        "\n",
        "    for item in items:\n",
        "        name = getattr(item, name_attr, None)\n",
        "        if name:\n",
        "            if name in seen:\n",
        "                seen[name] += 1\n",
        "                if name not in duplicates:\n",
        "                    duplicates.append(name)\n",
        "            else:\n",
        "                seen[name] = 1\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "def validate_dependency_chain(steps: Dict[str, Any]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Validate dependency chain and detect circular dependencies.\n",
        "\n",
        "    Args:\n",
        "        steps: Dictionary of steps with their dependencies\n",
        "\n",
        "    Returns:\n",
        "        List of validation errors (empty if valid)\n",
        "    \"\"\"\n",
        "    errors: List[str] = []\n",
        "\n",
        "    # Build dependency graph\n",
        "    dependencies: Dict[str, List[str]] = {}\n",
        "    for step_name, step in steps.items():\n",
        "        deps = []\n",
        "        if hasattr(step, \"source_bronze\") and step.source_bronze:\n",
        "            deps.append(step.source_bronze)\n",
        "        if hasattr(step, \"source_silvers\") and step.source_silvers:\n",
        "            if isinstance(step.source_silvers, list):\n",
        "                deps.extend(step.source_silvers)\n",
        "        if deps:\n",
        "            dependencies[step_name] = deps\n",
        "\n",
        "    # Check for circular dependencies using DFS\n",
        "    visited: Set[str] = set()\n",
        "    rec_stack: Set[str] = set()\n",
        "\n",
        "    def has_cycle(node: str) -> bool:\n",
        "        \"\"\"Check if there's a cycle starting from node.\"\"\"\n",
        "        visited.add(node)\n",
        "        rec_stack.add(node)\n",
        "\n",
        "        for neighbor in dependencies.get(node, []):\n",
        "            if neighbor not in visited:\n",
        "                if has_cycle(neighbor):\n",
        "                    return True\n",
        "            elif neighbor in rec_stack:\n",
        "                # Found a back edge, cycle exists\n",
        "                return True\n",
        "\n",
        "        rec_stack.remove(node)\n",
        "        return False\n",
        "\n",
        "    # Check all nodes for cycles\n",
        "    all_nodes = set(dependencies.keys())\n",
        "    for node in all_nodes:\n",
        "        if node not in visited:\n",
        "            if has_cycle(node):\n",
        "                errors.append(f\"Circular dependency detected involving step '{node}'\")\n",
        "\n",
        "    return errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.typing_stubs (pipeline_builder)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Type stubs and Protocol classes for dynamic PySpark/mock-spark attributes.\n",
        "\n",
        "This module provides Protocol classes that define the expected interface\n",
        "for DataFrame, Column, and SparkSession objects, allowing mypy to understand\n",
        "dynamic attributes that are added at runtime.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Any, Protocol\n",
        "\n",
        "class DataFrameProtocol(Protocol):\n",
        "    \"\"\"Protocol for DataFrame-like objects with dynamic attributes.\"\"\"\n",
        "\n",
        "    def write(self) -> Any:\n",
        "        \"\"\"Get DataFrameWriter for writing data.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def filter(self, condition: Any) -> Any:\n",
        "        \"\"\"Filter rows based on condition.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def select(self, *cols: Any) -> Any:\n",
        "        \"\"\"Select columns.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def withColumn(self, colName: str, col: Any) -> Any:\n",
        "        \"\"\"Add or replace a column.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def withColumnRenamed(self, existing: str, new: str) -> Any:\n",
        "        \"\"\"Rename a column.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def count(self) -> int:\n",
        "        \"\"\"Count rows.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def collect(self) -> list[Any]:\n",
        "        \"\"\"Collect rows to driver.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def cache(self) -> Any:\n",
        "        \"\"\"Cache the DataFrame.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def show(self, n: int = 20, truncate: bool = True) -> None:\n",
        "        \"\"\"Show DataFrame contents.\"\"\"\n",
        "        ...\n",
        "\n",
        "class ColumnProtocol(Protocol):\n",
        "    \"\"\"Protocol for Column-like objects with dynamic attributes.\"\"\"\n",
        "\n",
        "    def isNotNull(self) -> Any:\n",
        "        \"\"\"Check if column is not null.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def isNull(self) -> Any:\n",
        "        \"\"\"Check if column is null.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def __eq__(self, other: Any) -> Any:\n",
        "        \"\"\"Equality comparison.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def __ne__(self, other: Any) -> Any:\n",
        "        \"\"\"Inequality comparison.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def __gt__(self, other: Any) -> Any:\n",
        "        \"\"\"Greater than comparison.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def __lt__(self, other: Any) -> Any:\n",
        "        \"\"\"Less than comparison.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def __ge__(self, other: Any) -> Any:\n",
        "        \"\"\"Greater than or equal comparison.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def __le__(self, other: Any) -> Any:\n",
        "        \"\"\"Less than or equal comparison.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def __add__(self, other: Any) -> Any:\n",
        "        \"\"\"Addition operator.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def __sub__(self, other: Any) -> Any:\n",
        "        \"\"\"Subtraction operator.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def __mul__(self, other: Any) -> Any:\n",
        "        \"\"\"Multiplication operator.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def __div__(self, other: Any) -> Any:\n",
        "        \"\"\"Division operator.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def cast(self, dataType: Any) -> Any:\n",
        "        \"\"\"Cast column to different type.\"\"\"\n",
        "        ...\n",
        "\n",
        "class SparkSessionProtocol(Protocol):\n",
        "    \"\"\"Protocol for SparkSession-like objects with dynamic attributes.\"\"\"\n",
        "\n",
        "    catalog: Any\n",
        "    \"\"\"Catalog for accessing databases and tables.\"\"\"\n",
        "\n",
        "    def table(self, name: str) -> Any:\n",
        "        \"\"\"Get a table as DataFrame.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def createDataFrame(\n",
        "        self, data: Any, schema: Any = None, samplingRatio: Any = None\n",
        "    ) -> Any:\n",
        "        \"\"\"Create DataFrame from data.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def sql(self, sqlQuery: str) -> Any:\n",
        "        \"\"\"Execute SQL query and return DataFrame.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def stop(self) -> None:\n",
        "        \"\"\"Stop the SparkSession.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def sparkContext(self) -> Any:\n",
        "        \"\"\"Get SparkContext.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def conf(self) -> Any:\n",
        "        \"\"\"Get SparkConf.\"\"\"\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.protocols (pipeline_builder)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Protocol definitions for engine-agnostic Spark interfaces.\n",
        "\n",
        "These protocols represent the minimal surface area used by pipeline_builder.\n",
        "Any engine (PySpark, sparkless, or other) must satisfy these to work with\n",
        "pipeline_builder. Keep these protocols lean\u2014only include members actually\n",
        "consumed in src.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Protocol, runtime_checkable\n",
        "\n",
        "@runtime_checkable\n",
        "class ColumnProtocol(Protocol):\n",
        "    \"\"\"Column-like object with comparison and basic ops.\"\"\"\n",
        "\n",
        "    def isNotNull(self) -> Any: ...\n",
        "    def isNull(self) -> Any: ...\n",
        "    def cast(self, dataType: Any) -> Any: ...\n",
        "    def __eq__(self, other: Any) -> Any: ...\n",
        "    def __ne__(self, other: Any) -> Any: ...\n",
        "    def __gt__(self, other: Any) -> Any: ...\n",
        "    def __lt__(self, other: Any) -> Any: ...\n",
        "    def __ge__(self, other: Any) -> Any: ...\n",
        "    def __le__(self, other: Any) -> Any: ...\n",
        "    def __add__(self, other: Any) -> Any: ...\n",
        "    def __sub__(self, other: Any) -> Any: ...\n",
        "    def __mul__(self, other: Any) -> Any: ...\n",
        "    def __truediv__(self, other: Any) -> Any: ...\n",
        "\n",
        "@runtime_checkable\n",
        "class DataFrameProtocol(Protocol):\n",
        "    \"\"\"DataFrame-like object used throughout pipeline_builder.\"\"\"\n",
        "\n",
        "    # Core accessors\n",
        "    def schema(self) -> Any: ...\n",
        "    @property\n",
        "    def columns(self) -> list[str]: ...\n",
        "\n",
        "    # Actions\n",
        "    def count(self) -> int: ...\n",
        "    def collect(self) -> list[Any]: ...\n",
        "    def show(self, n: int = 20, truncate: bool = True) -> None: ...\n",
        "\n",
        "    # Transformations\n",
        "    def filter(self, condition: Any) -> Any: ...\n",
        "    def select(self, *cols: Any) -> Any: ...\n",
        "    def withColumn(self, colName: str, col: Any) -> Any: ...\n",
        "    def withColumnRenamed(self, existing: str, new: str) -> Any: ...\n",
        "    def groupBy(self, *cols: Any) -> Any: ...\n",
        "    def agg(self, *exprs: Any, **kwargs: Any) -> Any: ...\n",
        "    def limit(self, num: int) -> Any: ...\n",
        "    def cache(self) -> Any: ...\n",
        "\n",
        "    # SQL helpers\n",
        "    def createOrReplaceTempView(self, name: str) -> None: ...\n",
        "\n",
        "    # Writer\n",
        "    @property\n",
        "    def write(self) -> Any: ...\n",
        "\n",
        "@runtime_checkable\n",
        "class FunctionsProtocol(Protocol):\n",
        "    \"\"\"Functions module interface (col, lit, aggregations, etc.).\"\"\"\n",
        "\n",
        "    def col(self, col_name: str) -> ColumnProtocol: ...\n",
        "    def expr(self, expr: str) -> ColumnProtocol: ...\n",
        "    def lit(self, value: Any) -> ColumnProtocol: ...\n",
        "    def when(self, condition: ColumnProtocol, value: Any) -> ColumnProtocol: ...\n",
        "    def count(self, col: Any = \"*\") -> ColumnProtocol: ...\n",
        "    def countDistinct(self, *cols: Any) -> ColumnProtocol: ...\n",
        "    def sum(self, col: Any) -> ColumnProtocol: ...\n",
        "    def max(self, col: Any) -> ColumnProtocol: ...\n",
        "    def min(self, col: Any) -> ColumnProtocol: ...\n",
        "    def avg(self, col: Any) -> ColumnProtocol: ...\n",
        "    def length(self, col: Any) -> ColumnProtocol: ...\n",
        "    def date_trunc(self, fmt: str, col: Any) -> ColumnProtocol: ...\n",
        "    def dayofweek(self, col: Any) -> ColumnProtocol: ...\n",
        "    def current_timestamp(self) -> ColumnProtocol: ...\n",
        "\n",
        "@runtime_checkable\n",
        "class TypesProtocol(Protocol):\n",
        "    \"\"\"Types namespace used for schemas and fields.\"\"\"\n",
        "\n",
        "    StructType: Any\n",
        "    StructField: Any\n",
        "    StringType: Any\n",
        "    IntegerType: Any\n",
        "    FloatType: Any\n",
        "    DoubleType: Any\n",
        "    LongType: Any\n",
        "    TimestampType: Any\n",
        "    BooleanType: Any\n",
        "\n",
        "@runtime_checkable\n",
        "class WindowProtocol(Protocol):\n",
        "    \"\"\"Window spec placeholder.\"\"\"\n",
        "\n",
        "    def orderBy(self, *cols: Any, **kwargs: Any) -> Any: ...\n",
        "    def partitionBy(self, *cols: Any) -> Any: ...\n",
        "\n",
        "@runtime_checkable\n",
        "class AnalysisExceptionProtocol(Protocol):\n",
        "    \"\"\"Exception type placeholder for analysis errors.\"\"\"\n",
        "\n",
        "    @property\n",
        "    def desc(self) -> str: ...\n",
        "\n",
        "@runtime_checkable\n",
        "class SparkSessionProtocol(Protocol):\n",
        "    \"\"\"SparkSession-like interface.\"\"\"\n",
        "\n",
        "    @property\n",
        "    def catalog(self) -> Any: ...\n",
        "    @property\n",
        "    def conf(self) -> Any: ...\n",
        "\n",
        "    def table(self, name: str) -> DataFrameProtocol: ...\n",
        "    def createDataFrame(\n",
        "        self, data: Any, schema: Any = None, samplingRatio: Any = None\n",
        "    ) -> DataFrameProtocol: ...\n",
        "    def sql(self, sqlQuery: str) -> DataFrameProtocol: ...\n",
        "    def stop(self) -> None: ...\n",
        "\n",
        "    # Builder/config checks\n",
        "    @property\n",
        "    def _jsparkSession(self) -> Any: ...  # optional; used for ids\n",
        "\n",
        "__all__ = [\n",
        "    \"ColumnProtocol\",\n",
        "    \"DataFrameProtocol\",\n",
        "    \"FunctionsProtocol\",\n",
        "    \"TypesProtocol\",\n",
        "    \"WindowProtocol\",\n",
        "    \"AnalysisExceptionProtocol\",\n",
        "    \"SparkSessionProtocol\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.constants (pipeline_builder)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Constants and configuration values for the framework.\n",
        "\n",
        "This module contains all magic numbers, default values, and configuration\n",
        "constants used throughout the the codebase.\n",
        "\"\"\"\n",
        "\n",
        "# Memory and Size Constants\n",
        "BYTES_PER_KB = 1024\n",
        "BYTES_PER_MB = BYTES_PER_KB * 1024\n",
        "BYTES_PER_GB = BYTES_PER_MB * 1024\n",
        "\n",
        "# Default Memory Limits\n",
        "DEFAULT_MAX_MEMORY_MB = 1024\n",
        "DEFAULT_CACHE_MEMORY_MB = 512\n",
        "\n",
        "# File Size Constants\n",
        "DEFAULT_MAX_FILE_SIZE_MB = 10\n",
        "DEFAULT_BACKUP_COUNT = 5\n",
        "\n",
        "# Performance Constants\n",
        "DEFAULT_CACHE_PARTITIONS = 200\n",
        "DEFAULT_SHUFFLE_PARTITIONS = 200\n",
        "\n",
        "# Validation Constants\n",
        "DEFAULT_BRONZE_THRESHOLD = 95.0\n",
        "DEFAULT_SILVER_THRESHOLD = 98.0\n",
        "DEFAULT_GOLD_THRESHOLD = 99.0\n",
        "\n",
        "# Timeout Constants (in seconds)\n",
        "DEFAULT_TIMEOUT_SECONDS = 300\n",
        "DEFAULT_RETRY_TIMEOUT_SECONDS = 60\n",
        "\n",
        "# Logging Constants\n",
        "DEFAULT_LOG_LEVEL = \"INFO\"\n",
        "DEFAULT_VERBOSE = True\n",
        "\n",
        "# Schema Constants\n",
        "DEFAULT_SCHEMA = \"default\"\n",
        "TEST_SCHEMA = \"test_schema\"\n",
        "\n",
        "# Error Constants\n",
        "MAX_ERROR_MESSAGE_LENGTH = 1000\n",
        "MAX_STACK_TRACE_LINES = 50\n",
        "\n",
        "# Performance Monitoring Constants\n",
        "DEFAULT_METRICS_INTERVAL_SECONDS = 30\n",
        "DEFAULT_ALERT_THRESHOLD_PERCENT = 80.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.dependencies.graph (pipeline_builder)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Dependency graph representation for the framework pipelines.\n",
        "\n",
        "This module provides a clean, efficient representation of pipeline dependencies\n",
        "that can be used for dependency analysis, cycle detection, execution planning,\n",
        "and optimization. The graph supports topological sorting and validation.\n",
        "\n",
        "**Key Features:**\n",
        "    - **Dependency Tracking**: Track dependencies and dependents for each step\n",
        "    - **Cycle Detection**: Detect circular dependencies in the pipeline\n",
        "    - **Topological Sort**: Order steps by dependency requirements for sequential execution\n",
        "    - **Validation**: Validate graph structure and detect issues\n",
        "\n",
        "**Common Use Cases:**\n",
        "    - Analyze pipeline dependencies before execution\n",
        "    - Detect circular dependencies that would cause execution failures\n",
        "    - Determine execution order for sequential processing using topological sort\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.dependencies.graph import (\n",
        "    ...     DependencyGraph,\n",
        "    ...     StepNode,\n",
        "    ...     StepType\n",
        "    ... )\n",
        "    >>>\n",
        "    >>> # Create dependency graph\n",
        "    >>> graph = DependencyGraph()\n",
        "    >>>\n",
        "    >>> # Add nodes\n",
        "    >>> bronze = StepNode(\"bronze_step\", StepType.BRONZE)\n",
        "    >>> silver = StepNode(\"silver_step\", StepType.SILVER)\n",
        "    >>> graph.add_node(bronze)\n",
        "    >>> graph.add_node(silver)\n",
        "    >>>\n",
        "    >>> # Add dependency (silver depends on bronze)\n",
        "    >>> graph.add_dependency(\"silver_step\", \"bronze_step\")\n",
        "    >>>\n",
        "    >>> # Validate and get execution order\n",
        "    >>> issues = graph.validate()\n",
        "    >>> execution_order = graph.topological_sort()\n",
        "    >>> print(execution_order)  # [\"bronze_step\", \"silver_step\"]\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "from collections import defaultdict, deque\n",
        "from dataclasses import dataclass, field\n",
        "from enum import Enum\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class StepType(Enum):\n",
        "    \"\"\"Types of pipeline steps in the Medallion Architecture.\n",
        "\n",
        "    Represents the three layers of the Medallion Architecture:\n",
        "    - BRONZE: Raw data ingestion and validation layer\n",
        "    - SILVER: Cleaned and enriched data layer\n",
        "    - GOLD: Business-ready analytics and reporting layer\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.dependencies.graph import StepType\n",
        "        >>> step_type = StepType.BRONZE\n",
        "        >>> print(step_type.value)  # \"bronze\"\n",
        "    \"\"\"\n",
        "\n",
        "    BRONZE = \"bronze\"\n",
        "    SILVER = \"silver\"\n",
        "    GOLD = \"gold\"\n",
        "\n",
        "@dataclass\n",
        "class StepNode:\n",
        "    \"\"\"Represents a single step in the dependency graph.\n",
        "\n",
        "    A StepNode contains all information about a pipeline step including its\n",
        "    dependencies, dependents, execution metadata, and custom metadata.\n",
        "\n",
        "    Attributes:\n",
        "        name: Unique identifier for this step.\n",
        "        step_type: Type of step (BRONZE, SILVER, or GOLD).\n",
        "        dependencies: Set of step names that this step depends on. Steps in\n",
        "            this set must complete before this step can execute.\n",
        "        dependents: Set of step names that depend on this step. These steps\n",
        "            cannot execute until this step completes.\n",
        "        execution_group: (Deprecated) Legacy field, no longer used. Execution\n",
        "            order is determined by topological sort.\n",
        "        estimated_duration: Estimated execution duration in seconds. Used\n",
        "            for optimization and scheduling. Defaults to 0.0.\n",
        "        metadata: Dictionary for storing custom metadata about the step.\n",
        "            Can contain any key-value pairs.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.dependencies.graph import StepNode, StepType\n",
        "        >>> node = StepNode(\n",
        "        ...     name=\"user_events\",\n",
        "        ...     step_type=StepType.BRONZE,\n",
        "        ...     estimated_duration=10.5,\n",
        "        ...     metadata={\"source\": \"kafka\", \"partition_count\": 4}\n",
        "        ... )\n",
        "    \"\"\"\n",
        "\n",
        "    name: str\n",
        "    step_type: StepType\n",
        "    dependencies: set[str] = field(default_factory=set)\n",
        "    dependents: set[str] = field(default_factory=set)\n",
        "    execution_group: int = 0\n",
        "    estimated_duration: float = 0.0\n",
        "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "class DependencyGraph:\n",
        "    \"\"\"Represents the dependency graph of a pipeline.\n",
        "\n",
        "    This class provides efficient operations for dependency analysis,\n",
        "    cycle detection, and execution planning. It maintains both forward\n",
        "    and reverse adjacency lists for efficient traversal in both directions.\n",
        "\n",
        "    **Key Operations:**\n",
        "        - Add nodes and dependencies\n",
        "        - Detect circular dependencies\n",
        "        - Perform topological sort for execution order\n",
        "        - Validate graph structure\n",
        "\n",
        "    Attributes:\n",
        "        nodes: Dictionary mapping step names to StepNode instances.\n",
        "        _adjacency_list: Forward adjacency list for dependency traversal.\n",
        "        _reverse_adjacency_list: Reverse adjacency list for dependent traversal.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.dependencies.graph import (\n",
        "        ...     DependencyGraph,\n",
        "        ...     StepNode,\n",
        "        ...     StepType\n",
        "        ... )\n",
        "        >>>\n",
        "        >>> graph = DependencyGraph()\n",
        "        >>> graph.add_node(StepNode(\"bronze\", StepType.BRONZE))\n",
        "        >>> graph.add_node(StepNode(\"silver\", StepType.SILVER))\n",
        "        >>> graph.add_dependency(\"silver\", \"bronze\")\n",
        "        >>> execution_order = graph.topological_sort()\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initialize an empty dependency graph.\"\"\"\n",
        "        self.nodes: Dict[str, StepNode] = {}\n",
        "        self._adjacency_list: Dict[str, set[str]] = defaultdict(set)\n",
        "        self._reverse_adjacency_list: Dict[str, set[str]] = defaultdict(set)\n",
        "\n",
        "    def add_node(self, node: StepNode) -> None:\n",
        "        \"\"\"Add a node to the dependency graph.\n",
        "\n",
        "        Adds a StepNode to the graph and initializes its adjacency list entries.\n",
        "        If a node with the same name already exists, it will be replaced.\n",
        "\n",
        "        Args:\n",
        "            node: StepNode instance to add to the graph.\n",
        "\n",
        "        Example:\n",
        "            >>> graph = DependencyGraph()\n",
        "            >>> node = StepNode(\"bronze_step\", StepType.BRONZE)\n",
        "            >>> graph.add_node(node)\n",
        "        \"\"\"\n",
        "        self.nodes[node.name] = node\n",
        "        self._adjacency_list[node.name] = set()\n",
        "        self._reverse_adjacency_list[node.name] = set()\n",
        "\n",
        "    def add_dependency(self, from_step: str, to_step: str) -> None:\n",
        "        \"\"\"Add a dependency from one step to another.\n",
        "\n",
        "        Creates a dependency relationship where `from_step` depends on `to_step`.\n",
        "        This means `to_step` must complete before `from_step` can execute.\n",
        "\n",
        "        Args:\n",
        "            from_step: Name of the step that depends on `to_step`.\n",
        "            to_step: Name of the step that `from_step` depends on.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If either step is not found in the graph.\n",
        "\n",
        "        Example:\n",
        "            >>> graph = DependencyGraph()\n",
        "            >>> graph.add_node(StepNode(\"bronze\", StepType.BRONZE))\n",
        "            >>> graph.add_node(StepNode(\"silver\", StepType.SILVER))\n",
        "            >>> # Silver depends on bronze\n",
        "            >>> graph.add_dependency(\"silver\", \"bronze\")\n",
        "        \"\"\"\n",
        "        if from_step not in self.nodes or to_step not in self.nodes:\n",
        "            raise ValueError(f\"Steps {from_step} or {to_step} not found in graph\")\n",
        "\n",
        "        self._adjacency_list[from_step].add(to_step)\n",
        "        self._reverse_adjacency_list[to_step].add(from_step)\n",
        "\n",
        "        # Update node dependencies\n",
        "        self.nodes[from_step].dependencies.add(to_step)\n",
        "        self.nodes[to_step].dependents.add(from_step)\n",
        "\n",
        "    def get_dependencies(self, step_name: str) -> set[str]:\n",
        "        \"\"\"Get all dependencies for a step.\n",
        "\n",
        "        Returns a copy of the set of step names that the specified step\n",
        "        depends on. These steps must complete before the specified step\n",
        "        can execute.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step to get dependencies for.\n",
        "\n",
        "        Returns:\n",
        "            Set of step names that the specified step depends on. Returns\n",
        "            an empty set if the step is not found in the graph.\n",
        "\n",
        "        Example:\n",
        "            >>> graph = DependencyGraph()\n",
        "            >>> graph.add_node(StepNode(\"bronze\", StepType.BRONZE))\n",
        "            >>> graph.add_node(StepNode(\"silver\", StepType.SILVER))\n",
        "            >>> graph.add_dependency(\"silver\", \"bronze\")\n",
        "            >>> deps = graph.get_dependencies(\"silver\")\n",
        "            >>> print(deps)  # {\"bronze\"}\n",
        "        \"\"\"\n",
        "        return self.nodes.get(\n",
        "            step_name, StepNode(\"\", StepType.BRONZE)\n",
        "        ).dependencies.copy()\n",
        "\n",
        "    def get_dependents(self, step_name: str) -> set[str]:\n",
        "        \"\"\"Get all dependents for a step.\n",
        "\n",
        "        Returns a copy of the set of step names that depend on the specified\n",
        "        step. These steps cannot execute until the specified step completes.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step to get dependents for.\n",
        "\n",
        "        Returns:\n",
        "            Set of step names that depend on the specified step. Returns\n",
        "            an empty set if the step is not found in the graph.\n",
        "\n",
        "        Example:\n",
        "            >>> graph = DependencyGraph()\n",
        "            >>> graph.add_node(StepNode(\"bronze\", StepType.BRONZE))\n",
        "            >>> graph.add_node(StepNode(\"silver\", StepType.SILVER))\n",
        "            >>> graph.add_dependency(\"silver\", \"bronze\")\n",
        "            >>> dependents = graph.get_dependents(\"bronze\")\n",
        "            >>> print(dependents)  # {\"silver\"}\n",
        "        \"\"\"\n",
        "        return self.nodes.get(\n",
        "            step_name, StepNode(\"\", StepType.BRONZE)\n",
        "        ).dependents.copy()\n",
        "\n",
        "    def detect_cycles(self) -> list[list[str]]:\n",
        "        \"\"\"Detect cycles in the dependency graph using DFS.\n",
        "\n",
        "        Detects all circular dependencies in the graph using depth-first search.\n",
        "        A cycle indicates that there's a circular dependency that would prevent\n",
        "        execution (e.g., A depends on B, B depends on A).\n",
        "\n",
        "        Returns:\n",
        "            List of cycles, where each cycle is a list of step names forming\n",
        "            a circular dependency. Returns an empty list if no cycles are found.\n",
        "\n",
        "        Example:\n",
        "            >>> graph = DependencyGraph()\n",
        "            >>> graph.add_node(StepNode(\"step_a\", StepType.BRONZE))\n",
        "            >>> graph.add_node(StepNode(\"step_b\", StepType.SILVER))\n",
        "            >>> graph.add_dependency(\"step_a\", \"step_b\")\n",
        "            >>> graph.add_dependency(\"step_b\", \"step_a\")  # Creates cycle\n",
        "            >>> cycles = graph.detect_cycles()\n",
        "            >>> print(cycles)  # [[\"step_a\", \"step_b\", \"step_a\"]]\n",
        "        \"\"\"\n",
        "        visited = set()\n",
        "        rec_stack = set()\n",
        "        cycles = []\n",
        "\n",
        "        def dfs(node: str, path: list[str]) -> None:\n",
        "            if node in rec_stack:\n",
        "                # Found a cycle\n",
        "                cycle_start = path.index(node)\n",
        "                cycle = path[cycle_start:] + [node]\n",
        "                cycles.append(cycle)\n",
        "                return\n",
        "\n",
        "            if node in visited:\n",
        "                return\n",
        "\n",
        "            visited.add(node)\n",
        "            rec_stack.add(node)\n",
        "            path.append(node)\n",
        "\n",
        "            for neighbor in self._adjacency_list[node]:\n",
        "                dfs(neighbor, path)\n",
        "\n",
        "            rec_stack.remove(node)\n",
        "            path.pop()\n",
        "\n",
        "        for node in self.nodes:\n",
        "            if node not in visited:\n",
        "                dfs(node, [])\n",
        "\n",
        "        return cycles\n",
        "\n",
        "    def topological_sort(\n",
        "        self, creation_order: Optional[Dict[str, int]] = None\n",
        "    ) -> list[str]:\n",
        "        \"\"\"Perform topological sort of the dependency graph.\n",
        "\n",
        "        Returns nodes in an order such that all dependencies come before their\n",
        "        dependents. This provides a valid execution order for the pipeline steps.\n",
        "\n",
        "        **Algorithm:**\n",
        "            Uses Kahn's algorithm with in-degree counting. Steps with no\n",
        "            dependencies (in-degree 0) are processed first, then their dependents\n",
        "            are processed when all their dependencies are satisfied.\n",
        "\n",
        "            **Explicit dependencies (e.g., source_silvers) always override creation order.**\n",
        "            When multiple nodes have the same in-degree (no dependencies or same\n",
        "            dependency level), creation_order is used as a tie-breaker to ensure\n",
        "            deterministic ordering based on when steps were added to the pipeline.\n",
        "\n",
        "        Args:\n",
        "            creation_order: Optional dictionary mapping step names to creation order\n",
        "                (lower number = created earlier). Used as tie-breaker for deterministic\n",
        "                ordering when steps have no explicit dependencies. Explicit dependencies\n",
        "                (via source_silvers, source_bronze, etc.) always take precedence.\n",
        "\n",
        "        Returns:\n",
        "            List of step names in topological order. If there are cycles in\n",
        "            the graph, the result may be incomplete (some steps may be missing).\n",
        "\n",
        "        Raises:\n",
        "            RuntimeError: If cycles are detected (topological sort is not\n",
        "                possible for cyclic graphs).\n",
        "\n",
        "        Example:\n",
        "            >>> graph = DependencyGraph()\n",
        "            >>> graph.add_node(StepNode(\"bronze\", StepType.BRONZE))\n",
        "            >>> graph.add_node(StepNode(\"silver\", StepType.SILVER))\n",
        "            >>> graph.add_node(StepNode(\"gold\", StepType.GOLD))\n",
        "            >>> graph.add_dependency(\"silver\", \"bronze\")\n",
        "            >>> graph.add_dependency(\"gold\", \"silver\")\n",
        "            >>> order = graph.topological_sort()\n",
        "            >>> print(order)  # [\"bronze\", \"silver\", \"gold\"]\n",
        "        \"\"\"\n",
        "        in_degree = dict.fromkeys(self.nodes, 0)\n",
        "\n",
        "        # Calculate in-degrees using reverse adjacency\n",
        "        # If A depends on B, then B->A edge exists in reverse list\n",
        "        for node in self.nodes:\n",
        "            for dependent in self._reverse_adjacency_list[node]:\n",
        "                in_degree[dependent] += 1\n",
        "\n",
        "        # Helper function to get creation order for sorting\n",
        "        def get_sort_key(node_name: str) -> tuple[int, int]:\n",
        "            \"\"\"Return sort key: (in_degree, creation_order).\n",
        "\n",
        "            Lower creation_order (earlier created) comes first.\n",
        "            If creation_order not available, use a large number to sort to end.\n",
        "            \"\"\"\n",
        "            creation_ord: int = (\n",
        "                creation_order.get(node_name, 2**31 - 1)\n",
        "                if creation_order\n",
        "                else 2**31 - 1\n",
        "            )\n",
        "            return (in_degree[node_name], creation_ord)\n",
        "\n",
        "        # Find nodes with no incoming edges (no dependencies)\n",
        "        # Sort by creation order for deterministic ordering\n",
        "        ready_nodes = [node for node, degree in in_degree.items() if degree == 0]\n",
        "        if creation_order:\n",
        "            ready_nodes.sort(key=get_sort_key)\n",
        "        queue = deque(ready_nodes)\n",
        "        result = []\n",
        "\n",
        "        while queue:\n",
        "            node = queue.popleft()\n",
        "            result.append(node)\n",
        "\n",
        "            # Process nodes that depend on this one\n",
        "            for dependent in self._reverse_adjacency_list[node]:\n",
        "                in_degree[dependent] -= 1\n",
        "                if in_degree[dependent] == 0:\n",
        "                    queue.append(dependent)\n",
        "                    # Re-sort queue to maintain creation order when adding new nodes\n",
        "                    # Convert to list, sort, convert back to deque\n",
        "                    if creation_order and len(queue) > 1:\n",
        "                        queue_list = list(queue)\n",
        "                        queue_list.sort(key=get_sort_key)\n",
        "                        queue = deque(queue_list)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def validate(self) -> list[str]:\n",
        "        \"\"\"Validate the dependency graph and return any issues.\n",
        "\n",
        "        Checks the graph for common issues including:\n",
        "        - Circular dependencies (cycles)\n",
        "        - Missing dependencies (steps that reference non-existent steps)\n",
        "\n",
        "        Returns:\n",
        "            List of validation issue messages. Returns an empty list if the\n",
        "            graph is valid. Each message describes a specific issue found.\n",
        "\n",
        "        Example:\n",
        "            >>> graph = DependencyGraph()\n",
        "            >>> graph.add_node(StepNode(\"step_a\", StepType.BRONZE))\n",
        "            >>> graph.add_node(StepNode(\"step_b\", StepType.SILVER))\n",
        "            >>> # Add invalid dependency\n",
        "            >>> graph.nodes[\"step_b\"].dependencies.add(\"missing_step\")\n",
        "            >>> issues = graph.validate()\n",
        "            >>> print(issues)  # [\"Node step_b depends on missing node missing_step\"]\n",
        "        \"\"\"\n",
        "        issues = []\n",
        "\n",
        "        # Check for cycles\n",
        "        cycles = self.detect_cycles()\n",
        "        if cycles:\n",
        "            for cycle in cycles:\n",
        "                issues.append(f\"Circular dependency detected: {' -> '.join(cycle)}\")\n",
        "\n",
        "        # Check for missing dependencies\n",
        "        for node_name, node in self.nodes.items():\n",
        "            for dep in node.dependencies:\n",
        "                if dep not in self.nodes:\n",
        "                    issues.append(f\"Node {node_name} depends on missing node {dep}\")\n",
        "\n",
        "        return issues\n",
        "\n",
        "    def get_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get statistics about the dependency graph.\n",
        "\n",
        "        Calculates and returns various statistics about the graph structure,\n",
        "        including node counts, edge counts, type distribution, and cycle\n",
        "        detection.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing statistics with the following keys:\n",
        "                - `total_nodes`: Total number of nodes in the graph\n",
        "                - `total_edges`: Total number of dependency edges\n",
        "                - `type_counts`: Dictionary mapping step types to counts\n",
        "                - `average_dependencies`: Average number of dependencies per node\n",
        "                - `has_cycles`: Boolean indicating if cycles are detected\n",
        "\n",
        "        Example:\n",
        "            >>> graph = DependencyGraph()\n",
        "            >>> graph.add_node(StepNode(\"bronze\", StepType.BRONZE))\n",
        "            >>> graph.add_node(StepNode(\"silver\", StepType.SILVER))\n",
        "            >>> stats = graph.get_stats()\n",
        "            >>> print(f\"Total nodes: {stats['total_nodes']}\")  # 2\n",
        "            >>> print(f\"Has cycles: {stats['has_cycles']}\")  # False\n",
        "        \"\"\"\n",
        "        total_nodes = len(self.nodes)\n",
        "        total_edges = sum(len(deps) for deps in self._adjacency_list.values())\n",
        "\n",
        "        # Count by step type\n",
        "        type_counts: Dict[str, int] = defaultdict(int)\n",
        "        for node in self.nodes.values():\n",
        "            type_counts[node.step_type.value] += 1\n",
        "\n",
        "        # Calculate average dependencies\n",
        "        avg_dependencies = total_edges / total_nodes if total_nodes > 0 else 0\n",
        "\n",
        "        return {\n",
        "            \"total_nodes\": total_nodes,\n",
        "            \"total_edges\": total_edges,\n",
        "            \"type_counts\": dict(type_counts),\n",
        "            \"average_dependencies\": avg_dependencies,\n",
        "            \"has_cycles\": len(self.detect_cycles()) > 0,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.dependencies.analyzer (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.dependencies\n",
        "\n",
        "\"\"\"\n",
        "Unified dependency analyzer for the framework pipelines.\n",
        "\n",
        "This module re-exports the base DependencyAnalyzer which works with Spark steps\n",
        "via protocol-based typing.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "# Re-export from base - the base analyzer uses protocols so it works with Spark steps\n",
        "# from .dependencies import (  # Removed: defined in notebook cells above\n",
        "    # AnalysisStrategy,\n",
        "    # DependencyAnalysisResult,\n",
        "    # DependencyAnalyzer,\n",
        "    # DependencyError,\n",
        "    # DependencyGraph,\n",
        "    # StepNode,\n",
        "    # StepType,\n",
        "# )\n",
        "\n",
        "# Keep for backward compatibility - the base analyzer works with any step type via protocols\n",
        "__all__ = [\n",
        "    \"DependencyAnalyzer\",\n",
        "    \"DependencyAnalysisResult\",\n",
        "    \"AnalysisStrategy\",\n",
        "    \"DependencyGraph\",\n",
        "    \"StepNode\",\n",
        "    \"StepType\",\n",
        "    \"DependencyError\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.dependencies.exceptions (pipeline_builder)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Dependency analysis exceptions for the framework.\n",
        "\n",
        "This module defines exceptions specific to dependency analysis operations.\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Optional\n",
        "\n",
        "class DependencyError(Exception):\n",
        "    \"\"\"Base exception for dependency-related errors.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, step_name: Optional[str] = None):\n",
        "        super().__init__(message)\n",
        "        self.step_name = step_name\n",
        "\n",
        "class DependencyAnalysisError(DependencyError):\n",
        "    \"\"\"Raised when dependency analysis fails.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, analysis_step: Optional[str] = None):\n",
        "        super().__init__(message, analysis_step)\n",
        "        self.analysis_step = analysis_step\n",
        "\n",
        "class CircularDependencyError(DependencyError):\n",
        "    \"\"\"Raised when circular dependencies are detected.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, cycle: List[str]):\n",
        "        super().__init__(message)\n",
        "        self.cycle = cycle\n",
        "\n",
        "class InvalidDependencyError(DependencyError):\n",
        "    \"\"\"Raised when invalid dependencies are detected.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, invalid_dependencies: List[str]):\n",
        "        super().__init__(message)\n",
        "        self.invalid_dependencies = invalid_dependencies\n",
        "\n",
        "class DependencyConflictError(DependencyError):\n",
        "    \"\"\"Raised when dependency conflicts are detected.\"\"\"\n",
        "\n",
        "    def __init__(self, message: str, conflicting_steps: List[str]):\n",
        "        super().__init__(message)\n",
        "        self.conflicting_steps = conflicting_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.models.enums (pipeline_builder)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Enums for the Pipeline Builder models.\n",
        "\n",
        "This module provides enumeration classes for pipeline phases, execution modes,\n",
        "write modes, and validation results. These enums ensure type safety and\n",
        "provide clear constants for use throughout the pipeline system.\n",
        "\n",
        "Key Components:\n",
        "    - **PipelinePhase**: Medallion Architecture layers (BRONZE, SILVER, GOLD)\n",
        "    - **ExecutionMode**: Pipeline execution modes (INITIAL, INCREMENTAL, etc.)\n",
        "    - **WriteMode**: Data write modes (OVERWRITE, APPEND)\n",
        "    - **ValidationResult**: Validation outcomes (PASSED, FAILED, WARNING)\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.models.enums import (\n",
        "    ...     PipelinePhase,\n",
        "    ...     ExecutionMode,\n",
        "    ...     WriteMode,\n",
        "    ...     ValidationResult\n",
        "    ... )\n",
        "    >>>\n",
        "    >>> # Use pipeline phase\n",
        "    >>> phase = PipelinePhase.BRONZE\n",
        "    >>> print(phase.value)  # \"bronze\"\n",
        "    >>>\n",
        "    >>> # Use execution mode\n",
        "    >>> mode = ExecutionMode.INITIAL\n",
        "    >>> print(mode.value)  # \"initial\"\n",
        "\"\"\"\n",
        "\n",
        "from enum import Enum\n",
        "\n",
        "class PipelinePhase(Enum):\n",
        "    \"\"\"Enumeration of pipeline phases.\n",
        "\n",
        "    Represents the three layers of the Medallion Architecture:\n",
        "    - BRONZE: Raw data ingestion and validation layer\n",
        "    - SILVER: Cleaned and enriched data layer\n",
        "    - GOLD: Business-ready analytics and reporting layer\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.enums import PipelinePhase\n",
        "        >>> phase = PipelinePhase.BRONZE\n",
        "        >>> print(phase.value)  # \"bronze\"\n",
        "    \"\"\"\n",
        "\n",
        "    BRONZE = \"bronze\"\n",
        "    SILVER = \"silver\"\n",
        "    GOLD = \"gold\"\n",
        "\n",
        "class ExecutionMode(Enum):\n",
        "    \"\"\"Enumeration of execution modes.\n",
        "\n",
        "    Defines how a pipeline should be executed:\n",
        "    - INITIAL: First-time execution with full data processing\n",
        "    - INCREMENTAL: Process only new data based on watermark columns\n",
        "    - FULL_REFRESH: Reprocess all data, overwriting existing results\n",
        "    - VALIDATION_ONLY: Validate data without writing results\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.enums import ExecutionMode\n",
        "        >>> mode = ExecutionMode.INCREMENTAL\n",
        "        >>> print(mode.value)  # \"incremental\"\n",
        "    \"\"\"\n",
        "\n",
        "    INITIAL = \"initial\"\n",
        "    INCREMENTAL = \"incremental\"\n",
        "    FULL_REFRESH = \"full_refresh\"\n",
        "    VALIDATION_ONLY = \"validation_only\"\n",
        "\n",
        "class WriteMode(Enum):\n",
        "    \"\"\"Enumeration of write modes.\n",
        "\n",
        "    Defines how data should be written to tables:\n",
        "    - OVERWRITE: Replace all existing data in the table\n",
        "    - APPEND: Add new data to existing table data\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.enums import WriteMode\n",
        "        >>> mode = WriteMode.OVERWRITE\n",
        "        >>> print(mode.value)  # \"overwrite\"\n",
        "    \"\"\"\n",
        "\n",
        "    OVERWRITE = \"overwrite\"\n",
        "    APPEND = \"append\"\n",
        "\n",
        "class ValidationResult(Enum):\n",
        "    \"\"\"Enumeration of validation results.\n",
        "\n",
        "    Represents the outcome of data validation:\n",
        "    - PASSED: Validation succeeded, data meets quality requirements\n",
        "    - FAILED: Validation failed, data does not meet quality requirements\n",
        "    - WARNING: Validation passed but with warnings (e.g., low validation rate)\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.enums import ValidationResult\n",
        "        >>> result = ValidationResult.PASSED\n",
        "        >>> print(result.value)  # \"passed\"\n",
        "    \"\"\"\n",
        "\n",
        "    PASSED = \"passed\"\n",
        "    FAILED = \"failed\"\n",
        "    WARNING = \"warning\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.models.exceptions (pipeline_builder)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Custom exceptions for the Pipeline Builder models.\n",
        "\n",
        "This module provides custom exception classes for pipeline configuration\n",
        "and execution errors. These exceptions provide clearer error semantics\n",
        "than generic Python exceptions.\n",
        "\n",
        "Key Components:\n",
        "    - **PipelineConfigurationError**: Raised when pipeline configuration\n",
        "      is invalid (e.g., missing required fields, invalid values)\n",
        "    - **PipelineExecutionError**: Raised when pipeline execution fails\n",
        "      (e.g., step execution errors, validation failures)\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.models.exceptions import (\n",
        "    ...     PipelineConfigurationError,\n",
        "    ...     PipelineExecutionError\n",
        "    ... )\n",
        "    >>>\n",
        "    >>> # Raise configuration error\n",
        "    >>> if not schema:\n",
        "    ...     raise PipelineConfigurationError(\"Schema name is required\")\n",
        "    >>>\n",
        "    >>> # Raise execution error\n",
        "    >>> if step_failed:\n",
        "    ...     raise PipelineExecutionError(\"Step execution failed\")\n",
        "\"\"\"\n",
        "\n",
        "class PipelineConfigurationError(ValueError):\n",
        "    \"\"\"Raised when pipeline configuration is invalid.\n",
        "\n",
        "    This exception is raised when pipeline configuration objects (e.g.,\n",
        "    PipelineConfig, step configurations) are invalid. It indicates a\n",
        "    problem with the configuration itself, not with execution.\n",
        "\n",
        "    Common causes:\n",
        "        - Missing required fields\n",
        "        - Invalid field values (e.g., negative thresholds)\n",
        "        - Inconsistent configuration (e.g., invalid schema name)\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.exceptions import PipelineConfigurationError\n",
        "        >>> if not schema:\n",
        "        ...     raise PipelineConfigurationError(\"Schema name is required\")\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "class PipelineExecutionError(RuntimeError):\n",
        "    \"\"\"Raised when pipeline execution fails.\n",
        "\n",
        "    This exception is raised when pipeline execution encounters an error\n",
        "    during runtime. It indicates a problem with execution, not with\n",
        "    configuration.\n",
        "\n",
        "    Common causes:\n",
        "        - Step execution failures\n",
        "        - Data validation failures\n",
        "        - Write operation failures\n",
        "        - Resource constraints (memory, disk space)\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.exceptions import PipelineExecutionError\n",
        "        >>> if validation_rate < threshold:\n",
        "        ...     raise PipelineExecutionError(\n",
        "        ...         f\"Validation rate {validation_rate}% below threshold {threshold}%\"\n",
        "        ...     )\n",
        "    \"\"\"\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.storage.schema_utils (pipeline_builder)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Schema utility functions.\n",
        "\n",
        "This module provides utility functions for schema operations that are used\n",
        "by both execution and storage modules.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Optional\n",
        "\n",
        "def get_existing_schema_safe(spark: Any, table_name: str) -> Optional[Any]:\n",
        "    \"\"\"\n",
        "    Safely get the schema of an existing table.\n",
        "\n",
        "    Tries multiple methods to get the schema:\n",
        "    1. Direct schema from spark.table()\n",
        "    2. If empty schema (catalog sync issue), try DESCRIBE TABLE\n",
        "    3. If still empty, try reading a sample of data to infer schema\n",
        "\n",
        "    Args:\n",
        "        spark: Spark session\n",
        "        table_name: Fully qualified table name\n",
        "\n",
        "    Returns:\n",
        "        StructType schema if table exists and schema is readable (may be empty struct<>), None if table doesn't exist or schema can't be read\n",
        "    \"\"\"\n",
        "    try:\n",
        "        table_df = spark.table(table_name)\n",
        "        schema = table_df.schema\n",
        "\n",
        "        # If schema is empty (catalog sync issue), try DESCRIBE TABLE as fallback\n",
        "        if not schema.fields or len(schema.fields) == 0:\n",
        "            try:\n",
        "                # Try DESCRIBE TABLE to get schema information\n",
        "                describe_df = spark.sql(f\"DESCRIBE TABLE {table_name}\")\n",
        "                describe_rows = describe_df.collect()\n",
        "\n",
        "                # If DESCRIBE returns rows with column info, try to read schema from data\n",
        "                if describe_rows and len(describe_rows) > 0:\n",
        "                    # Try reading a sample row to infer schema\n",
        "                    try:\n",
        "                        sample_df = spark.sql(f\"SELECT * FROM {table_name} LIMIT 1\")\n",
        "                        inferred_schema = sample_df.schema\n",
        "                        if inferred_schema.fields and len(inferred_schema.fields) > 0:\n",
        "                            return inferred_schema\n",
        "                    except Exception:\n",
        "                        pass\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Return schema even if empty (struct<>) - caller will handle empty schemas specially\n",
        "        return schema\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "def schemas_match(existing_schema: Any, output_schema: Any) -> tuple[bool, list[str]]:\n",
        "    \"\"\"\n",
        "    Compare two schemas and determine if they match exactly.\n",
        "\n",
        "    Args:\n",
        "        existing_schema: Schema of the existing table\n",
        "        output_schema: Schema of the output DataFrame\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (matches: bool, differences: list[str])\n",
        "        differences contains descriptions of any mismatches\n",
        "    \"\"\"\n",
        "    differences = []\n",
        "\n",
        "    # Extract field dictionaries\n",
        "    existing_fields = (\n",
        "        {f.name: f for f in existing_schema.fields} if existing_schema.fields else {}\n",
        "    )\n",
        "    output_fields = (\n",
        "        {f.name: f for f in output_schema.fields} if output_schema.fields else {}\n",
        "    )\n",
        "\n",
        "    existing_columns = set(existing_fields.keys())\n",
        "    output_columns = set(output_fields.keys())\n",
        "\n",
        "    # Check for missing columns in output\n",
        "    missing_in_output = existing_columns - output_columns\n",
        "    if missing_in_output:\n",
        "        differences.append(f\"Missing columns in output: {sorted(missing_in_output)}\")\n",
        "\n",
        "    # Check for new columns in output\n",
        "    new_in_output = output_columns - existing_columns\n",
        "    if new_in_output:\n",
        "        differences.append(\n",
        "            f\"New columns in output (not in existing table): {sorted(new_in_output)}\"\n",
        "        )\n",
        "\n",
        "    # Check for type mismatches and nullable changes in common columns\n",
        "    common_columns = existing_columns & output_columns\n",
        "    type_mismatches = []\n",
        "    nullable_changes = []\n",
        "    for col in common_columns:\n",
        "        existing_field = existing_fields[col]\n",
        "        output_field = output_fields[col]\n",
        "\n",
        "        # Check type mismatch\n",
        "        if existing_field.dataType != output_field.dataType:\n",
        "            type_mismatches.append(\n",
        "                f\"{col}: existing={existing_field.dataType}, \"\n",
        "                f\"output={output_field.dataType}\"\n",
        "            )\n",
        "\n",
        "        # Check nullable changes (nullable -> non-nullable is stricter, non-nullable -> nullable is more lenient)\n",
        "        existing_nullable = getattr(existing_field, \"nullable\", True)\n",
        "        output_nullable = getattr(output_field, \"nullable\", True)\n",
        "        if existing_nullable != output_nullable:\n",
        "            if not existing_nullable and output_nullable:\n",
        "                # Existing is non-nullable, output is nullable - this is usually OK (more lenient)\n",
        "                nullable_changes.append(\n",
        "                    f\"{col}: nullable changed from False to True (more lenient - usually OK)\"\n",
        "                )\n",
        "            else:\n",
        "                # Existing is nullable, output is non-nullable - this is stricter and may cause issues\n",
        "                nullable_changes.append(\n",
        "                    f\"{col}: nullable changed from True to False (stricter - may cause issues if data has nulls)\"\n",
        "                )\n",
        "\n",
        "    if type_mismatches:\n",
        "        differences.append(f\"Type mismatches: {', '.join(type_mismatches)}\")\n",
        "\n",
        "    if nullable_changes:\n",
        "        # Note nullable changes but don't fail validation for them (Delta Lake handles this)\n",
        "        differences.append(\n",
        "            f\"Nullable changes (informational): {', '.join(nullable_changes)}\"\n",
        "        )\n",
        "\n",
        "    # Check for column order differences (informational only - order doesn't affect functionality)\n",
        "    existing_order = list(existing_fields.keys())\n",
        "    output_order = list(output_fields.keys())\n",
        "    if (\n",
        "        existing_order != output_order\n",
        "        and common_columns == existing_columns == output_columns\n",
        "    ):\n",
        "        # All columns match, just order is different\n",
        "        differences.append(\n",
        "            f\"Column order differs (informational - order doesn't affect functionality): \"\n",
        "            f\"existing={existing_order}, output={output_order}\"\n",
        "        )\n",
        "\n",
        "    return len(\n",
        "        [d for d in differences if \"informational\" not in d.lower()]\n",
        "    ) == 0, differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.writer.exceptions (pipeline_builder)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "\"\"\"\n",
        "Writer-specific exceptions.\n",
        "\n",
        "This module contains all the custom exceptions used by the writer module,\n",
        "providing clear error handling and debugging information.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "class WriterError(Exception):\n",
        "    \"\"\"\n",
        "    Base exception for all writer-related errors.\n",
        "\n",
        "    Provides a common base class for all writer exceptions with\n",
        "    enhanced error context and suggestions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        context: Optional[Dict[str, Any]] = None,\n",
        "        suggestions: Optional[list[str]] = None,\n",
        "        cause: Optional[Exception] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the writer error.\n",
        "\n",
        "        Args:\n",
        "            message: Error message\n",
        "            context: Additional context information\n",
        "            suggestions: List of suggestions to resolve the error\n",
        "            cause: The underlying exception that caused this error\n",
        "        \"\"\"\n",
        "        super().__init__(message)\n",
        "        self.message = message\n",
        "        self.context = context or {}\n",
        "        self.suggestions = suggestions or []\n",
        "        self.cause = cause\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        \"\"\"Return formatted error message.\"\"\"\n",
        "        msg = self.message\n",
        "        if self.context:\n",
        "            msg += f\"\\nContext: {self.context}\"\n",
        "        if self.suggestions:\n",
        "            msg += f\"\\nSuggestions: {'; '.join(self.suggestions)}\"\n",
        "        return msg\n",
        "\n",
        "class WriterValidationError(WriterError):\n",
        "    \"\"\"\n",
        "    Raised when writer validation fails.\n",
        "\n",
        "    This exception is raised when data validation fails during\n",
        "    the writing process, such as invalid log rows or schema mismatches.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        validation_errors: Optional[list[str]] = None,\n",
        "        context: Optional[Dict[str, Any]] = None,\n",
        "        suggestions: Optional[list[str]] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize validation error.\n",
        "\n",
        "        Args:\n",
        "            message: Error message\n",
        "            validation_errors: List of specific validation errors\n",
        "            context: Additional context information\n",
        "            suggestions: List of suggestions to resolve the error\n",
        "        \"\"\"\n",
        "        super().__init__(message, context, suggestions)\n",
        "        self.validation_errors = validation_errors or []\n",
        "\n",
        "class WriterConfigurationError(WriterError):\n",
        "    \"\"\"\n",
        "    Raised when writer configuration is invalid.\n",
        "\n",
        "    This exception is raised when the WriterConfig contains\n",
        "    invalid values or conflicting settings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        config_errors: Optional[list[str]] = None,\n",
        "        context: Optional[Dict[str, Any]] = None,\n",
        "        suggestions: Optional[list[str]] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize configuration error.\n",
        "\n",
        "        Args:\n",
        "            message: Error message\n",
        "            config_errors: List of specific configuration errors\n",
        "            context: Additional context information\n",
        "            suggestions: List of suggestions to resolve the error\n",
        "        \"\"\"\n",
        "        super().__init__(message, context, suggestions)\n",
        "        self.config_errors = config_errors or []\n",
        "\n",
        "class WriterTableError(WriterError):\n",
        "    \"\"\"\n",
        "    Raised when table operations fail.\n",
        "\n",
        "    This exception is raised when there are issues with Delta table\n",
        "    operations, such as table creation, writing, or schema evolution.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        table_name: Optional[str] = None,\n",
        "        operation: Optional[str] = None,\n",
        "        context: Optional[Dict[str, Any]] = None,\n",
        "        suggestions: Optional[list[str]] = None,\n",
        "        cause: Optional[Exception] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize table error.\n",
        "\n",
        "        Args:\n",
        "            message: Error message\n",
        "            table_name: Name of the table that caused the error\n",
        "            operation: The operation that failed\n",
        "            context: Additional context information\n",
        "            suggestions: List of suggestions to resolve the error\n",
        "            cause: The underlying exception that caused this error\n",
        "        \"\"\"\n",
        "        super().__init__(message, context, suggestions, cause)\n",
        "        self.table_name = table_name\n",
        "        self.operation = operation\n",
        "\n",
        "class WriterPerformanceError(WriterError):\n",
        "    \"\"\"\n",
        "    Raised when performance thresholds are exceeded.\n",
        "\n",
        "    This exception is raised when operations take longer than expected\n",
        "    or consume more resources than configured limits.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        actual_duration: Optional[float] = None,\n",
        "        expected_duration: Optional[float] = None,\n",
        "        actual_memory: Optional[float] = None,\n",
        "        expected_memory: Optional[float] = None,\n",
        "        context: Optional[Dict[str, Any]] = None,\n",
        "        suggestions: Optional[list[str]] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize performance error.\n",
        "\n",
        "        Args:\n",
        "            message: Error message\n",
        "            actual_duration: Actual duration in seconds\n",
        "            expected_duration: Expected duration in seconds\n",
        "            actual_memory: Actual memory usage in MB\n",
        "            expected_memory: Expected memory usage in MB\n",
        "            context: Additional context information\n",
        "            suggestions: List of suggestions to resolve the error\n",
        "        \"\"\"\n",
        "        super().__init__(message, context, suggestions)\n",
        "        self.actual_duration = actual_duration\n",
        "        self.expected_duration = expected_duration\n",
        "        self.actual_memory = actual_memory\n",
        "        self.expected_memory = expected_memory\n",
        "\n",
        "class WriterSchemaError(WriterError):\n",
        "    \"\"\"\n",
        "    Raised when schema operations fail.\n",
        "\n",
        "    This exception is raised when there are issues with schema\n",
        "    validation, evolution, or compatibility.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        schema_errors: Optional[list[str]] = None,\n",
        "        expected_schema: Optional[str] = None,\n",
        "        actual_schema: Optional[str] = None,\n",
        "        context: Optional[Dict[str, Any]] = None,\n",
        "        suggestions: Optional[list[str]] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize schema error.\n",
        "\n",
        "        Args:\n",
        "            message: Error message\n",
        "            schema_errors: List of specific schema errors\n",
        "            expected_schema: Expected schema definition\n",
        "            actual_schema: Actual schema definition\n",
        "            context: Additional context information\n",
        "            suggestions: List of suggestions to resolve the error\n",
        "        \"\"\"\n",
        "        super().__init__(message, context, suggestions)\n",
        "        self.schema_errors = schema_errors or []\n",
        "        self.expected_schema = expected_schema\n",
        "        self.actual_schema = actual_schema\n",
        "\n",
        "class WriterDataQualityError(WriterError):\n",
        "    \"\"\"\n",
        "    Raised when data quality checks fail.\n",
        "\n",
        "    This exception is raised when data quality validation fails,\n",
        "    such as when validation rates are too low or data anomalies are detected.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        message: str,\n",
        "        quality_issues: Optional[list[str]] = None,\n",
        "        validation_rate: Optional[float] = None,\n",
        "        threshold: Optional[float] = None,\n",
        "        context: Optional[Dict[str, Any]] = None,\n",
        "        suggestions: Optional[list[str]] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize data quality error.\n",
        "\n",
        "        Args:\n",
        "            message: Error message\n",
        "            quality_issues: List of specific quality issues\n",
        "            validation_rate: Actual validation rate\n",
        "            threshold: Expected validation threshold\n",
        "            context: Additional context information\n",
        "            suggestions: List of suggestions to resolve the error\n",
        "        \"\"\"\n",
        "        super().__init__(message, context, suggestions)\n",
        "        self.quality_issues = quality_issues or []\n",
        "        self.validation_rate = validation_rate\n",
        "        self.threshold = threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.rules (abstracts)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "from typing import Protocol\n",
        "\n",
        "# Rules Protocol is compatible with ColumnRules (Dict[str, List[Union[str, Column]]])\n",
        "# Any dictionary mapping column names to rule lists satisfies this Protocol.\n",
        "class Rules(Protocol):\n",
        "    \"\"\"\n",
        "    Protocol for validation rules.\n",
        "\n",
        "    This Protocol is satisfied by ColumnRules (Dict[str, List[Union[str, Column]]])\n",
        "    and any dictionary mapping column names to rule lists.\n",
        "    \"\"\"\n",
        "\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.transformer (abstracts)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "from typing import Protocol\n",
        "\n",
        "# Transformer Protocol is compatible with SilverTransformFunction and GoldTransformFunction\n",
        "# Any callable that transforms data satisfies this Protocol.\n",
        "class Transformer(Protocol):\n",
        "    \"\"\"\n",
        "    Protocol for transformation functions.\n",
        "\n",
        "    This Protocol is satisfied by:\n",
        "    - SilverTransformFunction: Callable[[SparkSession, DataFrame, Dict[str, DataFrame]], DataFrame]\n",
        "    - GoldTransformFunction: Callable[[SparkSession, Dict[str, DataFrame]], DataFrame]\n",
        "    - Any callable that transforms data sources\n",
        "    \"\"\"\n",
        "\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.source (abstracts)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "from typing import Protocol\n",
        "\n",
        "# Source Protocol is compatible with DataFrame and any object that can be used as a data source.\n",
        "# DataFrame naturally satisfies this Protocol since it's a structural type.\n",
        "class Source(Protocol):\n",
        "    \"\"\"\n",
        "    Protocol for data sources in the pipeline.\n",
        "\n",
        "    This Protocol is satisfied by DataFrame and any object that can be used\n",
        "    as a data source. DataFrame naturally satisfies this Protocol via duck typing.\n",
        "    \"\"\"\n",
        "\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.reports.run (abstracts)\n",
        "#\n",
        "# Dependencies: None (base module)\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import List, Optional, Protocol\n",
        "\n",
        "class Report(Protocol):\n",
        "    \"\"\"\n",
        "    Protocol for pipeline execution reports.\n",
        "\n",
        "    This Protocol is satisfied by PipelineReport and any object that provides\n",
        "    pipeline execution results and metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    pipeline_id: str\n",
        "    execution_id: str\n",
        "    status: (\n",
        "        str  # or enum - can be accessed via .value for enums or directly for strings\n",
        "    )\n",
        "    start_time: datetime\n",
        "    end_time: Optional[datetime]\n",
        "    duration_seconds: float\n",
        "    errors: List[str]\n",
        "\n",
        "    @property\n",
        "    def success(self) -> bool:\n",
        "        \"\"\"Whether the pipeline executed successfully.\"\"\"\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.runner.base_runner (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.logging, pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Base runner with common runner patterns.\n",
        "\n",
        "This module provides a base BaseRunner class that can be used\n",
        "by all pipeline runner implementations to reduce code duplication.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "# from ..logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from ..models import ExecutionResult, PipelineConfig, StepResult  # Removed: defined in notebook cells above\n",
        "\n",
        "class BaseRunner:\n",
        "    \"\"\"\n",
        "    Base runner with common runner patterns.\n",
        "\n",
        "    This class provides shared runner functionality that can be used\n",
        "    by all pipeline runner implementations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        config: PipelineConfig,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the base runner.\n",
        "\n",
        "        Args:\n",
        "            config: Pipeline configuration\n",
        "            logger: Optional logger instance\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.logger = logger or PipelineLogger()\n",
        "\n",
        "    def _handle_step_error(\n",
        "        self, step: Any, error: Exception, step_type: str = \"step\"\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Handle step execution error with logging.\n",
        "\n",
        "        Args:\n",
        "            step: Step object that failed\n",
        "            error: Exception that occurred\n",
        "            step_type: Type of step (bronze/silver/gold) for logging\n",
        "        \"\"\"\n",
        "        step_name = getattr(step, \"name\", \"unknown\")\n",
        "        self.logger.error(\n",
        "            f\"\u274c {step_type.capitalize()} step '{step_name}' failed: {str(error)}\"\n",
        "        )\n",
        "        self.logger.debug(f\"Error details: {error}\", exc_info=True)\n",
        "\n",
        "    def _collect_step_results(self, results: List[StepResult]) -> ExecutionResult:\n",
        "        \"\"\"\n",
        "        Collect step results into an execution result.\n",
        "\n",
        "        Args:\n",
        "            results: List of step results\n",
        "\n",
        "        Returns:\n",
        "            ExecutionResult with aggregated results\n",
        "        \"\"\"\n",
        "        from datetime import datetime, timezone\n",
        "\n",
        "        # from ..models import ExecutionContext, ExecutionMode, PipelineMetrics  # Removed: defined in notebook cells above\n",
        "\n",
        "        # Aggregate metrics from step results\n",
        "        metrics = PipelineMetrics.from_step_results(results)\n",
        "\n",
        "        # Determine overall status\n",
        "        all_succeeded = all(result.success for result in results)\n",
        "\n",
        "        # Create execution context\n",
        "        context = ExecutionContext(\n",
        "            mode=ExecutionMode.INITIAL,\n",
        "            start_time=datetime.now(timezone.utc),\n",
        "            end_time=datetime.now(timezone.utc),\n",
        "        )\n",
        "\n",
        "        return ExecutionResult(\n",
        "            context=context,\n",
        "            step_results=results,\n",
        "            metrics=metrics,\n",
        "            success=all_succeeded,\n",
        "        )\n",
        "\n",
        "    def _create_pipeline_report(\n",
        "        self,\n",
        "        status: str,\n",
        "        start_time: datetime,\n",
        "        end_time: datetime,\n",
        "        results: Optional[ExecutionResult] = None,\n",
        "        errors: Optional[List[str]] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Create a pipeline execution report.\n",
        "\n",
        "        Args:\n",
        "            status: Pipeline execution status\n",
        "            start_time: Pipeline start time\n",
        "            end_time: Pipeline end time\n",
        "            results: Optional execution results\n",
        "            errors: Optional list of error messages\n",
        "\n",
        "        Returns:\n",
        "            Dictionary representing pipeline report\n",
        "        \"\"\"\n",
        "        duration = (end_time - start_time).total_seconds()\n",
        "\n",
        "        report: Dict[str, Any] = {\n",
        "            \"status\": status,\n",
        "            \"start_time\": start_time,\n",
        "            \"end_time\": end_time,\n",
        "            \"duration_seconds\": duration,\n",
        "        }\n",
        "\n",
        "        if results:\n",
        "            report[\"results\"] = results\n",
        "            report[\"step_count\"] = (\n",
        "                len(results.step_results) if results.step_results else 0\n",
        "            )\n",
        "            report[\"success_count\"] = (\n",
        "                sum(1 for r in results.step_results if r.success)\n",
        "                if results.step_results\n",
        "                else 0\n",
        "            )\n",
        "\n",
        "        if errors:\n",
        "            report[\"errors\"] = errors\n",
        "            report[\"error_count\"] = len(errors)\n",
        "\n",
        "        return report\n",
        "\n",
        "    def _aggregate_step_reports(self, reports: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Aggregate multiple step reports into a single report.\n",
        "\n",
        "        Args:\n",
        "            reports: List of step reports\n",
        "\n",
        "        Returns:\n",
        "            Aggregated report dictionary\n",
        "        \"\"\"\n",
        "        if not reports:\n",
        "            return {\n",
        "                \"status\": \"unknown\",\n",
        "                \"step_count\": 0,\n",
        "                \"success_count\": 0,\n",
        "            }\n",
        "\n",
        "        all_succeeded = all(r.get(\"status\") == \"success\" for r in reports)\n",
        "        status = \"success\" if all_succeeded else \"partial_failure\"\n",
        "\n",
        "        total_duration = sum(r.get(\"duration_seconds\", 0.0) for r in reports)\n",
        "\n",
        "        return {\n",
        "            \"status\": status,\n",
        "            \"step_count\": len(reports),\n",
        "            \"success_count\": sum(1 for r in reports if r.get(\"status\") == \"success\"),\n",
        "            \"total_duration_seconds\": total_duration,\n",
        "            \"step_reports\": reports,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.validation.pipeline_validator (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.logging, pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Base pipeline validator with common validation logic.\n",
        "\n",
        "This module provides a base UnifiedValidator class that can be used\n",
        "by all pipeline builder implementations to validate pipeline configurations.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, List, Optional, Set\n",
        "\n",
        "# from ..logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from ..models import PipelineConfig  # Removed: defined in notebook cells above\n",
        "\n",
        "class UnifiedValidator:\n",
        "    \"\"\"\n",
        "    Base pipeline validator with common validation logic.\n",
        "\n",
        "    This class provides shared validation patterns that can be used\n",
        "    by all pipeline builder implementations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, logger: Optional[PipelineLogger] = None):\n",
        "        \"\"\"\n",
        "        Initialize the pipeline validator.\n",
        "\n",
        "        Args:\n",
        "            logger: Optional logger instance for validation messages\n",
        "        \"\"\"\n",
        "        self.logger = logger or PipelineLogger()\n",
        "\n",
        "    def validate_step_names(\n",
        "        self,\n",
        "        bronze_steps: Dict[str, Any],\n",
        "        silver_steps: Dict[str, Any],\n",
        "        gold_steps: Dict[str, Any],\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate that all step names are unique and valid.\n",
        "\n",
        "        Args:\n",
        "            bronze_steps: Dictionary of bronze steps\n",
        "            silver_steps: Dictionary of silver steps\n",
        "            gold_steps: Dictionary of gold steps\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "        all_step_names: Set[str] = set()\n",
        "\n",
        "        # Check bronze steps\n",
        "        for name in bronze_steps.keys():\n",
        "            if not name or not isinstance(name, str):\n",
        "                errors.append(f\"Invalid bronze step name: {name}\")\n",
        "            elif name in all_step_names:\n",
        "                errors.append(f\"Duplicate step name found: {name}\")\n",
        "            else:\n",
        "                all_step_names.add(name)\n",
        "\n",
        "        # Check silver steps\n",
        "        for name in silver_steps.keys():\n",
        "            if not name or not isinstance(name, str):\n",
        "                errors.append(f\"Invalid silver step name: {name}\")\n",
        "            elif name in all_step_names:\n",
        "                errors.append(f\"Duplicate step name found: {name}\")\n",
        "            else:\n",
        "                all_step_names.add(name)\n",
        "\n",
        "        # Check gold steps\n",
        "        for name in gold_steps.keys():\n",
        "            if not name or not isinstance(name, str):\n",
        "                errors.append(f\"Invalid gold step name: {name}\")\n",
        "            elif name in all_step_names:\n",
        "                errors.append(f\"Duplicate step name found: {name}\")\n",
        "            else:\n",
        "                all_step_names.add(name)\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def validate_bronze_steps(\n",
        "        self,\n",
        "        bronze_steps: Dict[str, Any],\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate bronze steps configuration.\n",
        "\n",
        "        Args:\n",
        "            bronze_steps: Dictionary of bronze steps\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "\n",
        "        for step_name, step in bronze_steps.items():\n",
        "            # Check if step has rules\n",
        "            if not hasattr(step, \"rules\") or not step.rules:\n",
        "                errors.append(f\"Bronze step '{step_name}' missing validation rules\")\n",
        "\n",
        "            # Check if step has name attribute\n",
        "            if not hasattr(step, \"name\") or not step.name:\n",
        "                errors.append(\"Bronze step missing name attribute\")\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def validate_silver_steps(\n",
        "        self,\n",
        "        silver_steps: Dict[str, Any],\n",
        "        bronze_steps: Dict[str, Any],\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate silver steps configuration and dependencies.\n",
        "\n",
        "        Args:\n",
        "            silver_steps: Dictionary of silver steps\n",
        "            bronze_steps: Dictionary of bronze steps\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "\n",
        "        for step_name, step in silver_steps.items():\n",
        "            # Skip validation for validation-only steps (existing=True, transform=None)\n",
        "            existing = getattr(step, \"existing\", False)\n",
        "            transform = getattr(step, \"transform\", None)\n",
        "            if existing and transform is None:\n",
        "                # Validation-only step - only check rules and table_name\n",
        "                if not hasattr(step, \"rules\") or not step.rules:\n",
        "                    errors.append(f\"Silver step '{step_name}' missing validation rules\")\n",
        "                if not hasattr(step, \"table_name\") or not step.table_name:\n",
        "                    errors.append(f\"Silver step '{step_name}' missing table_name\")\n",
        "                continue\n",
        "\n",
        "            # SQL-source steps (sql_source set) have no source_bronze\n",
        "            if getattr(step, \"sql_source\", None) is not None:\n",
        "                if not hasattr(step, \"rules\") or not step.rules:\n",
        "                    errors.append(f\"Silver step '{step_name}' missing validation rules\")\n",
        "                if not hasattr(step, \"table_name\") or not step.table_name:\n",
        "                    errors.append(f\"Silver step '{step_name}' missing table_name\")\n",
        "                continue\n",
        "\n",
        "            # Check if step has source_bronze (for non-validation-only steps)\n",
        "            source_bronze = getattr(step, \"source_bronze\", None)\n",
        "            if not source_bronze:\n",
        "                errors.append(f\"Silver step '{step_name}' missing source_bronze\")\n",
        "\n",
        "            # Check if source_bronze exists in bronze_steps\n",
        "            elif source_bronze not in bronze_steps:\n",
        "                errors.append(\n",
        "                    f\"Silver step '{step_name}' depends on non-existent bronze step '{source_bronze}'\"\n",
        "                )\n",
        "\n",
        "            # Check if step has rules\n",
        "            if not hasattr(step, \"rules\") or not step.rules:\n",
        "                errors.append(f\"Silver step '{step_name}' missing validation rules\")\n",
        "\n",
        "            # Check if step has table_name\n",
        "            if not hasattr(step, \"table_name\") or not step.table_name:\n",
        "                errors.append(f\"Silver step '{step_name}' missing table_name\")\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def validate_gold_steps(\n",
        "        self,\n",
        "        gold_steps: Dict[str, Any],\n",
        "        silver_steps: Dict[str, Any],\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate gold steps configuration and dependencies.\n",
        "\n",
        "        Args:\n",
        "            gold_steps: Dictionary of gold steps\n",
        "            silver_steps: Dictionary of silver steps\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "\n",
        "        for step_name, step in gold_steps.items():\n",
        "            # Check if step has source_silvers\n",
        "            source_silvers = getattr(step, \"source_silvers\", None)\n",
        "            if source_silvers:\n",
        "                if not isinstance(source_silvers, list):\n",
        "                    errors.append(\n",
        "                        f\"Gold step '{step_name}' source_silvers must be a list\"\n",
        "                    )\n",
        "                else:\n",
        "                    for silver_name in source_silvers:\n",
        "                        if silver_name not in silver_steps:\n",
        "                            errors.append(\n",
        "                                f\"Gold step '{step_name}' depends on non-existent silver step '{silver_name}'\"\n",
        "                            )\n",
        "\n",
        "            # Check if step has rules\n",
        "            if not hasattr(step, \"rules\") or not step.rules:\n",
        "                errors.append(f\"Gold step '{step_name}' missing validation rules\")\n",
        "\n",
        "            # Check if step has table_name\n",
        "            if not hasattr(step, \"table_name\") or not step.table_name:\n",
        "                errors.append(f\"Gold step '{step_name}' missing table_name\")\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def validate_dependencies(\n",
        "        self,\n",
        "        bronze_steps: Dict[str, Any],\n",
        "        silver_steps: Dict[str, Any],\n",
        "        gold_steps: Dict[str, Any],\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate step dependencies and detect circular dependencies.\n",
        "\n",
        "        Args:\n",
        "            bronze_steps: Dictionary of bronze steps\n",
        "            silver_steps: Dictionary of silver steps\n",
        "            gold_steps: Dictionary of gold steps\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "\n",
        "        # Build dependency graph\n",
        "        dependencies: Dict[str, List[str]] = {}\n",
        "\n",
        "        # Silver steps depend on bronze steps\n",
        "        for step_name, step in silver_steps.items():\n",
        "            source_bronze = getattr(step, \"source_bronze\", None)\n",
        "            if source_bronze:\n",
        "                dependencies[step_name] = [source_bronze]\n",
        "\n",
        "        # Gold steps depend on silver steps\n",
        "        for step_name, step in gold_steps.items():\n",
        "            source_silvers = getattr(step, \"source_silvers\", None)\n",
        "            if source_silvers and isinstance(source_silvers, list):\n",
        "                dependencies[step_name] = source_silvers\n",
        "\n",
        "        # Check for circular dependencies using DFS\n",
        "        visited: Set[str] = set()\n",
        "        rec_stack: Set[str] = set()\n",
        "\n",
        "        def has_cycle(node: str) -> bool:\n",
        "            \"\"\"Check if there's a cycle starting from node.\"\"\"\n",
        "            visited.add(node)\n",
        "            rec_stack.add(node)\n",
        "\n",
        "            for neighbor in dependencies.get(node, []):\n",
        "                if neighbor not in visited:\n",
        "                    if has_cycle(neighbor):\n",
        "                        return True\n",
        "                elif neighbor in rec_stack:\n",
        "                    # Found a back edge, cycle exists\n",
        "                    return True\n",
        "\n",
        "            rec_stack.remove(node)\n",
        "            return False\n",
        "\n",
        "        # Check all nodes for cycles\n",
        "        all_nodes = set(dependencies.keys())\n",
        "        for node in all_nodes:\n",
        "            if node not in visited:\n",
        "                if has_cycle(node):\n",
        "                    errors.append(\n",
        "                        f\"Circular dependency detected involving step '{node}'\"\n",
        "                    )\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def validate_schema(self, schema: Any) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate schema name format.\n",
        "\n",
        "        Args:\n",
        "            schema: Schema name to validate\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "\n",
        "        if not schema:\n",
        "            errors.append(\"Schema name cannot be empty\")\n",
        "        elif not isinstance(schema, str):\n",
        "            errors.append(\"Schema name must be a string\")\n",
        "        elif not schema.strip():\n",
        "            errors.append(\"Schema name cannot be whitespace only\")\n",
        "        elif len(schema) > 128:  # Reasonable limit\n",
        "            errors.append(\"Schema name is too long (max 128 characters)\")\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def validate_pipeline(\n",
        "        self,\n",
        "        config: PipelineConfig,\n",
        "        bronze_steps: Dict[str, Any],\n",
        "        silver_steps: Dict[str, Any],\n",
        "        gold_steps: Dict[str, Any],\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate entire pipeline configuration.\n",
        "\n",
        "        Args:\n",
        "            config: Pipeline configuration\n",
        "            bronze_steps: Dictionary of bronze steps\n",
        "            silver_steps: Dictionary of silver steps\n",
        "            gold_steps: Dictionary of gold steps\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "\n",
        "        # Validate schema\n",
        "        schema_errors = self.validate_schema(config.schema)\n",
        "        errors.extend(schema_errors)\n",
        "\n",
        "        # Validate step names\n",
        "        name_errors = self.validate_step_names(bronze_steps, silver_steps, gold_steps)\n",
        "        errors.extend(name_errors)\n",
        "\n",
        "        # Validate bronze steps\n",
        "        bronze_errors = self.validate_bronze_steps(bronze_steps)\n",
        "        errors.extend(bronze_errors)\n",
        "\n",
        "        # Validate silver steps\n",
        "        silver_errors = self.validate_silver_steps(silver_steps, bronze_steps)\n",
        "        errors.extend(silver_errors)\n",
        "\n",
        "        # Validate gold steps\n",
        "        gold_errors = self.validate_gold_steps(gold_steps, silver_steps)\n",
        "        errors.extend(gold_errors)\n",
        "\n",
        "        # Validate dependencies\n",
        "        dep_errors = self.validate_dependencies(bronze_steps, silver_steps, gold_steps)\n",
        "        errors.extend(dep_errors)\n",
        "\n",
        "        return errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.validation.step_validator (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"\n",
        "Base step validator with common step validation patterns.\n",
        "\n",
        "This module provides a base StepValidator class that can be used\n",
        "by all pipeline builder implementations to validate individual steps.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, List, Optional\n",
        "\n",
        "# from ..logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "class StepValidator:\n",
        "    \"\"\"\n",
        "    Base step validator with common step validation patterns.\n",
        "\n",
        "    This class provides shared validation patterns that can be used\n",
        "    by all pipeline builder implementations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, logger: Optional[PipelineLogger] = None):\n",
        "        \"\"\"\n",
        "        Initialize the step validator.\n",
        "\n",
        "        Args:\n",
        "            logger: Optional logger instance for validation messages\n",
        "        \"\"\"\n",
        "        self.logger = logger or PipelineLogger()\n",
        "\n",
        "    def validate_step_name(self, name: Any, step_type: str = \"step\") -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate step name format.\n",
        "\n",
        "        Args:\n",
        "            name: Step name to validate (can be any type, will be validated)\n",
        "            step_type: Type of step (bronze/silver/gold) for error messages\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "\n",
        "        if not isinstance(name, str):\n",
        "            errors.append(f\"{step_type.capitalize()} step name must be a string\")\n",
        "        elif not name:\n",
        "            errors.append(f\"{step_type.capitalize()} step name cannot be empty\")\n",
        "        elif not name.strip():\n",
        "            errors.append(\n",
        "                f\"{step_type.capitalize()} step name cannot be whitespace only\"\n",
        "            )\n",
        "        elif len(name) > 128:  # Reasonable limit\n",
        "            errors.append(\n",
        "                f\"{step_type.capitalize()} step name is too long (max 128 characters)\"\n",
        "            )\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def validate_step_rules(self, step: Any, step_type: str = \"step\") -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate that step has rules.\n",
        "\n",
        "        Args:\n",
        "            step: Step object to validate\n",
        "            step_type: Type of step (bronze/silver/gold) for error messages\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "\n",
        "        if not hasattr(step, \"rules\"):\n",
        "            errors.append(f\"{step_type.capitalize()} step missing 'rules' attribute\")\n",
        "        elif not step.rules:\n",
        "            step_name = getattr(step, \"name\", \"unknown\")\n",
        "            errors.append(\n",
        "                f\"{step_type.capitalize()} step '{step_name}' has empty validation rules\"\n",
        "            )\n",
        "        elif not isinstance(step.rules, dict):\n",
        "            step_name = getattr(step, \"name\", \"unknown\")\n",
        "            errors.append(\n",
        "                f\"{step_type.capitalize()} step '{step_name}' rules must be a dictionary\"\n",
        "            )\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def classify_step_type(self, step: Any) -> str:\n",
        "        \"\"\"\n",
        "        Classify step type from step object.\n",
        "\n",
        "        Args:\n",
        "            step: Step object to classify\n",
        "\n",
        "        Returns:\n",
        "            Step type: 'bronze', 'silver', 'gold', or 'unknown'\n",
        "        \"\"\"\n",
        "        # Check if step has type attribute\n",
        "        if hasattr(step, \"type\") and step.type:\n",
        "            step_type = str(step.type).lower()\n",
        "            if step_type in (\"bronze\", \"silver\", \"gold\"):\n",
        "                return step_type\n",
        "\n",
        "        # Determine type from class name\n",
        "        class_name = step.__class__.__name__\n",
        "        if \"Bronze\" in class_name:\n",
        "            return \"bronze\"\n",
        "        elif \"Silver\" in class_name:\n",
        "            return \"silver\"\n",
        "        elif \"Gold\" in class_name:\n",
        "            return \"gold\"\n",
        "\n",
        "        return \"unknown\"\n",
        "\n",
        "    def validate_step_dependencies(\n",
        "        self, step: Any, available_sources: List[str], step_type: str = \"step\"\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate step dependencies exist.\n",
        "\n",
        "        Args:\n",
        "            step: Step object to validate\n",
        "            available_sources: List of available source step names\n",
        "            step_type: Type of step (bronze/silver/gold) for error messages\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "        step_name = getattr(step, \"name\", \"unknown\")\n",
        "\n",
        "        if step_type == \"silver\":\n",
        "            # Silver steps depend on bronze steps\n",
        "            source_bronze = getattr(step, \"source_bronze\", None)\n",
        "            if source_bronze and source_bronze not in available_sources:\n",
        "                errors.append(\n",
        "                    f\"Silver step '{step_name}' references unknown bronze source '{source_bronze}'\"\n",
        "                )\n",
        "        elif step_type == \"gold\":\n",
        "            # Gold steps depend on silver steps\n",
        "            source_silvers = getattr(step, \"source_silvers\", None)\n",
        "            if source_silvers:\n",
        "                if not isinstance(source_silvers, list):\n",
        "                    errors.append(\n",
        "                        f\"Gold step '{step_name}' source_silvers must be a list\"\n",
        "                    )\n",
        "                else:\n",
        "                    for silver_name in source_silvers:\n",
        "                        if silver_name not in available_sources:\n",
        "                            errors.append(\n",
        "                                f\"Gold step '{step_name}' references unknown silver source '{silver_name}'\"\n",
        "                            )\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def validate_step(\n",
        "        self, step: Any, available_sources: Optional[List[str]] = None\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate a single step.\n",
        "\n",
        "        Args:\n",
        "            step: Step object to validate\n",
        "            available_sources: Optional list of available source step names for dependency validation\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "\n",
        "        # Classify step type\n",
        "        step_type = self.classify_step_type(step)\n",
        "\n",
        "        # Validate step name\n",
        "        step_name = getattr(step, \"name\", None)\n",
        "        if step_name:\n",
        "            name_errors = self.validate_step_name(step_name, step_type)\n",
        "            errors.extend(name_errors)\n",
        "        else:\n",
        "            errors.append(f\"{step_type.capitalize()} step missing 'name' attribute\")\n",
        "\n",
        "        # Validate step rules\n",
        "        rules_errors = self.validate_step_rules(step, step_type)\n",
        "        errors.extend(rules_errors)\n",
        "\n",
        "        # Validate dependencies if sources provided\n",
        "        if available_sources is not None:\n",
        "            dep_errors = self.validate_step_dependencies(\n",
        "                step, available_sources, step_type\n",
        "            )\n",
        "            errors.extend(dep_errors)\n",
        "\n",
        "        return errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.logging (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"\n",
        "Simplified logging system for the framework.\n",
        "\n",
        "This module re-exports logging classes from pipeline_builder_base\n",
        "for backward compatibility.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "# Re-export from base for backward compatibility\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "__all__ = [\"PipelineLogger\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.writer.exceptions (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.errors\n",
        "\n",
        "\"\"\"\n",
        "Writer-specific exceptions.\n",
        "\"\"\"\n",
        "\n",
        "# from ..errors import SparkForgeError  # Removed: defined in notebook cells above\n",
        "\n",
        "class WriterError(SparkForgeError):\n",
        "    \"\"\"Base exception for writer errors.\"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "class WriterConfigurationError(WriterError):\n",
        "    \"\"\"Raised when writer configuration is invalid.\"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "class WriterValidationError(WriterError):\n",
        "    \"\"\"Raised when writer validation fails.\"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "class WriterTableError(WriterError):\n",
        "    \"\"\"Raised when table operations fail.\"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "class WriterDataQualityError(WriterError):\n",
        "    \"\"\"Raised when data quality checks fail.\"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "class WriterPerformanceError(WriterError):\n",
        "    \"\"\"Raised when performance issues are detected.\"\"\"\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.steps.manager (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.errors, pipeline_builder_base.validation\n",
        "\n",
        "\"\"\"\n",
        "Step manager for managing step collections.\n",
        "\n",
        "This module provides a StepManager class for managing pipeline step collections\n",
        "with validation and query capabilities.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "# from ..errors import ValidationError  # Removed: defined in notebook cells above\n",
        "# from ..validation import StepValidator  # Removed: defined in notebook cells above\n",
        "\n",
        "class StepManager:\n",
        "    \"\"\"\n",
        "    Manager for pipeline step collections.\n",
        "\n",
        "    This class provides methods for managing step collections with\n",
        "    validation and query capabilities.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initialize the step manager.\"\"\"\n",
        "        self.bronze_steps: Dict[str, Any] = {}\n",
        "        self.silver_steps: Dict[str, Any] = {}\n",
        "        self.gold_steps: Dict[str, Any] = {}\n",
        "        self.validator = StepValidator()\n",
        "\n",
        "    def add_step(self, step: Any, step_type: str) -> None:\n",
        "        \"\"\"\n",
        "        Add a step to the appropriate collection.\n",
        "\n",
        "        Args:\n",
        "            step: Step object to add\n",
        "            step_type: Type of step (bronze/silver/gold)\n",
        "\n",
        "        Raises:\n",
        "            ValidationError: If step is invalid or name already exists\n",
        "        \"\"\"\n",
        "        step_name = getattr(step, \"name\", None)\n",
        "        if not step_name:\n",
        "            raise ValidationError(\n",
        "                f\"{step_type.capitalize()} step missing 'name' attribute\"\n",
        "            )\n",
        "\n",
        "        # Check for duplicate name\n",
        "        step_dict = getattr(self, f\"{step_type}_steps\", {})\n",
        "        if step_name in step_dict:\n",
        "            raise ValidationError(\n",
        "                f\"{step_type.capitalize()} step '{step_name}' already exists\"\n",
        "            )\n",
        "\n",
        "        # Validate step\n",
        "        errors = self.validator.validate_step(step)\n",
        "        if errors:\n",
        "            raise ValidationError(\n",
        "                f\"Invalid {step_type} step '{step_name}': {errors[0]}\",\n",
        "                context={\"step_name\": step_name, \"step_type\": step_type},\n",
        "            )\n",
        "\n",
        "        # Add step\n",
        "        step_dict[step_name] = step\n",
        "\n",
        "    def get_step(self, name: str, step_type: Optional[str] = None) -> Optional[Any]:\n",
        "        \"\"\"\n",
        "        Get a step by name and optional type.\n",
        "\n",
        "        Args:\n",
        "            name: Step name\n",
        "            step_type: Optional step type (bronze/silver/gold). If None, searches all types.\n",
        "\n",
        "        Returns:\n",
        "            Step object if found, None otherwise\n",
        "        \"\"\"\n",
        "        if step_type:\n",
        "            step_dict = getattr(self, f\"{step_type}_steps\", {})\n",
        "            return step_dict.get(name)\n",
        "        else:\n",
        "            # Search all step types\n",
        "            for step_type in [\"bronze\", \"silver\", \"gold\"]:\n",
        "                step_dict = getattr(self, f\"{step_type}_steps\", {})\n",
        "                if name in step_dict:\n",
        "                    return step_dict[name]\n",
        "        return None\n",
        "\n",
        "    def get_all_steps(self) -> Dict[str, Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Get all steps grouped by type.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping step types to step dictionaries\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"bronze\": self.bronze_steps,\n",
        "            \"silver\": self.silver_steps,\n",
        "            \"gold\": self.gold_steps,\n",
        "        }\n",
        "\n",
        "    def get_steps_by_type(self, step_type: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get all steps of a specific type.\n",
        "\n",
        "        Args:\n",
        "            step_type: Type of steps to get (bronze/silver/gold)\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of steps of the specified type\n",
        "        \"\"\"\n",
        "        step_dict = getattr(self, f\"{step_type}_steps\", {})\n",
        "        return step_dict.copy()\n",
        "\n",
        "    def validate_all_steps(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate all steps in the manager.\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if all valid)\n",
        "        \"\"\"\n",
        "        errors: List[str] = []\n",
        "\n",
        "        # Validate bronze steps\n",
        "        for step_name, step in self.bronze_steps.items():\n",
        "            step_errors = self.validator.validate_step(step)\n",
        "            errors.extend([f\"Bronze step '{step_name}': {e}\" for e in step_errors])\n",
        "\n",
        "        # Validate silver steps\n",
        "        bronze_names = list(self.bronze_steps.keys())\n",
        "        for step_name, step in self.silver_steps.items():\n",
        "            step_errors = self.validator.validate_step(\n",
        "                step, available_sources=bronze_names\n",
        "            )\n",
        "            errors.extend([f\"Silver step '{step_name}': {e}\" for e in step_errors])\n",
        "\n",
        "        # Validate gold steps\n",
        "        silver_names = list(self.silver_steps.keys())\n",
        "        for step_name, step in self.gold_steps.items():\n",
        "            step_errors = self.validator.validate_step(\n",
        "                step, available_sources=silver_names\n",
        "            )\n",
        "            errors.extend([f\"Gold step '{step_name}': {e}\" for e in step_errors])\n",
        "\n",
        "        return errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.builder.base_builder (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.errors, pipeline_builder_base.logging, pipeline_builder_base.models, pipeline_builder_base.validation\n",
        "\n",
        "\"\"\"\n",
        "Base pipeline builder with common builder patterns.\n",
        "\n",
        "This module provides a base BasePipelineBuilder class that can be used\n",
        "by all pipeline builder implementations to reduce code duplication.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "# from ..errors import ValidationError  # Removed: defined in notebook cells above\n",
        "# from ..logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from ..models import PipelineConfig  # Removed: defined in notebook cells above\n",
        "# from ..validation import UnifiedValidator, StepValidator  # Removed: defined in notebook cells above\n",
        "\n",
        "class BasePipelineBuilder:\n",
        "    \"\"\"\n",
        "    Base pipeline builder with common builder patterns.\n",
        "\n",
        "    This class provides shared builder functionality that can be used\n",
        "    by all pipeline builder implementations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        config: PipelineConfig,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the base pipeline builder.\n",
        "\n",
        "        Args:\n",
        "            config: Pipeline configuration\n",
        "            logger: Optional logger instance\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.logger = logger or PipelineLogger()\n",
        "        self.validator = UnifiedValidator(self.logger)\n",
        "        self.step_validator = StepValidator(self.logger)\n",
        "\n",
        "        # Step storage - subclasses should initialize these\n",
        "        self.bronze_steps: Dict[str, Any] = {}\n",
        "        self.silver_steps: Dict[str, Any] = {}\n",
        "        self.gold_steps: Dict[str, Any] = {}\n",
        "\n",
        "    def _check_duplicate_step_name(self, name: str, step_type: str) -> None:\n",
        "        \"\"\"\n",
        "        Check if step name already exists and raise error if duplicate.\n",
        "\n",
        "        Args:\n",
        "            name: Step name to check\n",
        "            step_type: Type of step (bronze/silver/gold)\n",
        "\n",
        "        Raises:\n",
        "            ValidationError: If step name already exists\n",
        "        \"\"\"\n",
        "        step_dict = getattr(self, f\"{step_type}_steps\", {})\n",
        "        if name in step_dict:\n",
        "            raise ValidationError(\n",
        "                f\"{step_type.capitalize()} step '{name}' already exists\",\n",
        "                context={\"step_name\": name, \"step_type\": step_type},\n",
        "                suggestions=[\n",
        "                    \"Use a different step name\",\n",
        "                    \"Remove the existing step first\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "    def _validate_step_dependencies(\n",
        "        self,\n",
        "        step: Any,\n",
        "        step_type: str,\n",
        "        available_sources: Optional[Dict[str, Any]] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Validate step dependencies exist.\n",
        "\n",
        "        Args:\n",
        "            step: Step object to validate\n",
        "            step_type: Type of step (bronze/silver/gold)\n",
        "            available_sources: Optional dictionary of available source steps\n",
        "\n",
        "        Raises:\n",
        "            ValidationError: If dependencies are invalid\n",
        "        \"\"\"\n",
        "        if step_type == \"silver\":\n",
        "            source_bronze = getattr(step, \"source_bronze\", None)\n",
        "            if source_bronze:\n",
        "                if available_sources is None:\n",
        "                    available_sources = self.bronze_steps\n",
        "                if source_bronze not in available_sources:\n",
        "                    raise ValidationError(\n",
        "                        f\"Bronze step '{source_bronze}' not found\",\n",
        "                        context={\n",
        "                            \"step_name\": getattr(step, \"name\", \"unknown\"),\n",
        "                            \"step_type\": step_type,\n",
        "                            \"missing_dependency\": source_bronze,\n",
        "                        },\n",
        "                        suggestions=[\n",
        "                            f\"Add bronze step '{source_bronze}' first\",\n",
        "                            f\"Check spelling of '{source_bronze}'\",\n",
        "                        ],\n",
        "                    )\n",
        "        elif step_type == \"gold\":\n",
        "            source_silvers = getattr(step, \"source_silvers\", None)\n",
        "            if source_silvers:\n",
        "                if not isinstance(source_silvers, list):\n",
        "                    raise ValidationError(\n",
        "                        \"Gold step source_silvers must be a list\",\n",
        "                        context={\n",
        "                            \"step_name\": getattr(step, \"name\", \"unknown\"),\n",
        "                            \"step_type\": step_type,\n",
        "                        },\n",
        "                    )\n",
        "                if available_sources is None:\n",
        "                    available_sources = self.silver_steps\n",
        "                for silver_name in source_silvers:\n",
        "                    if silver_name not in available_sources:\n",
        "                        raise ValidationError(\n",
        "                            f\"Silver step '{silver_name}' not found\",\n",
        "                            context={\n",
        "                                \"step_name\": getattr(step, \"name\", \"unknown\"),\n",
        "                                \"step_type\": step_type,\n",
        "                                \"missing_dependency\": silver_name,\n",
        "                            },\n",
        "                            suggestions=[\n",
        "                                f\"Add silver step '{silver_name}' first\",\n",
        "                                f\"Check spelling of '{silver_name}'\",\n",
        "                            ],\n",
        "                        )\n",
        "\n",
        "    def _validate_schema(self, schema: str) -> None:\n",
        "        \"\"\"\n",
        "        Validate schema name format.\n",
        "\n",
        "        Args:\n",
        "            schema: Schema name to validate\n",
        "\n",
        "        Raises:\n",
        "            ValidationError: If schema is invalid\n",
        "        \"\"\"\n",
        "        errors = self.validator.validate_schema(schema)\n",
        "        if errors:\n",
        "            raise ValidationError(\n",
        "                errors[0],\n",
        "                context={\"schema\": schema},\n",
        "                suggestions=[\n",
        "                    \"Schema name must be a non-empty string\",\n",
        "                    \"Schema name must be 128 characters or less\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "    def validate_pipeline(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate entire pipeline configuration.\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid)\n",
        "        \"\"\"\n",
        "        return self.validator.validate_pipeline(\n",
        "            self.config, self.bronze_steps, self.silver_steps, self.gold_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.errors (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.errors\n",
        "\n",
        "\"\"\"\n",
        "Simplified error handling system for the framework.\n",
        "\n",
        "This module re-exports error classes from pipeline_builder_base\n",
        "for backward compatibility.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "# Re-export from base for backward compatibility\n",
        "# from .errors import (  # Removed: defined in notebook cells above\n",
        "    # ConfigurationError,\n",
        "    # DataError,\n",
        "    # ErrorCategory,\n",
        "    # ErrorContext,\n",
        "    # ErrorContextValue,\n",
        "    # ErrorSeverity,\n",
        "    # ErrorSuggestions,\n",
        "    # ExecutionError,\n",
        "    # PerformanceError,\n",
        "    # PipelineValidationError,\n",
        "    # ResourceError,\n",
        "    # SparkForgeError,\n",
        "    # SystemError,\n",
        "    # ValidationError,\n",
        "# )\n",
        "\n",
        "__all__ = [\n",
        "    \"SparkForgeError\",\n",
        "    \"ValidationError\",\n",
        "    \"PipelineValidationError\",\n",
        "    \"ConfigurationError\",\n",
        "    \"ExecutionError\",\n",
        "    \"DataError\",\n",
        "    \"SystemError\",\n",
        "    \"PerformanceError\",\n",
        "    \"ResourceError\",\n",
        "    \"ErrorSeverity\",\n",
        "    \"ErrorCategory\",\n",
        "    \"ErrorContext\",\n",
        "    \"ErrorContextValue\",\n",
        "    \"ErrorSuggestions\",\n",
        "]\n",
        "\n",
        "# Backward compatibility aliases\n",
        "# Note: PipelineValidationError is already imported above, so we don't redefine it here\n",
        "# PipelineValidationError = ValidationError  # Already defined in import\n",
        "PipelineConfigurationError = ConfigurationError\n",
        "PipelineExecutionError = ExecutionError\n",
        "TableOperationError = DataError\n",
        "DependencyError = ValidationError\n",
        "StepError = ExecutionError\n",
        "PipelineError = ExecutionError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.sql_source.models (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.errors\n",
        "\n",
        "\"\"\"\n",
        "SQL source configuration models for pipeline_builder.\n",
        "\n",
        "JdbcSource: read via PySpark spark.read.jdbc() (no extra deps; JDBC driver JAR on classpath).\n",
        "SqlAlchemySource: read via SQLAlchemy + pandas then spark.createDataFrame (optional [sql] extra).\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, Optional\n",
        "# from .errors import ValidationError  # Removed: defined in notebook cells above\n",
        "\n",
        "def _validate_table_or_query(\n",
        "    table: Optional[str],\n",
        "    query: Optional[str],\n",
        "    source_type: str,\n",
        ") -> None:\n",
        "    \"\"\"Require exactly one of table or query.\"\"\"\n",
        "    has_table = table is not None and table.strip() != \"\"\n",
        "    has_query = query is not None and query.strip() != \"\"\n",
        "    if has_table and has_query:\n",
        "        raise ValidationError(\n",
        "            f\"{source_type} requires exactly one of 'table' or 'query'; got both.\"\n",
        "        )\n",
        "    if not has_table and not has_query:\n",
        "        raise ValidationError(\n",
        "            f\"{source_type} requires exactly one of 'table' or 'query'; got neither.\"\n",
        "        )\n",
        "\n",
        "@dataclass\n",
        "class JdbcSource:\n",
        "    \"\"\"\n",
        "    JDBC-backed SQL source for pipeline steps.\n",
        "\n",
        "    Data is read via spark.read.jdbc(). Requires the JDBC driver JAR\n",
        "    for the database to be on the Spark application classpath.\n",
        "\n",
        "    Exactly one of `table` or `query` must be set. For `query`, Spark\n",
        "    expects a subquery alias, e.g. \"(SELECT * FROM t WHERE x > 1) AS q\".\n",
        "    \"\"\"\n",
        "\n",
        "    url: str\n",
        "    properties: Dict[str, str]\n",
        "    table: Optional[str] = None\n",
        "    query: Optional[str] = None\n",
        "    driver: Optional[str] = None\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        if not self.url or not isinstance(self.url, str):\n",
        "            raise ValidationError(\"JdbcSource requires a non-empty 'url'.\")\n",
        "        if not isinstance(self.properties, dict):\n",
        "            raise ValidationError(\"JdbcSource 'properties' must be a dict.\")\n",
        "        _validate_table_or_query(self.table, self.query, \"JdbcSource\")\n",
        "\n",
        "@dataclass\n",
        "class SqlAlchemySource:\n",
        "    \"\"\"\n",
        "    SQLAlchemy-backed SQL source for pipeline steps.\n",
        "\n",
        "    Data is read via SQLAlchemy + pandas (read_sql_table or read_sql)\n",
        "    then spark.createDataFrame(). Requires pip install pipeline_builder[sql].\n",
        "\n",
        "    Exactly one of `table` or `query` must be set. Optionally set `schema`\n",
        "    for table reads (e.g. 'public' for PostgreSQL).\n",
        "    \"\"\"\n",
        "\n",
        "    url: Optional[str] = None\n",
        "    engine: Any = None\n",
        "    table: Optional[str] = None\n",
        "    query: Optional[str] = None\n",
        "    schema: Optional[str] = None\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        has_url = self.url is not None and (\n",
        "            isinstance(self.url, str) and self.url.strip() != \"\"\n",
        "        )\n",
        "        has_engine = self.engine is not None\n",
        "        if has_url and has_engine:\n",
        "            raise ValidationError(\n",
        "                \"SqlAlchemySource requires exactly one of 'url' or 'engine'; got both.\"\n",
        "            )\n",
        "        if not has_url and not has_engine:\n",
        "            raise ValidationError(\n",
        "                \"SqlAlchemySource requires exactly one of 'url' or 'engine'; got neither.\"\n",
        "            )\n",
        "        _validate_table_or_query(self.table, self.query, \"SqlAlchemySource\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.errors.error_handler (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.errors, pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"Error handling utilities for pipeline operations.\n",
        "\n",
        "This module provides centralized error handling with consistent error wrapping\n",
        "and context addition. The ErrorHandler ensures all errors are wrapped in\n",
        "ExecutionError with appropriate context and suggestions.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from contextlib import contextmanager\n",
        "from functools import wraps\n",
        "from typing import Any, Callable, Dict, Generator, List, Optional, TypeVar, Union\n",
        "# from .errors import ExecutionError  # Removed: defined in notebook cells above\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "F = TypeVar(\"F\", bound=Callable[..., Any])\n",
        "ContextType = Union[Optional[Dict[str, Any]], Callable[..., Dict[str, Any]]]\n",
        "SuggestionsType = Union[Optional[List[str]], Callable[..., List[str]]]\n",
        "\n",
        "class ErrorHandler:\n",
        "    \"\"\"Centralized error handler for pipeline operations.\n",
        "\n",
        "    Provides consistent error wrapping and context addition. Ensures all\n",
        "    errors are wrapped in ExecutionError with appropriate context and\n",
        "    suggestions for debugging.\n",
        "\n",
        "    Attributes:\n",
        "        logger: PipelineLogger instance for logging.\n",
        "\n",
        "    Example:\n",
        "        Using as context manager:\n",
        "\n",
        "        >>> from pipeline_builder.errors.error_handler import ErrorHandler\n",
        "        >>>\n",
        "        >>> handler = ErrorHandler()\n",
        "        >>> with handler.handle_errors(\n",
        "        ...     \"table write\",\n",
        "        ...     context={\"table\": \"analytics.events\"},\n",
        "        ...     suggestions=[\"Check table permissions\", \"Verify schema\"]\n",
        "        ... ):\n",
        "        ...     df.write.saveAsTable(\"analytics.events\")\n",
        "\n",
        "        Using as decorator:\n",
        "\n",
        "        >>> @handler.wrap_error(\"data validation\")\n",
        "        >>> def validate_data(df):\n",
        "        ...     # validation logic\n",
        "        ...     pass\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the error handler.\n",
        "\n",
        "        Args:\n",
        "            logger: Optional PipelineLogger instance. If None, creates a\n",
        "                default logger.\n",
        "        \"\"\"\n",
        "        self.logger = logger or PipelineLogger()\n",
        "\n",
        "    @contextmanager\n",
        "    def handle_errors(\n",
        "        self,\n",
        "        operation: str,\n",
        "        context: Optional[Dict[str, Any]] = None,\n",
        "        suggestions: Optional[List[str]] = None,\n",
        "    ) -> Generator[None, None, None]:\n",
        "        \"\"\"Context manager for error handling.\n",
        "\n",
        "        Wraps code in a context manager that catches exceptions and wraps\n",
        "        them in ExecutionError with context and suggestions. ExecutionError\n",
        "        exceptions are re-raised as-is.\n",
        "\n",
        "        Args:\n",
        "            operation: Description of the operation being performed (used in\n",
        "                error messages).\n",
        "            context: Optional dictionary with additional context about the\n",
        "                operation (e.g., table name, step name).\n",
        "            suggestions: Optional list of suggestions for fixing errors.\n",
        "\n",
        "        Yields:\n",
        "            None (context manager yields control to the wrapped code).\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: Wrapped error with context and suggestions.\n",
        "                ExecutionError exceptions are re-raised as-is without wrapping.\n",
        "\n",
        "        Example:\n",
        "            >>> with handler.handle_errors(\n",
        "            ...     \"table write\",\n",
        "            ...     context={\"table\": \"analytics.events\"},\n",
        "            ...     suggestions=[\"Check permissions\", \"Verify schema\"]\n",
        "            ... ):\n",
        "            ...     df.write.saveAsTable(\"analytics.events\")\n",
        "        \"\"\"\n",
        "        try:\n",
        "            yield\n",
        "        except ExecutionError:\n",
        "            # Re-raise ExecutionError as-is (already has context)\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            # Wrap other exceptions\n",
        "            raise ExecutionError(\n",
        "                f\"Error during {operation}: {str(e)}\",\n",
        "                context=context or {},\n",
        "                suggestions=suggestions or [],\n",
        "            ) from e\n",
        "\n",
        "    def wrap_error(\n",
        "        self,\n",
        "        operation: str,\n",
        "        context: ContextType = None,\n",
        "        suggestions: SuggestionsType = None,\n",
        "    ) -> Callable[[F], F]:\n",
        "        \"\"\"Decorator for wrapping function errors.\n",
        "\n",
        "        Decorator that wraps function exceptions in ExecutionError with context\n",
        "        and suggestions. Context and suggestions can be callables that receive\n",
        "        function arguments for dynamic error messages.\n",
        "\n",
        "        Args:\n",
        "            operation: Description of the operation being performed (used in\n",
        "                error messages).\n",
        "            context: Optional dictionary with additional context, or a callable\n",
        "                that receives function args and returns a context dictionary.\n",
        "            suggestions: Optional list of suggestions, or a callable that\n",
        "                receives function args and returns a list of suggestions.\n",
        "\n",
        "        Returns:\n",
        "            Decorator function that wraps the target function.\n",
        "\n",
        "        Example:\n",
        "            >>> @handler.wrap_error(\n",
        "            ...     \"data validation\",\n",
        "            ...     context=lambda df, rules: {\"df_rows\": df.count(), \"rules_count\": len(rules)},\n",
        "            ...     suggestions=[\"Check data quality\", \"Review validation rules\"]\n",
        "            ... )\n",
        "            >>> def validate_data(df, rules):\n",
        "            ...     # validation logic\n",
        "            ...     pass\n",
        "        \"\"\"\n",
        "\n",
        "        def decorator(func: F) -> F:\n",
        "            @wraps(func)\n",
        "            def wrapper(*args: Any, **kwargs: Any) -> Any:\n",
        "                try:\n",
        "                    # Build context if it's a callable\n",
        "                    if callable(context):\n",
        "                        ctx = context(*args, **kwargs)\n",
        "                    else:\n",
        "                        ctx = context or {}\n",
        "\n",
        "                    # Build suggestions if it's a callable\n",
        "                    if callable(suggestions):\n",
        "                        sugg = suggestions(*args, **kwargs)\n",
        "                    else:\n",
        "                        sugg = suggestions or []\n",
        "\n",
        "                    return func(*args, **kwargs)\n",
        "                except ExecutionError:\n",
        "                    # Re-raise ExecutionError as-is\n",
        "                    raise\n",
        "                except Exception as e:\n",
        "                    # Wrap other exceptions\n",
        "                    raise ExecutionError(\n",
        "                        f\"Error during {operation}: {str(e)}\",\n",
        "                        context=ctx,\n",
        "                        suggestions=sugg,\n",
        "                    ) from e\n",
        "\n",
        "            return wrapper  # type: ignore[return-value]\n",
        "\n",
        "        return decorator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.builder.step_classifier (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.dependencies, pipeline_builder_base.dependencies.graph\n",
        "\n",
        "\"\"\"\n",
        "Step classifier utility for identifying and grouping steps.\n",
        "\n",
        "This module provides utilities for classifying steps by type,\n",
        "extracting dependencies, and building dependency graphs.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, List, Set\n",
        "\n",
        "# from ..dependencies import DependencyGraph  # Removed: defined in notebook cells above\n",
        "\n",
        "class StepClassifier:\n",
        "    \"\"\"\n",
        "    Utility class for classifying and analyzing pipeline steps.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def classify_step_type(step: Any) -> str:\n",
        "        \"\"\"\n",
        "        Classify step type from step object.\n",
        "\n",
        "        Args:\n",
        "            step: Step object to classify\n",
        "\n",
        "        Returns:\n",
        "            Step type: 'bronze', 'silver', 'gold', or 'unknown'\n",
        "        \"\"\"\n",
        "        # Check if step has type attribute\n",
        "        if hasattr(step, \"type\") and step.type:\n",
        "            step_type = str(step.type).lower()\n",
        "            if step_type in (\"bronze\", \"silver\", \"gold\"):\n",
        "                return step_type\n",
        "\n",
        "        # Determine type from class name\n",
        "        class_name = step.__class__.__name__\n",
        "        if \"Bronze\" in class_name:\n",
        "            return \"bronze\"\n",
        "        elif \"Silver\" in class_name:\n",
        "            return \"silver\"\n",
        "        elif \"Gold\" in class_name:\n",
        "            return \"gold\"\n",
        "\n",
        "        return \"unknown\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_step_dependencies(step: Any) -> List[str]:\n",
        "        \"\"\"\n",
        "        Extract dependencies from a step.\n",
        "\n",
        "        Args:\n",
        "            step: Step object to analyze\n",
        "\n",
        "        Returns:\n",
        "            List of dependency step names\n",
        "        \"\"\"\n",
        "        dependencies: List[str] = []\n",
        "\n",
        "        # Check for source_bronze (silver steps)\n",
        "        source_bronze = getattr(step, \"source_bronze\", None)\n",
        "        if source_bronze:\n",
        "            dependencies.append(source_bronze)\n",
        "\n",
        "        # Check for source_silvers (gold steps)\n",
        "        source_silvers = getattr(step, \"source_silvers\", None)\n",
        "        if source_silvers:\n",
        "            if isinstance(source_silvers, list):\n",
        "                dependencies.extend(source_silvers)\n",
        "            elif isinstance(source_silvers, str):\n",
        "                dependencies.append(source_silvers)\n",
        "\n",
        "        # Check for source attribute (backward compatibility)\n",
        "        source = getattr(step, \"source\", None)\n",
        "        if source and source not in dependencies:\n",
        "            if isinstance(source, str):\n",
        "                dependencies.append(source)\n",
        "            elif isinstance(source, list):\n",
        "                dependencies.extend(source)\n",
        "\n",
        "        return dependencies\n",
        "\n",
        "    @staticmethod\n",
        "    def group_steps_by_type(\n",
        "        bronze_steps: Dict[str, Any],\n",
        "        silver_steps: Dict[str, Any],\n",
        "        gold_steps: Dict[str, Any],\n",
        "    ) -> Dict[str, Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Group steps by type into a single dictionary.\n",
        "\n",
        "        Args:\n",
        "            bronze_steps: Dictionary of bronze steps\n",
        "            silver_steps: Dictionary of silver steps\n",
        "            gold_steps: Dictionary of gold steps\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping step types to step dictionaries\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"bronze\": bronze_steps,\n",
        "            \"silver\": silver_steps,\n",
        "            \"gold\": gold_steps,\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def get_all_step_names(\n",
        "        bronze_steps: Dict[str, Any],\n",
        "        silver_steps: Dict[str, Any],\n",
        "        gold_steps: Dict[str, Any],\n",
        "    ) -> Set[str]:\n",
        "        \"\"\"\n",
        "        Get all step names from all step types.\n",
        "\n",
        "        Args:\n",
        "            bronze_steps: Dictionary of bronze steps\n",
        "            silver_steps: Dictionary of silver steps\n",
        "            gold_steps: Dictionary of gold steps\n",
        "\n",
        "        Returns:\n",
        "            Set of all step names\n",
        "        \"\"\"\n",
        "        all_names: Set[str] = set()\n",
        "        all_names.update(bronze_steps.keys())\n",
        "        all_names.update(silver_steps.keys())\n",
        "        all_names.update(gold_steps.keys())\n",
        "        return all_names\n",
        "\n",
        "    @staticmethod\n",
        "    def build_dependency_graph(\n",
        "        bronze_steps: Dict[str, Any],\n",
        "        silver_steps: Dict[str, Any],\n",
        "        gold_steps: Dict[str, Any],\n",
        "    ) -> DependencyGraph:\n",
        "        \"\"\"\n",
        "        Build a dependency graph from pipeline steps.\n",
        "\n",
        "        Args:\n",
        "            bronze_steps: Dictionary of bronze steps\n",
        "            silver_steps: Dictionary of silver steps\n",
        "            gold_steps: Dictionary of gold steps\n",
        "\n",
        "        Returns:\n",
        "            DependencyGraph instance\n",
        "        \"\"\"\n",
        "        # from ..dependencies.graph import StepNode, StepType  # Removed: defined in notebook cells above\n",
        "\n",
        "        graph = DependencyGraph()\n",
        "\n",
        "        # Add all steps as nodes\n",
        "        for step_name in StepClassifier.get_all_step_names(\n",
        "            bronze_steps, silver_steps, gold_steps\n",
        "        ):\n",
        "            # Determine step type\n",
        "            if step_name in bronze_steps:\n",
        "                step_type = StepType.BRONZE\n",
        "            elif step_name in silver_steps:\n",
        "                step_type = StepType.SILVER\n",
        "            elif step_name in gold_steps:\n",
        "                step_type = StepType.GOLD\n",
        "            else:\n",
        "                step_type = StepType.BRONZE  # Default\n",
        "\n",
        "            node = StepNode(name=step_name, step_type=step_type)\n",
        "            graph.add_node(node)\n",
        "\n",
        "        # Add dependencies for silver steps (depend on bronze)\n",
        "        for step_name, step in silver_steps.items():\n",
        "            source_bronze = getattr(step, \"source_bronze\", None)\n",
        "            if source_bronze and source_bronze in graph.nodes:\n",
        "                # add_dependency(from_step, to_step) means from_step depends on to_step\n",
        "                # So silver depends on bronze: add_dependency(silver, bronze)\n",
        "                graph.add_dependency(step_name, source_bronze)\n",
        "\n",
        "        # Add dependencies for gold steps (depend on silver)\n",
        "        for step_name, step in gold_steps.items():\n",
        "            source_silvers = getattr(step, \"source_silvers\", None)\n",
        "            if source_silvers:\n",
        "                if isinstance(source_silvers, list):\n",
        "                    for silver_name in source_silvers:\n",
        "                        if silver_name in graph.nodes:\n",
        "                            graph.add_dependency(step_name, silver_name)\n",
        "                elif isinstance(source_silvers, str):\n",
        "                    if source_silvers in graph.nodes:\n",
        "                        graph.add_dependency(step_name, source_silvers)\n",
        "\n",
        "        return graph\n",
        "\n",
        "    @staticmethod\n",
        "    def get_execution_order(\n",
        "        bronze_steps: Dict[str, Any],\n",
        "        silver_steps: Dict[str, Any],\n",
        "        gold_steps: Dict[str, Any],\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Get execution order for all steps based on dependencies.\n",
        "\n",
        "        Args:\n",
        "            bronze_steps: Dictionary of bronze steps\n",
        "            silver_steps: Dictionary of silver steps\n",
        "            gold_steps: Dictionary of gold steps\n",
        "\n",
        "        Returns:\n",
        "            List of step names in execution order\n",
        "        \"\"\"\n",
        "        graph = StepClassifier.build_dependency_graph(\n",
        "            bronze_steps, silver_steps, gold_steps\n",
        "        )\n",
        "        return graph.topological_sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.dependencies.analyzer (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: dependencies.exceptions, pipeline_builder_base.dependencies.exceptions, pipeline_builder_base.dependencies.graph, pipeline_builder_base.dependencies.graph, pipeline_builder_base.logging, pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"\n",
        "Unified dependency analyzer for the framework pipelines.\n",
        "\n",
        "This module provides a single, consolidated dependency analyzer that works\n",
        "with any step implementation that follows the step protocols.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import hashlib\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from typing import Any, Dict, Optional, Protocol\n",
        "\n",
        "# from ..logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .exceptions import DependencyError  # Removed: defined in notebook cells above\n",
        "# from .graph import DependencyGraph, StepNode, StepType  # Removed: defined in notebook cells above\n",
        "\n",
        "class AnalysisStrategy(Enum):\n",
        "    \"\"\"Strategies for dependency analysis.\"\"\"\n",
        "\n",
        "    CONSERVATIVE = \"conservative\"  # Assume all dependencies exist\n",
        "    OPTIMISTIC = \"optimistic\"  # Assume minimal dependencies\n",
        "    HYBRID = \"hybrid\"  # Balance between conservative and optimistic\n",
        "\n",
        "@dataclass\n",
        "class DependencyAnalysisResult:\n",
        "    \"\"\"Result of dependency analysis.\"\"\"\n",
        "\n",
        "    graph: DependencyGraph\n",
        "    execution_order: list[\n",
        "        str\n",
        "    ]  # Topologically sorted step names for sequential execution\n",
        "    cycles: list[list[str]]\n",
        "    conflicts: list[str]\n",
        "    recommendations: list[str]\n",
        "    stats: Dict[str, Any]\n",
        "    analysis_duration: float\n",
        "\n",
        "# Protocol for step objects that can be analyzed\n",
        "class StepProtocol(Protocol):\n",
        "    \"\"\"Protocol for steps that can be analyzed for dependencies.\"\"\"\n",
        "\n",
        "    name: str\n",
        "\n",
        "class BronzeStepProtocol(StepProtocol, Protocol):\n",
        "    \"\"\"Protocol for bronze steps.\"\"\"\n",
        "\n",
        "    incremental_col: Optional[str]\n",
        "\n",
        "class SilverStepProtocol(StepProtocol, Protocol):\n",
        "    \"\"\"Protocol for silver steps.\"\"\"\n",
        "\n",
        "    source_bronze: str\n",
        "\n",
        "class GoldStepProtocol(StepProtocol, Protocol):\n",
        "    \"\"\"Protocol for gold steps.\"\"\"\n",
        "\n",
        "    source_silvers: Optional[list[str]]\n",
        "\n",
        "class DependencyAnalyzer:\n",
        "    \"\"\"\n",
        "    Unified dependency analyzer for all pipeline step types.\n",
        "\n",
        "    This analyzer works with any step implementation that follows the step protocols.\n",
        "    It analyzes dependencies across bronze, silver, and gold steps.\n",
        "\n",
        "    Features:\n",
        "        - Single analyzer for all step types (Bronze, Silver, Gold)\n",
        "        - Multiple analysis strategies\n",
        "        - Cycle detection and resolution\n",
        "        - Topological sort for execution order\n",
        "        - Performance analysis and recommendations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        strategy: AnalysisStrategy = AnalysisStrategy.HYBRID,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        self.strategy = strategy\n",
        "        if logger is None:\n",
        "            self.logger = PipelineLogger()\n",
        "        else:\n",
        "            self.logger = logger\n",
        "        self._analysis_cache: Dict[str, DependencyAnalysisResult] = {}\n",
        "\n",
        "    def analyze_dependencies(\n",
        "        self,\n",
        "        bronze_steps: Optional[Dict[str, BronzeStepProtocol]] = None,\n",
        "        silver_steps: Optional[Dict[str, SilverStepProtocol]] = None,\n",
        "        gold_steps: Optional[Dict[str, GoldStepProtocol]] = None,\n",
        "        force_refresh: bool = False,\n",
        "        creation_order: Optional[Dict[str, int]] = None,\n",
        "    ) -> DependencyAnalysisResult:\n",
        "        \"\"\"\n",
        "        Analyze dependencies across all step types.\n",
        "\n",
        "        Args:\n",
        "            bronze_steps: Dictionary of bronze steps (any object with name and incremental_col)\n",
        "            silver_steps: Dictionary of silver steps (any object with name and source_bronze)\n",
        "            gold_steps: Dictionary of gold steps (any object with name and source_silvers)\n",
        "            force_refresh: Whether to force refresh of cached results\n",
        "\n",
        "        Returns:\n",
        "            DependencyAnalysisResult containing analysis results\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Create cache key\n",
        "        cache_key = self._create_cache_key(bronze_steps, silver_steps, gold_steps)\n",
        "\n",
        "        if not force_refresh and cache_key in self._analysis_cache:\n",
        "            self.logger.info(f\"Using cached dependency analysis: {cache_key}\")\n",
        "            return self._analysis_cache[cache_key]\n",
        "\n",
        "        self.logger.info(\n",
        "            f\"Starting dependency analysis with strategy: {self.strategy.value}\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            # Step 1: Build dependency graph with creation order\n",
        "            graph = self._build_dependency_graph(\n",
        "                bronze_steps, silver_steps, gold_steps, creation_order=creation_order\n",
        "            )\n",
        "\n",
        "            # Step 2: Detect cycles\n",
        "            cycles = graph.detect_cycles()\n",
        "            if cycles:\n",
        "                self.logger.warning(f\"Detected {len(cycles)} circular dependencies\")\n",
        "                graph = self._resolve_cycles(graph, cycles)\n",
        "\n",
        "            # Step 3: Detect conflicts\n",
        "            conflicts = self._detect_conflicts(graph)\n",
        "            if conflicts:\n",
        "                self.logger.warning(f\"Detected {len(conflicts)} dependency conflicts\")\n",
        "\n",
        "            # Step 4: Generate execution order (topological sort with creation order tie-breaker)\n",
        "            execution_order = graph.topological_sort(creation_order=creation_order)\n",
        "\n",
        "            # Step 5: Generate recommendations\n",
        "            recommendations = self._generate_recommendations(graph, cycles, conflicts)\n",
        "\n",
        "            # Step 6: Calculate statistics\n",
        "            stats = graph.get_stats()\n",
        "\n",
        "            # Create result\n",
        "            result = DependencyAnalysisResult(\n",
        "                graph=graph,\n",
        "                execution_order=execution_order,\n",
        "                cycles=cycles,\n",
        "                conflicts=conflicts,\n",
        "                recommendations=recommendations,\n",
        "                stats=stats,\n",
        "                analysis_duration=time.time() - start_time,\n",
        "            )\n",
        "\n",
        "            # Cache result\n",
        "            self._analysis_cache[cache_key] = result\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"Dependency analysis completed in {result.analysis_duration:.2f}s\"\n",
        "            )\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Dependency analysis failed: {str(e)}\")\n",
        "            raise DependencyError(f\"Dependency analysis failed: {str(e)}\") from e\n",
        "\n",
        "    def _build_dependency_graph(\n",
        "        self,\n",
        "        bronze_steps: Optional[Dict[str, BronzeStepProtocol]],\n",
        "        silver_steps: Optional[Dict[str, SilverStepProtocol]],\n",
        "        gold_steps: Optional[Dict[str, GoldStepProtocol]],\n",
        "        creation_order: Optional[Dict[str, int]] = None,\n",
        "    ) -> DependencyGraph:\n",
        "        \"\"\"Build the dependency graph from all step types.\"\"\"\n",
        "        graph = DependencyGraph()\n",
        "\n",
        "        # Add bronze steps\n",
        "        if bronze_steps:\n",
        "            for name, step in bronze_steps.items():\n",
        "                metadata: Dict[str, Any] = {\"step\": step}\n",
        "                if creation_order and name in creation_order:\n",
        "                    metadata[\"creation_order\"] = creation_order[name]\n",
        "                node = StepNode(name=name, step_type=StepType.BRONZE, metadata=metadata)\n",
        "                graph.add_node(node)\n",
        "\n",
        "        # Add silver steps - first pass: add all nodes\n",
        "        silver_step_info: Dict[\n",
        "            str, SilverStepProtocol\n",
        "        ] = {}  # Store step info for dependency processing\n",
        "        if silver_steps:\n",
        "            for name, silver_step in silver_steps.items():\n",
        "                metadata_s: Dict[str, Any] = {\"step\": silver_step}\n",
        "                if creation_order and name in creation_order:\n",
        "                    metadata_s[\"creation_order\"] = creation_order[name]\n",
        "                node = StepNode(\n",
        "                    name=name, step_type=StepType.SILVER, metadata=metadata_s\n",
        "                )\n",
        "                graph.add_node(node)\n",
        "                # Store step info for second pass\n",
        "                silver_step_info[name] = silver_step\n",
        "\n",
        "        # Second pass: add dependencies (now all nodes exist in graph)\n",
        "        for name, silver_step in silver_step_info.items():\n",
        "            # Add dependencies\n",
        "            # SilverStep always has source_bronze attribute\n",
        "            source_bronze = getattr(silver_step, \"source_bronze\", None)\n",
        "            if source_bronze:\n",
        "                # Check if the source bronze step exists\n",
        "                if source_bronze in graph.nodes:\n",
        "                    graph.add_dependency(name, source_bronze)\n",
        "                else:\n",
        "                    # Log warning about missing dependency\n",
        "                    self.logger.warning(\n",
        "                        f\"Silver step {name} references non-existent bronze step {source_bronze}\"\n",
        "                    )\n",
        "\n",
        "            # Check for silver-to-silver dependencies via source_silvers\n",
        "            # This allows silver steps to depend on other silver steps\n",
        "            # IMPORTANT: source_silvers overrides creation order\n",
        "            source_silvers = getattr(silver_step, \"source_silvers\", None)\n",
        "            if source_silvers:\n",
        "                if isinstance(source_silvers, (list, tuple)):\n",
        "                    for dep in source_silvers:\n",
        "                        if dep in graph.nodes:\n",
        "                            graph.add_dependency(name, dep)\n",
        "                        else:\n",
        "                            self.logger.warning(\n",
        "                                f\"Silver step {name} references non-existent silver step {dep}\"\n",
        "                            )\n",
        "                elif isinstance(source_silvers, str):\n",
        "                    if source_silvers in graph.nodes:\n",
        "                        graph.add_dependency(name, source_silvers)\n",
        "                    else:\n",
        "                        self.logger.warning(\n",
        "                            f\"Silver step {name} references non-existent silver step {source_silvers}\"\n",
        "                        )\n",
        "\n",
        "            # Check for additional dependencies (backward compatibility)\n",
        "            if hasattr(silver_step, \"depends_on\"):\n",
        "                depends_on = getattr(silver_step, \"depends_on\", None)\n",
        "                if depends_on and isinstance(depends_on, (list, tuple, set)):\n",
        "                    for dep in depends_on:\n",
        "                        if dep in graph.nodes:\n",
        "                            graph.add_dependency(name, dep)\n",
        "                        else:\n",
        "                            self.logger.warning(\n",
        "                                f\"Silver step {name} references non-existent dependency {dep}\"\n",
        "                            )\n",
        "\n",
        "        # Add gold steps - first pass: add all nodes\n",
        "        gold_step_info: Dict[\n",
        "            str, GoldStepProtocol\n",
        "        ] = {}  # Store step info for dependency processing\n",
        "        if gold_steps:\n",
        "            for name, gold_step in gold_steps.items():\n",
        "                metadata_g: Dict[str, Any] = {\"step\": gold_step}\n",
        "                if creation_order and name in creation_order:\n",
        "                    metadata_g[\"creation_order\"] = creation_order[name]\n",
        "                node = StepNode(name=name, step_type=StepType.GOLD, metadata=metadata_g)\n",
        "                graph.add_node(node)\n",
        "                # Store step info for second pass\n",
        "                gold_step_info[name] = gold_step\n",
        "\n",
        "        # Second pass: add dependencies (now all nodes exist in graph)\n",
        "        for name, gold_step in gold_step_info.items():\n",
        "            # Add dependencies\n",
        "            # GoldStep always has source_silvers attribute (can be None)\n",
        "            # IMPORTANT: source_silvers overrides creation order\n",
        "            source_silvers = getattr(gold_step, \"source_silvers\", None)\n",
        "            if source_silvers:\n",
        "                for dep in source_silvers:\n",
        "                    if dep in graph.nodes:\n",
        "                        graph.add_dependency(name, dep)\n",
        "                    else:\n",
        "                        self.logger.warning(\n",
        "                            f\"Gold step {name} references non-existent silver step {dep}\"\n",
        "                        )\n",
        "\n",
        "        return graph\n",
        "\n",
        "    def _resolve_cycles(\n",
        "        self, graph: DependencyGraph, cycles: list[list[str]]\n",
        "    ) -> DependencyGraph:\n",
        "        \"\"\"Resolve cycles in the dependency graph.\"\"\"\n",
        "        # Simple cycle resolution: break cycles by removing the last dependency\n",
        "        for cycle in cycles:\n",
        "            if len(cycle) > 1:\n",
        "                # Remove the last dependency in the cycle\n",
        "                from_step = cycle[-2]\n",
        "                to_step = cycle[-1]\n",
        "\n",
        "                self.logger.warning(\n",
        "                    f\"Breaking cycle by removing dependency: {from_step} -> {to_step}\"\n",
        "                )\n",
        "\n",
        "                # Remove from adjacency lists\n",
        "                if to_step in graph._adjacency_list[from_step]:\n",
        "                    graph._adjacency_list[from_step].remove(to_step)\n",
        "                if from_step in graph._reverse_adjacency_list[to_step]:\n",
        "                    graph._reverse_adjacency_list[to_step].remove(from_step)\n",
        "\n",
        "                # Update node dependencies\n",
        "                if to_step in graph.nodes[from_step].dependencies:\n",
        "                    graph.nodes[from_step].dependencies.remove(to_step)\n",
        "                if from_step in graph.nodes[to_step].dependents:\n",
        "                    graph.nodes[to_step].dependents.remove(from_step)\n",
        "\n",
        "        return graph\n",
        "\n",
        "    def _detect_conflicts(self, graph: DependencyGraph) -> list[str]:\n",
        "        \"\"\"Detect dependency conflicts.\"\"\"\n",
        "        conflicts = []\n",
        "\n",
        "        # Check for conflicting step names\n",
        "        step_names = list(graph.nodes.keys())\n",
        "        seen_names = set()\n",
        "        for node_name in step_names:\n",
        "            if node_name in seen_names:\n",
        "                conflicts.append(f\"Conflicting step name: {node_name}\")\n",
        "            seen_names.add(node_name)\n",
        "\n",
        "        # Check for missing dependencies\n",
        "        for node_name, node in graph.nodes.items():\n",
        "            for dep in node.dependencies:\n",
        "                if dep not in graph.nodes:\n",
        "                    conflicts.append(f\"Node {node_name} depends on missing node {dep}\")\n",
        "\n",
        "        return conflicts\n",
        "\n",
        "    def _generate_recommendations(\n",
        "        self, graph: DependencyGraph, cycles: list[list[str]], conflicts: list[str]\n",
        "    ) -> list[str]:\n",
        "        \"\"\"Generate optimization recommendations.\"\"\"\n",
        "        recommendations = []\n",
        "\n",
        "        # Cycle recommendations\n",
        "        if cycles:\n",
        "            recommendations.append(\n",
        "                \"Consider refactoring to eliminate circular dependencies\"\n",
        "            )\n",
        "\n",
        "        # Conflict recommendations\n",
        "        if conflicts:\n",
        "            recommendations.append(\"Resolve dependency conflicts before execution\")\n",
        "\n",
        "        # Performance recommendations\n",
        "        stats = graph.get_stats()\n",
        "        if stats[\"average_dependencies\"] > 3:\n",
        "            recommendations.append(\n",
        "                \"Consider reducing step dependencies for better performance\"\n",
        "            )\n",
        "\n",
        "        if len(graph.nodes) > 10:\n",
        "            recommendations.append(\n",
        "                \"Consider breaking large pipelines into smaller, focused pipelines\"\n",
        "            )\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def _create_cache_key(\n",
        "        self,\n",
        "        bronze_steps: Optional[Dict[str, BronzeStepProtocol]],\n",
        "        silver_steps: Optional[Dict[str, SilverStepProtocol]],\n",
        "        gold_steps: Optional[Dict[str, GoldStepProtocol]],\n",
        "    ) -> str:\n",
        "        \"\"\"Create a cache key for the analysis.\"\"\"\n",
        "        # Create a simple hash of the step configurations\n",
        "        key_parts = []\n",
        "\n",
        "        if bronze_steps:\n",
        "            key_parts.extend(sorted(bronze_steps.keys()))\n",
        "        if silver_steps:\n",
        "            key_parts.extend(sorted(silver_steps.keys()))\n",
        "        if gold_steps:\n",
        "            key_parts.extend(sorted(gold_steps.keys()))\n",
        "\n",
        "        key_string = f\"{self.strategy.value}:{':'.join(key_parts)}\"\n",
        "        return hashlib.sha256(key_string.encode()).hexdigest()\n",
        "\n",
        "    def clear_cache(self) -> None:\n",
        "        \"\"\"Clear the analysis cache.\"\"\"\n",
        "        self._analysis_cache.clear()\n",
        "        self.logger.info(\"Dependency analysis cache cleared\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.models.base (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.errors, pipeline_builder_base.errors, pipeline_builder_base.models.enums, pipeline_builder_base.models.enums, pipeline_builder_base.models.types, pipeline_builder_base.models.types\n",
        "\n",
        "\"\"\"\n",
        "Base classes and configuration models for the Pipeline Builder.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "\n",
        "# from ..errors import PipelineValidationError  # Removed: defined in notebook cells above\n",
        "# from .enums import PipelinePhase  # Removed: defined in notebook cells above\n",
        "# from .types import ModelValue  # Removed: defined in notebook cells above\n",
        "\n",
        "@dataclass\n",
        "class BaseModel(ABC):\n",
        "    \"\"\"\n",
        "    Base class for all pipeline models with common functionality.\n",
        "\n",
        "    Provides standard validation, serialization, and representation methods\n",
        "    for all pipeline data models. All models in the pipeline system inherit\n",
        "    from this base class to ensure consistent behavior.\n",
        "\n",
        "    Features:\n",
        "    - Automatic validation support\n",
        "    - JSON serialization and deserialization\n",
        "    - Dictionary conversion for easy data exchange\n",
        "    - String representation for debugging\n",
        "    - Type-safe field access\n",
        "\n",
        "    Example:\n",
        "        >>> @dataclass\n",
        "        >>> class MyStep(BaseModel):\n",
        "        ...     name: str\n",
        "        ...     rules: Dict[str, List[ColumnRule]]\n",
        "        ...\n",
        "        ...     def validate(self) -> None:\n",
        "        ...         if not self.name:\n",
        "        ...             raise ValueError(\"Name cannot be empty\")\n",
        "        ...         if not self.rules:\n",
        "        ...             raise ValueError(\"Rules cannot be empty\")\n",
        "        >>>\n",
        "        >>> step = MyStep(name=\"test\", rules={\"id\": [F.col(\"id\").isNotNull()]})\n",
        "        >>> step.validate()\n",
        "        >>> print(step.to_json())\n",
        "    \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the model. Override in subclasses.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def to_dict(self) -> Dict[str, ModelValue]:\n",
        "        \"\"\"Convert model to dictionary.\"\"\"\n",
        "        result: Dict[str, ModelValue] = {}\n",
        "        for field_info in self.__dataclass_fields__.values():\n",
        "            value = getattr(self, field_info.name)\n",
        "            if hasattr(value, \"to_dict\"):\n",
        "                result[field_info.name] = value.to_dict()\n",
        "            else:\n",
        "                result[field_info.name] = value\n",
        "        return result\n",
        "\n",
        "    def to_json(self) -> str:\n",
        "        \"\"\"Convert model to JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), default=str, indent=2)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        \"\"\"String representation of the model.\"\"\"\n",
        "        return f\"{self.__class__.__name__}({', '.join(f'{k}={v}' for k, v in self.to_dict().items())})\"\n",
        "\n",
        "@dataclass\n",
        "class ValidationThresholds(BaseModel):\n",
        "    \"\"\"\n",
        "    Validation thresholds for different pipeline phases.\n",
        "\n",
        "    Attributes:\n",
        "        bronze: Bronze layer validation threshold (0-100)\n",
        "        silver: Silver layer validation threshold (0-100)\n",
        "        gold: Gold layer validation threshold (0-100)\n",
        "    \"\"\"\n",
        "\n",
        "    bronze: float\n",
        "    silver: float\n",
        "    gold: float\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate threshold values.\"\"\"\n",
        "        for phase, threshold in [\n",
        "            (\"bronze\", self.bronze),\n",
        "            (\"silver\", self.silver),\n",
        "            (\"gold\", self.gold),\n",
        "        ]:\n",
        "            if not 0 <= threshold <= 100:\n",
        "                raise PipelineValidationError(\n",
        "                    f\"{phase} threshold must be between 0 and 100, got {threshold}\"\n",
        "                )\n",
        "\n",
        "    def get_threshold(self, phase: PipelinePhase) -> float:\n",
        "        \"\"\"Get threshold for a specific phase.\"\"\"\n",
        "        phase_map = {\n",
        "            PipelinePhase.BRONZE: self.bronze,\n",
        "            PipelinePhase.SILVER: self.silver,\n",
        "            PipelinePhase.GOLD: self.gold,\n",
        "        }\n",
        "        return phase_map[phase]\n",
        "\n",
        "    @classmethod\n",
        "    def create_default(cls) -> ValidationThresholds:\n",
        "        \"\"\"Create default validation thresholds.\"\"\"\n",
        "        return cls(bronze=95.0, silver=98.0, gold=99.0)\n",
        "\n",
        "    @classmethod\n",
        "    def create_strict(cls) -> ValidationThresholds:\n",
        "        \"\"\"Create strict validation thresholds.\"\"\"\n",
        "        return cls(bronze=99.0, silver=99.5, gold=99.9)\n",
        "\n",
        "    @classmethod\n",
        "    def create_loose(cls) -> ValidationThresholds:\n",
        "        \"\"\"Create loose validation thresholds.\"\"\"\n",
        "        return cls(bronze=80.0, silver=85.0, gold=90.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.writer.base (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: pipeline_builder_base.logging, pipeline_builder_base.models, pipeline_builder_base.writer.models\n",
        "\n",
        "\"\"\"\n",
        "Base LogWriter class for pipeline builders.\n",
        "\n",
        "This module provides an abstract base class for LogWriter implementations\n",
        "that can be used by both Spark and SQL pipeline builders.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Optional\n",
        "\n",
        "# from ..logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from ..models import ExecutionResult  # Removed: defined in notebook cells above\n",
        "# from .models import (  # Removed: defined in notebook cells above\n",
        "    # LogRow,\n",
        "    # WriteMode,\n",
        "    # WriterConfig,\n",
        "    # WriterMetrics,\n",
        "    # create_log_rows_from_execution_result,\n",
        "# )\n",
        "\n",
        "class BaseLogWriter(ABC):\n",
        "    \"\"\"\n",
        "    Abstract base class for LogWriter implementations.\n",
        "\n",
        "    This class defines the interface that all LogWriter implementations\n",
        "    must follow, while allowing engine-specific implementations for\n",
        "    storage operations.\n",
        "\n",
        "    Subclasses must implement:\n",
        "    - _write_log_rows() - Engine-specific write operation\n",
        "    - _read_log_table() - Engine-specific read operation\n",
        "    - _table_exists() - Engine-specific table existence check\n",
        "    - _create_table() - Engine-specific table creation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        schema: str,\n",
        "        table_name: str,\n",
        "        config: Optional[WriterConfig] = None,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the base LogWriter.\n",
        "\n",
        "        Args:\n",
        "            schema: Database schema name\n",
        "            table_name: Table name\n",
        "            config: Writer configuration (optional)\n",
        "            logger: Pipeline logger (optional)\n",
        "        \"\"\"\n",
        "        self.schema = schema\n",
        "        self.table_name = table_name\n",
        "        self.logger = logger or PipelineLogger()\n",
        "\n",
        "        # Create config from schema/table_name if not provided\n",
        "        if config is None:\n",
        "            # from .models import WriteMode  # Removed: defined in notebook cells above\n",
        "\n",
        "            config = WriterConfig(\n",
        "                table_schema=schema,\n",
        "                table_name=table_name,\n",
        "                write_mode=WriteMode.APPEND,\n",
        "            )\n",
        "        self.config = config\n",
        "        self.config.validate()\n",
        "\n",
        "    @property\n",
        "    def table_fqn(self) -> str:\n",
        "        \"\"\"Get fully qualified table name.\"\"\"\n",
        "        return f\"{self.schema}.{self.table_name}\"\n",
        "\n",
        "    def create_table(self, execution_result: ExecutionResult) -> None:\n",
        "        \"\"\"\n",
        "        Create the log table from the first execution result.\n",
        "\n",
        "        Args:\n",
        "            execution_result: The execution result to create table from\n",
        "        \"\"\"\n",
        "        if self._table_exists():\n",
        "            self.logger.warning(\n",
        "                f\"Table {self.table_fqn} already exists, skipping creation\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        self.logger.info(f\"Creating log table {self.table_fqn}\")\n",
        "        # Cast run_mode to Literal type for type safety\n",
        "        from typing import Literal, cast\n",
        "\n",
        "        RunModeType = Literal[\n",
        "            \"initial\", \"incremental\", \"full_refresh\", \"validation_only\"\n",
        "        ]\n",
        "        run_mode = cast(RunModeType, execution_result.context.run_mode)\n",
        "        log_rows = create_log_rows_from_execution_result(\n",
        "            execution_result,\n",
        "            run_id=execution_result.context.run_id,\n",
        "            run_mode=run_mode,\n",
        "        )\n",
        "\n",
        "        if not log_rows:\n",
        "            self.logger.warning(\"No log rows to create table from\")\n",
        "            return\n",
        "\n",
        "        self._create_table(log_rows)\n",
        "        self._write_log_rows(log_rows, WriteMode.APPEND)\n",
        "\n",
        "    def append(self, execution_result: ExecutionResult) -> WriterMetrics:\n",
        "        \"\"\"\n",
        "        Append execution result to the log table.\n",
        "\n",
        "        Args:\n",
        "            execution_result: The execution result to append\n",
        "\n",
        "        Returns:\n",
        "            Writer metrics\n",
        "        \"\"\"\n",
        "        if not self._table_exists():\n",
        "            self.logger.warning(f\"Table {self.table_fqn} does not exist, creating it\")\n",
        "            self.create_table(execution_result)\n",
        "            return self._get_metrics()\n",
        "\n",
        "        # Cast run_mode to Literal type for type safety\n",
        "        from typing import Literal, cast\n",
        "\n",
        "        RunModeType = Literal[\n",
        "            \"initial\", \"incremental\", \"full_refresh\", \"validation_only\"\n",
        "        ]\n",
        "        run_mode = cast(RunModeType, execution_result.context.run_mode)\n",
        "        log_rows = create_log_rows_from_execution_result(\n",
        "            execution_result,\n",
        "            run_id=execution_result.context.run_id,\n",
        "            run_mode=run_mode,\n",
        "        )\n",
        "\n",
        "        if not log_rows:\n",
        "            self.logger.warning(\"No log rows to append\")\n",
        "            return self._get_metrics()\n",
        "\n",
        "        self._write_log_rows(log_rows, WriteMode.APPEND)\n",
        "        return self._get_metrics()\n",
        "\n",
        "    def write(\n",
        "        self, execution_result: ExecutionResult, mode: WriteMode = WriteMode.APPEND\n",
        "    ) -> WriterMetrics:\n",
        "        \"\"\"\n",
        "        Write execution result to the log table.\n",
        "\n",
        "        Args:\n",
        "            execution_result: The execution result to write\n",
        "            mode: Write mode (APPEND or OVERWRITE)\n",
        "\n",
        "        Returns:\n",
        "            Writer metrics\n",
        "        \"\"\"\n",
        "        if mode == WriteMode.OVERWRITE or not self._table_exists():\n",
        "            if not self._table_exists():\n",
        "                self.logger.info(f\"Table {self.table_fqn} does not exist, creating it\")\n",
        "                self.create_table(execution_result)\n",
        "            else:\n",
        "                self.logger.info(f\"Overwriting table {self.table_fqn}\")\n",
        "                # For overwrite, we need to clear the table first\n",
        "                # This is engine-specific, so subclasses should override if needed\n",
        "                self._write_log_rows([], WriteMode.OVERWRITE)\n",
        "\n",
        "        # Cast run_mode to Literal type for type safety\n",
        "        from typing import Literal, cast\n",
        "\n",
        "        RunModeType = Literal[\n",
        "            \"initial\", \"incremental\", \"full_refresh\", \"validation_only\"\n",
        "        ]\n",
        "        run_mode = cast(RunModeType, execution_result.context.run_mode)\n",
        "        log_rows = create_log_rows_from_execution_result(\n",
        "            execution_result,\n",
        "            run_id=execution_result.context.run_id,\n",
        "            run_mode=run_mode,\n",
        "        )\n",
        "\n",
        "        if not log_rows:\n",
        "            self.logger.warning(\"No log rows to write\")\n",
        "            return self._get_metrics()\n",
        "\n",
        "        self._write_log_rows(log_rows, mode)\n",
        "        return self._get_metrics()\n",
        "\n",
        "    def read(self, limit: Optional[int] = None) -> list[LogRow]:\n",
        "        \"\"\"\n",
        "        Read log rows from the table.\n",
        "\n",
        "        Args:\n",
        "            limit: Maximum number of rows to read (None for all)\n",
        "\n",
        "        Returns:\n",
        "            List of log rows\n",
        "        \"\"\"\n",
        "        if not self._table_exists():\n",
        "            self.logger.warning(f\"Table {self.table_fqn} does not exist\")\n",
        "            return []\n",
        "\n",
        "        return self._read_log_table(limit)\n",
        "\n",
        "    # Abstract methods that must be implemented by subclasses\n",
        "\n",
        "    @abstractmethod\n",
        "    def _write_log_rows(self, log_rows: list[LogRow], mode: WriteMode) -> None:\n",
        "        \"\"\"\n",
        "        Write log rows to the storage system.\n",
        "\n",
        "        This is an engine-specific operation that must be implemented\n",
        "        by subclasses.\n",
        "\n",
        "        Args:\n",
        "            log_rows: List of log rows to write\n",
        "            mode: Write mode\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def _read_log_table(self, limit: Optional[int] = None) -> list[LogRow]:\n",
        "        \"\"\"\n",
        "        Read log rows from the storage system.\n",
        "\n",
        "        This is an engine-specific operation that must be implemented\n",
        "        by subclasses.\n",
        "\n",
        "        Args:\n",
        "            limit: Maximum number of rows to read (None for all)\n",
        "\n",
        "        Returns:\n",
        "            List of log rows\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def _table_exists(self) -> bool:\n",
        "        \"\"\"\n",
        "        Check if the log table exists.\n",
        "\n",
        "        This is an engine-specific operation that must be implemented\n",
        "        by subclasses.\n",
        "\n",
        "        Returns:\n",
        "            True if table exists, False otherwise\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def _create_table(self, sample_rows: list[LogRow]) -> None:\n",
        "        \"\"\"\n",
        "        Create the log table with appropriate schema.\n",
        "\n",
        "        This is an engine-specific operation that must be implemented\n",
        "        by subclasses.\n",
        "\n",
        "        Args:\n",
        "            sample_rows: Sample log rows to infer schema from\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def _get_metrics(self) -> WriterMetrics:\n",
        "        \"\"\"\n",
        "        Get writer metrics.\n",
        "\n",
        "        This is a default implementation that can be overridden\n",
        "        by subclasses for more detailed metrics.\n",
        "\n",
        "        Returns:\n",
        "            Writer metrics\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"total_writes\": 1,\n",
        "            \"successful_writes\": 1,\n",
        "            \"failed_writes\": 0,\n",
        "            \"total_duration_secs\": 0.0,\n",
        "            \"avg_write_duration_secs\": 0.0,\n",
        "            \"total_rows_written\": 0,\n",
        "            \"memory_usage_peak_mb\": 0.0,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.engine_config (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.protocols\n",
        "\n",
        "\"\"\"\n",
        "Engine injection for pipeline_builder.\n",
        "\n",
        "Holds injected engine components (functions, types, window, desc,\n",
        "AnalysisException) that satisfy the protocols in `protocols.py`. Users/tests\n",
        "must call `configure_engine(...)` after creating their engine (PySpark,\n",
        "sparkless, etc.). Defaults raise to ensure misconfiguration surfaces early.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import threading\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Optional, cast\n",
        "\n",
        "# from .protocols import (  # Removed: defined in notebook cells above\n",
        "    # AnalysisExceptionProtocol,\n",
        "    # FunctionsProtocol,\n",
        "    # TypesProtocol,\n",
        "    # WindowProtocol,\n",
        "# )\n",
        "\n",
        "@dataclass\n",
        "class EngineConfig:\n",
        "    functions: FunctionsProtocol\n",
        "    types: TypesProtocol\n",
        "    analysis_exception: type[BaseException] | AnalysisExceptionProtocol\n",
        "    window: Optional[WindowProtocol] = None\n",
        "    desc: Optional[Any] = None\n",
        "    engine_name: str = \"unknown\"\n",
        "    dataframe_cls: Optional[Any] = None\n",
        "    spark_session_cls: Optional[Any] = None\n",
        "    column_cls: Optional[Any] = None\n",
        "\n",
        "# Global engine state (for backward compatibility)\n",
        "_engine: Optional[EngineConfig] = None\n",
        "\n",
        "# Thread-local engine state (for parallel test isolation)\n",
        "_thread_local = threading.local()\n",
        "\n",
        "def _configure_engine_from_session(spark: Any) -> None:\n",
        "    \"\"\"Configure engine from a SparkSession (PySpark or sparkless). Used by configure_engine(spark=...).\"\"\"\n",
        "    session_module = type(spark).__module__\n",
        "    if \"pyspark\" in session_module:\n",
        "        from pyspark.sql import (\n",
        "            Column as PySparkColumn,\n",
        "        )\n",
        "        from pyspark.sql import (\n",
        "            DataFrame as PySparkDataFrame,\n",
        "        )\n",
        "        from pyspark.sql import (\n",
        "            SparkSession as PySparkSparkSession,\n",
        "        )\n",
        "        from pyspark.sql import functions as pyspark_functions\n",
        "        from pyspark.sql import types as pyspark_types\n",
        "        from pyspark.sql.functions import desc as pyspark_desc\n",
        "        from pyspark.sql.utils import AnalysisException as PySparkAnalysisException\n",
        "        from pyspark.sql.window import Window as PySparkWindow\n",
        "\n",
        "        configure_engine(\n",
        "            functions=cast(FunctionsProtocol, pyspark_functions),\n",
        "            types=cast(TypesProtocol, pyspark_types),\n",
        "            analysis_exception=PySparkAnalysisException,\n",
        "            window=PySparkWindow,\n",
        "            desc=pyspark_desc,\n",
        "            engine_name=\"pyspark\",\n",
        "            dataframe_cls=PySparkDataFrame,\n",
        "            spark_session_cls=PySparkSparkSession,\n",
        "            column_cls=PySparkColumn,\n",
        "        )\n",
        "    elif \"sparkless\" in session_module or \"mock_spark\" in session_module:\n",
        "        from sparkless import AnalysisException as MockAnalysisException\n",
        "        from sparkless import Column as MockColumn\n",
        "        from sparkless import DataFrame as MockDataFrame\n",
        "        from sparkless import SparkSession as MockSparkSession\n",
        "        from sparkless import Window as MockWindow\n",
        "        from sparkless import functions as mock_functions\n",
        "        from sparkless import spark_types as mock_types\n",
        "        from sparkless.functions import desc as mock_desc\n",
        "\n",
        "        configure_engine(\n",
        "            functions=cast(FunctionsProtocol, mock_functions),\n",
        "            types=cast(TypesProtocol, mock_types),\n",
        "            analysis_exception=MockAnalysisException,\n",
        "            window=MockWindow,\n",
        "            desc=mock_desc,\n",
        "            engine_name=\"mock\",\n",
        "            dataframe_cls=MockDataFrame,\n",
        "            spark_session_cls=MockSparkSession,\n",
        "            column_cls=MockColumn,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Unknown Spark session type: {type(spark).__module__}. \"\n",
        "            \"Use configure_engine(functions=..., types=..., analysis_exception=...) for custom engines.\"\n",
        "        )\n",
        "\n",
        "def configure_engine(\n",
        "    *,\n",
        "    spark: Optional[Any] = None,\n",
        "    functions: Optional[FunctionsProtocol] = None,\n",
        "    types: Optional[TypesProtocol] = None,\n",
        "    analysis_exception: Optional[\n",
        "        type[BaseException] | AnalysisExceptionProtocol\n",
        "    ] = None,\n",
        "    window: Optional[WindowProtocol] = None,\n",
        "    desc: Optional[Any] = None,\n",
        "    engine_name: str = \"unknown\",\n",
        "    dataframe_cls: Optional[Any] = None,\n",
        "    spark_session_cls: Optional[Any] = None,\n",
        "    column_cls: Optional[Any] = None,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Inject engine components.\n",
        "\n",
        "    Convenience: pass spark=your_spark_session to auto-configure from PySpark or sparkless.\n",
        "    Otherwise pass functions=..., types=..., analysis_exception=... (and optional window, desc, etc.).\n",
        "\n",
        "    Sets both thread-local and global engine state for backward compatibility.\n",
        "    Thread-local state takes precedence in get_engine() for parallel test isolation.\n",
        "    \"\"\"\n",
        "    if spark is not None:\n",
        "        _configure_engine_from_session(spark)\n",
        "        return\n",
        "    if functions is None or types is None or analysis_exception is None:\n",
        "        raise TypeError(\n",
        "            \"configure_engine() requires either spark=<SparkSession> or \"\n",
        "            \"functions=..., types=..., and analysis_exception=...\"\n",
        "        )\n",
        "    global _engine\n",
        "    engine_config = EngineConfig(\n",
        "        functions=functions,\n",
        "        types=types,\n",
        "        analysis_exception=analysis_exception,\n",
        "        window=window,\n",
        "        desc=desc,\n",
        "        engine_name=engine_name,\n",
        "        dataframe_cls=dataframe_cls,\n",
        "        spark_session_cls=spark_session_cls,\n",
        "        column_cls=column_cls,\n",
        "    )\n",
        "\n",
        "    # Set global state (for backward compatibility)\n",
        "    _engine = engine_config\n",
        "\n",
        "    # Set thread-local state (for parallel test isolation)\n",
        "    _thread_local.engine = engine_config\n",
        "\n",
        "def get_engine() -> EngineConfig:\n",
        "    \"\"\"\n",
        "    Get the current engine config, raising if not configured.\n",
        "\n",
        "    Checks thread-local storage first (for parallel test isolation),\n",
        "    then falls back to global state (for backward compatibility).\n",
        "    \"\"\"\n",
        "\n",
        "    # Try thread-local first (for parallel test isolation)\n",
        "    if hasattr(_thread_local, \"engine\") and _thread_local.engine is not None:\n",
        "        engine: EngineConfig = _thread_local.engine\n",
        "        return engine\n",
        "\n",
        "    # Fallback to global state (for backward compatibility)\n",
        "    if _engine is None:\n",
        "        raise RuntimeError(\n",
        "            \"Engine not configured. Call configure_engine(functions=..., types=..., analysis_exception=..., window=..., desc=...) before using pipeline_builder.\"\n",
        "        )\n",
        "    return _engine\n",
        "\n",
        "def reset_engine_state() -> None:\n",
        "    \"\"\"\n",
        "    Reset thread-local engine state.\n",
        "\n",
        "    This is useful for test isolation - clears the thread-local engine\n",
        "    so the next get_engine() call will use global state or raise an error.\n",
        "    \"\"\"\n",
        "    if hasattr(_thread_local, \"engine\"):\n",
        "        delattr(_thread_local, \"engine\")\n",
        "\n",
        "__all__ = [\"EngineConfig\", \"configure_engine\", \"get_engine\", \"reset_engine_state\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.engine (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.protocols\n",
        "\n",
        "\"\"\"\n",
        "Engine injection for pipeline_builder.\n",
        "\n",
        "This module holds injected engine components (functions, types, window, desc,\n",
        "AnalysisException) that satisfy the protocols in `protocols.py`. Users/tests\n",
        "must call `configure_engine(...)` after creating their engine (PySpark,\n",
        "sparkless, etc.). Defaults raise to ensure misconfiguration surfaces early.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Optional\n",
        "\n",
        "# from .protocols import (  # Removed: defined in notebook cells above\n",
        "    # AnalysisExceptionProtocol,\n",
        "    # FunctionsProtocol,\n",
        "    # TypesProtocol,\n",
        "    # WindowProtocol,\n",
        "# )\n",
        "\n",
        "@dataclass\n",
        "class EngineConfig:\n",
        "    functions: FunctionsProtocol\n",
        "    types: TypesProtocol\n",
        "    analysis_exception: type[BaseException] | AnalysisExceptionProtocol\n",
        "    window: Optional[WindowProtocol] = None\n",
        "    desc: Optional[Any] = None\n",
        "\n",
        "_engine: Optional[EngineConfig] = None\n",
        "\n",
        "def configure_engine(\n",
        "    *,\n",
        "    functions: FunctionsProtocol,\n",
        "    types: TypesProtocol,\n",
        "    analysis_exception: type[BaseException] | AnalysisExceptionProtocol,\n",
        "    window: Optional[WindowProtocol] = None,\n",
        "    desc: Optional[Any] = None,\n",
        ") -> None:\n",
        "    \"\"\"Inject engine components.\"\"\"\n",
        "\n",
        "    global _engine\n",
        "    _engine = EngineConfig(\n",
        "        functions=functions,\n",
        "        types=types,\n",
        "        analysis_exception=analysis_exception,\n",
        "        window=window,\n",
        "        desc=desc,\n",
        "    )\n",
        "\n",
        "def get_engine() -> EngineConfig:\n",
        "    \"\"\"Get the current engine config, raising if not configured.\"\"\"\n",
        "\n",
        "    if _engine is None:\n",
        "        raise RuntimeError(\n",
        "            \"Engine not configured. Call configure_engine(functions=..., types=..., analysis_exception=..., window=..., desc=...) before using pipeline_builder.\"\n",
        "        )\n",
        "    return _engine\n",
        "\n",
        "__all__ = [\"EngineConfig\", \"configure_engine\", \"get_engine\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.step (abstracts)\n",
        "#\n",
        "# Dependencies: abstracts.rules, abstracts.transformer\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Literal, Optional, Protocol\n",
        "# from .rules import Rules  # Removed: defined in notebook cells above\n",
        "# from .transformer import Transformer  # Removed: defined in notebook cells above\n",
        "\n",
        "class Step(Protocol):\n",
        "    \"\"\"\n",
        "    Protocol for pipeline steps that BronzeStep, SilverStep, and GoldStep naturally satisfy.\n",
        "\n",
        "    This Protocol defines the interface that all step types must implement,\n",
        "    allowing duck typing compatibility between abstracts and pipeline_builder.\n",
        "    \"\"\"\n",
        "\n",
        "    name: str\n",
        "    type: Literal[\"bronze\", \"silver\", \"gold\"]\n",
        "    rules: Rules\n",
        "    source: Optional[str]\n",
        "    target: Optional[str]\n",
        "    transform: Optional[Transformer]\n",
        "    write_mode: Optional[Literal[\"overwrite\", \"append\"]]\n",
        "    write_schema: Optional[str]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.reports.write (abstracts)\n",
        "#\n",
        "# Dependencies: abstracts.source\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional\n",
        "# from .source import Source  # Removed: defined in notebook cells above\n",
        "\n",
        "@dataclass\n",
        "class WriteReport:\n",
        "    source: Source\n",
        "    written_rows: int\n",
        "    failed_rows: int\n",
        "    error: Optional[Exception] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.reports.transform (abstracts)\n",
        "#\n",
        "# Dependencies: abstracts.source\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional\n",
        "# from .source import Source  # Removed: defined in notebook cells above\n",
        "\n",
        "@dataclass\n",
        "class TransformReport:\n",
        "    source: Source\n",
        "    error: Optional[Exception] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.reports.validation (abstracts)\n",
        "#\n",
        "# Dependencies: abstracts.source\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional\n",
        "# from .source import Source  # Removed: defined in notebook cells above\n",
        "\n",
        "@dataclass\n",
        "class ValidationReport:\n",
        "    source: Source\n",
        "    valid_rows: int\n",
        "    invalid_rows: int\n",
        "    error: Optional[Exception] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.sql_source.reader (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.sql_source.models\n",
        "\n",
        "\"\"\"\n",
        "Unified reader for JdbcSource and SqlAlchemySource.\n",
        "\n",
        "Dispatches on source type and returns a Spark DataFrame.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, Union, cast\n",
        "# from .sql_source.models import JdbcSource, SqlAlchemySource  # Removed: defined in notebook cells above\n",
        "\n",
        "def read_sql_source(\n",
        "    source: Union[JdbcSource, SqlAlchemySource],\n",
        "    spark: Any,\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    Read a SQL source into a Spark DataFrame.\n",
        "\n",
        "    Args:\n",
        "        source: JdbcSource or SqlAlchemySource configuration.\n",
        "        spark: SparkSession (from pipeline_builder.compat or pyspark).\n",
        "\n",
        "    Returns:\n",
        "        Spark DataFrame.\n",
        "\n",
        "    Raises:\n",
        "        ValidationError: If source config is invalid.\n",
        "        RuntimeError: If SqlAlchemySource is used but sqlalchemy/pandas not installed.\n",
        "    \"\"\"\n",
        "    if isinstance(source, JdbcSource):\n",
        "        return _read_jdbc(source, spark)\n",
        "    if isinstance(source, SqlAlchemySource):\n",
        "        return _read_sqlalchemy(source, spark)\n",
        "    raise TypeError(\n",
        "        f\"source must be JdbcSource or SqlAlchemySource, got {type(source).__name__}\"\n",
        "    )\n",
        "\n",
        "def _read_jdbc(source: JdbcSource, spark: Any) -> Any:\n",
        "    table_or_query = source.table if source.table else source.query\n",
        "    if not table_or_query:\n",
        "        raise ValueError(\"JdbcSource must have table or query set\")\n",
        "\n",
        "    # Copy properties to a mutable dict so type checkers know we can mutate it\n",
        "    props: Dict[str, str] = dict(source.properties)\n",
        "\n",
        "    if source.driver:\n",
        "        props[\"driver\"] = source.driver\n",
        "\n",
        "    kwargs = {\n",
        "        \"url\": source.url,\n",
        "        \"table\": table_or_query,\n",
        "        \"properties\": props,\n",
        "    }\n",
        "\n",
        "    return spark.read.jdbc(**kwargs)\n",
        "\n",
        "def _read_sqlalchemy(source: SqlAlchemySource, spark: Any) -> Any:\n",
        "    try:\n",
        "        import pandas as pd\n",
        "    except ImportError as e:\n",
        "        raise RuntimeError(\n",
        "            \"SqlAlchemySource requires pandas. Install with: pip install pipeline_builder[sql]\"\n",
        "        ) from e\n",
        "    try:\n",
        "        from sqlalchemy import create_engine\n",
        "    except ImportError as e:\n",
        "        raise RuntimeError(\n",
        "            \"SqlAlchemySource requires sqlalchemy. Install with: pip install pipeline_builder[sql]\"\n",
        "        ) from e\n",
        "\n",
        "    if source.engine is not None:\n",
        "        engine = source.engine\n",
        "    else:\n",
        "        # __post_init__ guarantees that url is a non-empty string when engine is None,\n",
        "        # but type checkers cannot deduce this, so we cast explicitly.\n",
        "        engine = create_engine(cast(str, source.url))\n",
        "\n",
        "    if source.query is not None:\n",
        "        pdf = pd.read_sql(source.query, engine)\n",
        "    else:\n",
        "        # SqlAlchemySource validation guarantees that table is set when query is None,\n",
        "        # but we add a defensive assertion for type checkers and runtime safety.\n",
        "        assert source.table is not None, (\n",
        "            \"SqlAlchemySource.table must be set when query is None\"\n",
        "        )\n",
        "\n",
        "        if source.schema:\n",
        "            pdf = pd.read_sql_table(source.table, engine, schema=source.schema)\n",
        "        else:\n",
        "            pdf = pd.read_sql_table(source.table, engine)\n",
        "\n",
        "    return spark.createDataFrame(pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.models.pipeline (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: models.base, pipeline_builder_base.errors, pipeline_builder_base.errors, pipeline_builder_base.models.base\n",
        "\n",
        "\"\"\"\n",
        "Pipeline configuration models.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any\n",
        "\n",
        "# from ..errors import PipelineValidationError  # Removed: defined in notebook cells above\n",
        "# from .base import BaseModel, ValidationThresholds  # Removed: defined in notebook cells above\n",
        "\n",
        "@dataclass\n",
        "class PipelineConfig(BaseModel):\n",
        "    \"\"\"\n",
        "    Main pipeline configuration.\n",
        "\n",
        "    Attributes:\n",
        "        schema: Database schema name\n",
        "        thresholds: Validation thresholds for each phase\n",
        "        verbose: Whether to enable verbose logging\n",
        "    \"\"\"\n",
        "\n",
        "    schema: str\n",
        "    thresholds: ValidationThresholds\n",
        "    verbose: bool = True\n",
        "\n",
        "    @property\n",
        "    def min_bronze_rate(self) -> float:\n",
        "        \"\"\"Get bronze validation threshold.\"\"\"\n",
        "        return self.thresholds.bronze\n",
        "\n",
        "    @property\n",
        "    def min_silver_rate(self) -> float:\n",
        "        \"\"\"Get silver validation threshold.\"\"\"\n",
        "        return self.thresholds.silver\n",
        "\n",
        "    @property\n",
        "    def min_gold_rate(self) -> float:\n",
        "        \"\"\"Get gold validation threshold.\"\"\"\n",
        "        return self.thresholds.gold\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate pipeline configuration.\"\"\"\n",
        "        if not self.schema or not isinstance(self.schema, str):\n",
        "            raise PipelineValidationError(\"Schema name must be a non-empty string\")\n",
        "        self.thresholds.validate()\n",
        "\n",
        "    @classmethod\n",
        "    def create_default(cls, schema: str) -> PipelineConfig:\n",
        "        \"\"\"Create default pipeline configuration.\"\"\"\n",
        "        return cls(\n",
        "            schema=schema,\n",
        "            thresholds=ValidationThresholds.create_default(),\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def create_high_performance(cls, schema: str) -> PipelineConfig:\n",
        "        \"\"\"Create high-performance pipeline configuration with strict validation.\"\"\"\n",
        "        return cls(\n",
        "            schema=schema,\n",
        "            thresholds=ValidationThresholds.create_strict(),\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def create_conservative(cls, schema: str) -> PipelineConfig:\n",
        "        \"\"\"Create conservative pipeline configuration with strict validation.\"\"\"\n",
        "        return cls(\n",
        "            schema=schema,\n",
        "            thresholds=ValidationThresholds.create_strict(),\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "@dataclass\n",
        "class PipelineMetrics(BaseModel):\n",
        "    \"\"\"\n",
        "    Overall pipeline execution metrics.\n",
        "\n",
        "    Attributes:\n",
        "        total_steps: Total number of steps\n",
        "        successful_steps: Number of successful steps\n",
        "        failed_steps: Number of failed steps\n",
        "        skipped_steps: Number of skipped steps\n",
        "        total_duration: Total execution duration\n",
        "        bronze_duration: Bronze layer duration\n",
        "        silver_duration: Silver layer duration\n",
        "        gold_duration: Gold layer duration\n",
        "        total_rows_processed: Total rows processed\n",
        "        total_rows_written: Total rows written\n",
        "        avg_validation_rate: Average validation rate\n",
        "        cache_hit_rate: Cache hit rate\n",
        "        error_count: Number of errors\n",
        "        retry_count: Number of retries\n",
        "    \"\"\"\n",
        "\n",
        "    total_steps: int = 0\n",
        "    successful_steps: int = 0\n",
        "    failed_steps: int = 0\n",
        "    skipped_steps: int = 0\n",
        "    total_duration: float = 0.0\n",
        "    bronze_duration: float = 0.0\n",
        "    silver_duration: float = 0.0\n",
        "    gold_duration: float = 0.0\n",
        "    total_rows_processed: int = 0\n",
        "    total_rows_written: int = 0\n",
        "    avg_validation_rate: float = 0.0\n",
        "    cache_hit_rate: float = 0.0\n",
        "    error_count: int = 0\n",
        "    retry_count: int = 0\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the pipeline metrics.\"\"\"\n",
        "        if self.total_steps < 0:\n",
        "            raise ValueError(\"Total steps cannot be negative\")\n",
        "        if self.successful_steps < 0:\n",
        "            raise ValueError(\"Successful steps cannot be negative\")\n",
        "        if self.failed_steps < 0:\n",
        "            raise ValueError(\"Failed steps cannot be negative\")\n",
        "        if self.skipped_steps < 0:\n",
        "            raise ValueError(\"Skipped steps cannot be negative\")\n",
        "        if self.total_duration < 0:\n",
        "            raise ValueError(\"Total duration cannot be negative\")\n",
        "        if not 0 <= self.avg_validation_rate <= 100:\n",
        "            raise ValueError(\"Average validation rate must be between 0 and 100\")\n",
        "\n",
        "    @property\n",
        "    def success_rate(self) -> float:\n",
        "        \"\"\"Calculate success rate.\"\"\"\n",
        "        return (\n",
        "            (self.successful_steps / self.total_steps * 100)\n",
        "            if self.total_steps > 0\n",
        "            else 0.0\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def failure_rate(self) -> float:\n",
        "        \"\"\"Calculate failure rate.\"\"\"\n",
        "        return 100.0 - self.success_rate\n",
        "\n",
        "    @classmethod\n",
        "    def from_step_results(cls, step_results: list[Any]) -> PipelineMetrics:\n",
        "        \"\"\"Create metrics from step results.\"\"\"\n",
        "        total_steps = len(step_results)\n",
        "        successful_steps = sum(1 for result in step_results if result.success)\n",
        "        failed_steps = total_steps - successful_steps\n",
        "        total_duration_secs = sum(result.duration_secs for result in step_results)\n",
        "        total_rows_processed = sum(result.rows_processed for result in step_results)\n",
        "        total_rows_written = sum(result.rows_written for result in step_results)\n",
        "        avg_validation_rate = (\n",
        "            sum(result.validation_rate for result in step_results) / total_steps\n",
        "            if total_steps > 0\n",
        "            else 0.0\n",
        "        )\n",
        "\n",
        "        return cls(\n",
        "            total_steps=total_steps,\n",
        "            successful_steps=successful_steps,\n",
        "            failed_steps=failed_steps,\n",
        "            total_duration=total_duration_secs,\n",
        "            total_rows_processed=total_rows_processed,\n",
        "            total_rows_written=total_rows_written,\n",
        "            avg_validation_rate=avg_validation_rate,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.compat (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.engine_config, pipeline_builder.protocols\n",
        "\n",
        "# mypy: ignore-errors\n",
        "\"\"\"\n",
        "Protocol-based compatibility layer for engine abstraction.\n",
        "\n",
        "This module provides a compatibility layer that abstracts over different\n",
        "Spark/PySpark implementations (real PySpark, mock Spark, sparkless, etc.).\n",
        "It exposes protocol aliases and injected engine components that are configured\n",
        "at runtime through the engine configuration system.\n",
        "\n",
        "**Key Features:**\n",
        "    - **Engine Detection**: Automatically detects and uses the configured engine\n",
        "    - **Protocol Aliases**: Provides type-safe aliases for DataFrame, SparkSession, Column\n",
        "    - **Lazy Loading**: Components are loaded lazily to avoid import-time cycles\n",
        "    - **Mock Support**: Supports both real PySpark and mock Spark for testing\n",
        "\n",
        "**Usage:**\n",
        "    Before using pipeline_builder, you must configure the engine:\n",
        "\n",
        "    >>> from pipeline_builder.engine_config import configure_engine\n",
        "    >>> from pyspark.sql import SparkSession\n",
        "    >>>\n",
        "    >>> spark = SparkSession.builder.appName(\"test\").getOrCreate()\n",
        "    >>> configure_engine(spark=spark)\n",
        "\n",
        "    Then you can import and use the compatibility layer:\n",
        "\n",
        "    >>> from pipeline_builder.compat import DataFrame, SparkSession, F\n",
        "    >>> df: DataFrame = spark.createDataFrame([(1, \"test\")], [\"id\", \"name\"])\n",
        "\n",
        "**Exported Components:**\n",
        "    - **DataFrame**: Protocol alias for DataFrame type\n",
        "    - **SparkSession**: Protocol alias for SparkSession type\n",
        "    - **Column**: Protocol alias for Column type\n",
        "    - **F**: Functions module (PySpark functions or mock equivalent)\n",
        "    - **types**: Types module (StructType, StringType, etc.)\n",
        "    - **AnalysisException**: Exception class for analysis errors\n",
        "    - **Window**: Window functions\n",
        "    - **desc**: Descending sort function\n",
        "\n",
        "**Engine Configuration:**\n",
        "    The engine must be configured before use. See `engine_config.configure_engine()`\n",
        "    for details on how to configure the engine with your Spark/PySpark objects.\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.engine_config import configure_engine\n",
        "    >>> from pipeline_builder.compat import DataFrame, F\n",
        "    >>> from pyspark.sql import SparkSession\n",
        "    >>>\n",
        "    >>> # Configure engine\n",
        "    >>> spark = SparkSession.builder.appName(\"test\").getOrCreate()\n",
        "    >>> configure_engine(spark=spark)\n",
        "    >>>\n",
        "    >>> # Use compatibility layer\n",
        "    >>> from pipeline_builder.compat import DataFrame\n",
        "    >>> df: DataFrame = spark.createDataFrame([(1, \"test\")], [\"id\", \"name\"])\n",
        "    >>> result = df.filter(F.col(\"id\") > 0)\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import TYPE_CHECKING, Any, cast\n",
        "\n",
        "# from .engine_config import get_engine  # Removed: defined in notebook cells above\n",
        "# from .protocols import (  # Removed: defined in notebook cells above\n",
        "    # ColumnProtocol,\n",
        "    # DataFrameProtocol,\n",
        "    # SparkSessionProtocol,\n",
        "# )\n",
        "\n",
        "# Type aliases for typing\n",
        "if TYPE_CHECKING:\n",
        "    from .protocols import ColumnProtocol as Column\n",
        "    from .protocols import DataFrameProtocol as DataFrame\n",
        "    from .protocols import SparkSessionProtocol as SparkSession\n",
        "else:\n",
        "    DataFrame = Any  # type: ignore[assignment]\n",
        "    SparkSession = Any  # type: ignore[assignment]\n",
        "    Column = Any  # type: ignore[assignment]\n",
        "\n",
        "# Try to bind engine components immediately if configured\n",
        "try:\n",
        "    _eng = get_engine()\n",
        "    DataFrame = cast(Any, _eng.dataframe_cls or DataFrameProtocol)\n",
        "    SparkSession = cast(Any, _eng.spark_session_cls or SparkSessionProtocol)\n",
        "    Column = cast(Any, _eng.column_cls or ColumnProtocol)\n",
        "    # F = _eng.functions  # In standalone notebook, use global F from pyspark\n",
        "    # F is available from imports cell (pyspark.sql.functions)\n",
        "    types = _eng.types\n",
        "    AnalysisException = _eng.analysis_exception  # type: ignore[assignment]\n",
        "    Window = _eng.window  # type: ignore[assignment]\n",
        "    desc = _eng.desc\n",
        "except Exception:\n",
        "    # Defer to __getattr__ if not configured yet\n",
        "    pass\n",
        "\n",
        "def __getattr__(name: str) -> Any:\n",
        "    \"\"\"Lazily resolve injected engine components to avoid import-time cycles.\n",
        "\n",
        "    This function is called when an attribute is accessed that wasn't found\n",
        "    during module initialization. It allows lazy loading of engine components\n",
        "    to avoid circular import issues.\n",
        "\n",
        "    Args:\n",
        "        name: Name of the attribute to resolve. Supported names:\n",
        "            - \"F\": Functions module\n",
        "            - \"types\": Types module\n",
        "            - \"AnalysisException\": Analysis exception class\n",
        "            - \"Window\": Window functions\n",
        "            - \"desc\": Descending sort function\n",
        "            - \"DataFrame\": DataFrame protocol/class\n",
        "            - \"SparkSession\": SparkSession protocol/class\n",
        "            - \"Column\": Column protocol/class\n",
        "\n",
        "    Returns:\n",
        "        The requested engine component from the configured engine.\n",
        "\n",
        "    Raises:\n",
        "        AttributeError: If the requested attribute is not supported or\n",
        "            the engine is not configured.\n",
        "\n",
        "    Note:\n",
        "        This function is automatically called by Python when accessing\n",
        "        module attributes that don't exist at import time. It should not\n",
        "        be called directly.\n",
        "    \"\"\"\n",
        "    if name in {\"F\", \"types\", \"AnalysisException\", \"Window\", \"desc\"}:\n",
        "        eng = get_engine()\n",
        "        if name == \"F\":\n",
        "            # In standalone notebook, return global F from pyspark\n",
        "            from pyspark.sql import functions as F\n",
        "            return F\n",
        "        if name == \"types\":\n",
        "            # In standalone notebook, return types from pyspark.sql.types\n",
        "            from pyspark.sql import types\n",
        "            return types\n",
        "        if name == \"AnalysisException\":\n",
        "            return eng.analysis_exception\n",
        "        if name == \"Window\":\n",
        "            return eng.window\n",
        "        if name == \"desc\":\n",
        "            return eng.desc\n",
        "    if name == \"DataFrame\":\n",
        "        eng = get_engine()\n",
        "        return eng.dataframe_cls or DataFrameProtocol\n",
        "    if name == \"SparkSession\":\n",
        "        eng = get_engine()\n",
        "        return eng.spark_session_cls or SparkSessionProtocol\n",
        "    if name == \"Column\":\n",
        "        eng = get_engine()\n",
        "        return eng.column_cls or ColumnProtocol\n",
        "    raise AttributeError(f\"module {__name__} has no attribute {name}\")\n",
        "\n",
        "def is_mock_spark() -> bool:\n",
        "    \"\"\"Check if the configured engine is a mock Spark implementation.\n",
        "\n",
        "    This function is useful for conditional logic that needs to behave\n",
        "    differently in test environments vs production.\n",
        "\n",
        "    Returns:\n",
        "        True if the configured engine is \"mock\", False otherwise.\n",
        "        Returns False if the engine is not configured or an error occurs.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.compat import is_mock_spark\n",
        "        >>> if is_mock_spark():\n",
        "        ...     print(\"Running in test mode\")\n",
        "        ... else:\n",
        "        ...     print(\"Running with real PySpark\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return get_engine().engine_name == \"mock\"\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def compat_name() -> str:\n",
        "    \"\"\"Get the name of the currently configured engine.\n",
        "\n",
        "    Returns the engine name that was configured via `engine_config.configure_engine()`.\n",
        "    Common values include \"pyspark\", \"mock\", \"sparkless\", etc.\n",
        "\n",
        "    Returns:\n",
        "        Engine name string. Returns \"unknown\" if the engine is not configured\n",
        "        or an error occurs.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.compat import compat_name\n",
        "        >>> engine_name = compat_name()\n",
        "        >>> print(f\"Using engine: {engine_name}\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return get_engine().engine_name\n",
        "    except Exception:\n",
        "        return \"unknown\"\n",
        "\n",
        "def get_functions_from_session(spark: SparkSession) -> Any:\n",
        "    \"\"\"Get functions module from a SparkSession.\n",
        "\n",
        "    Compatibility helper function that returns the configured functions\n",
        "    module (F). The spark parameter is accepted for API compatibility\n",
        "    but is not used, as the functions module comes from the configured\n",
        "    engine, not from the SparkSession directly.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance. Accepted for API compatibility\n",
        "            but not used internally.\n",
        "\n",
        "    Returns:\n",
        "        Functions module (F) from the configured engine. This is the\n",
        "        same as accessing `F` directly from the compat module.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.compat import get_functions_from_session\n",
        "        >>> from pyspark.sql import SparkSession\n",
        "        >>>\n",
        "        >>> spark = SparkSession.builder.appName(\"test\").getOrCreate()\n",
        "        >>> F = get_functions_from_session(spark)\n",
        "        >>> # Use F for DataFrame operations\n",
        "        >>> df.select(F.col(\"id\"), F.lit(\"test\"))\n",
        "    \"\"\"\n",
        "    return F\n",
        "\n",
        "def get_current_timestamp() -> Any:\n",
        "    \"\"\"Get current timestamp using the configured engine's timestamp function.\n",
        "\n",
        "    Returns the current timestamp using the engine's `current_timestamp()`\n",
        "    function if available, otherwise falls back to a Python datetime ISO string.\n",
        "\n",
        "    Returns:\n",
        "        Current timestamp as a Column expression (if using PySpark) or\n",
        "        ISO format string (if fallback is used).\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.compat import get_current_timestamp\n",
        "        >>> timestamp = get_current_timestamp()\n",
        "        >>> # Use in DataFrame operations\n",
        "        >>> df.withColumn(\"created_at\", timestamp)\n",
        "    \"\"\"\n",
        "    ct = getattr(F, \"current_timestamp\", None)\n",
        "    if callable(ct):\n",
        "        return ct()\n",
        "    # Fallback: literal current timestamp string\n",
        "    from datetime import datetime\n",
        "\n",
        "    return datetime.now().isoformat()\n",
        "\n",
        "__all__ = [\n",
        "    \"DataFrame\",\n",
        "    \"SparkSession\",\n",
        "    \"Column\",\n",
        "    \"F\",\n",
        "    \"types\",\n",
        "    \"AnalysisException\",\n",
        "    \"Window\",\n",
        "    \"desc\",\n",
        "    \"get_functions_from_session\",\n",
        "    \"get_current_timestamp\",\n",
        "    \"is_mock_spark\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.engine (abstracts)\n",
        "#\n",
        "# Dependencies: abstracts.reports.transform, abstracts.reports.validation, abstracts.reports.write, abstracts.source, abstracts.step\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "# from .reports.transform import TransformReport  # Removed: defined in notebook cells above\n",
        "# from .reports.validation import ValidationReport  # Removed: defined in notebook cells above\n",
        "# from .reports.write import WriteReport  # Removed: defined in notebook cells above\n",
        "# from .source import Source  # Removed: defined in notebook cells above\n",
        "# from .step import Step  # Removed: defined in notebook cells above\n",
        "\n",
        "class Engine(ABC):\n",
        "    @abstractmethod\n",
        "    def validate_source(self, step: Step, source: Source) -> ValidationReport: ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def transform_source(self, step: Step, source: Source) -> TransformReport: ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def write_target(self, step: Step, source: Source) -> WriteReport: ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.models.execution (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: models.base, models.exceptions, models.pipeline, pipeline_builder_base.models.base, pipeline_builder_base.models.enums, pipeline_builder_base.models.enums, pipeline_builder_base.models.exceptions, pipeline_builder_base.models.pipeline\n",
        "\n",
        "\"\"\"\n",
        "Execution models for the Pipeline Builder.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import uuid\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime, timezone\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "# from .base import BaseModel  # Removed: defined in notebook cells above\n",
        "# from .enums import ExecutionMode, PipelinePhase  # Removed: defined in notebook cells above\n",
        "# from .exceptions import PipelineConfigurationError  # Removed: defined in notebook cells above\n",
        "# from .pipeline import PipelineMetrics  # Removed: defined in notebook cells above\n",
        "\n",
        "@dataclass\n",
        "class ExecutionContext(BaseModel):\n",
        "    \"\"\"\n",
        "    Context for pipeline execution.\n",
        "\n",
        "    Attributes:\n",
        "        mode: Execution mode (initial/incremental)\n",
        "        start_time: When execution started\n",
        "        end_time: When execution ended\n",
        "        duration_secs: Total execution duration\n",
        "        run_id: Unique run identifier\n",
        "        execution_id: Unique identifier for this execution\n",
        "        pipeline_id: Identifier for the pipeline being executed\n",
        "        schema: Target schema for data storage\n",
        "        started_at: When execution started (alias for start_time)\n",
        "        ended_at: When execution ended (alias for end_time)\n",
        "        run_mode: Mode of execution (alias for mode)\n",
        "        config: Pipeline configuration as dictionary\n",
        "    \"\"\"\n",
        "\n",
        "    mode: ExecutionMode\n",
        "    start_time: datetime\n",
        "    end_time: Optional[datetime] = None\n",
        "    duration_secs: Optional[float] = None\n",
        "    run_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
        "\n",
        "    # Additional fields for writer compatibility\n",
        "    execution_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
        "    pipeline_id: str = \"unknown\"\n",
        "    schema: str = \"default\"\n",
        "    started_at: Optional[datetime] = None\n",
        "    ended_at: Optional[datetime] = None\n",
        "    run_mode: str = \"initial\"\n",
        "    config: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        \"\"\"Initialize aliases and defaults.\"\"\"\n",
        "        if self.started_at is None:\n",
        "            self.started_at = self.start_time\n",
        "        if self.ended_at is None:\n",
        "            self.ended_at = self.end_time\n",
        "        if self.run_mode == \"initial\":\n",
        "            # Map mode to run_mode string\n",
        "            if hasattr(self.mode, \"value\"):\n",
        "                self.run_mode = self.mode.value\n",
        "            elif hasattr(self.mode, \"name\"):\n",
        "                self.run_mode = self.mode.name.lower()\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the execution context.\"\"\"\n",
        "        if not self.run_id:\n",
        "            raise ValueError(\"Run ID cannot be empty\")\n",
        "        if self.duration_secs is not None and self.duration_secs < 0:\n",
        "            raise ValueError(\"Duration cannot be negative\")\n",
        "\n",
        "    def finish(self) -> None:\n",
        "        \"\"\"Mark execution as finished and calculate duration.\"\"\"\n",
        "        self.end_time = datetime.now(timezone.utc)\n",
        "        if self.start_time:\n",
        "            self.duration_secs = (self.end_time - self.start_time).total_seconds()\n",
        "\n",
        "    @property\n",
        "    def is_finished(self) -> bool:\n",
        "        \"\"\"Check if execution is finished.\"\"\"\n",
        "        return self.end_time is not None\n",
        "\n",
        "    @property\n",
        "    def is_running(self) -> bool:\n",
        "        \"\"\"Check if execution is currently running.\"\"\"\n",
        "        return not self.is_finished\n",
        "\n",
        "@dataclass\n",
        "class StageStats(BaseModel):\n",
        "    \"\"\"\n",
        "    Statistics for a pipeline stage.\n",
        "\n",
        "    Attributes:\n",
        "        stage: Stage name (bronze/silver/gold)\n",
        "        step: Step name\n",
        "        total_rows: Total number of rows processed\n",
        "        valid_rows: Number of valid rows\n",
        "        invalid_rows: Number of invalid rows\n",
        "        validation_rate: Validation success rate (0-100)\n",
        "        duration_secs: Processing duration in seconds\n",
        "        start_time: When processing started\n",
        "        end_time: When processing ended\n",
        "    \"\"\"\n",
        "\n",
        "    stage: str\n",
        "    step: str\n",
        "    total_rows: int\n",
        "    valid_rows: int\n",
        "    invalid_rows: int\n",
        "    validation_rate: float\n",
        "    duration_secs: float\n",
        "    start_time: Optional[datetime] = None\n",
        "    end_time: Optional[datetime] = None\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate stage statistics.\"\"\"\n",
        "        if self.total_rows != self.valid_rows + self.invalid_rows:\n",
        "            raise PipelineConfigurationError(\n",
        "                f\"Total rows ({self.total_rows}) must equal valid ({self.valid_rows}) + invalid ({self.invalid_rows})\"\n",
        "            )\n",
        "        if not 0 <= self.validation_rate <= 100:\n",
        "            raise PipelineConfigurationError(\n",
        "                f\"Validation rate must be between 0 and 100, got {self.validation_rate}\"\n",
        "            )\n",
        "        if self.duration_secs < 0:\n",
        "            raise PipelineConfigurationError(\n",
        "                f\"Duration must be non-negative, got {self.duration_secs}\"\n",
        "            )\n",
        "\n",
        "    @property\n",
        "    def is_valid(self) -> bool:\n",
        "        \"\"\"Check if the stage passed validation.\"\"\"\n",
        "        return self.validation_rate >= 95.0  # Default threshold\n",
        "\n",
        "    @property\n",
        "    def error_rate(self) -> float:\n",
        "        \"\"\"Calculate error rate.\"\"\"\n",
        "        if self.total_rows == 0:\n",
        "            return 0.0\n",
        "        return (self.invalid_rows / self.total_rows) * 100\n",
        "\n",
        "    @property\n",
        "    def throughput_rows_per_sec(self) -> float:\n",
        "        \"\"\"Calculate throughput in rows per second.\"\"\"\n",
        "        if self.duration_secs == 0:\n",
        "            return 0.0\n",
        "        return self.total_rows / self.duration_secs\n",
        "\n",
        "@dataclass\n",
        "class StepResult(BaseModel):\n",
        "    \"\"\"\n",
        "    Result of a pipeline step execution.\n",
        "\n",
        "    Attributes:\n",
        "        step_name: Name of the step\n",
        "        phase: Pipeline phase\n",
        "        success: Whether the step succeeded\n",
        "        start_time: When execution started\n",
        "        end_time: When execution ended\n",
        "        duration_secs: Execution duration in seconds\n",
        "        rows_processed: Number of rows processed\n",
        "        rows_written: Number of rows written\n",
        "        validation_rate: Validation success rate\n",
        "        error_message: Error message if failed\n",
        "        step_type: Type of step (bronze, silver, gold)\n",
        "        table_fqn: Fully qualified table name if step writes to table\n",
        "        write_mode: Write mode used (overwrite, append)\n",
        "        input_rows: Number of input rows processed\n",
        "    \"\"\"\n",
        "\n",
        "    step_name: str\n",
        "    phase: PipelinePhase\n",
        "    success: bool\n",
        "    start_time: datetime\n",
        "    end_time: datetime\n",
        "    duration_secs: float\n",
        "    rows_processed: int\n",
        "    rows_written: int\n",
        "    validation_rate: float\n",
        "    error_message: Optional[str] = None\n",
        "    step_type: Optional[str] = None\n",
        "    table_fqn: Optional[str] = None\n",
        "    write_mode: Optional[str] = None\n",
        "    input_rows: Optional[int] = None\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the step result.\"\"\"\n",
        "        if not self.step_name:\n",
        "            raise ValueError(\"Step name cannot be empty\")\n",
        "        if self.duration_secs < 0:\n",
        "            raise ValueError(\"Duration cannot be negative\")\n",
        "        if self.rows_processed < 0:\n",
        "            raise ValueError(\"Rows processed cannot be negative\")\n",
        "        if self.rows_written < 0:\n",
        "            raise ValueError(\"Rows written cannot be negative\")\n",
        "        if not 0 <= self.validation_rate <= 100:\n",
        "            raise ValueError(\"Validation rate must be between 0 and 100\")\n",
        "\n",
        "    @property\n",
        "    def is_valid(self) -> bool:\n",
        "        \"\"\"Check if the step result is valid.\"\"\"\n",
        "        return self.success and self.validation_rate >= 95.0\n",
        "\n",
        "    @property\n",
        "    def is_high_quality(self) -> bool:\n",
        "        \"\"\"Check if the step result is high quality.\"\"\"\n",
        "        return self.success and self.validation_rate >= 98.0\n",
        "\n",
        "    @property\n",
        "    def throughput_rows_per_sec(self) -> float:\n",
        "        \"\"\"Calculate throughput in rows per second.\"\"\"\n",
        "        if self.duration_secs == 0:\n",
        "            return 0.0\n",
        "        return self.rows_processed / self.duration_secs\n",
        "\n",
        "    @classmethod\n",
        "    def create_success(\n",
        "        cls,\n",
        "        step_name: str,\n",
        "        phase: PipelinePhase,\n",
        "        start_time: datetime,\n",
        "        end_time: datetime,\n",
        "        rows_processed: int,\n",
        "        rows_written: int,\n",
        "        validation_rate: float,\n",
        "        step_type: Optional[str] = None,\n",
        "        table_fqn: Optional[str] = None,\n",
        "        write_mode: Optional[str] = None,\n",
        "        input_rows: Optional[int] = None,\n",
        "    ) -> StepResult:\n",
        "        \"\"\"Create a successful step result.\"\"\"\n",
        "        duration_secs = (end_time - start_time).total_seconds()\n",
        "        return cls(\n",
        "            step_name=step_name,\n",
        "            phase=phase,\n",
        "            success=True,\n",
        "            start_time=start_time,\n",
        "            end_time=end_time,\n",
        "            duration_secs=duration_secs,\n",
        "            rows_processed=rows_processed,\n",
        "            rows_written=rows_written,\n",
        "            validation_rate=validation_rate,\n",
        "            error_message=None,\n",
        "            step_type=step_type,\n",
        "            table_fqn=table_fqn,\n",
        "            write_mode=write_mode,\n",
        "            input_rows=input_rows,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def create_failure(\n",
        "        cls,\n",
        "        step_name: str,\n",
        "        phase: PipelinePhase,\n",
        "        start_time: datetime,\n",
        "        end_time: datetime,\n",
        "        error_message: str,\n",
        "        step_type: Optional[str] = None,\n",
        "        table_fqn: Optional[str] = None,\n",
        "        write_mode: Optional[str] = None,\n",
        "        input_rows: Optional[int] = None,\n",
        "    ) -> StepResult:\n",
        "        \"\"\"Create a failed step result.\"\"\"\n",
        "        duration_secs = (end_time - start_time).total_seconds()\n",
        "        return cls(\n",
        "            step_name=step_name,\n",
        "            phase=phase,\n",
        "            success=False,\n",
        "            start_time=start_time,\n",
        "            end_time=end_time,\n",
        "            duration_secs=duration_secs,\n",
        "            rows_processed=0,\n",
        "            rows_written=0,\n",
        "            validation_rate=0.0,\n",
        "            error_message=error_message,\n",
        "            step_type=step_type,\n",
        "            table_fqn=table_fqn,\n",
        "            write_mode=write_mode,\n",
        "            input_rows=input_rows,\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def error_rate(self) -> float:\n",
        "        \"\"\"Calculate error rate.\"\"\"\n",
        "        if self.rows_processed == 0:\n",
        "            return 0.0\n",
        "        return 100.0 - self.validation_rate\n",
        "\n",
        "@dataclass\n",
        "class ExecutionResult(BaseModel):\n",
        "    \"\"\"\n",
        "    Result of pipeline execution.\n",
        "\n",
        "    Attributes:\n",
        "        context: Execution context\n",
        "        step_results: Results for each step\n",
        "        metrics: Overall execution metrics\n",
        "        success: Whether the entire pipeline succeeded\n",
        "    \"\"\"\n",
        "\n",
        "    context: ExecutionContext\n",
        "    step_results: list[StepResult]\n",
        "    metrics: PipelineMetrics\n",
        "    success: bool\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate execution result.\"\"\"\n",
        "        if not isinstance(self.context, ExecutionContext):\n",
        "            raise PipelineConfigurationError(\n",
        "                \"Context must be an ExecutionContext instance\"\n",
        "            )\n",
        "        if not isinstance(self.step_results, list):\n",
        "            raise PipelineConfigurationError(\"Step results must be a list\")\n",
        "        if not isinstance(self.metrics, PipelineMetrics):\n",
        "            raise PipelineConfigurationError(\n",
        "                \"Metrics must be a PipelineMetrics instance\"\n",
        "            )\n",
        "        if not isinstance(self.success, bool):\n",
        "            raise PipelineConfigurationError(\"Success must be a boolean\")\n",
        "\n",
        "    @classmethod\n",
        "    def from_context_and_results(\n",
        "        cls, context: ExecutionContext, step_results: list[StepResult]\n",
        "    ) -> ExecutionResult:\n",
        "        \"\"\"Create execution result from context and step results.\"\"\"\n",
        "        metrics = PipelineMetrics.from_step_results(step_results)\n",
        "        success = all(result.success for result in step_results)\n",
        "        return cls(\n",
        "            context=context, step_results=step_results, metrics=metrics, success=success\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.pipeline.models (pipeline_builder)\n",
        "#\n",
        "# Dependencies: models.pipeline, pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Pipeline models and data structures for the framework.\n",
        "\n",
        "This module defines the core data structures used throughout the pipeline system,\n",
        "providing a clean separation of concerns and better type safety.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "from typing import Any, Dict, Optional\n",
        "# from .models import PipelineMetrics  # Removed: defined in notebook cells above\n",
        "\n",
        "class PipelineMode(Enum):\n",
        "    \"\"\"Pipeline execution modes.\"\"\"\n",
        "\n",
        "    INITIAL = \"initial\"\n",
        "    INCREMENTAL = \"incremental\"\n",
        "    FULL_REFRESH = \"full_refresh\"\n",
        "    VALIDATION_ONLY = \"validation_only\"\n",
        "\n",
        "class PipelineStatus(Enum):\n",
        "    \"\"\"Pipeline execution status.\"\"\"\n",
        "\n",
        "    PENDING = \"pending\"\n",
        "    RUNNING = \"running\"\n",
        "    COMPLETED = \"completed\"\n",
        "    FAILED = \"failed\"\n",
        "    CANCELLED = \"cancelled\"\n",
        "    PAUSED = \"paused\"\n",
        "\n",
        "# PipelineMetrics moved to main models.py to avoid duplication\n",
        "\n",
        "@dataclass\n",
        "class PipelineReport:\n",
        "    \"\"\"Comprehensive pipeline execution report.\"\"\"\n",
        "\n",
        "    pipeline_id: str\n",
        "    execution_id: str\n",
        "    mode: PipelineMode\n",
        "    status: PipelineStatus  # Protocol expects str, but we use enum - structural typing allows this\n",
        "    start_time: datetime\n",
        "    end_time: Optional[datetime] = None\n",
        "    duration_seconds: float = 0.0\n",
        "    metrics: PipelineMetrics = field(default_factory=PipelineMetrics)\n",
        "    bronze_results: Dict[str, Any] = field(default_factory=dict)\n",
        "    silver_results: Dict[str, Any] = field(default_factory=dict)\n",
        "    gold_results: Dict[str, Any] = field(default_factory=dict)\n",
        "    errors: list[str] = field(default_factory=list)\n",
        "    warnings: list[str] = field(default_factory=list)\n",
        "    recommendations: list[str] = field(default_factory=list)\n",
        "\n",
        "    @property\n",
        "    def success(self) -> bool:\n",
        "        \"\"\"Whether the pipeline executed successfully.\"\"\"\n",
        "        return self.status == PipelineStatus.COMPLETED and len(self.errors) == 0\n",
        "\n",
        "    @property\n",
        "    def status_str(self) -> str:\n",
        "        \"\"\"Return status as string for Protocol compatibility.\"\"\"\n",
        "        return self.status.value\n",
        "\n",
        "    @property\n",
        "    def successful_steps(self) -> int:\n",
        "        \"\"\"Number of successful steps.\"\"\"\n",
        "        return self.metrics.successful_steps\n",
        "\n",
        "    @property\n",
        "    def failed_steps(self) -> int:\n",
        "        \"\"\"Number of failed steps.\"\"\"\n",
        "        return self.metrics.failed_steps\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Convert report to dictionary.\"\"\"\n",
        "        return {\n",
        "            \"pipeline_id\": self.pipeline_id,\n",
        "            \"execution_id\": self.execution_id,\n",
        "            \"mode\": self.mode.value,\n",
        "            \"status\": self.status.value,\n",
        "            \"start_time\": self.start_time.isoformat(),\n",
        "            \"end_time\": self.end_time.isoformat() if self.end_time else None,\n",
        "            \"duration_seconds\": self.duration_seconds,\n",
        "            \"metrics\": {\n",
        "                \"total_steps\": self.metrics.total_steps,\n",
        "                \"successful_steps\": self.metrics.successful_steps,\n",
        "                \"failed_steps\": self.metrics.failed_steps,\n",
        "                \"skipped_steps\": self.metrics.skipped_steps,\n",
        "                \"total_duration\": self.metrics.total_duration,\n",
        "                \"bronze_duration\": self.metrics.bronze_duration,\n",
        "                \"silver_duration\": self.metrics.silver_duration,\n",
        "                \"gold_duration\": self.metrics.gold_duration,\n",
        "                \"total_rows_processed\": self.metrics.total_rows_processed,\n",
        "                \"total_rows_written\": self.metrics.total_rows_written,\n",
        "                \"cache_hit_rate\": self.metrics.cache_hit_rate,\n",
        "                \"error_count\": self.metrics.error_count,\n",
        "                \"retry_count\": self.metrics.retry_count,\n",
        "            },\n",
        "            \"bronze_results\": self.bronze_results,\n",
        "            \"silver_results\": self.silver_results,\n",
        "            \"gold_results\": self.gold_results,\n",
        "            \"errors\": self.errors,\n",
        "            \"warnings\": self.warnings,\n",
        "            \"recommendations\": self.recommendations,\n",
        "        }\n",
        "\n",
        "# PipelineConfig moved to main models.py to avoid duplication\n",
        "\n",
        "@dataclass\n",
        "class StepExecutionContext:\n",
        "    \"\"\"Context for step execution.\"\"\"\n",
        "\n",
        "    step_name: str\n",
        "    step_type: str\n",
        "    mode: PipelineMode\n",
        "    start_time: datetime\n",
        "    dependencies: list[str] = field(default_factory=list)\n",
        "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "    @property\n",
        "    def duration(self) -> float:\n",
        "        \"\"\"Duration of step execution in seconds.\"\"\"\n",
        "        return (datetime.now() - self.start_time).total_seconds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.compat_helpers (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat\n",
        "\n",
        "\"\"\"\n",
        "Compatibility helpers for working with protocol-based Spark sessions.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Optional\n",
        "\n",
        "# from .compat import SparkSession  # Removed: defined in notebook cells above\n",
        "\n",
        "def create_dataframe_compat(\n",
        "    spark: SparkSession,  # type: ignore[valid-type]\n",
        "    data: Any,\n",
        "    schema: Optional[Any] = None,\n",
        "    original_method: Optional[Any] = None,\n",
        "    **kwargs: Any,\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    Create DataFrame with compatibility for PySpark.\n",
        "\n",
        "    Supports all schema formats: list of strings, StructType, None.\n",
        "    Handles PySpark 3.5+ schema argument position differences.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance\n",
        "        data: Data to create DataFrame from (list of tuples, list of dicts, etc.)\n",
        "        schema: Schema definition (list of strings, StructType, or None)\n",
        "        original_method: Original createDataFrame method (to avoid recursion when monkey-patched)\n",
        "        **kwargs: Additional arguments passed to createDataFrame\n",
        "\n",
        "    Returns:\n",
        "        DataFrame instance\n",
        "    \"\"\"\n",
        "    # Use original method if provided (to avoid recursion), otherwise use spark.createDataFrame\n",
        "    create_df = (\n",
        "        original_method if original_method is not None else spark.createDataFrame\n",
        "    )\n",
        "\n",
        "    # Call createDataFrame method\n",
        "    # Handle PySpark 3.5+ schema argument issues (PySpark bug, not mock-spark)\n",
        "    if schema is None:\n",
        "        return create_df(data, **kwargs)\n",
        "    else:\n",
        "        # Try different calling patterns to handle PySpark version differences\n",
        "        # Pattern 1: Positional schema (PySpark 3.5+)\n",
        "        try:\n",
        "            if kwargs:\n",
        "                return create_df(data, schema, **kwargs)\n",
        "            else:\n",
        "                return create_df(data, schema)\n",
        "        except Exception as e:\n",
        "            error_str = str(e)\n",
        "            # Check if this is the PySpark StructType error (known PySpark 3.5+ bug)\n",
        "            if \"NOT_LIST_OR_NONE_OR_STRUCT\" in error_str:\n",
        "                # Try without kwargs\n",
        "                try:\n",
        "                    return create_df(data, schema)\n",
        "                except Exception:\n",
        "                    # Last resort: try with schema as keyword\n",
        "                    return create_df(data, schema=schema, **kwargs)\n",
        "            # For other errors, try keyword argument (older PySpark)\n",
        "            try:\n",
        "                return create_df(data, schema=schema, **kwargs)\n",
        "            except Exception:\n",
        "                # Final fallback: try without kwargs and keyword schema\n",
        "                return create_df(data, schema=schema)\n",
        "\n",
        "def is_dataframe_like(obj: Any) -> bool:\n",
        "    \"\"\"\n",
        "    Check if object is DataFrame-like using structural typing.\n",
        "\n",
        "    Checks for essential DataFrame methods: count, columns (property), filter.\n",
        "\n",
        "    Args:\n",
        "        obj: Object to check\n",
        "\n",
        "    Returns:\n",
        "        True if object has DataFrame-like interface, False otherwise\n",
        "    \"\"\"\n",
        "    # columns is typically a property (not callable), count and filter are methods\n",
        "    return (\n",
        "        hasattr(obj, \"count\")\n",
        "        and hasattr(obj, \"columns\")\n",
        "        and hasattr(obj, \"filter\")\n",
        "        and callable(getattr(obj, \"count\", None))\n",
        "        and callable(getattr(obj, \"filter\", None))\n",
        "    )\n",
        "\n",
        "def detect_spark_type(spark: SparkSession) -> str:\n",
        "    \"\"\"\n",
        "    Detect if spark session is PySpark.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance to check\n",
        "\n",
        "    Returns:\n",
        "        'pyspark', 'mock', or 'unknown'\n",
        "    \"\"\"\n",
        "    # Fast-path: PySpark sessions have a JVM bridge\n",
        "    if hasattr(spark, \"sparkContext\") and hasattr(spark.sparkContext, \"_jsc\"):\n",
        "        return \"pyspark\"\n",
        "\n",
        "    try:\n",
        "        spark_module = type(spark).__module__\n",
        "        if \"pyspark\" in spark_module:\n",
        "            return \"pyspark\"\n",
        "        # Detect sparkless/mock sessions by module path\n",
        "        if \"sparkless\" in spark_module or \"mock\" in spark_module:\n",
        "            return \"mock\"\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Fallback to engine name if available\n",
        "    try:\n",
        "        # from .compat import compat_name  # Local import to avoid cycles  # Removed: defined in notebook cells above\n",
        "\n",
        "        engine_name = compat_name()\n",
        "        if engine_name in {\"mock\", \"sparkless\"}:\n",
        "            return \"mock\"\n",
        "        if engine_name == \"pyspark\":\n",
        "            return \"pyspark\"\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return \"unknown\"\n",
        "\n",
        "def create_test_dataframe(\n",
        "    spark: SparkSession,  # type: ignore[valid-type]\n",
        "    data: Any,\n",
        "    schema: Optional[Any] = None,\n",
        "    **kwargs: Any,\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    High-level helper for creating test DataFrames.\n",
        "\n",
        "    Provides a consistent API for creating DataFrames in tests.\n",
        "    Handles PySpark 3.5+ schema argument position differences.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance (PySpark or mock-spark)\n",
        "        data: Data to create DataFrame from (list of tuples, list of dicts, etc.)\n",
        "        schema: Schema definition (list of strings, StructType, or None)\n",
        "        **kwargs: Additional arguments passed to createDataFrame\n",
        "\n",
        "    Returns:\n",
        "        DataFrame instance\n",
        "    \"\"\"\n",
        "    return create_dataframe_compat(spark, data, schema, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.functions (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.protocols\n",
        "\n",
        "\"\"\"\n",
        "Functions interface protocol for the framework.\n",
        "\n",
        "This module provides a protocol-based interface for PySpark functions that can\n",
        "be injected into framework components. This design allows for better testability,\n",
        "flexibility, and engine abstraction.\n",
        "\n",
        "**Key Features:**\n",
        "    - **Protocol-Based**: Uses Python Protocol for type safety and duck typing\n",
        "    - **Engine Abstraction**: Works with both real PySpark and mock implementations\n",
        "    - **Injection Support**: Functions can be injected via engine configuration\n",
        "    - **Type Safety**: Provides type hints for all function signatures\n",
        "\n",
        "**Usage:**\n",
        "    The functions protocol is typically accessed through the compat module:\n",
        "\n",
        "    >>> from pipeline_builder.compat import F\n",
        "    >>> df.select(F.col(\"id\"), F.lit(\"test\"))\n",
        "\n",
        "    Or via the get_default_functions() helper:\n",
        "\n",
        "    >>> from pipeline_builder.functions import get_default_functions\n",
        "    >>> F = get_default_functions()\n",
        "    >>> df.select(F.col(\"id\"))\n",
        "\n",
        "**Supported Functions:**\n",
        "    The protocol defines common PySpark functions including:\n",
        "    - Column operations: col, expr, lit, when\n",
        "    - Aggregations: count, countDistinct, sum, max, min, avg\n",
        "    - String functions: length\n",
        "    - Date functions: date_trunc, dayofweek, current_timestamp\n",
        "\n",
        "Dependencies:\n",
        "    - compat: Compatibility layer for engine detection\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.functions import FunctionsProtocol, get_default_functions\n",
        "    >>> from pipeline_builder.compat import F\n",
        "    >>>\n",
        "    >>> # Get functions from compat module\n",
        "    >>> functions = get_default_functions()\n",
        "    >>> # Use functions for DataFrame operations\n",
        "    >>> df.select(functions.col(\"id\"), functions.lit(\"value\"))\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Optional, Protocol, Union, cast\n",
        "\n",
        "# from .protocols import ColumnProtocol  # Removed: defined in notebook cells above\n",
        "\n",
        "class FunctionsProtocol(Protocol):\n",
        "    \"\"\"Protocol for PySpark functions interface.\n",
        "\n",
        "    This protocol defines the interface that all functions implementations\n",
        "    must satisfy. It includes common PySpark functions for column operations,\n",
        "    aggregations, and transformations.\n",
        "\n",
        "    **Implementation Requirements:**\n",
        "        Any class or module implementing this protocol must provide all\n",
        "        the methods defined here with matching signatures. The protocol\n",
        "        supports both real PySpark functions and mock implementations\n",
        "        for testing.\n",
        "\n",
        "    **Common Implementations:**\n",
        "        - PySpark `pyspark.sql.functions` module\n",
        "        - Mock functions for testing (see test utilities)\n",
        "        - Custom function wrappers for specific engines\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.functions import FunctionsProtocol\n",
        "        >>> from pipeline_builder.compat import F\n",
        "        >>>\n",
        "        >>> # F implements FunctionsProtocol\n",
        "        >>> def use_functions(f: FunctionsProtocol):\n",
        "        ...     return f.col(\"id\")\n",
        "        >>>\n",
        "        >>> result = use_functions(F)\n",
        "    \"\"\"\n",
        "\n",
        "    def col(self, col_name: str) -> ColumnProtocol:\n",
        "        \"\"\"Create a column reference.\n",
        "\n",
        "        Args:\n",
        "            col_name: Name of the column to reference.\n",
        "\n",
        "        Returns:\n",
        "            Column expression representing the column reference.\n",
        "\n",
        "        Example:\n",
        "            >>> F.col(\"user_id\")\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "    def expr(self, expr: str) -> ColumnProtocol:\n",
        "        \"\"\"Create an expression from a string.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def lit(\n",
        "        self, value: Union[str, int] | Union[float, Optional[bool]]\n",
        "    ) -> ColumnProtocol:\n",
        "        \"\"\"Create a literal column.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def when(\n",
        "        self,\n",
        "        condition: ColumnProtocol,\n",
        "        value: Union[str, int] | Union[float, Optional[bool]],\n",
        "    ) -> ColumnProtocol:\n",
        "        \"\"\"Create a conditional expression.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def count(self, col: Union[str, ColumnProtocol] = \"*\") -> ColumnProtocol:\n",
        "        \"\"\"Create a count aggregation.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def countDistinct(self, *cols: Union[str, ColumnProtocol]) -> ColumnProtocol:\n",
        "        \"\"\"Create a count distinct aggregation.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def sum(self, col: Union[str, ColumnProtocol]) -> ColumnProtocol:\n",
        "        \"\"\"Create a sum aggregation.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def max(self, col: Union[str, ColumnProtocol]) -> ColumnProtocol:\n",
        "        \"\"\"Create a max aggregation.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def min(self, col: Union[str, ColumnProtocol]) -> ColumnProtocol:\n",
        "        \"\"\"Create a min aggregation.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def avg(self, col: Union[str, ColumnProtocol]) -> ColumnProtocol:\n",
        "        \"\"\"Create an average aggregation.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def length(self, col: Union[str, ColumnProtocol]) -> ColumnProtocol:\n",
        "        \"\"\"Create a length function.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def date_trunc(\n",
        "        self, format: str, col: Union[str, ColumnProtocol]\n",
        "    ) -> ColumnProtocol:\n",
        "        \"\"\"Create a date truncation function.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def dayofweek(self, col: Union[str, ColumnProtocol]) -> ColumnProtocol:\n",
        "        \"\"\"Create a day of week function.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def current_timestamp(self) -> ColumnProtocol:\n",
        "        \"\"\"Create a current timestamp function.\"\"\"\n",
        "        ...\n",
        "\n",
        "def get_default_functions() -> FunctionsProtocol:\n",
        "    \"\"\"Get the injected functions implementation.\n",
        "\n",
        "    Returns the functions module (F) from the configured engine. This is\n",
        "    the same as accessing `F` directly from the compat module, but provides\n",
        "    a typed interface for dependency injection.\n",
        "\n",
        "    Returns:\n",
        "        FunctionsProtocol instance from the configured engine. This is\n",
        "        typically the PySpark functions module or a mock equivalent.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.functions import get_default_functions\n",
        "        >>> F = get_default_functions()\n",
        "        >>> # Use F for DataFrame operations\n",
        "        >>> df.select(F.col(\"id\"), F.count(\"*\"))\n",
        "    \"\"\"\n",
        "\n",
        "    # from .compat import F  # Removed: defined in notebook cells above\n",
        "    from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "\n",
        "    return cast(FunctionsProtocol, F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.types (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.compat\n",
        "\n",
        "\"\"\"\n",
        "Simplified type definitions for the framework.\n",
        "\n",
        "This module provides essential type definitions and aliases\n",
        "for better type safety without over-engineering.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from enum import Enum\n",
        "from typing import Any, Callable, Dict, List, Optional, Protocol, Union\n",
        "\n",
        "# from .compat import Column, DataFrame, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "\n",
        "# ============================================================================\n",
        "# Basic Type Aliases\n",
        "# ============================================================================\n",
        "\n",
        "# String types\n",
        "StepName = str\n",
        "PipelineId = str\n",
        "ExecutionId = str\n",
        "TableName = str\n",
        "SchemaName = str\n",
        "ErrorCode = str\n",
        "\n",
        "# Numeric types\n",
        "QualityRate = float\n",
        "Duration = float\n",
        "RowCount = int\n",
        "\n",
        "# Dictionary types\n",
        "StringDict = Dict[str, str]\n",
        "NumericDict = Dict[str, Union[int, float]]\n",
        "GenericDict = Dict[str, Any]\n",
        "OptionalDict = Optional[Dict[str, Any]]\n",
        "OptionalList = Optional[List[Any]]\n",
        "\n",
        "# ============================================================================\n",
        "# Enums\n",
        "# ============================================================================\n",
        "\n",
        "class StepType(Enum):\n",
        "    \"\"\"Types of pipeline steps.\"\"\"\n",
        "\n",
        "    BRONZE = \"bronze\"\n",
        "    SILVER = \"silver\"\n",
        "    GOLD = \"gold\"\n",
        "\n",
        "class StepStatus(Enum):\n",
        "    \"\"\"Step execution status.\"\"\"\n",
        "\n",
        "    PENDING = \"pending\"\n",
        "    RUNNING = \"running\"\n",
        "    COMPLETED = \"completed\"\n",
        "    FAILED = \"failed\"\n",
        "    SKIPPED = \"skipped\"\n",
        "\n",
        "# PipelineMode moved to pipeline/models.py to avoid duplication\n",
        "\n",
        "# ============================================================================\n",
        "# Function Types\n",
        "# ============================================================================\n",
        "\n",
        "# Transform function types\n",
        "# Note: SparkSession, DataFrame, and Column are type aliases from compat.py\n",
        "# They work correctly at runtime and mypy understands them via TYPE_CHECKING\n",
        "TransformFunction = Callable[[SparkSession, DataFrame], DataFrame]\n",
        "BronzeTransformFunction = Callable[[SparkSession, DataFrame], DataFrame]\n",
        "SilverTransformFunction = Callable[\n",
        "    [SparkSession, DataFrame, Dict[str, DataFrame], Optional[Dict[str, DataFrame]]],\n",
        "    DataFrame,\n",
        "]\n",
        "GoldTransformFunction = Callable[\n",
        "    [SparkSession, Dict[str, DataFrame], Optional[Dict[str, DataFrame]]], DataFrame\n",
        "]\n",
        "\n",
        "# Filter function type\n",
        "FilterFunction = Callable[[DataFrame], DataFrame]\n",
        "\n",
        "# ============================================================================\n",
        "# Data Types\n",
        "# ============================================================================\n",
        "\n",
        "# Column rules type\n",
        "ColumnRules = Dict[str, List[Union[str, Column]]]\n",
        "\n",
        "# Result types\n",
        "StepResult = Dict[str, Any]\n",
        "PipelineResult = Dict[str, Any]\n",
        "ExecutionResultDict = Dict[str, Any]\n",
        "ValidationResultDict = Dict[str, Any]\n",
        "\n",
        "# Context types\n",
        "StepContext = Dict[str, Any]\n",
        "ExecutionContext = Dict[str, Any]\n",
        "\n",
        "# Configuration types\n",
        "PipelineConfigDict = Dict[str, Any]\n",
        "ExecutionConfig = Dict[str, Any]\n",
        "ValidationConfig = Dict[str, Any]\n",
        "MonitoringConfig = Dict[str, Any]\n",
        "\n",
        "# Quality types\n",
        "QualityThresholds = Dict[str, float]\n",
        "\n",
        "# Error types\n",
        "ErrorContext = Dict[str, Any]\n",
        "ErrorSuggestions = List[str]\n",
        "\n",
        "# ============================================================================\n",
        "# Protocols (Simplified)\n",
        "# ============================================================================\n",
        "\n",
        "class Validatable(Protocol):\n",
        "    \"\"\"Protocol for objects that can be validated.\"\"\"\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the object and raise ValidationError if invalid.\"\"\"\n",
        "        ...\n",
        "\n",
        "class Serializable(Protocol):\n",
        "    \"\"\"Protocol for objects that can be serialized.\"\"\"\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Convert object to dictionary.\"\"\"\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.transformation.transform_service (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.models, pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"Transform service for applying transformations.\n",
        "\n",
        "This module provides a service for applying transformation functions to\n",
        "DataFrames. The TransformService handles transform function execution and\n",
        "context preparation for Silver and Gold steps.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Dict, Optional\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..models import GoldStep, SilverStep  # Removed: defined in notebook cells above\n",
        "\n",
        "class TransformService:\n",
        "    \"\"\"Service for applying transformations to DataFrames.\n",
        "\n",
        "    Handles transform function execution and context preparation for Silver\n",
        "    and Gold steps. Separates transformation logic from execution flow.\n",
        "\n",
        "    Attributes:\n",
        "        spark: SparkSession instance for DataFrame operations.\n",
        "        logger: PipelineLogger instance for logging.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.transformation.transform_service import TransformService\n",
        "        >>> from pipeline_builder.compat import SparkSession\n",
        "        >>>\n",
        "        >>> service = TransformService(spark)\n",
        "        >>> result = service.apply_silver_transform(\n",
        "        ...     step=silver_step,\n",
        "        ...     bronze_df=bronze_data,\n",
        "        ...     silvers={}\n",
        "        ... )\n",
        "        >>> gold_result = service.apply_gold_transform(\n",
        "        ...     step=gold_step,\n",
        "        ...     silvers={\"clean_events\": silver_data}\n",
        "        ... )\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the transform service.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance for DataFrame operations.\n",
        "            logger: Optional PipelineLogger instance. If None, creates a\n",
        "                default logger.\n",
        "        \"\"\"\n",
        "        self.spark = spark\n",
        "        self.logger = logger or PipelineLogger()\n",
        "\n",
        "    def apply_silver_transform(\n",
        "        self,\n",
        "        step: SilverStep,\n",
        "        bronze_df: DataFrame,\n",
        "        silvers: Dict[str, DataFrame],\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"Apply a silver step transformation.\n",
        "\n",
        "        Executes the transform function for a Silver step. Silver transforms\n",
        "        receive bronze DataFrame and silvers dictionary (usually empty).\n",
        "\n",
        "        Args:\n",
        "            step: SilverStep instance with transform function.\n",
        "            bronze_df: Bronze DataFrame to transform (source data).\n",
        "            silvers: Dictionary of silver DataFrames. Usually empty for\n",
        "                Silver steps, but available for cross-silver dependencies.\n",
        "\n",
        "        Returns:\n",
        "            Transformed DataFrame after applying the step's transform function.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If step.transform is None.\n",
        "\n",
        "        Note:\n",
        "            Silver transforms have signature:\n",
        "            (spark: SparkSession, bronze_df: DataFrame, silvers: Dict[str, DataFrame]) -> DataFrame\n",
        "        \"\"\"\n",
        "        if step.transform is None:\n",
        "            raise ValueError(f\"Silver step '{step.name}' requires a transform function\")\n",
        "\n",
        "        return step.transform(self.spark, bronze_df, silvers)  # type: ignore[call-arg,misc]\n",
        "\n",
        "    def apply_gold_transform(\n",
        "        self,\n",
        "        step: GoldStep,\n",
        "        silvers: Dict[str, DataFrame],\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"Apply a gold step transformation.\n",
        "\n",
        "        Executes the transform function for a Gold step. Gold transforms\n",
        "        receive a dictionary of silver DataFrames for aggregation and\n",
        "        business logic.\n",
        "\n",
        "        Args:\n",
        "            step: GoldStep instance with transform function.\n",
        "            silvers: Dictionary mapping silver step names to DataFrames.\n",
        "                Must contain all step.source_silvers.\n",
        "\n",
        "        Returns:\n",
        "            Transformed DataFrame after applying the step's transform function.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If step.transform is None.\n",
        "\n",
        "        Note:\n",
        "            Gold transforms have signature:\n",
        "            (spark: SparkSession, silvers: Dict[str, DataFrame]) -> DataFrame\n",
        "        \"\"\"\n",
        "        if step.transform is None:\n",
        "            raise ValueError(f\"Gold step '{step.name}' requires a transform function\")\n",
        "\n",
        "        return step.transform(self.spark, silvers)  # type: ignore[call-arg,misc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.models.types (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat\n",
        "\n",
        "\"\"\"\n",
        "Type definitions and protocols for the Pipeline Builder models.\n",
        "\n",
        "This module provides type aliases, protocols, and type definitions used\n",
        "throughout the pipeline system. It defines the structure of validation rules,\n",
        "transform functions, and model values.\n",
        "\n",
        "Key Components:\n",
        "    - **Type Aliases**: ColumnRules, TransformFunction, SilverTransformFunction,\n",
        "      GoldTransformFunction for better code readability\n",
        "    - **Protocols**: Validatable, Serializable for type checking and duck typing\n",
        "    - **Model Types**: ModelValue, ColumnRule, ResourceValue for type safety\n",
        "\n",
        "Dependencies:\n",
        "    - compat: Compatibility layer for Spark/PySpark types\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.models.types import ColumnRules, SilverTransformFunction\n",
        "    >>> from pipeline_builder.compat import SparkSession, DataFrame\n",
        "    >>>\n",
        "    >>> # Define validation rules\n",
        "    >>> rules: ColumnRules = {\n",
        "    ...     \"user_id\": [F.col(\"user_id\").isNotNull()],\n",
        "    ...     \"email\": [F.col(\"email\").contains(\"@\")]\n",
        "    ... }\n",
        "    >>>\n",
        "    >>> # Define transform function\n",
        "    >>> def clean_data(spark: SparkSession, bronze_df: DataFrame, prior_silvers: dict) -> DataFrame:\n",
        "    ...     return bronze_df.filter(F.col(\"user_id\").isNotNull())\n",
        "    >>>\n",
        "    >>> transform: SilverTransformFunction = clean_data\n",
        "\"\"\"\n",
        "\n",
        "from typing import Callable, Dict, List, Optional, Protocol, TypeVar, Union\n",
        "\n",
        "# from ..compat import Column, DataFrame, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "\n",
        "# Specific types for model values instead of Any\n",
        "ModelValue = Union[str, int, float, bool, List[str], Dict[str, str], None]\n",
        "ColumnRule = Union[DataFrame, str, bool]  # PySpark Column, string, or boolean\n",
        "ResourceValue = Union[str, int, float, bool, List[str], Dict[str, str]]\n",
        "\n",
        "# Type aliases for better readability\n",
        "ColumnRules = Dict[str, List[Union[str, Column]]]\n",
        "TransformFunction = Callable[[DataFrame], DataFrame]\n",
        "SilverTransformFunction = Callable[\n",
        "    [SparkSession, DataFrame, Dict[str, DataFrame], Optional[Dict[str, DataFrame]]],\n",
        "    DataFrame,\n",
        "]\n",
        "GoldTransformFunction = Callable[\n",
        "    [SparkSession, Dict[str, DataFrame], Optional[Dict[str, DataFrame]]], DataFrame\n",
        "]\n",
        "\n",
        "# Generic type for pipeline results\n",
        "T = TypeVar(\"T\")\n",
        "\n",
        "class Validatable(Protocol):\n",
        "    \"\"\"Protocol for objects that can be validated.\n",
        "\n",
        "    This protocol defines the interface for objects that support validation.\n",
        "    Any class implementing this protocol must provide a `validate` method\n",
        "    that checks the object's state and raises an exception if invalid.\n",
        "\n",
        "    Example:\n",
        "        >>> class MyModel:\n",
        "        ...     def validate(self) -> None:\n",
        "        ...         if not self.name:\n",
        "        ...             raise ValueError(\"Name required\")\n",
        "        >>>\n",
        "        >>> def check_valid(obj: Validatable) -> None:\n",
        "        ...     obj.validate()\n",
        "        >>>\n",
        "        >>> model = MyModel()\n",
        "        >>> check_valid(model)  # Type checker accepts this\n",
        "    \"\"\"\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the object and raise ValidationError if invalid.\n",
        "\n",
        "        Raises:\n",
        "            ValidationError: If the object is invalid. Subclasses should\n",
        "                raise specific error types (e.g., PipelineValidationError).\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "class Serializable(Protocol):\n",
        "    \"\"\"Protocol for objects that can be serialized.\n",
        "\n",
        "    This protocol defines the interface for objects that support serialization\n",
        "    to dictionaries and JSON strings. Any class implementing this protocol\n",
        "    must provide `to_dict` and `to_json` methods.\n",
        "\n",
        "    Example:\n",
        "        >>> class MyModel:\n",
        "        ...     def to_dict(self) -> Dict[str, ModelValue]:\n",
        "        ...         return {\"name\": self.name}\n",
        "        ...\n",
        "        ...     def to_json(self) -> str:\n",
        "        ...         return json.dumps(self.to_dict())\n",
        "        >>>\n",
        "        >>> def serialize(obj: Serializable) -> str:\n",
        "        ...     return obj.to_json()\n",
        "        >>>\n",
        "        >>> model = MyModel()\n",
        "        >>> serialize(model)  # Type checker accepts this\n",
        "    \"\"\"\n",
        "\n",
        "    def to_dict(self) -> Dict[str, ModelValue]:\n",
        "        \"\"\"Convert object to dictionary.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary representation of the object with all fields\n",
        "            converted to primitive types or dictionaries.\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "    def to_json(self) -> str:\n",
        "        \"\"\"Convert object to JSON string.\n",
        "\n",
        "        Returns:\n",
        "            JSON string representation of the object.\n",
        "        \"\"\"\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.storage.schema_manager (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.storage.schema_utils, pipeline_builder_base.errors, pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"Schema manager for table schema validation and management.\n",
        "\n",
        "This module provides schema validation and management functionality. The\n",
        "SchemaManager handles schema creation, retrieval, and validation operations\n",
        "for pipeline tables.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Optional, Tuple\n",
        "# from .errors import ExecutionError  # Removed: defined in notebook cells above\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import SparkSession  # Removed: defined in notebook cells above\n",
        "# from .schema_utils import get_existing_schema_safe, schemas_match  # Removed: defined in notebook cells above\n",
        "\n",
        "class SchemaManager:\n",
        "    \"\"\"Manages schema validation and operations.\n",
        "\n",
        "    Handles schema existence checks, validation, and schema matching. Provides\n",
        "    centralized schema management for the pipeline execution engine.\n",
        "\n",
        "    Attributes:\n",
        "        spark: SparkSession instance for schema operations.\n",
        "        logger: PipelineLogger instance for logging.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.storage.schema_manager import SchemaManager\n",
        "        >>> from pipeline_builder.compat import SparkSession\n",
        "        >>>\n",
        "        >>> manager = SchemaManager(spark)\n",
        "        >>> manager.ensure_schema_exists(\"analytics\")\n",
        "        >>> schema = manager.get_table_schema(\"analytics.events\")\n",
        "        >>> matches, differences = manager.validate_schema_match(\n",
        "        ...     \"analytics.events\", output_schema, ExecutionMode.INCREMENTAL, \"clean_events\"\n",
        "        ... )\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the schema manager.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance for schema operations.\n",
        "            logger: Optional PipelineLogger instance. If None, creates a\n",
        "                default logger.\n",
        "        \"\"\"\n",
        "        self.spark = spark\n",
        "        self.logger = logger or PipelineLogger()\n",
        "\n",
        "    def ensure_schema_exists(self, schema: str) -> None:\n",
        "        \"\"\"Ensure a schema exists, creating it if necessary.\n",
        "\n",
        "        Checks if schema exists in catalog, and creates it if it doesn't.\n",
        "        Uses idempotent CREATE SCHEMA IF NOT EXISTS for safe creation.\n",
        "\n",
        "        Args:\n",
        "            schema: Schema name to create or verify.\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If schema creation fails after all attempts.\n",
        "        \"\"\"\n",
        "        # Check if schema already exists\n",
        "        try:\n",
        "            databases = [db.name for db in self.spark.catalog.listDatabases()]\n",
        "            if schema in databases:\n",
        "                return  # Schema already exists, nothing to do\n",
        "        except Exception:\n",
        "            pass  # If we can't check, try to create anyway\n",
        "\n",
        "        try:\n",
        "            # Use SQL CREATE SCHEMA (works for both PySpark and mock-spark)\n",
        "            self.spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema}\")\n",
        "            # Verify it was created\n",
        "            databases = [db.name for db in self.spark.catalog.listDatabases()]\n",
        "            if schema not in databases:\n",
        "                raise ExecutionError(\n",
        "                    f\"Schema '{schema}' creation via SQL failed - schema not in catalog. \"\n",
        "                    f\"Available databases: {databases}\"\n",
        "                )\n",
        "        except ExecutionError:\n",
        "            raise  # Re-raise ExecutionError\n",
        "        except Exception as e:\n",
        "            # Wrap other exceptions\n",
        "            raise ExecutionError(f\"Failed to create schema '{schema}': {str(e)}\") from e\n",
        "\n",
        "    def get_table_schema(\n",
        "        self,\n",
        "        table_name: str,\n",
        "        refresh: bool = False,\n",
        "    ) -> Optional[Any]:\n",
        "        \"\"\"\n",
        "        Get the schema of an existing table.\n",
        "\n",
        "        Args:\n",
        "            table_name: Fully qualified table name\n",
        "            refresh: Whether to refresh table metadata before reading schema\n",
        "\n",
        "        Returns:\n",
        "            StructType schema if table exists and schema is readable, None otherwise\n",
        "        \"\"\"\n",
        "        if refresh:\n",
        "            try:\n",
        "                self.spark.sql(f\"REFRESH TABLE {table_name}\")\n",
        "            except Exception as refresh_error:\n",
        "                # Refresh might fail for some table types - log but continue\n",
        "                self.logger.debug(\n",
        "                    f\"Could not refresh table {table_name} before schema read: {refresh_error}\"\n",
        "                )\n",
        "\n",
        "        return get_existing_schema_safe(self.spark, table_name)\n",
        "\n",
        "    def validate_schema_match(\n",
        "        self,\n",
        "        table_name: str,\n",
        "        output_schema: Any,\n",
        "        mode: Any,\n",
        "        step_name: str,\n",
        "    ) -> Tuple[bool, list[str]]:\n",
        "        \"\"\"\n",
        "        Validate that output schema matches existing table schema.\n",
        "\n",
        "        Args:\n",
        "            table_name: Fully qualified table name\n",
        "            output_schema: Schema of the output DataFrame\n",
        "            mode: Execution mode\n",
        "            step_name: Name of the step being validated\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (matches: bool, differences: list[str])\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If schema cannot be read or doesn't match (depending on mode)\n",
        "        \"\"\"\n",
        "        existing_schema = self.get_table_schema(table_name, refresh=True)\n",
        "\n",
        "        if existing_schema is None:\n",
        "            # Cannot read schema - raise error\n",
        "            raise ExecutionError(\n",
        "                f\"Cannot read schema for table '{table_name}' in {mode.value} mode. \"\n",
        "                \"Schema validation is required for INCREMENTAL and FULL_REFRESH modes.\",\n",
        "                context={\n",
        "                    \"step_name\": step_name,\n",
        "                    \"table\": table_name,\n",
        "                    \"mode\": mode.value,\n",
        "                },\n",
        "                suggestions=[\n",
        "                    \"Ensure the table exists and is accessible\",\n",
        "                    \"Check that the table schema is readable\",\n",
        "                    \"Use INITIAL mode if you need to recreate the table\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        # If catalog reports empty schema, treat as mismatch with explicit guidance\n",
        "        schema_is_empty = not existing_schema.fields or len(existing_schema.fields) == 0\n",
        "        if schema_is_empty:\n",
        "            raise ExecutionError(\n",
        "                f\"Schema mismatch for table '{table_name}' in {mode.value} mode. \"\n",
        "                f\"Catalog reports empty schema (struct<>), but output schema has {len(output_schema.fields)} fields: {[f.name for f in output_schema.fields]}. \"\n",
        "                f\"Use INITIAL mode to recreate the table or provide schema_override explicitly.\",\n",
        "                context={\n",
        "                    \"step_name\": step_name,\n",
        "                    \"table\": table_name,\n",
        "                    \"mode\": mode.value,\n",
        "                    \"existing_schema\": \"struct<> (empty - catalog sync issue)\",\n",
        "                    \"output_schema\": str(output_schema),\n",
        "                },\n",
        "                suggestions=[\n",
        "                    \"Run initial_load/full_refresh to recreate the table with the desired schema\",\n",
        "                    \"Provide schema_override to force the schema in allowed modes\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        matches, differences = schemas_match(existing_schema, output_schema)\n",
        "\n",
        "        if not matches:\n",
        "            raise ExecutionError(\n",
        "                f\"Schema mismatch for table '{table_name}' in {mode.value} mode. \"\n",
        "                f\"Schema changes are only allowed in INITIAL mode.\\n\"\n",
        "                f\"{chr(10).join(differences)}\\n\\n\"\n",
        "                f\"Existing table schema: {existing_schema}\\n\"\n",
        "                f\"Output DataFrame schema: {output_schema}\",\n",
        "                context={\n",
        "                    \"step_name\": step_name,\n",
        "                    \"table\": table_name,\n",
        "                    \"mode\": mode.value,\n",
        "                    \"existing_schema\": str(existing_schema),\n",
        "                    \"output_schema\": str(output_schema),\n",
        "                },\n",
        "                suggestions=[\n",
        "                    \"Ensure the output schema matches the existing table schema exactly\",\n",
        "                    \"Run with INITIAL mode to recreate the table with the new schema\",\n",
        "                    \"Manually update the existing table schema to match the new schema\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        return matches, differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.writer.query_builder (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.compat\n",
        "\n",
        "# mypy: ignore-errors\n",
        "\"\"\"\n",
        "Query builder module for common PySpark DataFrame operations.\n",
        "\n",
        "This module provides reusable query builders and common aggregations\n",
        "to reduce code duplication across the writer modules.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Any, Dict\n",
        "\n",
        "# from ..compat import DataFrame  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "\n",
        "# Import specific functions for convenience\n",
        "# from ..compat import F as functions  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "\n",
        "class QueryBuilder:\n",
        "    \"\"\"Builder class for common PySpark DataFrame operations.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def filter_by_date_range(\n",
        "        df: DataFrame,\n",
        "        days: int = 30,\n",
        "        date_column: str = \"created_at\",\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Filter DataFrame by date range.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            days: Number of days to look back\n",
        "\n",
        "        Returns:\n",
        "            Filtered DataFrame\n",
        "        \"\"\"\n",
        "        end_date = datetime.now()\n",
        "        start_date = end_date - timedelta(days=days)\n",
        "        result = df.filter(\n",
        "            functions.col(date_column) >= functions.lit(start_date.strftime(\"%Y-%m-%d\"))\n",
        "        )\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def add_date_column(\n",
        "        df: DataFrame,\n",
        "        date_column: str = \"created_at\",\n",
        "        output_column: str = \"date\",\n",
        "        format: str = \"yyyy-MM-dd\",\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Add formatted date column to DataFrame.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            date_column: Source date column name\n",
        "            output_column: Output column name\n",
        "            format: Date format string\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with added date column\n",
        "        \"\"\"\n",
        "        result = df.withColumn(\n",
        "            output_column,\n",
        "            functions.date_format(functions.col(date_column), format),  # type: ignore[attr-defined]\n",
        "        )\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def get_common_aggregations() -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get common aggregation functions.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of common aggregations\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"count_all\": functions.count(\"*\").alias(\"total_executions\"),  # type: ignore[attr-defined]\n",
        "            \"count_rows\": functions.count(\"*\").alias(\"execution_count\"),  # type: ignore[attr-defined]\n",
        "            \"avg_validation_rate\": functions.avg(\"validation_rate\").alias(  # type: ignore[attr-defined]\n",
        "                \"avg_validation_rate\"\n",
        "            ),\n",
        "            \"min_validation_rate\": functions.min(\"validation_rate\").alias(  # type: ignore[attr-defined]\n",
        "                \"min_validation_rate\"\n",
        "            ),\n",
        "            \"max_validation_rate\": functions.max(\"validation_rate\").alias(  # type: ignore[attr-defined]\n",
        "                \"max_validation_rate\"\n",
        "            ),\n",
        "            \"stddev_validation_rate\": functions.stddev(\"validation_rate\").alias(  # type: ignore[attr-defined]\n",
        "                \"stddev_validation_rate\"\n",
        "            ),\n",
        "            \"avg_execution_time\": functions.avg(\"execution_time\").alias(  # type: ignore[attr-defined]\n",
        "                \"avg_execution_time\"\n",
        "            ),\n",
        "            \"min_execution_time\": functions.min(\"execution_time\").alias(  # type: ignore[attr-defined]\n",
        "                \"min_execution_time\"\n",
        "            ),\n",
        "            \"max_execution_time\": functions.max(\"execution_time\").alias(  # type: ignore[attr-defined]\n",
        "                \"max_execution_time\"\n",
        "            ),\n",
        "            \"stddev_execution_time\": functions.stddev(\"execution_time\").alias(  # type: ignore[attr-defined]\n",
        "                \"stddev_execution_time\"\n",
        "            ),\n",
        "            \"sum_rows_written\": functions.sum(\"rows_written\").alias(  # type: ignore[attr-defined]\n",
        "                \"total_rows_written\"\n",
        "            ),\n",
        "            \"successful_executions\": functions.sum(  # type: ignore[attr-defined]\n",
        "                functions.when(functions.col(\"success\"), 1).otherwise(0)  # type: ignore[attr-defined]\n",
        "            ).alias(\"successful_executions\"),\n",
        "            \"failed_executions\": functions.sum(  # type: ignore[attr-defined]\n",
        "                functions.when(~functions.col(\"success\"), 1).otherwise(0)  # type: ignore[attr-defined]\n",
        "            ).alias(\"failed_executions\"),\n",
        "            \"high_quality_executions\": functions.sum(  # type: ignore[attr-defined]\n",
        "                functions.when(functions.col(\"validation_rate\") >= 95.0, 1).otherwise(0)  # type: ignore[attr-defined]\n",
        "            ).alias(\"high_quality_executions\"),\n",
        "            \"low_quality_executions\": functions.sum(  # type: ignore[attr-defined]\n",
        "                functions.when(functions.col(\"validation_rate\") < 80.0, 1).otherwise(0)  # type: ignore[attr-defined]\n",
        "            ).alias(\"low_quality_executions\"),\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def get_quality_aggregations() -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get quality-specific aggregations.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of quality aggregations\n",
        "        \"\"\"\n",
        "        aggs = QueryBuilder.get_common_aggregations()\n",
        "        return {\n",
        "            \"total_executions\": aggs[\"count_all\"],\n",
        "            \"avg_validation_rate\": aggs[\"avg_validation_rate\"],\n",
        "            \"min_validation_rate\": aggs[\"min_validation_rate\"],\n",
        "            \"max_validation_rate\": aggs[\"max_validation_rate\"],\n",
        "            \"stddev_validation_rate\": aggs[\"stddev_validation_rate\"],\n",
        "            \"high_quality_executions\": aggs[\"high_quality_executions\"],\n",
        "            \"low_quality_executions\": aggs[\"low_quality_executions\"],\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def get_performance_aggregations() -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get performance-specific aggregations.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of performance aggregations\n",
        "        \"\"\"\n",
        "        aggs = QueryBuilder.get_common_aggregations()\n",
        "        return {\n",
        "            \"execution_count\": aggs[\"count_rows\"],\n",
        "            \"avg_execution_time\": aggs[\"avg_execution_time\"],\n",
        "            \"min_execution_time\": aggs[\"min_execution_time\"],\n",
        "            \"max_execution_time\": aggs[\"max_execution_time\"],\n",
        "            \"stddev_execution_time\": aggs[\"stddev_execution_time\"],\n",
        "            \"avg_validation_rate\": aggs[\"avg_validation_rate\"],\n",
        "            \"total_rows_written\": aggs[\"sum_rows_written\"],\n",
        "            \"successful_executions\": aggs[\"successful_executions\"],\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def get_trend_aggregations() -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get trend-specific aggregations.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of trend aggregations\n",
        "        \"\"\"\n",
        "        aggs = QueryBuilder.get_common_aggregations()\n",
        "        return {\n",
        "            \"daily_executions\": aggs[\"count_all\"],\n",
        "            \"successful_executions\": aggs[\"successful_executions\"],\n",
        "            \"failed_executions\": aggs[\"failed_executions\"],\n",
        "            \"avg_execution_time\": aggs[\"avg_execution_time\"],\n",
        "            \"total_rows_written\": aggs[\"sum_rows_written\"],\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def build_daily_trends_query(\n",
        "        df: DataFrame,\n",
        "        days: int = 30,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Build daily trends query with common aggregations.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            days: Number of days to analyze\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with daily trends\n",
        "        \"\"\"\n",
        "        filtered_df = QueryBuilder.filter_by_date_range(df, days)\n",
        "        aggs = QueryBuilder.get_trend_aggregations()\n",
        "\n",
        "        result = (\n",
        "            filtered_df.transform(lambda df: QueryBuilder.add_date_column(df))\n",
        "            .groupBy(\"date\")\n",
        "            .agg(**aggs)\n",
        "            .orderBy(\"date\")\n",
        "        )\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def build_phase_trends_query(\n",
        "        df: DataFrame,\n",
        "        days: int = 30,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Build phase trends query with common aggregations.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            days: Number of days to analyze\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with phase trends\n",
        "        \"\"\"\n",
        "        filtered_df = QueryBuilder.filter_by_date_range(df, days)\n",
        "        aggs = QueryBuilder.get_performance_aggregations()\n",
        "\n",
        "        result = filtered_df.groupBy(\"phase\").agg(**aggs).orderBy(\"phase\")\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def build_step_trends_query(\n",
        "        df: DataFrame,\n",
        "        days: int = 30,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Build step trends query with common aggregations.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            days: Number of days to analyze\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with step trends\n",
        "        \"\"\"\n",
        "        filtered_df = QueryBuilder.filter_by_date_range(df, days)\n",
        "        aggs = QueryBuilder.get_performance_aggregations()\n",
        "\n",
        "        result = (\n",
        "            filtered_df.groupBy(\"step\")\n",
        "            .agg(**aggs)\n",
        "            .orderBy(functions.desc(\"avg_execution_time\"))\n",
        "        )\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def build_quality_trends_query(\n",
        "        df: DataFrame,\n",
        "        days: int = 30,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Build quality trends query with common aggregations.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            days: Number of days to analyze\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with quality trends\n",
        "        \"\"\"\n",
        "        filtered_df = QueryBuilder.filter_by_date_range(df, days)\n",
        "        aggs = QueryBuilder.get_quality_aggregations()\n",
        "\n",
        "        return (\n",
        "            filtered_df.transform(lambda df: QueryBuilder.add_date_column(df))\n",
        "            .groupBy(\"date\")\n",
        "            .agg(**aggs)\n",
        "            .orderBy(\"date\")\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def build_overall_metrics_query(\n",
        "        df: DataFrame,\n",
        "        days: int = 30,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Build overall metrics query.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            days: Number of days to analyze\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with overall metrics\n",
        "        \"\"\"\n",
        "        filtered_df = QueryBuilder.filter_by_date_range(df, days)\n",
        "        aggs = QueryBuilder.get_quality_aggregations()\n",
        "\n",
        "        result = filtered_df.agg(**aggs)\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def build_anomaly_detection_query(\n",
        "        df: DataFrame,\n",
        "        threshold_column: str,\n",
        "        threshold_value: float,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Build anomaly detection query.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            threshold_column: Column to check against threshold\n",
        "            threshold_value: Threshold value\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with anomalies\n",
        "        \"\"\"\n",
        "        result = df.filter(functions.col(threshold_column) < threshold_value)\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def build_performance_anomaly_query(\n",
        "        df: DataFrame,\n",
        "        performance_threshold: float,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Build performance anomaly detection query.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            performance_threshold: Performance threshold value\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with performance anomalies\n",
        "        \"\"\"\n",
        "        result = df.filter(\n",
        "            (functions.col(\"execution_time\") > performance_threshold)\n",
        "            | (functions.col(\"validation_rate\") < 80.0)\n",
        "            | (~functions.col(\"success\"))\n",
        "        )\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def build_quality_anomaly_query(\n",
        "        df: DataFrame,\n",
        "        quality_threshold: float = 90.0,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Build quality anomaly detection query.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            quality_threshold: Quality threshold value\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with quality anomalies\n",
        "        \"\"\"\n",
        "        result = df.filter(functions.col(\"validation_rate\") < quality_threshold)\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def build_temporal_anomaly_query(\n",
        "        df: DataFrame,\n",
        "        change_threshold: float = -10.0,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Build temporal anomaly detection query.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            change_threshold: Change threshold value\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with temporal anomalies\n",
        "        \"\"\"\n",
        "        # First, calculate daily quality metrics\n",
        "        daily_quality_df = (\n",
        "            df.transform(lambda df: QueryBuilder.add_date_column(df))\n",
        "            .groupBy(\"date\")\n",
        "            .agg(functions.avg(\"validation_rate\").alias(\"daily_avg_validation_rate\"))\n",
        "            .orderBy(\"date\")\n",
        "        )\n",
        "\n",
        "        # Use window function to calculate lag and quality change\n",
        "        # from ..compat import Window  # Removed: defined in notebook cells above\n",
        "\n",
        "        window_spec = Window.orderBy(\"date\")\n",
        "        result = (\n",
        "            daily_quality_df.withColumn(\n",
        "                \"prev_avg_validation_rate\",\n",
        "                functions.lag(\"daily_avg_validation_rate\", 1).over(window_spec),\n",
        "            )\n",
        "            .withColumn(\n",
        "                \"quality_change\",\n",
        "                functions.col(\"daily_avg_validation_rate\")\n",
        "                - functions.col(\"prev_avg_validation_rate\"),\n",
        "            )\n",
        "            .filter(functions.col(\"quality_change\") < change_threshold)\n",
        "            .orderBy(\"quality_change\")\n",
        "        )\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_statistics(\n",
        "        df: DataFrame,\n",
        "        column: str,\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Calculate basic statistics for a column.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            column: Column name to calculate statistics for\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with statistics\n",
        "        \"\"\"\n",
        "        stats_df = df.agg(\n",
        "            functions.avg(column).alias(\"avg\"),\n",
        "            functions.stddev(column).alias(\"stddev\"),\n",
        "            functions.min(column).alias(\"min\"),\n",
        "            functions.max(column).alias(\"max\"),\n",
        "        )\n",
        "\n",
        "        result = stats_df.collect()[0]\n",
        "        return {\n",
        "            \"avg\": result[\"avg\"],\n",
        "            \"stddev\": result[\"stddev\"],\n",
        "            \"min\": result[\"min\"],\n",
        "            \"max\": result[\"max\"],\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def build_recent_performance_query(\n",
        "        df: DataFrame,\n",
        "        days: int = 7,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Build recent performance query.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            days: Number of recent days to analyze\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with recent performance\n",
        "        \"\"\"\n",
        "        filtered_df = QueryBuilder.filter_by_date_range(df, days)\n",
        "        aggs = {\n",
        "            \"daily_executions\": functions.count(\"*\").alias(\"daily_executions\"),\n",
        "            \"avg_execution_time\": functions.avg(\"execution_time\").alias(\n",
        "                \"avg_execution_time\"\n",
        "            ),\n",
        "            \"avg_validation_rate\": functions.avg(\"validation_rate\").alias(\n",
        "                \"avg_validation_rate\"\n",
        "            ),\n",
        "        }\n",
        "\n",
        "        result = (\n",
        "            filtered_df.transform(lambda df: QueryBuilder.add_date_column(df))\n",
        "            .groupBy(\"date\")\n",
        "            .agg(**aggs)\n",
        "            .orderBy(\"date\")\n",
        "        )\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.validation.utils (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.compat, pipeline_builder_base.validation\n",
        "\n",
        "\"\"\"\n",
        "Utility functions for the framework validation.\n",
        "\n",
        "This module provides utility functions for data analysis and validation operations.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict\n",
        "\n",
        "# Re-export safe_divide from base for backward compatibility\n",
        "# from .validation import safe_divide  # noqa: F401  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "\n",
        "def get_dataframe_info(df: DataFrame) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Get basic information about a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to analyze\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with DataFrame information\n",
        "    \"\"\"\n",
        "    try:\n",
        "        row_count = df.count()\n",
        "        column_count = len(df.columns)\n",
        "        schema = df.schema\n",
        "\n",
        "        return {\n",
        "            \"row_count\": row_count,\n",
        "            \"column_count\": column_count,\n",
        "            \"columns\": df.columns,\n",
        "            \"schema\": str(schema),\n",
        "            \"is_empty\": row_count == 0,\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"error\": str(e),\n",
        "            \"row_count\": 0,\n",
        "            \"column_count\": 0,\n",
        "            \"columns\": [],\n",
        "            \"schema\": \"unknown\",\n",
        "            \"is_empty\": True,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.runner (abstracts)\n",
        "#\n",
        "# Dependencies: abstracts.engine, abstracts.reports.run, abstracts.reports.transform, abstracts.reports.validation, abstracts.reports.write, abstracts.source, abstracts.step\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Dict, List, Optional, Union\n",
        "# from .engine import Engine  # Removed: defined in notebook cells above\n",
        "# from .reports.run import Report  # Removed: defined in notebook cells above\n",
        "# from .reports.transform import TransformReport  # Removed: defined in notebook cells above\n",
        "# from .reports.validation import ValidationReport  # Removed: defined in notebook cells above\n",
        "# from .reports.write import WriteReport  # Removed: defined in notebook cells above\n",
        "# from .source import Source  # Removed: defined in notebook cells above\n",
        "# from .step import Step  # Removed: defined in notebook cells above\n",
        "\n",
        "class StepRunner:\n",
        "    def __init__(self, steps: List[Step], engine: Engine) -> None:\n",
        "        self.steps = steps\n",
        "        self.engine = engine\n",
        "        self.bronze_sources: Dict[str, Source] = {}\n",
        "        self.prior_silvers: Dict[str, Source] = {}\n",
        "        self.step_reports: Dict[\n",
        "            str, Union[ValidationReport, TransformReport, WriteReport]\n",
        "        ] = {}\n",
        "\n",
        "    def __iter__(self) -> StepRunner:\n",
        "        self._current_step = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self) -> Union[ValidationReport, TransformReport, WriteReport]:\n",
        "        if self._current_step < len(self.steps):\n",
        "            step = self.steps[self._current_step]\n",
        "            self._current_step += 1\n",
        "            return self.run_step(step)\n",
        "        raise StopIteration\n",
        "\n",
        "    def run_next_step(self) -> Union[ValidationReport, TransformReport, WriteReport]:\n",
        "        return next(self)\n",
        "\n",
        "    def run_step(\n",
        "        self, step: Step\n",
        "    ) -> Union[ValidationReport, TransformReport, WriteReport]:\n",
        "        if step.type == \"bronze\":\n",
        "            if step.name not in self.bronze_sources:\n",
        "                raise ValueError(\n",
        "                    f\"Bronze source '{step.name}' not found in bronze_sources\"\n",
        "                )\n",
        "            validation_report = self.engine.validate_source(\n",
        "                step, self.bronze_sources[step.name]\n",
        "            )\n",
        "            self.step_reports[step.name] = validation_report\n",
        "            return validation_report\n",
        "        elif step.type == \"silver\":\n",
        "            if step.source is None:\n",
        "                raise ValueError(f\"Silver step '{step.name}' requires a source\")\n",
        "            if step.source not in self.prior_silvers:\n",
        "                raise ValueError(f\"Source '{step.source}' not found in prior_silvers\")\n",
        "            transform_report = self.engine.transform_source(\n",
        "                step, self.prior_silvers[step.source]\n",
        "            )\n",
        "            validation_report = self.engine.validate_source(\n",
        "                step, transform_report.source\n",
        "            )\n",
        "            self.prior_silvers[step.name] = transform_report.source\n",
        "            self.step_reports[step.name] = validation_report\n",
        "            write_report = self.engine.write_target(step, transform_report.source)\n",
        "            return write_report\n",
        "        elif step.type == \"gold\":\n",
        "            if step.source is None:\n",
        "                raise ValueError(f\"Gold step '{step.name}' requires a source\")\n",
        "            if step.source not in self.prior_silvers:\n",
        "                raise ValueError(f\"Source '{step.source}' not found in prior_silvers\")\n",
        "            transform_report = self.engine.transform_source(\n",
        "                step, self.prior_silvers[step.source]\n",
        "            )\n",
        "            write_report = self.engine.write_target(step, transform_report.source)\n",
        "            self.step_reports[step.name] = write_report\n",
        "            return write_report\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown step type: {step.type}\")\n",
        "\n",
        "class Runner(ABC):\n",
        "    \"\"\"\n",
        "    Abstract base class for pipeline runners.\n",
        "\n",
        "    Concrete implementations should provide run_initial_load and run_incremental methods.\n",
        "    Additional methods like run_full_refresh and run_validation_only can be added\n",
        "    by concrete implementations beyond the abstract interface.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, steps: List[Step], engine: Engine) -> None:\n",
        "        self.steps = steps\n",
        "        self.engine = engine\n",
        "\n",
        "    @abstractmethod\n",
        "    def run_initial_load(\n",
        "        self, bronze_sources: Optional[Dict[str, Source]] = None\n",
        "    ) -> Report:\n",
        "        \"\"\"\n",
        "        Run initial load pipeline execution.\n",
        "\n",
        "        Args:\n",
        "            bronze_sources: Dictionary mapping bronze step names to source data\n",
        "\n",
        "        Returns:\n",
        "            Report with execution results\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def run_incremental(\n",
        "        self, bronze_sources: Optional[Dict[str, Source]] = None\n",
        "    ) -> Report:\n",
        "        \"\"\"\n",
        "        Run incremental pipeline execution.\n",
        "\n",
        "        Args:\n",
        "            bronze_sources: Dictionary mapping bronze step names to source data\n",
        "\n",
        "        Returns:\n",
        "            Report with execution results\n",
        "        \"\"\"\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.pipeline.monitor (pipeline_builder)\n",
        "#\n",
        "# Dependencies: models.pipeline, pipeline.models, pipeline_builder.pipeline.models, pipeline_builder_base.logging, pipeline_builder_base.logging, pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Simplified pipeline monitoring for the framework.\n",
        "\n",
        "This module provides basic monitoring and reporting for pipeline execution.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, Optional\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .models import PipelineMetrics  # Removed: defined in notebook cells above\n",
        "\n",
        "# from .models import PipelineMode, PipelineReport, PipelineStatus  # Removed: defined in notebook cells above\n",
        "\n",
        "class SimplePipelineMonitor:\n",
        "    \"\"\"\n",
        "    Simplified pipeline monitoring.\n",
        "\n",
        "    This monitor provides basic execution tracking and reporting\n",
        "    without complex metrics collection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, logger: Optional[PipelineLogger] = None):\n",
        "        \"\"\"Initialize the simplified monitor.\"\"\"\n",
        "        self.logger = logger or PipelineLogger()\n",
        "        self._current_report: Optional[PipelineReport] = None\n",
        "\n",
        "    def start_execution(\n",
        "        self,\n",
        "        pipeline_id: str,\n",
        "        mode: PipelineMode,\n",
        "        bronze_steps: Dict[str, Any],\n",
        "        silver_steps: Dict[str, Any],\n",
        "        gold_steps: Dict[str, Any],\n",
        "    ) -> PipelineReport:\n",
        "        \"\"\"Start monitoring a pipeline execution.\"\"\"\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        self._current_report = PipelineReport(\n",
        "            pipeline_id=pipeline_id,\n",
        "            execution_id=f\"exec_{pipeline_id}\",\n",
        "            status=PipelineStatus.RUNNING,\n",
        "            mode=mode,\n",
        "            start_time=start_time,\n",
        "            end_time=None,\n",
        "            duration_seconds=0.0,\n",
        "            metrics=PipelineMetrics(\n",
        "                total_steps=len(bronze_steps) + len(silver_steps) + len(gold_steps),\n",
        "                successful_steps=0,\n",
        "                failed_steps=0,\n",
        "                total_duration=0.0,\n",
        "            ),\n",
        "            errors=[],\n",
        "            warnings=[],\n",
        "        )\n",
        "\n",
        "        self.logger.info(f\"Started monitoring pipeline: {pipeline_id}\")\n",
        "        return self._current_report\n",
        "\n",
        "    def update_step_execution(\n",
        "        self,\n",
        "        step_name: str,\n",
        "        step_type: str,\n",
        "        success: bool,\n",
        "        duration: float,\n",
        "        error_message: Optional[str] = None,\n",
        "        rows_processed: int = 0,\n",
        "        rows_written: int = 0,\n",
        "    ) -> None:\n",
        "        \"\"\"Update step execution metrics.\"\"\"\n",
        "        if not self._current_report:\n",
        "            return\n",
        "\n",
        "        if success:\n",
        "            self._current_report.metrics.successful_steps += 1\n",
        "        else:\n",
        "            self._current_report.metrics.failed_steps += 1\n",
        "            if error_message:\n",
        "                self._current_report.errors.append(f\"{step_name}: {error_message}\")\n",
        "\n",
        "        self.logger.debug(\n",
        "            f\"Updated step {step_name}: success={success}, duration={duration:.2f}s\"\n",
        "        )\n",
        "\n",
        "    def finish_execution(self, success: bool) -> PipelineReport:\n",
        "        \"\"\"Finish monitoring and return final report.\"\"\"\n",
        "        if not self._current_report:\n",
        "            raise RuntimeError(\"No active execution to finish\")\n",
        "\n",
        "        end_time = datetime.now()\n",
        "        total_duration = (end_time - self._current_report.start_time).total_seconds()\n",
        "\n",
        "        # Update final metrics\n",
        "        self._current_report.end_time = end_time\n",
        "        self._current_report.duration_seconds = total_duration\n",
        "        self._current_report.status = (\n",
        "            PipelineStatus.COMPLETED if success else PipelineStatus.FAILED\n",
        "        )\n",
        "        self._current_report.metrics.total_duration = total_duration\n",
        "\n",
        "        self.logger.info(\n",
        "            f\"Finished monitoring pipeline: {self._current_report.pipeline_id}\"\n",
        "        )\n",
        "        return self._current_report\n",
        "\n",
        "# Alias for backward compatibility\n",
        "PipelineMonitor = SimplePipelineMonitor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.validation.execution_validator (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.functions, pipeline_builder.validation, pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"Execution validator service.\n",
        "\n",
        "This module provides validation services that can be used during pipeline\n",
        "execution to validate data according to step rules. The ExecutionValidator\n",
        "separates validation logic from execution flow, making it composable and\n",
        "testable.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, Optional, Tuple\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..functions import FunctionsProtocol  # Removed: defined in notebook cells above\n",
        "# from ..validation import apply_column_rules  # Removed: defined in notebook cells above\n",
        "\n",
        "class ExecutionValidator:\n",
        "    \"\"\"Service for validating data during pipeline execution.\n",
        "\n",
        "    Handles validation logic separately from execution flow, making it\n",
        "    composable and testable. Validates DataFrames according to step rules\n",
        "    and provides validation metrics.\n",
        "\n",
        "    Attributes:\n",
        "        logger: PipelineLogger instance for logging.\n",
        "        functions: FunctionsProtocol instance for PySpark operations.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.validation.execution_validator import ExecutionValidator\n",
        "        >>> from pipeline_builder.functions import get_default_functions\n",
        "        >>>\n",
        "        >>> validator = ExecutionValidator(functions=get_default_functions())\n",
        "        >>> valid_df, invalid_df, stats = validator.validate_step_output(\n",
        "        ...     df=output_df,\n",
        "        ...     step_name=\"clean_events\",\n",
        "        ...     rules={\"status\": [F.col(\"status\").isNotNull()]}\n",
        "        ... )\n",
        "        >>> rate, invalid_count = validator.get_validation_metrics(stats)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the execution validator.\n",
        "\n",
        "        Args:\n",
        "            logger: Optional PipelineLogger instance. If None, creates a default\n",
        "                logger.\n",
        "            functions: Optional FunctionsProtocol instance for PySpark\n",
        "                operations. If None, functions must be provided when calling\n",
        "                validation methods.\n",
        "        \"\"\"\n",
        "        self.logger = logger or PipelineLogger()\n",
        "        self.functions = functions\n",
        "\n",
        "    def ensure_materialized_for_validation(\n",
        "        self,\n",
        "        df: DataFrame,\n",
        "        rules: Dict[str, Any],\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Force DataFrame materialization before validation to avoid CTE optimization issues.\n",
        "\n",
        "        Mock-spark's CTE optimization can fail when validation rules reference columns\n",
        "        created by transforms (via withColumn). By materializing the DataFrame first,\n",
        "        we ensure all columns are available in the validation context.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to potentially materialize\n",
        "            rules: Validation rules dictionary\n",
        "\n",
        "        Returns:\n",
        "            Materialized DataFrame (or original if materialization not needed/available)\n",
        "        \"\"\"\n",
        "        # Check if rules reference columns that might be new (not in original input)\n",
        "        # Materialize before validation so downstream rules see all columns.\n",
        "        if not rules:\n",
        "            return df\n",
        "\n",
        "        try:\n",
        "            if hasattr(df, \"cache\"):\n",
        "                df = df.cache()\n",
        "            _ = df.count()\n",
        "        except Exception as e:\n",
        "            # Surface materialization problems instead of masking them\n",
        "            self.logger.debug(f\"Could not materialize DataFrame before validation: {e}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def validate_step_output(\n",
        "        self,\n",
        "        df: DataFrame,\n",
        "        step_name: str,\n",
        "        rules: Dict[str, Any],\n",
        "        stage: str = \"pipeline\",\n",
        "    ) -> Tuple[DataFrame, DataFrame, Any]:\n",
        "        \"\"\"Validate step output according to rules.\n",
        "\n",
        "        Validates a DataFrame according to step validation rules. Returns\n",
        "        separate DataFrames for valid and invalid rows, plus validation\n",
        "        statistics.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to validate.\n",
        "            step_name: Name of the step being validated (for error messages).\n",
        "            rules: Dictionary mapping column names to lists of validation rules.\n",
        "            stage: Stage name for validation context. Defaults to \"pipeline\".\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (valid_df, invalid_df, validation_stats) where:\n",
        "            - valid_df: DataFrame containing rows that passed validation\n",
        "            - invalid_df: DataFrame containing rows that failed validation\n",
        "            - validation_stats: Validation statistics object with metrics\n",
        "\n",
        "        Note:\n",
        "            - Materializes DataFrame before validation to avoid CTE issues\n",
        "            - Returns empty invalid_df if no rules provided\n",
        "            - Uses apply_column_rules() for actual validation logic\n",
        "        \"\"\"\n",
        "        if not rules:\n",
        "            # No rules to apply, return original DataFrame\n",
        "            return df, df.limit(0), None\n",
        "\n",
        "        # Materialize before validation to avoid CTE issues\n",
        "        df = self.ensure_materialized_for_validation(df, rules)\n",
        "\n",
        "        # Apply validation rules\n",
        "        valid_df, invalid_df, validation_stats = apply_column_rules(\n",
        "            df,\n",
        "            rules,\n",
        "            stage,\n",
        "            step_name,\n",
        "            functions=self.functions,\n",
        "        )\n",
        "\n",
        "        return valid_df, invalid_df, validation_stats\n",
        "\n",
        "    def get_validation_metrics(\n",
        "        self,\n",
        "        validation_stats: Any,\n",
        "    ) -> Tuple[float, int]:\n",
        "        \"\"\"\n",
        "        Extract validation metrics from validation stats.\n",
        "\n",
        "        Args:\n",
        "            validation_stats: Validation statistics object\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (validation_rate, invalid_rows)\n",
        "        \"\"\"\n",
        "        if validation_stats is None:\n",
        "            return 100.0, 0\n",
        "\n",
        "        validation_rate = getattr(validation_stats, \"validation_rate\", 100.0)\n",
        "        invalid_rows = getattr(validation_stats, \"invalid_rows\", 0)\n",
        "\n",
        "        return validation_rate, invalid_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.pipeline.step_factory (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.models, pipeline_builder.types, pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"Step factory for creating pipeline steps.\n",
        "\n",
        "This module provides a factory for creating step instances, separating\n",
        "step creation from pipeline building logic. The StepFactory centralizes\n",
        "step creation, making it easier to modify step creation logic and test\n",
        "pipeline building.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Optional\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..models import BronzeStep, GoldStep, SilverStep  # Removed: defined in notebook cells above\n",
        "# from ..types import (  # Removed: defined in notebook cells above\n",
        "    # ColumnRules,\n",
        "    # GoldTransformFunction,\n",
        "    # SilverTransformFunction,\n",
        "    # StepName,\n",
        "    # TableName,\n",
        "# )\n",
        "\n",
        "class StepFactory:\n",
        "    \"\"\"Factory for creating pipeline step instances.\n",
        "\n",
        "    Handles step creation logic separately from pipeline building. Provides\n",
        "    methods to create BronzeStep, SilverStep, and GoldStep instances with\n",
        "    proper validation and configuration.\n",
        "\n",
        "    Attributes:\n",
        "        logger: PipelineLogger instance for logging.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.pipeline.step_factory import StepFactory\n",
        "        >>> from pipeline_builder.functions import get_default_functions\n",
        "        >>> F = get_default_functions()\n",
        "        >>>\n",
        "        >>> factory = StepFactory()\n",
        "        >>> bronze = factory.create_bronze_step(\n",
        "        ...     name=\"events\",\n",
        "        ...     rules={\"id\": [F.col(\"id\").isNotNull()]},\n",
        "        ...     incremental_col=\"timestamp\"\n",
        "        ... )\n",
        "        >>> silver = factory.create_silver_step(\n",
        "        ...     name=\"clean_events\",\n",
        "        ...     source_bronze=\"events\",\n",
        "        ...     transform=lambda spark, df, silvers: df.filter(F.col(\"status\") == \"active\"),\n",
        "        ...     rules={\"status\": [F.col(\"status\").isNotNull()]},\n",
        "        ...     table_name=\"clean_events\"\n",
        "        ... )\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the step factory.\n",
        "\n",
        "        Args:\n",
        "            logger: Optional PipelineLogger instance. If None, creates a\n",
        "                default logger.\n",
        "        \"\"\"\n",
        "        self.logger = logger or PipelineLogger()\n",
        "\n",
        "    def create_bronze_step(\n",
        "        self,\n",
        "        name: StepName,\n",
        "        rules: ColumnRules,\n",
        "        incremental_col: Optional[str] = None,\n",
        "        schema: Optional[str] = None,\n",
        "    ) -> BronzeStep:\n",
        "        \"\"\"\n",
        "        Create a bronze step.\n",
        "\n",
        "        Args:\n",
        "            name: Step name\n",
        "            rules: Validation rules\n",
        "            incremental_col: Optional incremental column name\n",
        "            schema: Optional schema name\n",
        "\n",
        "        Returns:\n",
        "            BronzeStep instance\n",
        "        \"\"\"\n",
        "        return BronzeStep(\n",
        "            name=name,\n",
        "            rules=rules,\n",
        "            incremental_col=incremental_col,\n",
        "            schema=schema,\n",
        "        )\n",
        "\n",
        "    def create_silver_step(\n",
        "        self,\n",
        "        name: StepName,\n",
        "        source_bronze: StepName,\n",
        "        transform: SilverTransformFunction,\n",
        "        rules: ColumnRules,\n",
        "        table_name: TableName,\n",
        "        schema: Optional[str] = None,\n",
        "        source_incremental_col: Optional[str] = None,\n",
        "        watermark_col: Optional[str] = None,\n",
        "        schema_override: Optional[Any] = None,\n",
        "    ) -> SilverStep:\n",
        "        \"\"\"\n",
        "        Create a silver step.\n",
        "\n",
        "        Args:\n",
        "            name: Step name\n",
        "            source_bronze: Source bronze step name\n",
        "            transform: Transform function\n",
        "            rules: Validation rules\n",
        "            table_name: Target table name\n",
        "            schema: Optional schema name\n",
        "            source_incremental_col: Optional source incremental column\n",
        "            watermark_col: Optional watermark column\n",
        "            schema_override: Optional schema override\n",
        "\n",
        "        Returns:\n",
        "            SilverStep instance\n",
        "        \"\"\"\n",
        "        return SilverStep(\n",
        "            name=name,\n",
        "            source_bronze=source_bronze,\n",
        "            transform=transform,\n",
        "            rules=rules,\n",
        "            table_name=table_name,\n",
        "            schema=schema,\n",
        "            source_incremental_col=source_incremental_col,\n",
        "            watermark_col=watermark_col,\n",
        "            schema_override=schema_override,\n",
        "        )\n",
        "\n",
        "    def create_gold_step(\n",
        "        self,\n",
        "        name: StepName,\n",
        "        transform: GoldTransformFunction,\n",
        "        rules: ColumnRules,\n",
        "        table_name: TableName,\n",
        "        source_silvers: Optional[list[StepName]] = None,\n",
        "        schema: Optional[str] = None,\n",
        "        schema_override: Optional[Any] = None,\n",
        "    ) -> GoldStep:\n",
        "        \"\"\"\n",
        "        Create a gold step.\n",
        "\n",
        "        Args:\n",
        "            name: Step name\n",
        "            transform: Transform function\n",
        "            rules: Validation rules\n",
        "            table_name: Target table name\n",
        "            source_silvers: Optional list of source silver step names\n",
        "            schema: Optional schema name\n",
        "            schema_override: Optional schema override\n",
        "\n",
        "        Returns:\n",
        "            GoldStep instance\n",
        "        \"\"\"\n",
        "        return GoldStep(\n",
        "            name=name,\n",
        "            transform=transform,\n",
        "            rules=rules,\n",
        "            table_name=table_name,\n",
        "            source_silvers=source_silvers,\n",
        "            schema=schema,\n",
        "            schema_override=schema_override,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.models.base (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.errors, pipeline_builder.models.enums, pipeline_builder.models.types\n",
        "\n",
        "\"\"\"\n",
        "Base classes and configuration models for the Pipeline Builder.\n",
        "\n",
        "This module provides the foundational model classes that all pipeline components\n",
        "inherit from, including base validation, serialization, and configuration models.\n",
        "\n",
        "Key Components:\n",
        "    - **BaseModel**: Abstract base class for all pipeline models with common\n",
        "      functionality for validation, serialization, and representation\n",
        "    - **ValidationThresholds**: Configuration for validation thresholds across\n",
        "      pipeline phases (Bronze, Silver, Gold)\n",
        "\n",
        "Dependencies:\n",
        "    - errors: Pipeline validation and error handling\n",
        "    - models.enums: Pipeline phase enumerations\n",
        "    - models.types: Type definitions and protocols\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.models.base import BaseModel, ValidationThresholds\n",
        "    >>> from dataclasses import dataclass\n",
        "    >>>\n",
        "    >>> @dataclass\n",
        "    >>> class MyStep(BaseModel):\n",
        "    ...     name: str\n",
        "    ...     value: int\n",
        "    ...\n",
        "    ...     def validate(self) -> None:\n",
        "    ...         if not self.name:\n",
        "    ...             raise ValueError(\"Name required\")\n",
        "    ...         if self.value < 0:\n",
        "    ...             raise ValueError(\"Value must be non-negative\")\n",
        "    >>>\n",
        "    >>> step = MyStep(name=\"test\", value=42)\n",
        "    >>> step.validate()\n",
        "    >>> print(step.to_json())\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "\n",
        "# from ..errors import PipelineValidationError  # Removed: defined in notebook cells above\n",
        "# from .enums import PipelinePhase  # Removed: defined in notebook cells above\n",
        "# from .types import ModelValue  # Removed: defined in notebook cells above\n",
        "\n",
        "@dataclass\n",
        "class BaseModel(ABC):\n",
        "    \"\"\"\n",
        "    Base class for all pipeline models with common functionality.\n",
        "\n",
        "    Provides standard validation, serialization, and representation methods\n",
        "    for all pipeline data models. All models in the pipeline system inherit\n",
        "    from this base class to ensure consistent behavior.\n",
        "\n",
        "    Features:\n",
        "    - Automatic validation support\n",
        "    - JSON serialization and deserialization\n",
        "    - Dictionary conversion for easy data exchange\n",
        "    - String representation for debugging\n",
        "    - Type-safe field access\n",
        "\n",
        "    Example:\n",
        "        >>> @dataclass\n",
        "        >>> class MyStep(BaseModel):\n",
        "        ...     name: str\n",
        "        ...     rules: Dict[str, List[ColumnRule]]\n",
        "        ...\n",
        "        ...     def validate(self) -> None:\n",
        "        ...         if not self.name:\n",
        "        ...             raise ValueError(\"Name cannot be empty\")\n",
        "        ...         if not self.rules:\n",
        "        ...             raise ValueError(\"Rules cannot be empty\")\n",
        "        >>>\n",
        "        >>> step = MyStep(name=\"test\", rules={\"id\": [F.col(\"id\").isNotNull()]})\n",
        "        >>> step.validate()\n",
        "        >>> print(step.to_json())\n",
        "    \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the model.\n",
        "\n",
        "        This method must be implemented by all subclasses to ensure model\n",
        "        integrity. It should raise appropriate exceptions if validation fails.\n",
        "\n",
        "        Raises:\n",
        "            ValidationError: If the model is invalid. Subclasses should raise\n",
        "                specific error types (e.g., PipelineValidationError).\n",
        "\n",
        "        Example:\n",
        "            >>> @dataclass\n",
        "            >>> class MyModel(BaseModel):\n",
        "            ...     name: str\n",
        "            ...\n",
        "            ...     def validate(self) -> None:\n",
        "            ...         if not self.name:\n",
        "            ...             raise ValueError(\"Name cannot be empty\")\n",
        "            >>>\n",
        "            >>> model = MyModel(name=\"test\")\n",
        "            >>> model.validate()  # Passes\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def to_dict(self) -> Dict[str, ModelValue]:\n",
        "        \"\"\"Convert model to dictionary.\n",
        "\n",
        "        Recursively converts the model and all nested models to dictionaries.\n",
        "        Nested models that have a `to_dict` method will be converted recursively.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary representation of the model with all fields converted\n",
        "            to primitive types or dictionaries.\n",
        "\n",
        "        Example:\n",
        "            >>> step = BronzeStep(name=\"test\", rules={\"id\": [F.col(\"id\").isNotNull()]})\n",
        "            >>> step_dict = step.to_dict()\n",
        "            >>> print(step_dict[\"name\"])  # \"test\"\n",
        "        \"\"\"\n",
        "        result: Dict[str, ModelValue] = {}\n",
        "        for field_info in self.__dataclass_fields__.values():\n",
        "            value = getattr(self, field_info.name)\n",
        "            if hasattr(value, \"to_dict\"):\n",
        "                result[field_info.name] = value.to_dict()\n",
        "            else:\n",
        "                result[field_info.name] = value\n",
        "        return result\n",
        "\n",
        "    def to_json(self) -> str:\n",
        "        \"\"\"Convert model to JSON string.\n",
        "\n",
        "        Serializes the model to a formatted JSON string with indentation.\n",
        "        Uses the model's `to_dict` method for conversion.\n",
        "\n",
        "        Returns:\n",
        "            JSON string representation of the model, formatted with 2-space\n",
        "            indentation.\n",
        "\n",
        "        Example:\n",
        "            >>> step = BronzeStep(name=\"test\", rules={\"id\": [F.col(\"id\").isNotNull()]})\n",
        "            >>> json_str = step.to_json()\n",
        "            >>> print(json_str)\n",
        "            {\n",
        "              \"name\": \"test\",\n",
        "              \"rules\": {...}\n",
        "            }\n",
        "        \"\"\"\n",
        "        return json.dumps(self.to_dict(), default=str, indent=2)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        \"\"\"String representation of the model.\n",
        "\n",
        "        Returns:\n",
        "            Human-readable string representation showing the class name and\n",
        "            all field values.\n",
        "\n",
        "        Example:\n",
        "            >>> step = BronzeStep(name=\"test\", rules={\"id\": [F.col(\"id\").isNotNull()]})\n",
        "            >>> print(str(step))\n",
        "            BronzeStep(name=test, rules={'id': [...]})\n",
        "        \"\"\"\n",
        "        return f\"{self.__class__.__name__}({', '.join(f'{k}={v}' for k, v in self.to_dict().items())})\"\n",
        "\n",
        "@dataclass\n",
        "class ValidationThresholds(BaseModel):\n",
        "    \"\"\"Validation thresholds for different pipeline phases.\n",
        "\n",
        "    Defines the minimum validation success rates required for each layer\n",
        "    of the Medallion Architecture. Thresholds are expressed as percentages\n",
        "    (0-100) and are used to determine if pipeline execution meets quality\n",
        "    requirements.\n",
        "\n",
        "    **Validation Rules:**\n",
        "        - All thresholds must be between 0 and 100 (inclusive)\n",
        "        - Thresholds are validated during model validation\n",
        "\n",
        "    Attributes:\n",
        "        bronze: Bronze layer validation threshold (0-100). Defaults to 95.0\n",
        "            for standard configurations. Represents the minimum percentage\n",
        "            of rows that must pass validation in the Bronze layer.\n",
        "        silver: Silver layer validation threshold (0-100). Defaults to 98.0\n",
        "            for standard configurations. Represents the minimum percentage\n",
        "            of rows that must pass validation in the Silver layer.\n",
        "        gold: Gold layer validation threshold (0-100). Defaults to 99.0\n",
        "            for standard configurations. Represents the minimum percentage\n",
        "            of rows that must pass validation in the Gold layer.\n",
        "\n",
        "    Raises:\n",
        "        PipelineValidationError: If any threshold is outside the valid range\n",
        "            (0-100) during validation.\n",
        "\n",
        "    Example:\n",
        "        >>> # Create default thresholds\n",
        "        >>> thresholds = ValidationThresholds.create_default()\n",
        "        >>> print(f\"Bronze: {thresholds.bronze}%\")  # Bronze: 95.0%\n",
        "        >>>\n",
        "        >>> # Create custom thresholds\n",
        "        >>> thresholds = ValidationThresholds(\n",
        "        ...     bronze=90.0,\n",
        "        ...     silver=95.0,\n",
        "        ...     gold=99.0\n",
        "        ... )\n",
        "        >>> thresholds.validate()\n",
        "        >>>\n",
        "        >>> # Get threshold for specific phase\n",
        "        >>> from pipeline_builder.models.enums import PipelinePhase\n",
        "        >>> bronze_threshold = thresholds.get_threshold(PipelinePhase.BRONZE)\n",
        "    \"\"\"\n",
        "\n",
        "    bronze: float\n",
        "    silver: float\n",
        "    gold: float\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate threshold values.\n",
        "\n",
        "        Ensures all thresholds are within the valid range (0-100).\n",
        "        Raises an error if any threshold is invalid.\n",
        "\n",
        "        Raises:\n",
        "            PipelineValidationError: If any threshold is outside the valid\n",
        "                range (0-100).\n",
        "\n",
        "        Example:\n",
        "            >>> thresholds = ValidationThresholds(bronze=95.0, silver=98.0, gold=99.0)\n",
        "            >>> thresholds.validate()  # Passes\n",
        "            >>>\n",
        "            >>> invalid = ValidationThresholds(bronze=150.0, silver=98.0, gold=99.0)\n",
        "            >>> invalid.validate()  # Raises PipelineValidationError\n",
        "        \"\"\"\n",
        "        for phase, threshold in [\n",
        "            (\"bronze\", self.bronze),\n",
        "            (\"silver\", self.silver),\n",
        "            (\"gold\", self.gold),\n",
        "        ]:\n",
        "            if not 0 <= threshold <= 100:\n",
        "                raise PipelineValidationError(\n",
        "                    f\"{phase} threshold must be between 0 and 100, got {threshold}\"\n",
        "                )\n",
        "\n",
        "    def get_threshold(self, phase: PipelinePhase) -> float:\n",
        "        \"\"\"Get threshold for a specific phase.\n",
        "\n",
        "        Args:\n",
        "            phase: The pipeline phase to get the threshold for.\n",
        "\n",
        "        Returns:\n",
        "            The validation threshold for the specified phase (0-100).\n",
        "\n",
        "        Example:\n",
        "            >>> thresholds = ValidationThresholds(bronze=95.0, silver=98.0, gold=99.0)\n",
        "            >>> from pipeline_builder.models.enums import PipelinePhase\n",
        "            >>> bronze_threshold = thresholds.get_threshold(PipelinePhase.BRONZE)\n",
        "            >>> print(bronze_threshold)  # 95.0\n",
        "        \"\"\"\n",
        "        phase_map = {\n",
        "            PipelinePhase.BRONZE: self.bronze,\n",
        "            PipelinePhase.SILVER: self.silver,\n",
        "            PipelinePhase.GOLD: self.gold,\n",
        "        }\n",
        "        return phase_map[phase]\n",
        "\n",
        "    @classmethod\n",
        "    def create_default(cls) -> ValidationThresholds:\n",
        "        \"\"\"Create default validation thresholds.\n",
        "\n",
        "        Returns a standard configuration suitable for most production use cases:\n",
        "        - Bronze: 95.0% (allows some data quality issues in raw data)\n",
        "        - Silver: 98.0% (higher quality after cleaning)\n",
        "        - Gold: 99.0% (very high quality for analytics)\n",
        "\n",
        "        Returns:\n",
        "            ValidationThresholds instance with default values.\n",
        "\n",
        "        Example:\n",
        "            >>> thresholds = ValidationThresholds.create_default()\n",
        "            >>> print(f\"Bronze: {thresholds.bronze}%\")  # Bronze: 95.0%\n",
        "        \"\"\"\n",
        "        return cls(bronze=95.0, silver=98.0, gold=99.0)\n",
        "\n",
        "    @classmethod\n",
        "    def create_strict(cls) -> ValidationThresholds:\n",
        "        \"\"\"Create strict validation thresholds.\n",
        "\n",
        "        Returns a high-quality configuration for critical data pipelines:\n",
        "        - Bronze: 99.0% (very high quality raw data)\n",
        "        - Silver: 99.5% (extremely high quality after cleaning)\n",
        "        - Gold: 99.9% (near-perfect quality for analytics)\n",
        "\n",
        "        Use this configuration when data quality is critical and you can\n",
        "        afford to reject more rows.\n",
        "\n",
        "        Returns:\n",
        "            ValidationThresholds instance with strict values.\n",
        "\n",
        "        Example:\n",
        "            >>> thresholds = ValidationThresholds.create_strict()\n",
        "            >>> print(f\"Gold: {thresholds.gold}%\")  # Gold: 99.9%\n",
        "        \"\"\"\n",
        "        return cls(bronze=99.0, silver=99.5, gold=99.9)\n",
        "\n",
        "    @classmethod\n",
        "    def create_loose(cls) -> ValidationThresholds:\n",
        "        \"\"\"Create loose validation thresholds.\n",
        "\n",
        "        Returns a permissive configuration for exploratory or development use:\n",
        "        - Bronze: 80.0% (allows significant data quality issues)\n",
        "        - Silver: 85.0% (moderate quality after cleaning)\n",
        "        - Gold: 90.0% (acceptable quality for analytics)\n",
        "\n",
        "        Use this configuration for development, testing, or when working\n",
        "        with noisy data sources.\n",
        "\n",
        "        Returns:\n",
        "            ValidationThresholds instance with loose values.\n",
        "\n",
        "        Example:\n",
        "            >>> thresholds = ValidationThresholds.create_loose()\n",
        "            >>> print(f\"Bronze: {thresholds.bronze}%\")  # Bronze: 80.0%\n",
        "        \"\"\"\n",
        "        return cls(bronze=80.0, silver=85.0, gold=90.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.writer.analytics (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.compat, pipeline_builder.logging, pipeline_builder.writer.exceptions, pipeline_builder.writer.exceptions, pipeline_builder.writer.query_builder, pipeline_builder.writer.query_builder, pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"\n",
        "Writer analytics module for data quality and trend analysis.\n",
        "\n",
        "This module provides comprehensive analytics capabilities for analyzing\n",
        "pipeline execution data, detecting trends, and generating insights.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, Literal, Optional, TypedDict, Union, cast\n",
        "\n",
        "# from ..compat import DataFrame, F, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .exceptions import WriterError  # Removed: defined in notebook cells above\n",
        "# from .query_builder import QueryBuilder  # Removed: defined in notebook cells above\n",
        "\n",
        "# Alias for convenience\n",
        "col = F.col\n",
        "\n",
        "# ============================================================================\n",
        "# TypedDict Definitions\n",
        "# ============================================================================\n",
        "\n",
        "class AnalysisPeriod(TypedDict):\n",
        "    \"\"\"Analysis period structure.\"\"\"\n",
        "\n",
        "    start_date: str\n",
        "    end_date: str\n",
        "    days_analyzed: int\n",
        "\n",
        "class DailyQualityTrend(TypedDict):\n",
        "    \"\"\"Daily quality trend data point.\"\"\"\n",
        "\n",
        "    date: str\n",
        "    total_executions: int\n",
        "    avg_validation_rate: float\n",
        "    min_validation_rate: float\n",
        "    max_validation_rate: float\n",
        "    stddev_validation_rate: float\n",
        "    high_quality_executions: int\n",
        "    low_quality_executions: int\n",
        "    quality_score: str\n",
        "\n",
        "class OverallQualityMetrics(TypedDict):\n",
        "    \"\"\"Overall quality metrics.\"\"\"\n",
        "\n",
        "    total_executions: int\n",
        "    avg_validation_rate: float\n",
        "    min_validation_rate: float\n",
        "    max_validation_rate: float\n",
        "    stddev_validation_rate: float\n",
        "\n",
        "class DegradationAlert(TypedDict):\n",
        "    \"\"\"Quality degradation alert.\"\"\"\n",
        "\n",
        "    type: str\n",
        "    message: str\n",
        "    severity: Literal[\"high\", \"medium\", \"low\"]\n",
        "\n",
        "class QualityTrends(TypedDict):\n",
        "    \"\"\"Quality trends analysis structure.\"\"\"\n",
        "\n",
        "    analysis_period: AnalysisPeriod\n",
        "    daily_trends: list[DailyQualityTrend]\n",
        "    overall_metrics: OverallQualityMetrics\n",
        "    degradation_alerts: list[DegradationAlert]\n",
        "    quality_grade: str\n",
        "\n",
        "class ValidationAnomaly(TypedDict):\n",
        "    \"\"\"Validation anomaly data point.\"\"\"\n",
        "\n",
        "    step: str\n",
        "    phase: str\n",
        "    validation_rate: float\n",
        "    valid_rows: int\n",
        "    invalid_rows: int\n",
        "    timestamp: str\n",
        "\n",
        "class StepAnomaly(TypedDict):\n",
        "    \"\"\"Step-level anomaly data point.\"\"\"\n",
        "\n",
        "    step: str\n",
        "    execution_count: int\n",
        "    avg_validation_rate: float\n",
        "    min_validation_rate: float\n",
        "    stddev_validation_rate: float\n",
        "    anomaly_score: float\n",
        "\n",
        "class TemporalAnomaly(TypedDict):\n",
        "    \"\"\"Temporal anomaly data point.\"\"\"\n",
        "\n",
        "    date: str\n",
        "    daily_avg_validation_rate: float\n",
        "    prev_avg_validation_rate: float\n",
        "    quality_change: float\n",
        "\n",
        "class AnomalySummary(TypedDict):\n",
        "    \"\"\"Anomaly summary statistics.\"\"\"\n",
        "\n",
        "    total_validation_anomalies: int\n",
        "    total_step_anomalies: int\n",
        "    total_temporal_anomalies: int\n",
        "    overall_anomaly_score: float\n",
        "\n",
        "class QualityAnomalies(TypedDict):\n",
        "    \"\"\"Quality anomalies analysis structure.\"\"\"\n",
        "\n",
        "    validation_anomalies: list[ValidationAnomaly]\n",
        "    step_anomalies: list[StepAnomaly]\n",
        "    temporal_anomalies: list[TemporalAnomaly]\n",
        "    anomaly_summary: AnomalySummary\n",
        "\n",
        "class VolumeTrendPoint(TypedDict):\n",
        "    \"\"\"Volume trend data point.\"\"\"\n",
        "\n",
        "    date: str\n",
        "    daily_executions: int\n",
        "    successful_executions: int\n",
        "    failed_executions: int\n",
        "    success_rate: float\n",
        "    avg_execution_time: float\n",
        "    total_rows_written: int\n",
        "\n",
        "class PhaseTrendPoint(TypedDict):\n",
        "    \"\"\"Phase trend data point.\"\"\"\n",
        "\n",
        "    phase: str\n",
        "    execution_count: int\n",
        "    avg_execution_time: float\n",
        "    avg_validation_rate: float\n",
        "    total_rows_written: int\n",
        "    success_rate: float\n",
        "\n",
        "class StepTrendPoint(TypedDict):\n",
        "    \"\"\"Step trend data point.\"\"\"\n",
        "\n",
        "    step: str\n",
        "    execution_count: int\n",
        "    avg_execution_time: float\n",
        "    avg_validation_rate: float\n",
        "    stddev_execution_time: float\n",
        "    min_execution_time: float\n",
        "    max_execution_time: float\n",
        "    performance_grade: str\n",
        "\n",
        "class TrendIndicators(TypedDict):\n",
        "    \"\"\"Trend indicators.\"\"\"\n",
        "\n",
        "    execution_volume_trend: str\n",
        "    success_rate_trend: str\n",
        "    recent_executions: int\n",
        "    historical_avg_executions: float\n",
        "    recent_success_rate: float\n",
        "    historical_success_rate: float\n",
        "\n",
        "class ExecutionTrends(TypedDict):\n",
        "    \"\"\"Execution trends analysis structure.\"\"\"\n",
        "\n",
        "    analysis_period: AnalysisPeriod\n",
        "    volume_trends: list[VolumeTrendPoint]\n",
        "    phase_trends: list[PhaseTrendPoint]\n",
        "    step_trends: list[StepTrendPoint]\n",
        "    trend_indicators: TrendIndicators\n",
        "\n",
        "class DataQualityAnalyzer:\n",
        "    \"\"\"Analyzes data quality metrics and trends.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the data quality analyzer.\"\"\"\n",
        "        self.spark = spark\n",
        "        if logger is None:\n",
        "            self.logger = PipelineLogger(\"DataQualityAnalyzer\")\n",
        "        else:\n",
        "            self.logger = logger\n",
        "\n",
        "    def analyze_quality_trends(\n",
        "        self,\n",
        "        df: DataFrame,\n",
        "        days: int = 30,\n",
        "    ) -> QualityTrends:\n",
        "        \"\"\"\n",
        "        Analyze data quality trends over time.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing log data\n",
        "            days: Number of days to analyze\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing quality trend analysis\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Analyzing data quality trends for last {days} days\")\n",
        "\n",
        "            # Use query builder for quality trends\n",
        "            quality_trends_df = QueryBuilder.build_quality_trends_query(df, days)\n",
        "            quality_trends = quality_trends_df.collect()\n",
        "\n",
        "            # Use query builder for overall metrics\n",
        "            overall_metrics_df = QueryBuilder.build_overall_metrics_query(df, days)\n",
        "            overall_metrics = overall_metrics_df.collect()[0]\n",
        "\n",
        "            # Detect quality degradation\n",
        "            degradation_alerts = []\n",
        "            if len(quality_trends) > 1:\n",
        "                recent_avg = quality_trends[-1][\"avg_validation_rate\"]\n",
        "                historical_avg = sum(\n",
        "                    row[\"avg_validation_rate\"] for row in quality_trends[:-1]\n",
        "                ) / len(quality_trends[:-1])\n",
        "\n",
        "                if recent_avg < historical_avg - 5.0:  # 5% degradation threshold\n",
        "                    degradation_alerts.append(\n",
        "                        {\n",
        "                            \"type\": \"quality_degradation\",\n",
        "                            \"message\": f\"Recent validation rate ({recent_avg:.1f}%) is significantly lower than historical average ({historical_avg:.1f}%)\",\n",
        "                            \"severity\": (\n",
        "                                \"high\"\n",
        "                                if recent_avg < historical_avg - 10.0\n",
        "                                else \"medium\"\n",
        "                            ),\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "            # Get date range for analysis period\n",
        "            end_date = datetime.now()\n",
        "            start_date = end_date - timedelta(days=days)\n",
        "\n",
        "            analysis_result = {\n",
        "                \"analysis_period\": {\n",
        "                    \"start_date\": start_date.strftime(\"%Y-%m-%d\"),\n",
        "                    \"end_date\": end_date.strftime(\"%Y-%m-%d\"),\n",
        "                    \"days_analyzed\": days,\n",
        "                },\n",
        "                \"daily_trends\": [\n",
        "                    {\n",
        "                        \"date\": row[\"date\"].strftime(\"%Y-%m-%d\"),\n",
        "                        \"total_executions\": row[\"total_executions\"],\n",
        "                        \"avg_validation_rate\": round(row[\"avg_validation_rate\"], 2),\n",
        "                        \"min_validation_rate\": round(row[\"min_validation_rate\"], 2),\n",
        "                        \"max_validation_rate\": round(row[\"max_validation_rate\"], 2),\n",
        "                        \"stddev_validation_rate\": round(\n",
        "                            row[\"stddev_validation_rate\"], 2\n",
        "                        ),\n",
        "                        \"high_quality_executions\": row[\"high_quality_executions\"],\n",
        "                        \"low_quality_executions\": row[\"low_quality_executions\"],\n",
        "                        \"quality_score\": self._calculate_quality_score(row.asDict()),\n",
        "                    }\n",
        "                    for row in quality_trends\n",
        "                ],\n",
        "                \"overall_metrics\": {\n",
        "                    \"total_executions\": overall_metrics[\"total_executions\"],\n",
        "                    \"avg_validation_rate\": round(\n",
        "                        overall_metrics[\"overall_avg_validation_rate\"], 2\n",
        "                    ),\n",
        "                    \"min_validation_rate\": round(\n",
        "                        overall_metrics[\"overall_min_validation_rate\"], 2\n",
        "                    ),\n",
        "                    \"max_validation_rate\": round(\n",
        "                        overall_metrics[\"overall_max_validation_rate\"], 2\n",
        "                    ),\n",
        "                    \"stddev_validation_rate\": round(\n",
        "                        overall_metrics[\"overall_stddev_validation_rate\"], 2\n",
        "                    ),\n",
        "                },\n",
        "                \"degradation_alerts\": degradation_alerts,\n",
        "                \"quality_grade\": self._calculate_quality_grade(\n",
        "                    overall_metrics[\"overall_avg_validation_rate\"]\n",
        "                ),\n",
        "            }\n",
        "\n",
        "            self.logger.info(\"Data quality trends analysis completed\")\n",
        "            return cast(QualityTrends, analysis_result)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to analyze quality trends: {e}\")\n",
        "            raise WriterError(f\"Failed to analyze quality trends: {e}\") from e\n",
        "\n",
        "    def detect_quality_anomalies(self, df: DataFrame) -> QualityAnomalies:\n",
        "        \"\"\"\n",
        "        Detect data quality anomalies.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing log data\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing anomaly detection results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Detecting data quality anomalies\")\n",
        "\n",
        "            # Calculate overall statistics for anomaly detection\n",
        "            overall_stats = QueryBuilder.calculate_statistics(df, \"validation_rate\")\n",
        "            threshold = overall_stats[\"avg\"] - (2 * overall_stats[\"stddev\"])\n",
        "\n",
        "            # Detect validation rate anomalies using query builder\n",
        "            validation_anomalies_df = (\n",
        "                QueryBuilder.build_anomaly_detection_query(\n",
        "                    df, \"validation_rate\", threshold\n",
        "                )\n",
        "                .select(\n",
        "                    \"step\",\n",
        "                    \"phase\",\n",
        "                    \"validation_rate\",\n",
        "                    \"valid_rows\",\n",
        "                    \"invalid_rows\",\n",
        "                    \"created_at\",\n",
        "                )\n",
        "                .orderBy(\"validation_rate\")\n",
        "            )\n",
        "\n",
        "            validation_anomalies = validation_anomalies_df.collect()\n",
        "\n",
        "            # Detect step-specific anomalies using query builder\n",
        "            step_anomalies_df = (\n",
        "                df.groupBy(\"step\")\n",
        "                .agg(**QueryBuilder.get_performance_aggregations())\n",
        "                .filter(\n",
        "                    (col(\"avg_validation_rate\") < 90.0)\n",
        "                    | (col(\"stddev_validation_rate\") > 10.0)\n",
        "                )\n",
        "                .orderBy(\"avg_validation_rate\")\n",
        "            )\n",
        "\n",
        "            step_anomalies = step_anomalies_df.collect()\n",
        "\n",
        "            # Detect temporal anomalies using query builder\n",
        "            temporal_anomalies_df = QueryBuilder.build_temporal_anomaly_query(df)\n",
        "            temporal_anomalies = temporal_anomalies_df.collect()\n",
        "\n",
        "            anomaly_result = {\n",
        "                \"validation_anomalies\": [\n",
        "                    {\n",
        "                        \"step\": row[\"step\"],\n",
        "                        \"phase\": row[\"phase\"],\n",
        "                        \"validation_rate\": round(row[\"validation_rate\"], 2),\n",
        "                        \"valid_rows\": row[\"valid_rows\"],\n",
        "                        \"invalid_rows\": row[\"invalid_rows\"],\n",
        "                        \"timestamp\": row[\"created_at\"].strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                    }\n",
        "                    for row in validation_anomalies\n",
        "                ],\n",
        "                \"step_anomalies\": [\n",
        "                    {\n",
        "                        \"step\": row[\"step\"],\n",
        "                        \"execution_count\": row[\"execution_count\"],\n",
        "                        \"avg_validation_rate\": round(row[\"avg_validation_rate\"], 2),\n",
        "                        \"min_validation_rate\": round(row[\"min_validation_rate\"], 2),\n",
        "                        \"stddev_validation_rate\": round(\n",
        "                            row[\"stddev_validation_rate\"], 2\n",
        "                        ),\n",
        "                        \"anomaly_score\": self._calculate_anomaly_score(row.asDict()),\n",
        "                    }\n",
        "                    for row in step_anomalies\n",
        "                ],\n",
        "                \"temporal_anomalies\": [\n",
        "                    {\n",
        "                        \"date\": row[\"date\"].strftime(\"%Y-%m-%d\"),\n",
        "                        \"daily_avg_validation_rate\": round(\n",
        "                            row[\"daily_avg_validation_rate\"], 2\n",
        "                        ),\n",
        "                        \"prev_avg_validation_rate\": round(\n",
        "                            row[\"prev_avg_validation_rate\"], 2\n",
        "                        ),\n",
        "                        \"quality_change\": round(row[\"quality_change\"], 2),\n",
        "                    }\n",
        "                    for row in temporal_anomalies\n",
        "                ],\n",
        "                \"anomaly_summary\": {\n",
        "                    \"total_validation_anomalies\": len(validation_anomalies),\n",
        "                    \"total_step_anomalies\": len(step_anomalies),\n",
        "                    \"total_temporal_anomalies\": len(temporal_anomalies),\n",
        "                    \"overall_anomaly_score\": self._calculate_overall_anomaly_score(\n",
        "                        len(validation_anomalies),\n",
        "                        len(step_anomalies),\n",
        "                        len(temporal_anomalies),\n",
        "                    ),\n",
        "                },\n",
        "            }\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"Quality anomaly detection completed: {len(validation_anomalies)} validation anomalies found\"\n",
        "            )\n",
        "            return cast(QualityAnomalies, anomaly_result)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to detect quality anomalies: {e}\")\n",
        "            raise WriterError(f\"Failed to detect quality anomalies: {e}\") from e\n",
        "\n",
        "    def _calculate_quality_score(self, row: Dict[str, Union[int, float]]) -> str:\n",
        "        \"\"\"Calculate quality score for a row.\"\"\"\n",
        "        avg_rate = row[\"avg_validation_rate\"]\n",
        "        if avg_rate >= 95.0:\n",
        "            return \"A\"\n",
        "        elif avg_rate >= 90.0:\n",
        "            return \"B\"\n",
        "        elif avg_rate >= 80.0:\n",
        "            return \"C\"\n",
        "        else:\n",
        "            return \"D\"\n",
        "\n",
        "    def _calculate_quality_grade(self, avg_validation_rate: float) -> str:\n",
        "        \"\"\"Calculate overall quality grade.\"\"\"\n",
        "        if avg_validation_rate >= 95.0:\n",
        "            return \"A\"\n",
        "        elif avg_validation_rate >= 90.0:\n",
        "            return \"B\"\n",
        "        elif avg_validation_rate >= 80.0:\n",
        "            return \"C\"\n",
        "        else:\n",
        "            return \"D\"\n",
        "\n",
        "    def _calculate_anomaly_score(self, row: Dict[str, Union[int, float]]) -> float:\n",
        "        \"\"\"Calculate anomaly score for a step.\"\"\"\n",
        "        avg_rate = row[\"avg_validation_rate\"]\n",
        "        stddev_rate = row[\"stddev_validation_rate\"]\n",
        "\n",
        "        # Lower average rate and higher standard deviation = higher anomaly score\n",
        "        anomaly_score = (100 - avg_rate) + (stddev_rate * 2)\n",
        "        return float(round(min(anomaly_score, 100.0), 2))\n",
        "\n",
        "    def _calculate_overall_anomaly_score(\n",
        "        self, validation_anomalies: int, step_anomalies: int, temporal_anomalies: int\n",
        "    ) -> float:\n",
        "        \"\"\"Calculate overall anomaly score.\"\"\"\n",
        "        total_anomalies = validation_anomalies + step_anomalies + temporal_anomalies\n",
        "\n",
        "        if total_anomalies == 0:\n",
        "            return 0.0\n",
        "\n",
        "        # Weight different types of anomalies\n",
        "        weighted_score = (\n",
        "            (validation_anomalies * 1.0)\n",
        "            + (step_anomalies * 0.8)\n",
        "            + (temporal_anomalies * 1.2)\n",
        "        )\n",
        "        return round(min(weighted_score, 100.0), 2)\n",
        "\n",
        "class TrendAnalyzer:\n",
        "    \"\"\"Analyzes execution trends and patterns.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the trend analyzer.\"\"\"\n",
        "        self.spark = spark\n",
        "        if logger is None:\n",
        "            self.logger = PipelineLogger(\"TrendAnalyzer\")\n",
        "        else:\n",
        "            self.logger = logger\n",
        "\n",
        "    def analyze_execution_trends(\n",
        "        self,\n",
        "        df: DataFrame,\n",
        "        days: int = 30,\n",
        "    ) -> ExecutionTrends:\n",
        "        \"\"\"\n",
        "        Analyze execution trends over time.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing log data\n",
        "            days: Number of days to analyze\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing trend analysis\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Analyzing execution trends for last {days} days\")\n",
        "\n",
        "            # Use query builder for all trend analyses\n",
        "            volume_trends_df = QueryBuilder.build_daily_trends_query(df, days)\n",
        "            volume_trends = volume_trends_df.collect()\n",
        "\n",
        "            phase_trends_df = QueryBuilder.build_phase_trends_query(df, days)\n",
        "            phase_trends = phase_trends_df.collect()\n",
        "\n",
        "            step_trends_df = QueryBuilder.build_step_trends_query(df, days)\n",
        "            step_trends = step_trends_df.collect()\n",
        "\n",
        "            # Calculate trend indicators\n",
        "            trend_indicators = self._calculate_trend_indicators(\n",
        "                [row.asDict() for row in volume_trends]\n",
        "            )\n",
        "\n",
        "            # Get date range for analysis period\n",
        "            end_date = datetime.now()\n",
        "            start_date = end_date - timedelta(days=days)\n",
        "\n",
        "            analysis_result = {\n",
        "                \"analysis_period\": {\n",
        "                    \"start_date\": start_date.strftime(\"%Y-%m-%d\"),\n",
        "                    \"end_date\": end_date.strftime(\"%Y-%m-%d\"),\n",
        "                    \"days_analyzed\": days,\n",
        "                },\n",
        "                \"volume_trends\": [\n",
        "                    {\n",
        "                        \"date\": row[\"date\"].strftime(\"%Y-%m-%d\"),\n",
        "                        \"daily_executions\": row[\"daily_executions\"],\n",
        "                        \"successful_executions\": row[\"successful_executions\"],\n",
        "                        \"failed_executions\": row[\"failed_executions\"],\n",
        "                        \"success_rate\": (\n",
        "                            round(\n",
        "                                (row[\"successful_executions\"] / row[\"daily_executions\"])\n",
        "                                * 100,\n",
        "                                2,\n",
        "                            )\n",
        "                            if row[\"daily_executions\"] > 0\n",
        "                            else 0\n",
        "                        ),\n",
        "                        \"avg_execution_time\": round(row[\"avg_execution_time\"], 2),\n",
        "                        \"total_rows_written\": row[\"total_rows_written\"],\n",
        "                    }\n",
        "                    for row in volume_trends\n",
        "                ],\n",
        "                \"phase_trends\": [\n",
        "                    {\n",
        "                        \"phase\": row[\"phase\"],\n",
        "                        \"execution_count\": row[\"execution_count\"],\n",
        "                        \"avg_execution_time\": round(row[\"avg_execution_time\"], 2),\n",
        "                        \"avg_validation_rate\": round(row[\"avg_validation_rate\"], 2),\n",
        "                        \"total_rows_written\": row[\"total_rows_written\"],\n",
        "                        \"success_rate\": round(\n",
        "                            (row[\"successful_executions\"] / row[\"execution_count\"])\n",
        "                            * 100,\n",
        "                            2,\n",
        "                        ),\n",
        "                    }\n",
        "                    for row in phase_trends\n",
        "                ],\n",
        "                \"step_trends\": [\n",
        "                    {\n",
        "                        \"step\": row[\"step\"],\n",
        "                        \"execution_count\": row[\"execution_count\"],\n",
        "                        \"avg_execution_time\": round(row[\"avg_execution_time\"], 2),\n",
        "                        \"avg_validation_rate\": round(row[\"avg_validation_rate\"], 2),\n",
        "                        \"stddev_execution_time\": round(row[\"stddev_execution_time\"], 2),\n",
        "                        \"min_execution_time\": round(row[\"min_execution_time\"], 2),\n",
        "                        \"max_execution_time\": round(row[\"max_execution_time\"], 2),\n",
        "                        \"performance_grade\": self._calculate_performance_grade(\n",
        "                            row.asDict()\n",
        "                        ),\n",
        "                    }\n",
        "                    for row in step_trends\n",
        "                ],\n",
        "                \"trend_indicators\": trend_indicators,\n",
        "            }\n",
        "\n",
        "            self.logger.info(\"Execution trends analysis completed\")\n",
        "            return cast(ExecutionTrends, analysis_result)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to analyze execution trends: {e}\")\n",
        "            raise WriterError(f\"Failed to analyze execution trends: {e}\") from e\n",
        "\n",
        "    def _calculate_trend_indicators(\n",
        "        self, volume_trends: list[Dict[str, Union[int, float]]]\n",
        "    ) -> TrendIndicators:\n",
        "        \"\"\"Calculate trend indicators from volume trends.\"\"\"\n",
        "        if len(volume_trends) < 2:\n",
        "            return {\n",
        "                \"execution_volume_trend\": \"insufficient_data\",\n",
        "                \"success_rate_trend\": \"insufficient_data\",\n",
        "                \"recent_executions\": 0,\n",
        "                \"historical_avg_executions\": 0.0,\n",
        "                \"recent_success_rate\": 0.0,\n",
        "                \"historical_success_rate\": 0.0,\n",
        "            }\n",
        "\n",
        "        # Calculate execution volume trend\n",
        "        recent_executions = volume_trends[-1][\"daily_executions\"]\n",
        "        historical_avg = sum(\n",
        "            row[\"daily_executions\"] for row in volume_trends[:-1]\n",
        "        ) / len(volume_trends[:-1])\n",
        "\n",
        "        execution_trend = (\n",
        "            \"increasing\"\n",
        "            if recent_executions > historical_avg * 1.1\n",
        "            else \"decreasing\"\n",
        "            if recent_executions < historical_avg * 0.9\n",
        "            else \"stable\"\n",
        "        )\n",
        "\n",
        "        # Calculate success rate trend\n",
        "        recent_success_rate = (\n",
        "            (\n",
        "                volume_trends[-1][\"successful_executions\"]\n",
        "                / volume_trends[-1][\"daily_executions\"]\n",
        "            )\n",
        "            * 100\n",
        "            if volume_trends[-1][\"daily_executions\"] > 0\n",
        "            else 0\n",
        "        )\n",
        "        historical_success_rate = sum(\n",
        "            (row[\"successful_executions\"] / row[\"daily_executions\"]) * 100\n",
        "            for row in volume_trends[:-1]\n",
        "            if row[\"daily_executions\"] > 0\n",
        "        ) / len([row for row in volume_trends[:-1] if row[\"daily_executions\"] > 0])\n",
        "\n",
        "        success_trend = (\n",
        "            \"improving\"\n",
        "            if recent_success_rate > historical_success_rate + 2\n",
        "            else (\n",
        "                \"declining\"\n",
        "                if recent_success_rate < historical_success_rate - 2\n",
        "                else \"stable\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"execution_volume_trend\": execution_trend,\n",
        "            \"success_rate_trend\": success_trend,\n",
        "            \"recent_executions\": int(recent_executions),\n",
        "            \"historical_avg_executions\": round(historical_avg, 2),\n",
        "            \"recent_success_rate\": round(recent_success_rate, 2),\n",
        "            \"historical_success_rate\": round(historical_success_rate, 2),\n",
        "        }\n",
        "\n",
        "    def _calculate_performance_grade(self, row: Dict[str, Union[int, float]]) -> str:\n",
        "        \"\"\"Calculate performance grade for a step.\"\"\"\n",
        "        avg_time = row[\"avg_execution_time\"]\n",
        "        stddev_time = row[\"stddev_execution_time\"]\n",
        "\n",
        "        # Consider both average time and consistency (low stddev)\n",
        "        if avg_time < 60 and stddev_time < 30:  # Fast and consistent\n",
        "            return \"A\"\n",
        "        elif avg_time < 120 and stddev_time < 60:  # Reasonable and somewhat consistent\n",
        "            return \"B\"\n",
        "        elif avg_time < 300:  # Acceptable\n",
        "            return \"C\"\n",
        "        else:  # Slow\n",
        "            return \"D\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: abstracts.builder (abstracts)\n",
        "#\n",
        "# Dependencies: abstracts.engine, abstracts.rules, abstracts.runner, abstracts.step, abstracts.transformer\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import List, Literal, Optional, Type\n",
        "# from .engine import Engine  # Removed: defined in notebook cells above\n",
        "# from .rules import Rules  # Removed: defined in notebook cells above\n",
        "# from .runner import Runner  # Removed: defined in notebook cells above\n",
        "# from .step import Step  # Removed: defined in notebook cells above\n",
        "# from .transformer import Transformer  # Removed: defined in notebook cells above\n",
        "\n",
        "class PipelineBuilder:\n",
        "    \"\"\"\n",
        "    Abstract pipeline builder that uses dependency injection for engine and runner.\n",
        "\n",
        "    This builder provides a fluent API for constructing pipelines with engine injection,\n",
        "    allowing different engine implementations (SparkEngine, SqlEngine, etc.) to be used.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, runner_cls: Type[Runner], engine: Engine) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the pipeline builder.\n",
        "\n",
        "        Args:\n",
        "            runner_cls: Runner class to use for pipeline execution\n",
        "            engine: Engine instance to use for step execution\n",
        "        \"\"\"\n",
        "        self.runner_cls = runner_cls\n",
        "        self.engine = engine\n",
        "        self.steps: List[Step] = []\n",
        "\n",
        "    def validate_steps(self, steps: List[Step]) -> bool:\n",
        "        \"\"\"\n",
        "        Validate pipeline steps configuration.\n",
        "\n",
        "        Args:\n",
        "            steps: List of steps to validate\n",
        "\n",
        "        Returns:\n",
        "            True if all steps are valid, False otherwise\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If validation fails with details\n",
        "        \"\"\"\n",
        "        # Allow empty pipelines (some tests create empty pipelines)\n",
        "        # if not steps:\n",
        "        #     raise ValueError(\"Pipeline must have at least one step\")\n",
        "\n",
        "        # Check for duplicate step names\n",
        "        step_names = [step.name for step in steps]\n",
        "        if len(step_names) != len(set(step_names)):\n",
        "            duplicates = [name for name in step_names if step_names.count(name) > 1]\n",
        "            raise ValueError(f\"Duplicate step names found: {set(duplicates)}\")\n",
        "\n",
        "        # Validate step dependencies\n",
        "        # Determine step types by checking class type or type attribute\n",
        "        # Concrete steps (BronzeStep, SilverStep, GoldStep) don't have type attribute\n",
        "        # but satisfy the Step Protocol\n",
        "        bronze_names = set()\n",
        "        silver_names = set()\n",
        "        gold_names = set()\n",
        "\n",
        "        for step in steps:\n",
        "            # Check if step has type attribute (for Protocol compatibility)\n",
        "            if hasattr(step, \"type\") and step.type:\n",
        "                step_type = step.type\n",
        "            else:\n",
        "                # Determine type from class name\n",
        "                class_name = step.__class__.__name__\n",
        "                if \"Bronze\" in class_name:\n",
        "                    step_type = \"bronze\"\n",
        "                elif \"Silver\" in class_name:\n",
        "                    step_type = \"silver\"\n",
        "                elif \"Gold\" in class_name:\n",
        "                    step_type = \"gold\"\n",
        "                else:\n",
        "                    raise ValueError(f\"Cannot determine step type for {class_name}\")\n",
        "\n",
        "            if step_type == \"bronze\":\n",
        "                bronze_names.add(step.name)\n",
        "            elif step_type == \"silver\":\n",
        "                silver_names.add(step.name)\n",
        "            elif step_type == \"gold\":\n",
        "                gold_names.add(step.name)\n",
        "\n",
        "        for step in steps:\n",
        "            # Determine step type again for validation\n",
        "            if hasattr(step, \"type\") and step.type:\n",
        "                step_type = step.type\n",
        "            else:\n",
        "                class_name = step.__class__.__name__\n",
        "                if \"Bronze\" in class_name:\n",
        "                    step_type = \"bronze\"\n",
        "                elif \"Silver\" in class_name:\n",
        "                    step_type = \"silver\"\n",
        "                elif \"Gold\" in class_name:\n",
        "                    step_type = \"gold\"\n",
        "                else:\n",
        "                    continue  # Skip unknown types\n",
        "\n",
        "            if step_type == \"silver\":\n",
        "                # Silver steps use source_bronze attribute, not source\n",
        "                source = getattr(step, \"source_bronze\", None) or getattr(\n",
        "                    step, \"source\", None\n",
        "                )\n",
        "                if source and source not in bronze_names:\n",
        "                    raise ValueError(\n",
        "                        f\"Silver step '{step.name}' references unknown bronze source '{source}'\"\n",
        "                    )\n",
        "            elif step_type == \"gold\":\n",
        "                # Gold steps use source_silvers attribute (list), not source\n",
        "                source_silvers = getattr(step, \"source_silvers\", None)\n",
        "                if source_silvers:\n",
        "                    for silver_name in source_silvers:\n",
        "                        if silver_name not in silver_names:\n",
        "                            raise ValueError(\n",
        "                                f\"Gold step '{step.name}' references unknown silver source '{silver_name}'\"\n",
        "                            )\n",
        "                # Also check source attribute for backward compatibility\n",
        "                source = getattr(step, \"source\", None)\n",
        "                if source and source not in silver_names:\n",
        "                    raise ValueError(\n",
        "                        f\"Gold step '{step.name}' references unknown silver source '{source}'\"\n",
        "                    )\n",
        "\n",
        "        return True\n",
        "\n",
        "    def to_pipeline(\n",
        "        self, steps: Optional[List[Step]] = None, engine: Optional[Engine] = None\n",
        "    ) -> Runner:\n",
        "        \"\"\"\n",
        "        Build and return a Runner for executing the pipeline.\n",
        "\n",
        "        Args:\n",
        "            steps: Optional list of steps (uses self.steps if not provided)\n",
        "            engine: Optional engine instance (uses self.engine if not provided)\n",
        "\n",
        "        Returns:\n",
        "            Runner instance ready for execution\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If step validation fails\n",
        "        \"\"\"\n",
        "        steps_to_use = steps if steps is not None else self.steps\n",
        "        engine_to_use = engine if engine is not None else self.engine\n",
        "\n",
        "        if not steps_to_use:\n",
        "            raise ValueError(\"No steps provided to build pipeline\")\n",
        "\n",
        "        if self.validate_steps(steps_to_use):\n",
        "            return self.runner_cls(steps_to_use, engine_to_use)\n",
        "        raise ValueError(\"Invalid steps configuration\")\n",
        "\n",
        "    def with_bronze_rules(self, name: str, rules: Rules) -> PipelineBuilder:\n",
        "        \"\"\"\n",
        "        Add a bronze step with validation rules.\n",
        "\n",
        "        Args:\n",
        "            name: Unique name for the bronze step\n",
        "            rules: Validation rules for the bronze step\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining\n",
        "        \"\"\"\n",
        "        # Note: Step is a Protocol, so we can't instantiate it directly.\n",
        "        # Concrete implementations will create appropriate step objects.\n",
        "        # This method is meant to be overridden or used with concrete step types.\n",
        "        raise NotImplementedError(\n",
        "            \"with_bronze_rules must be implemented by concrete PipelineBuilder subclasses\"\n",
        "        )\n",
        "\n",
        "    def add_silver_transform(\n",
        "        self,\n",
        "        name: str,\n",
        "        source: str,\n",
        "        transform: Transformer,\n",
        "        rules: Rules,\n",
        "        write_target: str,\n",
        "        write_mode: Literal[\"overwrite\", \"append\"],\n",
        "        write_schema: Optional[str] = None,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"\n",
        "        Add a silver transformation step.\n",
        "\n",
        "        Args:\n",
        "            name: Unique name for the silver step\n",
        "            source: Name of the bronze step this depends on\n",
        "            transform: Transformation function\n",
        "            rules: Validation rules\n",
        "            write_target: Target table name\n",
        "            write_mode: Write mode (overwrite or append)\n",
        "            write_schema: Optional schema name\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining\n",
        "        \"\"\"\n",
        "        # Note: Step is a Protocol, so we can't instantiate it directly.\n",
        "        # Concrete implementations will create appropriate step objects.\n",
        "        raise NotImplementedError(\n",
        "            \"add_silver_transform must be implemented by concrete PipelineBuilder subclasses\"\n",
        "        )\n",
        "\n",
        "    def add_gold_transform(\n",
        "        self,\n",
        "        name: str,\n",
        "        source: str,\n",
        "        transform: Transformer,\n",
        "        rules: Rules,\n",
        "        write_target: str,\n",
        "        write_schema: Optional[str] = None,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"\n",
        "        Add a gold transformation step.\n",
        "\n",
        "        Args:\n",
        "            name: Unique name for the gold step\n",
        "            source: Name of the silver step this depends on\n",
        "            transform: Transformation function\n",
        "            rules: Validation rules\n",
        "            write_target: Target table name\n",
        "            write_schema: Optional schema name\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining\n",
        "        \"\"\"\n",
        "        # Note: Step is a Protocol, so we can't instantiate it directly.\n",
        "        # Concrete implementations will create appropriate step objects.\n",
        "        raise NotImplementedError(\n",
        "            \"add_gold_transform must be implemented by concrete PipelineBuilder subclasses\"\n",
        "        )\n",
        "\n",
        "# Store as global alias to avoid name collision with pipeline_builder.pipeline.builder.PipelineBuilder\n",
        "_AbstractsPipelineBuilderClass = PipelineBuilder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.models.steps (pipeline_builder)\n",
        "#\n",
        "# Dependencies: models.base, models.types, pipeline_builder.compat, pipeline_builder.models.base, pipeline_builder.models.enums, pipeline_builder.models.types, pipeline_builder.sql_source.models, pipeline_builder_base.errors, pipeline_builder_base.errors\n",
        "\n",
        "\"\"\"\n",
        "Step models for the Pipeline Builder.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import TYPE_CHECKING, Optional, Union\n",
        "\n",
        "# TypeAlias is available in Python 3.10+, use typing_extensions for 3.8/3.9\n",
        "# Mypy prefers typing_extensions even for Python 3.11\n",
        "from typing_extensions import TypeAlias\n",
        "# from .sql_source.models import JdbcSource, SqlAlchemySource  # Removed: defined in notebook cells above\n",
        "# from .errors import PipelineValidationError, ValidationError  # Removed: defined in notebook cells above\n",
        "\n",
        "# from .base import BaseModel  # Removed: defined in notebook cells above\n",
        "# from .enums import PipelinePhase  # Removed: defined in notebook cells above\n",
        "# from .types import ColumnRules, GoldTransformFunction, SilverTransformFunction  # Removed: defined in notebook cells above\n",
        "\n",
        "SqlSourceType: TypeAlias = Union[JdbcSource, SqlAlchemySource]\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    # Engine-specific StructType should satisfy the TypesProtocol.StructType\n",
        "    # Import the actual type from pyspark.sql.types for type checking\n",
        "    try:\n",
        "        from pyspark.sql.types import StructType as _StructTypeBase\n",
        "    except ImportError:\n",
        "        # Fallback if PySpark not available during type checking\n",
        "        from typing import Any as _StructTypeBase  # type: ignore[assignment]\n",
        "\n",
        "    StructType: TypeAlias = _StructTypeBase\n",
        "else:\n",
        "    try:\n",
        "        # from ..compat import types as compat_types  # Removed: defined in notebook cells above\n",
        "        from pyspark.sql import types  # types from pyspark (not from compat)\n",
        "\n",
        "        StructType: TypeAlias = compat_types.StructType  # type: ignore[assignment]\n",
        "    except Exception:\n",
        "        # Use object instead of Any for Python 3.8 compatibility\n",
        "        # Any cannot be used with isinstance() in Python 3.8\n",
        "        # For runtime, we use object, but mypy will use the TypeAlias from TYPE_CHECKING\n",
        "        StructType: TypeAlias = object  # type: ignore[assignment, misc]\n",
        "\n",
        "@dataclass\n",
        "class BronzeStep(BaseModel):\n",
        "    \"\"\"\n",
        "    Bronze layer step configuration for raw data validation and ingestion.\n",
        "\n",
        "    Bronze steps represent the first layer of the Medallion Architecture,\n",
        "    handling raw data validation and establishing the foundation for downstream\n",
        "    processing. They define validation rules and incremental processing capabilities.\n",
        "\n",
        "    **Validation Requirements:**\n",
        "        - `name`: Must be a non-empty string\n",
        "        - `rules`: Must be a non-empty dictionary with validation rules\n",
        "        - `incremental_col`: Must be a string if provided\n",
        "\n",
        "    Attributes:\n",
        "        name: Unique identifier for this Bronze step\n",
        "        rules: Dictionary mapping column names to validation rule lists.\n",
        "               Each rule should be a PySpark Column expression.\n",
        "        incremental_col: Column name for incremental processing (e.g., \"timestamp\").\n",
        "                        If provided, enables watermarking for efficient updates.\n",
        "                        If None, forces full refresh mode for downstream steps.\n",
        "        schema: Optional schema name for reading bronze data\n",
        "\n",
        "    Raises:\n",
        "        ValidationError: If validation requirements are not met during construction\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.functions import get_default_functions\n",
        "        >>> F = get_default_functions()\n",
        "        >>>\n",
        "        >>> # Valid Bronze step with PySpark expressions\n",
        "        >>> bronze_step = BronzeStep(\n",
        "        ...     name=\"user_events\",\n",
        "        ...     rules={\n",
        "        ...         \"user_id\": [F.col(\"user_id\").isNotNull()],\n",
        "        ...         \"event_type\": [F.col(\"event_type\").isin([\"click\", \"view\", \"purchase\"])],\n",
        "        ...         \"timestamp\": [F.col(\"timestamp\").isNotNull(), F.col(\"timestamp\") > \"2020-01-01\"]\n",
        "        ...     },\n",
        "        ...     incremental_col=\"timestamp\"\n",
        "        ... )\n",
        "        >>>\n",
        "        >>> # Validate configuration\n",
        "        >>> bronze_step.validate()\n",
        "        >>> print(f\"Supports incremental: {bronze_step.has_incremental_capability}\")\n",
        "\n",
        "        >>> # Invalid Bronze step (will raise ValidationError)\n",
        "        >>> try:\n",
        "        ...     BronzeStep(name=\"\", rules={})  # Empty name and rules\n",
        "        ... except ValidationError as e:\n",
        "        ...     print(f\"Validation failed: {e}\")\n",
        "        ...     # Output: \"Step name must be a non-empty string\"\n",
        "    \"\"\"\n",
        "\n",
        "    name: str\n",
        "    rules: ColumnRules\n",
        "    incremental_col: Optional[str] = None\n",
        "    schema: Optional[str] = None\n",
        "    sql_source: Optional[SqlSourceType] = None\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        \"\"\"Validate required fields after initialization.\"\"\"\n",
        "        if not self.name or not isinstance(self.name, str):\n",
        "            raise ValidationError(\"Step name must be a non-empty string\")\n",
        "        if not isinstance(self.rules, dict) or not self.rules:\n",
        "            raise ValidationError(\"Rules must be a non-empty dictionary\")\n",
        "        if self.incremental_col is not None and not isinstance(\n",
        "            self.incremental_col, str\n",
        "        ):\n",
        "            raise ValidationError(\"Incremental column must be a string\")\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate bronze step configuration.\"\"\"\n",
        "        if not self.name or not isinstance(self.name, str):\n",
        "            raise PipelineValidationError(\"Step name must be a non-empty string\")\n",
        "        if not isinstance(self.rules, dict):\n",
        "            raise PipelineValidationError(\"Rules must be a dictionary\")\n",
        "        if self.incremental_col is not None and not isinstance(\n",
        "            self.incremental_col, str\n",
        "        ):\n",
        "            raise PipelineValidationError(\"Incremental column must be a string\")\n",
        "\n",
        "    @property\n",
        "    def has_incremental_capability(self) -> bool:\n",
        "        \"\"\"Check if this Bronze step supports incremental processing.\"\"\"\n",
        "        return self.incremental_col is not None\n",
        "\n",
        "    @property\n",
        "    def step_type(self) -> PipelinePhase:\n",
        "        \"\"\"Return the pipeline phase for this step.\"\"\"\n",
        "        return PipelinePhase.BRONZE\n",
        "\n",
        "@dataclass\n",
        "class SilverStep(BaseModel):\n",
        "    \"\"\"\n",
        "    Silver layer step configuration for data cleaning and enrichment.\n",
        "\n",
        "    Silver steps represent the second layer of the Medallion Architecture,\n",
        "    transforming raw Bronze data into clean, business-ready datasets.\n",
        "    They apply data quality rules, business logic, and data transformations.\n",
        "\n",
        "    **Validation Requirements:**\n",
        "        - `name`: Must be a non-empty string\n",
        "        - `source_bronze`: Must be a non-empty string (except for existing tables)\n",
        "        - `transform`: Must be callable and cannot be None\n",
        "        - `rules`: Must be a non-empty dictionary with validation rules\n",
        "        - `table_name`: Must be a non-empty string\n",
        "\n",
        "    Attributes:\n",
        "        name: Unique identifier for this Silver step\n",
        "        source_bronze: Name of the Bronze step providing input data\n",
        "        transform: Transformation function with signature:\n",
        "                 (spark: SparkSession  # type: ignore[valid-type], bronze_df: DataFrame  # type: ignore[valid-type], prior_silvers: Dict[str, DataFrame]  # type: ignore[valid-type]) -> DataFrame\n",
        "                 Must be callable and cannot be None.\n",
        "        rules: Dictionary mapping column names to validation rule lists.\n",
        "               Each rule should be a PySpark Column expression.\n",
        "        table_name: Target Delta table name where results will be stored\n",
        "        watermark_col: Column name for watermarking (e.g., \"timestamp\", \"updated_at\").\n",
        "                      If provided, enables incremental processing with append mode.\n",
        "                      If None, uses overwrite mode for full refresh.\n",
        "        existing: Whether this represents an existing table (for validation-only steps)\n",
        "        schema: Optional schema name for writing silver data\n",
        "        schema_override: Optional PySpark StructType schema to override DataFrame schema\n",
        "                        when creating tables. Uses Delta Lake's overwriteSchema option.\n",
        "                        Applied during initial runs and when table doesn't exist.\n",
        "\n",
        "    Raises:\n",
        "        ValidationError: If validation requirements are not met during construction\n",
        "\n",
        "    Example:\n",
        "        >>> def clean_user_events(spark, bronze_df, prior_silvers):\n",
        "        ...     return (bronze_df\n",
        "        ...         .filter(F.col(\"user_id\").isNotNull())\n",
        "        ...         .withColumn(\"event_date\", F.date_trunc(\"day\", \"timestamp\"))\n",
        "        ...         .withColumn(\"is_weekend\", F.dayofweek(\"timestamp\").isin([1, 7]))\n",
        "        ...     )\n",
        "        >>>\n",
        "        >>> # Valid Silver step\n",
        "        >>> silver_step = SilverStep(\n",
        "        ...     name=\"clean_events\",\n",
        "        ...     source_bronze=\"user_events\",\n",
        "        ...     transform=clean_user_events,\n",
        "        ...     rules={\n",
        "        ...         \"user_id\": [F.col(\"user_id\").isNotNull()],\n",
        "        ...         \"event_date\": [F.col(\"event_date\").isNotNull()]\n",
        "        ...     },\n",
        "        ...     table_name=\"clean_user_events\",\n",
        "        ...     watermark_col=\"timestamp\"\n",
        "        ... )\n",
        "\n",
        "        >>> # Invalid Silver step (will raise ValidationError)\n",
        "        >>> try:\n",
        "        ...     SilverStep(name=\"clean_events\", source_bronze=\"\", transform=None, rules={}, table_name=\"\")\n",
        "        ... except ValidationError as e:\n",
        "        ...     print(f\"Validation failed: {e}\")\n",
        "        ...     # Output: \"Transform function is required and must be callable\"\n",
        "    \"\"\"\n",
        "\n",
        "    name: str\n",
        "    source_bronze: str\n",
        "    rules: ColumnRules\n",
        "    table_name: str\n",
        "    transform: Optional[SilverTransformFunction] = None\n",
        "    watermark_col: Optional[str] = None\n",
        "    existing: bool = False\n",
        "    optional: bool = False\n",
        "    schema: Optional[str] = None\n",
        "    source_incremental_col: Optional[str] = None\n",
        "    schema_override: Optional[StructType] = None\n",
        "    source_silvers: Optional[list[str]] = None\n",
        "    sql_source: Optional[SqlSourceType] = None\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        \"\"\"Validate required fields after initialization.\"\"\"\n",
        "        if not self.name or not isinstance(self.name, str):\n",
        "            raise ValidationError(\"Step name must be a non-empty string\")\n",
        "        if (\n",
        "            not self.existing\n",
        "            and not self.sql_source\n",
        "            and (not self.source_bronze or not isinstance(self.source_bronze, str))\n",
        "        ):\n",
        "            raise ValidationError(\"Source bronze step name must be a non-empty string\")\n",
        "        if self.transform is not None and not callable(self.transform):\n",
        "            raise ValidationError(\"Transform function must be callable if provided\")\n",
        "        if not self.existing and not self.sql_source and self.transform is None:\n",
        "            raise ValidationError(\n",
        "                \"Transform function is required for non-existing silver steps\"\n",
        "            )\n",
        "        if not self.table_name or not isinstance(self.table_name, str):\n",
        "            raise ValidationError(\"Table name must be a non-empty string\")\n",
        "        if self.source_incremental_col is not None and not isinstance(\n",
        "            self.source_incremental_col, str\n",
        "        ):\n",
        "            raise ValidationError(\"source_incremental_col must be a string\")\n",
        "        if self.schema_override is not None:\n",
        "            # Accept any StructType-like object; engine enforces correctness at write time.\n",
        "            pass\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate silver step configuration.\"\"\"\n",
        "        if not self.name or not isinstance(self.name, str):\n",
        "            raise PipelineValidationError(\"Step name must be a non-empty string\")\n",
        "        if not self.sql_source and (\n",
        "            not self.source_bronze or not isinstance(self.source_bronze, str)\n",
        "        ):\n",
        "            raise PipelineValidationError(\n",
        "                \"Source bronze step name must be a non-empty string\"\n",
        "            )\n",
        "        if not self.sql_source and not callable(self.transform):\n",
        "            raise PipelineValidationError(\"Transform must be a callable function\")\n",
        "        if not isinstance(self.rules, dict):\n",
        "            raise PipelineValidationError(\"Rules must be a dictionary\")\n",
        "        if not self.table_name or not isinstance(self.table_name, str):\n",
        "            raise PipelineValidationError(\"Table name must be a non-empty string\")\n",
        "        if self.source_incremental_col is not None and not isinstance(\n",
        "            self.source_incremental_col, str\n",
        "        ):\n",
        "            raise PipelineValidationError(\n",
        "                \"source_incremental_col must be a string when provided\"\n",
        "            )\n",
        "        if self.schema_override is not None:\n",
        "            # Accept any StructType-like object; engine enforces correctness at write time.\n",
        "            pass\n",
        "\n",
        "    @property\n",
        "    def step_type(self) -> PipelinePhase:\n",
        "        \"\"\"Return the pipeline phase for this step.\"\"\"\n",
        "        return PipelinePhase.SILVER\n",
        "\n",
        "@dataclass\n",
        "class GoldStep(BaseModel):\n",
        "    \"\"\"\n",
        "    Gold layer step configuration for business analytics and reporting.\n",
        "\n",
        "    Gold steps represent the third layer of the Medallion Architecture,\n",
        "    creating business-ready datasets for analytics, reporting, and dashboards.\n",
        "    They aggregate and transform Silver layer data into meaningful business insights.\n",
        "\n",
        "    **Validation Requirements:**\n",
        "        - `name`: Must be a non-empty string\n",
        "        - `transform`: Must be callable and cannot be None\n",
        "        - `rules`: Must be a non-empty dictionary with validation rules\n",
        "        - `table_name`: Must be a non-empty string\n",
        "        - `source_silvers`: Must be a non-empty list if provided\n",
        "\n",
        "    Attributes:\n",
        "        name: Unique identifier for this Gold step\n",
        "        transform: Transformation function with signature:\n",
        "                 (spark: SparkSession  # type: ignore[valid-type], silvers: Dict[str, DataFrame]  # type: ignore[valid-type]) -> DataFrame\n",
        "                 - spark: Active SparkSession for operations\n",
        "                 - silvers: Dictionary of all Silver DataFrames by step name\n",
        "                 Must be callable and cannot be None.\n",
        "        rules: Dictionary mapping column names to validation rule lists.\n",
        "               Each rule should be a PySpark Column expression.\n",
        "        table_name: Target Delta table name where results will be stored\n",
        "        source_silvers: List of Silver step names to use as input sources.\n",
        "                       If None, uses all available Silver steps.\n",
        "                       Allows selective consumption of Silver data.\n",
        "        schema: Optional schema name for writing gold data\n",
        "        schema_override: Optional PySpark StructType schema to override DataFrame schema\n",
        "                        when writing to gold tables. Uses Delta Lake's overwriteSchema option.\n",
        "                        Always applied for gold table writes.\n",
        "\n",
        "    Raises:\n",
        "        ValidationError: If validation requirements are not met during construction\n",
        "\n",
        "    Example:\n",
        "        >>> def user_daily_metrics(spark, silvers):\n",
        "        ...     events_df = silvers[\"clean_events\"]\n",
        "        ...     return (events_df\n",
        "        ...         .groupBy(\"user_id\", \"event_date\")\n",
        "        ...         .agg(\n",
        "        ...             F.count(\"*\").alias(\"total_events\"),\n",
        "        ...             F.countDistinct(\"event_type\").alias(\"unique_event_types\"),\n",
        "        ...             F.max(\"timestamp\").alias(\"last_activity\"),\n",
        "        ...             F.sum(F.when(F.col(\"event_type\") == \"purchase\", 1).otherwise(0)).alias(\"purchases\")\n",
        "        ...         )\n",
        "        ...         .withColumn(\"is_active_user\", F.col(\"total_events\") > 5)\n",
        "        ...     )\n",
        "        >>>\n",
        "        >>> # Valid Gold step\n",
        "        >>> gold_step = GoldStep(\n",
        "        ...     name=\"user_metrics\",\n",
        "        ...     transform=user_daily_metrics,\n",
        "        ...     rules={\n",
        "        ...         \"user_id\": [F.col(\"user_id\").isNotNull()],\n",
        "        ...         \"total_events\": [F.col(\"total_events\") > 0]\n",
        "        ...     },\n",
        "        ...     table_name=\"user_daily_metrics\",\n",
        "        ...     source_silvers=[\"clean_events\"]\n",
        "        ... )\n",
        "\n",
        "        >>> # Invalid Gold step (will raise ValidationError)\n",
        "        >>> try:\n",
        "        ...     GoldStep(name=\"\", transform=None, rules={}, table_name=\"\", source_silvers=[])\n",
        "        ... except ValidationError as e:\n",
        "        ...     print(f\"Validation failed: {e}\")\n",
        "        ...     # Output: \"Step name must be a non-empty string\"\n",
        "    \"\"\"\n",
        "\n",
        "    name: str\n",
        "    rules: ColumnRules\n",
        "    table_name: str\n",
        "    transform: Optional[GoldTransformFunction] = None\n",
        "    existing: bool = False\n",
        "    optional: bool = False\n",
        "    source_silvers: Optional[list[str]] = None\n",
        "    schema: Optional[str] = None\n",
        "    schema_override: Optional[StructType] = None\n",
        "    sql_source: Optional[SqlSourceType] = None\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        \"\"\"Validate required fields after initialization.\"\"\"\n",
        "        if not self.name or not isinstance(self.name, str):\n",
        "            raise ValidationError(\"Step name must be a non-empty string\")\n",
        "        if self.transform is not None and not callable(self.transform):\n",
        "            raise ValidationError(\"Transform function must be callable if provided\")\n",
        "        if not self.existing and not self.sql_source and self.transform is None:\n",
        "            raise ValidationError(\n",
        "                \"Transform function is required for non-existing gold steps\"\n",
        "            )\n",
        "        if not self.table_name or not isinstance(self.table_name, str):\n",
        "            raise ValidationError(\"Table name must be a non-empty string\")\n",
        "        if not isinstance(self.rules, dict) or not self.rules:\n",
        "            raise ValidationError(\"Rules must be a non-empty dictionary\")\n",
        "        if self.source_silvers is not None and (\n",
        "            not isinstance(self.source_silvers, list)\n",
        "            or (not self.source_silvers and not self.sql_source)\n",
        "        ):\n",
        "            raise ValidationError(\"Source silvers must be a non-empty list\")\n",
        "        if self.schema_override is not None:\n",
        "            # Accept any StructType-like object; engine enforces correctness.\n",
        "            pass\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate gold step configuration.\"\"\"\n",
        "        if not self.name or not isinstance(self.name, str):\n",
        "            raise PipelineValidationError(\"Step name must be a non-empty string\")\n",
        "        if self.transform is not None and not callable(self.transform):\n",
        "            raise PipelineValidationError(\n",
        "                \"Transform must be a callable function if provided\"\n",
        "            )\n",
        "        if not self.existing and not self.sql_source and self.transform is None:\n",
        "            raise PipelineValidationError(\n",
        "                \"Transform function is required for non-existing gold steps\"\n",
        "            )\n",
        "        if not isinstance(self.rules, dict):\n",
        "            raise PipelineValidationError(\"Rules must be a dictionary\")\n",
        "        if not self.table_name or not isinstance(self.table_name, str):\n",
        "            raise PipelineValidationError(\"Table name must be a non-empty string\")\n",
        "        if self.source_silvers is not None and not isinstance(\n",
        "            self.source_silvers, list\n",
        "        ):\n",
        "            raise PipelineValidationError(\"Source silvers must be a list or None\")\n",
        "        if self.schema_override is not None:\n",
        "            # Accept any StructType-like object; engine enforces correctness.\n",
        "            pass\n",
        "\n",
        "    @property\n",
        "    def step_type(self) -> PipelinePhase:\n",
        "        \"\"\"Return the pipeline phase for this step.\"\"\"\n",
        "        return PipelinePhase.GOLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.models.pipeline (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.errors, pipeline_builder.models.base\n",
        "\n",
        "\"\"\"\n",
        "Pipeline configuration models.\n",
        "\n",
        "This module provides configuration and metrics models for pipeline execution,\n",
        "including the main PipelineConfig and PipelineMetrics classes.\n",
        "\n",
        "Key Components:\n",
        "    - **PipelineConfig**: Main configuration for pipeline execution, including\n",
        "      schema, validation thresholds, and logging settings\n",
        "    - **PipelineMetrics**: Aggregated metrics from pipeline execution, including\n",
        "      step counts, durations, row counts, and validation rates\n",
        "\n",
        "Dependencies:\n",
        "    - errors: Pipeline validation and error handling\n",
        "    - models.base: Base model classes and ValidationThresholds\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.models.pipeline import PipelineConfig, PipelineMetrics\n",
        "    >>> from pipeline_builder.models.base import ValidationThresholds\n",
        "    >>>\n",
        "    >>> # Create pipeline configuration\n",
        "    >>> config = PipelineConfig.create_default(schema=\"my_schema\")\n",
        "    >>> config.validate()\n",
        "    >>>\n",
        "    >>> # Create metrics from step results\n",
        "    >>> metrics = PipelineMetrics.from_step_results(step_results)\n",
        "    >>> print(f\"Success rate: {metrics.success_rate}%\")\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any\n",
        "\n",
        "# from ..errors import PipelineValidationError  # Removed: defined in notebook cells above\n",
        "# from .base import BaseModel, ValidationThresholds  # Removed: defined in notebook cells above\n",
        "\n",
        "@dataclass\n",
        "class PipelineConfig(BaseModel):\n",
        "    \"\"\"Main pipeline configuration.\n",
        "\n",
        "    Central configuration class for pipeline execution. Defines the target\n",
        "    schema, validation thresholds for each Medallion Architecture layer,\n",
        "    and logging verbosity.\n",
        "\n",
        "    **Validation Rules:**\n",
        "        - `schema`: Must be a non-empty string\n",
        "        - `thresholds`: Must be a valid ValidationThresholds instance\n",
        "        - All thresholds are validated during model validation\n",
        "\n",
        "    Attributes:\n",
        "        schema: Database schema name where pipeline tables will be created.\n",
        "            Must be a non-empty string. Used to construct fully qualified\n",
        "            table names (e.g., \"my_schema.my_table\").\n",
        "        thresholds: ValidationThresholds instance defining minimum validation\n",
        "            success rates for Bronze, Silver, and Gold layers. Defaults to\n",
        "            standard thresholds (95%, 98%, 99%).\n",
        "        verbose: Whether to enable verbose logging during pipeline execution.\n",
        "            Defaults to True. When True, detailed execution logs are printed.\n",
        "\n",
        "    Raises:\n",
        "        PipelineValidationError: If schema is empty or invalid, or if\n",
        "            thresholds fail validation.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.pipeline import PipelineConfig\n",
        "        >>> from pipeline_builder.models.base import ValidationThresholds\n",
        "        >>>\n",
        "        >>> # Create default configuration\n",
        "        >>> config = PipelineConfig.create_default(schema=\"analytics\")\n",
        "        >>> print(config.schema)  # \"analytics\"\n",
        "        >>>\n",
        "        >>> # Create custom configuration\n",
        "        >>> thresholds = ValidationThresholds(bronze=90.0, silver=95.0, gold=99.0)\n",
        "        >>> config = PipelineConfig(\n",
        "        ...     schema=\"production\",\n",
        "        ...     thresholds=thresholds,\n",
        "        ...     verbose=False\n",
        "        ... )\n",
        "        >>> config.validate()\n",
        "        >>>\n",
        "        >>> # Access thresholds\n",
        "        >>> print(f\"Bronze threshold: {config.min_bronze_rate}%\")\n",
        "    \"\"\"\n",
        "\n",
        "    schema: str\n",
        "    thresholds: ValidationThresholds\n",
        "    verbose: bool = True\n",
        "\n",
        "    @property\n",
        "    def min_bronze_rate(self) -> float:\n",
        "        \"\"\"Get bronze validation threshold.\n",
        "\n",
        "        Returns:\n",
        "            Minimum validation success rate for Bronze layer (0-100).\n",
        "\n",
        "        Example:\n",
        "            >>> config = PipelineConfig.create_default(schema=\"test\")\n",
        "            >>> print(config.min_bronze_rate)  # 95.0\n",
        "        \"\"\"\n",
        "        return self.thresholds.bronze\n",
        "\n",
        "    @property\n",
        "    def min_silver_rate(self) -> float:\n",
        "        \"\"\"Get silver validation threshold.\n",
        "\n",
        "        Returns:\n",
        "            Minimum validation success rate for Silver layer (0-100).\n",
        "\n",
        "        Example:\n",
        "            >>> config = PipelineConfig.create_default(schema=\"test\")\n",
        "            >>> print(config.min_silver_rate)  # 98.0\n",
        "        \"\"\"\n",
        "        return self.thresholds.silver\n",
        "\n",
        "    @property\n",
        "    def min_gold_rate(self) -> float:\n",
        "        \"\"\"Get gold validation threshold.\n",
        "\n",
        "        Returns:\n",
        "            Minimum validation success rate for Gold layer (0-100).\n",
        "\n",
        "        Example:\n",
        "            >>> config = PipelineConfig.create_default(schema=\"test\")\n",
        "            >>> print(config.min_gold_rate)  # 99.0\n",
        "        \"\"\"\n",
        "        return self.thresholds.gold\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate pipeline configuration.\n",
        "\n",
        "        Ensures the configuration is valid by checking schema name and\n",
        "        validation thresholds. Raises an error if validation fails.\n",
        "\n",
        "        Raises:\n",
        "            PipelineValidationError: If schema is empty or invalid, or if\n",
        "                thresholds fail validation.\n",
        "\n",
        "        Example:\n",
        "            >>> config = PipelineConfig.create_default(schema=\"test\")\n",
        "            >>> config.validate()  # Passes\n",
        "            >>>\n",
        "            >>> invalid = PipelineConfig(schema=\"\", thresholds=ValidationThresholds.create_default())\n",
        "            >>> invalid.validate()  # Raises PipelineValidationError\n",
        "        \"\"\"\n",
        "        if not self.schema or not isinstance(self.schema, str):\n",
        "            raise PipelineValidationError(\"Schema name must be a non-empty string\")\n",
        "        self.thresholds.validate()\n",
        "\n",
        "    @classmethod\n",
        "    def create_default(cls, schema: str) -> PipelineConfig:\n",
        "        \"\"\"Create default pipeline configuration.\n",
        "\n",
        "        Creates a standard configuration suitable for most production use cases:\n",
        "        - Standard validation thresholds (95%, 98%, 99%)\n",
        "        - Verbose logging enabled\n",
        "\n",
        "        Args:\n",
        "            schema: Database schema name for pipeline tables.\n",
        "\n",
        "        Returns:\n",
        "            PipelineConfig instance with default settings.\n",
        "\n",
        "        Example:\n",
        "            >>> config = PipelineConfig.create_default(schema=\"analytics\")\n",
        "            >>> print(config.verbose)  # True\n",
        "            >>> print(config.min_bronze_rate)  # 95.0\n",
        "        \"\"\"\n",
        "        return cls(\n",
        "            schema=schema,\n",
        "            thresholds=ValidationThresholds.create_default(),\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def create_high_performance(cls, schema: str) -> PipelineConfig:\n",
        "        \"\"\"Create high-performance pipeline configuration with strict validation.\n",
        "\n",
        "        Creates a configuration optimized for performance and data quality:\n",
        "        - Strict validation thresholds (99%, 99.5%, 99.9%)\n",
        "        - Verbose logging disabled for better performance\n",
        "\n",
        "        Args:\n",
        "            schema: Database schema name for pipeline tables.\n",
        "\n",
        "        Returns:\n",
        "            PipelineConfig instance with high-performance settings.\n",
        "\n",
        "        Example:\n",
        "            >>> config = PipelineConfig.create_high_performance(schema=\"production\")\n",
        "            >>> print(config.verbose)  # False\n",
        "            >>> print(config.min_gold_rate)  # 99.9\n",
        "        \"\"\"\n",
        "        return cls(\n",
        "            schema=schema,\n",
        "            thresholds=ValidationThresholds.create_strict(),\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def create_conservative(cls, schema: str) -> PipelineConfig:\n",
        "        \"\"\"Create conservative pipeline configuration with strict validation.\n",
        "\n",
        "        Creates a configuration prioritizing data quality and observability:\n",
        "        - Strict validation thresholds (99%, 99.5%, 99.9%)\n",
        "        - Verbose logging enabled for detailed monitoring\n",
        "\n",
        "        Args:\n",
        "            schema: Database schema name for pipeline tables.\n",
        "\n",
        "        Returns:\n",
        "            PipelineConfig instance with conservative settings.\n",
        "\n",
        "        Example:\n",
        "            >>> config = PipelineConfig.create_conservative(schema=\"critical\")\n",
        "            >>> print(config.verbose)  # True\n",
        "            >>> print(config.min_gold_rate)  # 99.9\n",
        "        \"\"\"\n",
        "        return cls(\n",
        "            schema=schema,\n",
        "            thresholds=ValidationThresholds.create_strict(),\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "@dataclass\n",
        "class PipelineMetrics(BaseModel):\n",
        "    \"\"\"Overall pipeline execution metrics.\n",
        "\n",
        "    Aggregates metrics from all pipeline steps to provide a comprehensive\n",
        "    view of pipeline execution performance and quality. Metrics include step\n",
        "    counts, durations, row counts, validation rates, and efficiency measures.\n",
        "\n",
        "    **Validation Rules:**\n",
        "        - All counts must be non-negative\n",
        "        - All durations must be non-negative\n",
        "        - Validation rate must be between 0 and 100\n",
        "        - Total steps must equal successful + failed + skipped\n",
        "\n",
        "    Attributes:\n",
        "        total_steps: Total number of steps in the pipeline. Defaults to 0.\n",
        "        successful_steps: Number of steps that completed successfully.\n",
        "            Defaults to 0.\n",
        "        failed_steps: Number of steps that failed during execution.\n",
        "            Defaults to 0.\n",
        "        skipped_steps: Number of steps that were skipped (e.g., due to\n",
        "            dependencies). Defaults to 0.\n",
        "        total_duration: Total execution duration in seconds. Defaults to 0.0.\n",
        "        bronze_duration: Total duration for Bronze layer steps in seconds.\n",
        "            Defaults to 0.0.\n",
        "        silver_duration: Total duration for Silver layer steps in seconds.\n",
        "            Defaults to 0.0.\n",
        "        gold_duration: Total duration for Gold layer steps in seconds.\n",
        "            Defaults to 0.0.\n",
        "        total_rows_processed: Total number of rows processed across all steps.\n",
        "            Defaults to 0.\n",
        "        total_rows_written: Total number of rows written to tables across\n",
        "            all steps. Defaults to 0.\n",
        "        avg_validation_rate: Average validation success rate across all steps\n",
        "            (0-100). Defaults to 0.0.\n",
        "        cache_hit_rate: Cache hit rate (0-100). Defaults to 0.0.\n",
        "        error_count: Total number of errors encountered. Defaults to 0.\n",
        "        retry_count: Total number of retries attempted. Defaults to 0.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.pipeline import PipelineMetrics\n",
        "        >>>\n",
        "        >>> # Create metrics from step results\n",
        "        >>> metrics = PipelineMetrics.from_step_results(step_results)\n",
        "        >>> print(f\"Success rate: {metrics.success_rate}%\")\n",
        "        >>> print(f\"Total rows: {metrics.total_rows_processed}\")\n",
        "        >>>\n",
        "        >>> # Create metrics manually\n",
        "        >>> metrics = PipelineMetrics(\n",
        "        ...     total_steps=5,\n",
        "        ...     successful_steps=4,\n",
        "        ...     failed_steps=1,\n",
        "        ...     total_duration=120.5,\n",
        "        ...     total_rows_processed=1000000,\n",
        "        ...     avg_validation_rate=98.5\n",
        "        ... )\n",
        "        >>> metrics.validate()\n",
        "    \"\"\"\n",
        "\n",
        "    total_steps: int = 0\n",
        "    successful_steps: int = 0\n",
        "    failed_steps: int = 0\n",
        "    skipped_steps: int = 0\n",
        "    total_duration: float = 0.0\n",
        "    bronze_duration: float = 0.0\n",
        "    silver_duration: float = 0.0\n",
        "    gold_duration: float = 0.0\n",
        "    total_rows_processed: int = 0\n",
        "    total_rows_written: int = 0\n",
        "    avg_validation_rate: float = 0.0\n",
        "    cache_hit_rate: float = 0.0\n",
        "    error_count: int = 0\n",
        "    retry_count: int = 0\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the pipeline metrics.\n",
        "\n",
        "        Ensures all metric values are within valid ranges and consistent\n",
        "        with each other. Raises an error if validation fails.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If any metric value is invalid or inconsistent.\n",
        "\n",
        "        Example:\n",
        "            >>> metrics = PipelineMetrics(total_steps=5, successful_steps=4)\n",
        "            >>> metrics.validate()  # Passes\n",
        "            >>>\n",
        "            >>> invalid = PipelineMetrics(total_steps=-1)\n",
        "            >>> invalid.validate()  # Raises ValueError\n",
        "        \"\"\"\n",
        "        if self.total_steps < 0:\n",
        "            raise ValueError(\"Total steps cannot be negative\")\n",
        "        if self.successful_steps < 0:\n",
        "            raise ValueError(\"Successful steps cannot be negative\")\n",
        "        if self.failed_steps < 0:\n",
        "            raise ValueError(\"Failed steps cannot be negative\")\n",
        "        if self.skipped_steps < 0:\n",
        "            raise ValueError(\"Skipped steps cannot be negative\")\n",
        "        if self.total_duration < 0:\n",
        "            raise ValueError(\"Total duration cannot be negative\")\n",
        "        if not 0 <= self.avg_validation_rate <= 100:\n",
        "            raise ValueError(\"Average validation rate must be between 0 and 100\")\n",
        "\n",
        "    @property\n",
        "    def success_rate(self) -> float:\n",
        "        \"\"\"Calculate success rate.\n",
        "\n",
        "        Returns:\n",
        "            Percentage of successful steps (0-100). Returns 0.0 if there\n",
        "            are no steps.\n",
        "\n",
        "        Example:\n",
        "            >>> metrics = PipelineMetrics(total_steps=10, successful_steps=8)\n",
        "            >>> print(f\"Success rate: {metrics.success_rate}%\")  # 80.0%\n",
        "        \"\"\"\n",
        "        return (\n",
        "            (self.successful_steps / self.total_steps * 100)\n",
        "            if self.total_steps > 0\n",
        "            else 0.0\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def failure_rate(self) -> float:\n",
        "        \"\"\"Calculate failure rate.\n",
        "\n",
        "        Returns:\n",
        "            Percentage of failed steps (0-100). Returns 0.0 if there\n",
        "            are no steps.\n",
        "\n",
        "        Example:\n",
        "            >>> metrics = PipelineMetrics(total_steps=10, successful_steps=8)\n",
        "            >>> print(f\"Failure rate: {metrics.failure_rate}%\")  # 20.0%\n",
        "        \"\"\"\n",
        "        return 100.0 - self.success_rate\n",
        "\n",
        "    @classmethod\n",
        "    def from_step_results(cls, step_results: list[Any]) -> PipelineMetrics:\n",
        "        \"\"\"Create metrics from step results.\n",
        "\n",
        "        Aggregates metrics from a list of StepResult objects to create\n",
        "        comprehensive pipeline metrics.\n",
        "\n",
        "        Args:\n",
        "            step_results: List of StepResult objects from pipeline execution.\n",
        "\n",
        "        Returns:\n",
        "            PipelineMetrics instance with aggregated metrics from all steps.\n",
        "\n",
        "        Example:\n",
        "            >>> from pipeline_builder.models.execution import StepResult\n",
        "            >>> from pipeline_builder.models.enums import PipelinePhase\n",
        "            >>> from datetime import datetime, timezone\n",
        "            >>>\n",
        "            >>> # Create step results\n",
        "            >>> results = [\n",
        "            ...     StepResult.create_success(\n",
        "            ...         step_name=\"bronze_step\",\n",
        "            ...         phase=PipelinePhase.BRONZE,\n",
        "            ...         start_time=datetime.now(timezone.utc),\n",
        "            ...         end_time=datetime.now(timezone.utc),\n",
        "            ...         rows_processed=1000,\n",
        "            ...         rows_written=950,\n",
        "            ...         validation_rate=95.0\n",
        "            ...     )\n",
        "            ... ]\n",
        "            >>>\n",
        "            >>> # Aggregate metrics\n",
        "            >>> metrics = PipelineMetrics.from_step_results(results)\n",
        "            >>> print(f\"Total steps: {metrics.total_steps}\")  # 1\n",
        "            >>> print(f\"Success rate: {metrics.success_rate}%\")  # 100.0%\n",
        "        \"\"\"\n",
        "        total_steps = len(step_results)\n",
        "        successful_steps = sum(1 for result in step_results if result.success)\n",
        "        failed_steps = total_steps - successful_steps\n",
        "        total_duration_secs = sum(result.duration_secs for result in step_results)\n",
        "        total_rows_processed = sum(result.rows_processed for result in step_results)\n",
        "        total_rows_written = sum(result.rows_written for result in step_results)\n",
        "        avg_validation_rate = (\n",
        "            sum(result.validation_rate for result in step_results) / total_steps\n",
        "            if total_steps > 0\n",
        "            else 0.0\n",
        "        )\n",
        "\n",
        "        return cls(\n",
        "            total_steps=total_steps,\n",
        "            successful_steps=successful_steps,\n",
        "            failed_steps=failed_steps,\n",
        "            total_duration=total_duration_secs,\n",
        "            total_rows_processed=total_rows_processed,\n",
        "            total_rows_written=total_rows_written,\n",
        "            avg_validation_rate=avg_validation_rate,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.models.dependencies (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.models.base, pipeline_builder.models.base, pipeline_builder_base.errors, pipeline_builder_base.errors\n",
        "\n",
        "\"\"\"\n",
        "Dependency models for the Pipeline Builder.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict\n",
        "# from .errors import PipelineValidationError  # Removed: defined in notebook cells above\n",
        "\n",
        "# from .base import BaseModel  # Removed: defined in notebook cells above\n",
        "\n",
        "@dataclass\n",
        "class SilverDependencyInfo(BaseModel):\n",
        "    \"\"\"\n",
        "    Dependency information for Silver steps.\n",
        "\n",
        "    Attributes:\n",
        "        step_name: Name of the silver step\n",
        "        source_bronze: Source bronze step name\n",
        "        depends_on_silvers: Set of silver step names this step depends on\n",
        "        execution_group: (Deprecated) Legacy field, no longer used. Execution\n",
        "            order is determined by topological sort.\n",
        "    \"\"\"\n",
        "\n",
        "    step_name: str\n",
        "    source_bronze: str\n",
        "    depends_on_silvers: set[str]\n",
        "    execution_group: int\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate dependency information.\"\"\"\n",
        "        if not self.step_name or not isinstance(self.step_name, str):\n",
        "            raise PipelineValidationError(\"Step name must be a non-empty string\")\n",
        "        if not self.source_bronze or not isinstance(self.source_bronze, str):\n",
        "            raise PipelineValidationError(\n",
        "                \"Source bronze step name must be a non-empty string\"\n",
        "            )\n",
        "        if not isinstance(self.depends_on_silvers, set):\n",
        "            raise PipelineValidationError(\"Depends on silvers must be a set\")\n",
        "        if self.execution_group < 0:\n",
        "            raise PipelineValidationError(\"Execution group must be non-negative\")\n",
        "\n",
        "@dataclass\n",
        "class CrossLayerDependency(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents a dependency between steps across different layers.\n",
        "\n",
        "    Attributes:\n",
        "        source_step: Name of the source step\n",
        "        target_step: Name of the target step\n",
        "        dependency_type: Type of dependency (data, validation, etc.)\n",
        "        is_required: Whether this dependency is required for execution\n",
        "    \"\"\"\n",
        "\n",
        "    source_step: str\n",
        "    target_step: str\n",
        "    dependency_type: str = \"data\"\n",
        "    is_required: bool = True\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate dependency information.\"\"\"\n",
        "        if not self.source_step or not isinstance(self.source_step, str):\n",
        "            raise PipelineValidationError(\"Source step must be a non-empty string\")\n",
        "        if not self.target_step or not isinstance(self.target_step, str):\n",
        "            raise PipelineValidationError(\"Target step must be a non-empty string\")\n",
        "        if self.source_step == self.target_step:\n",
        "            raise PipelineValidationError(\"Source and target steps cannot be the same\")\n",
        "\n",
        "@dataclass\n",
        "class UnifiedStepConfig(BaseModel):\n",
        "    \"\"\"\n",
        "    Unified configuration for pipeline steps.\n",
        "\n",
        "    Attributes:\n",
        "        step_name: Name of the step\n",
        "        step_type: Type of step (bronze/silver/gold)\n",
        "        dependencies: List of step dependencies\n",
        "        config: Step-specific configuration\n",
        "    \"\"\"\n",
        "\n",
        "    step_name: str\n",
        "    step_type: str\n",
        "    dependencies: list[str]\n",
        "    config: Dict[str, Any]\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate unified step configuration.\"\"\"\n",
        "        if not self.step_name or not isinstance(self.step_name, str):\n",
        "            raise PipelineValidationError(\"Step name must be a non-empty string\")\n",
        "        if self.step_type not in [\"bronze\", \"silver\", \"gold\"]:\n",
        "            raise PipelineValidationError(\"Step type must be bronze, silver, or gold\")\n",
        "        if not isinstance(self.dependencies, list):\n",
        "            raise PipelineValidationError(\"Dependencies must be a list\")\n",
        "        if not isinstance(self.config, dict):\n",
        "            raise PipelineValidationError(\"Config must be a dictionary\")\n",
        "\n",
        "@dataclass\n",
        "class UnifiedExecutionPlan(BaseModel):\n",
        "    \"\"\"\n",
        "    Unified execution plan for pipeline steps.\n",
        "\n",
        "    Attributes:\n",
        "        steps: List of unified step configurations\n",
        "        execution_order: Ordered list of step names for execution\n",
        "    \"\"\"\n",
        "\n",
        "    steps: list[UnifiedStepConfig]\n",
        "    execution_order: list[str]\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate unified execution plan.\"\"\"\n",
        "        if not isinstance(self.steps, list):\n",
        "            raise PipelineValidationError(\"Steps must be a list\")\n",
        "        if not isinstance(self.execution_order, list):\n",
        "            raise PipelineValidationError(\"Execution order must be a list\")\n",
        "\n",
        "        # Validate that all steps in execution order exist\n",
        "        step_names = {step.step_name for step in self.steps}\n",
        "        for step_name in self.execution_order:\n",
        "            if step_name not in step_names:\n",
        "                raise PipelineValidationError(f\"Step {step_name} not found in steps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.models.execution (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.models.base, pipeline_builder.models.enums, pipeline_builder.models.exceptions, pipeline_builder.models.pipeline\n",
        "\n",
        "\"\"\"\n",
        "Execution models for the Pipeline Builder.\n",
        "\n",
        "This module provides models for tracking pipeline execution state and results,\n",
        "including execution contexts, step results, stage statistics, and overall\n",
        "execution results.\n",
        "\n",
        "Key Components:\n",
        "    - **ExecutionContext**: Tracks execution state, timing, and metadata\n",
        "    - **StageStats**: Statistics for individual pipeline stages\n",
        "    - **StepResult**: Results from individual step execution\n",
        "    - **ExecutionResult**: Aggregated results from entire pipeline execution\n",
        "\n",
        "Dependencies:\n",
        "    - models.base: BaseModel\n",
        "    - models.enums: ExecutionMode, PipelinePhase\n",
        "    - models.exceptions: PipelineConfigurationError\n",
        "    - models.pipeline: PipelineMetrics\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.models.execution import (\n",
        "    ...     ExecutionContext,\n",
        "    ...     StepResult,\n",
        "    ...     ExecutionResult\n",
        "    ... )\n",
        "    >>> from pipeline_builder.models.enums import ExecutionMode, PipelinePhase\n",
        "    >>> from datetime import datetime, timezone\n",
        "    >>>\n",
        "    >>> # Create execution context\n",
        "    >>> context = ExecutionContext(\n",
        "    ...     mode=ExecutionMode.INITIAL,\n",
        "    ...     start_time=datetime.now(timezone.utc)\n",
        "    ... )\n",
        "    >>>\n",
        "    >>> # Create step result\n",
        "    >>> result = StepResult.create_success(\n",
        "    ...     step_name=\"bronze_step\",\n",
        "    ...     phase=PipelinePhase.BRONZE,\n",
        "    ...     start_time=datetime.now(timezone.utc),\n",
        "    ...     end_time=datetime.now(timezone.utc),\n",
        "    ...     rows_processed=1000,\n",
        "    ...     rows_written=950,\n",
        "    ...     validation_rate=95.0\n",
        "    ... )\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import uuid\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime, timezone\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "# from .base import BaseModel  # Removed: defined in notebook cells above\n",
        "# from .enums import ExecutionMode, PipelinePhase  # Removed: defined in notebook cells above\n",
        "# from .exceptions import PipelineConfigurationError  # Removed: defined in notebook cells above\n",
        "# from .pipeline import PipelineMetrics  # Removed: defined in notebook cells above\n",
        "\n",
        "@dataclass\n",
        "class ExecutionContext(BaseModel):\n",
        "    \"\"\"Context for pipeline execution.\n",
        "\n",
        "    Tracks the state and metadata of a pipeline execution run, including\n",
        "    timing information, execution mode, and identifiers. Provides both\n",
        "    primary fields and aliases for compatibility with different parts of\n",
        "    the system.\n",
        "\n",
        "    **Validation Rules:**\n",
        "        - `run_id`: Must be a non-empty string\n",
        "        - `duration_secs`: Must be non-negative if set\n",
        "\n",
        "    Attributes:\n",
        "        mode: Execution mode (INITIAL, INCREMENTAL, FULL_REFRESH,\n",
        "            VALIDATION_ONLY). Determines how the pipeline is executed.\n",
        "        start_time: When execution started. Required field.\n",
        "        end_time: When execution ended. None if execution is still running.\n",
        "        duration_secs: Total execution duration in seconds. None if execution\n",
        "            is still running. Automatically calculated when `finish()` is called.\n",
        "        run_id: Unique run identifier (UUID string). Automatically generated\n",
        "            if not provided.\n",
        "        execution_id: Unique identifier for this execution (UUID string).\n",
        "            Used for tracking and logging. Automatically generated if not provided.\n",
        "        pipeline_id: Identifier for the pipeline being executed. Defaults\n",
        "            to \"unknown\" if not provided.\n",
        "        schema: Target schema for data storage. Defaults to \"default\" if\n",
        "            not provided.\n",
        "        started_at: When execution started (alias for start_time). Set\n",
        "            automatically from start_time if not provided.\n",
        "        ended_at: When execution ended (alias for end_time). Set automatically\n",
        "            from end_time if not provided.\n",
        "        run_mode: Mode of execution as string (alias for mode.value).\n",
        "            Automatically set from mode if not provided.\n",
        "        config: Pipeline configuration as dictionary. Defaults to empty dict.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.execution import ExecutionContext\n",
        "        >>> from pipeline_builder.models.enums import ExecutionMode\n",
        "        >>> from datetime import datetime, timezone\n",
        "        >>>\n",
        "        >>> # Create context\n",
        "        >>> context = ExecutionContext(\n",
        "        ...     mode=ExecutionMode.INITIAL,\n",
        "        ...     start_time=datetime.now(timezone.utc)\n",
        "        ... )\n",
        "        >>> print(context.run_id)  # Unique UUID\n",
        "        >>>\n",
        "        >>> # Finish execution\n",
        "        >>> context.finish()\n",
        "        >>> print(context.duration_secs)  # Execution duration\n",
        "    \"\"\"\n",
        "\n",
        "    mode: ExecutionMode\n",
        "    start_time: datetime\n",
        "    end_time: Optional[datetime] = None\n",
        "    duration_secs: Optional[float] = None\n",
        "    run_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
        "\n",
        "    # Additional fields for writer compatibility\n",
        "    execution_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
        "    pipeline_id: str = \"unknown\"\n",
        "    schema: str = \"default\"\n",
        "    started_at: Optional[datetime] = None\n",
        "    ended_at: Optional[datetime] = None\n",
        "    run_mode: str = \"initial\"\n",
        "    config: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        \"\"\"Initialize aliases and defaults.\n",
        "\n",
        "        Sets up alias fields (started_at, ended_at, run_mode) from primary\n",
        "        fields if they are not explicitly provided. This ensures backward\n",
        "        compatibility with code that uses the alias fields.\n",
        "        \"\"\"\n",
        "        if self.started_at is None:\n",
        "            self.started_at = self.start_time\n",
        "        if self.ended_at is None:\n",
        "            self.ended_at = self.end_time\n",
        "        if self.run_mode == \"initial\":\n",
        "            # Map mode to run_mode string\n",
        "            if hasattr(self.mode, \"value\"):\n",
        "                self.run_mode = self.mode.value\n",
        "            elif hasattr(self.mode, \"name\"):\n",
        "                self.run_mode = self.mode.name.lower()\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the execution context.\n",
        "\n",
        "        Ensures the context has valid values for required fields and that\n",
        "        numeric fields are within valid ranges.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If run_id is empty or duration_secs is negative.\n",
        "\n",
        "        Example:\n",
        "            >>> context = ExecutionContext(\n",
        "            ...     mode=ExecutionMode.INITIAL,\n",
        "            ...     start_time=datetime.now(timezone.utc)\n",
        "            ... )\n",
        "            >>> context.validate()  # Passes\n",
        "        \"\"\"\n",
        "        if not self.run_id:\n",
        "            raise ValueError(\"Run ID cannot be empty\")\n",
        "        if self.duration_secs is not None and self.duration_secs < 0:\n",
        "            raise ValueError(\"Duration cannot be negative\")\n",
        "\n",
        "    def finish(self) -> None:\n",
        "        \"\"\"Mark execution as finished and calculate duration.\n",
        "\n",
        "        Sets the end_time to the current timestamp and calculates the\n",
        "        execution duration. Also updates the ended_at alias field.\n",
        "\n",
        "        Example:\n",
        "            >>> context = ExecutionContext(\n",
        "            ...     mode=ExecutionMode.INITIAL,\n",
        "            ...     start_time=datetime.now(timezone.utc)\n",
        "            ... )\n",
        "            >>> # ... execution happens ...\n",
        "            >>> context.finish()\n",
        "            >>> print(context.duration_secs)  # Execution duration in seconds\n",
        "        \"\"\"\n",
        "        self.end_time = datetime.now(timezone.utc)\n",
        "        if self.start_time:\n",
        "            self.duration_secs = (self.end_time - self.start_time).total_seconds()\n",
        "\n",
        "    @property\n",
        "    def is_finished(self) -> bool:\n",
        "        \"\"\"Check if execution is finished.\n",
        "\n",
        "        Returns:\n",
        "            True if end_time is set, False otherwise.\n",
        "\n",
        "        Example:\n",
        "            >>> context = ExecutionContext(...)\n",
        "            >>> print(context.is_finished)  # False\n",
        "            >>> context.finish()\n",
        "            >>> print(context.is_finished)  # True\n",
        "        \"\"\"\n",
        "        return self.end_time is not None\n",
        "\n",
        "    @property\n",
        "    def is_running(self) -> bool:\n",
        "        \"\"\"Check if execution is currently running.\n",
        "\n",
        "        Returns:\n",
        "            True if execution is still running (end_time is None),\n",
        "            False otherwise.\n",
        "\n",
        "        Example:\n",
        "            >>> context = ExecutionContext(...)\n",
        "            >>> print(context.is_running)  # True\n",
        "            >>> context.finish()\n",
        "            >>> print(context.is_running)  # False\n",
        "        \"\"\"\n",
        "        return not self.is_finished\n",
        "\n",
        "@dataclass\n",
        "class StageStats(BaseModel):\n",
        "    \"\"\"Statistics for a pipeline stage.\n",
        "\n",
        "    Tracks detailed statistics for a single pipeline stage (Bronze, Silver,\n",
        "    or Gold), including row counts, validation rates, and timing information.\n",
        "\n",
        "    **Validation Rules:**\n",
        "        - `total_rows` must equal `valid_rows + invalid_rows`\n",
        "        - `validation_rate` must be between 0 and 100\n",
        "        - `duration_secs` must be non-negative\n",
        "\n",
        "    Attributes:\n",
        "        stage: Stage name (bronze, silver, or gold). Identifies which\n",
        "            Medallion Architecture layer this stage belongs to.\n",
        "        step: Step name within the stage. Identifies the specific step\n",
        "            these statistics are for.\n",
        "        total_rows: Total number of rows processed in this stage.\n",
        "        valid_rows: Number of rows that passed validation.\n",
        "        invalid_rows: Number of rows that failed validation.\n",
        "        validation_rate: Validation success rate (0-100). Percentage of\n",
        "            rows that passed validation.\n",
        "        duration_secs: Processing duration in seconds for this stage.\n",
        "        start_time: When processing started. Optional timestamp.\n",
        "        end_time: When processing ended. Optional timestamp.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.execution import StageStats\n",
        "        >>> from datetime import datetime, timezone\n",
        "        >>>\n",
        "        >>> stats = StageStats(\n",
        "        ...     stage=\"bronze\",\n",
        "        ...     step=\"user_events\",\n",
        "        ...     total_rows=1000,\n",
        "        ...     valid_rows=950,\n",
        "        ...     invalid_rows=50,\n",
        "        ...     validation_rate=95.0,\n",
        "        ...     duration_secs=10.5\n",
        "        ... )\n",
        "        >>> stats.validate()\n",
        "        >>> print(f\"Error rate: {stats.error_rate}%\")  # 5.0%\n",
        "    \"\"\"\n",
        "\n",
        "    stage: str\n",
        "    step: str\n",
        "    total_rows: int\n",
        "    valid_rows: int\n",
        "    invalid_rows: int\n",
        "    validation_rate: float\n",
        "    duration_secs: float\n",
        "    start_time: Optional[datetime] = None\n",
        "    end_time: Optional[datetime] = None\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate stage statistics.\n",
        "\n",
        "        Ensures row counts are consistent and all values are within valid\n",
        "        ranges. Raises an error if validation fails.\n",
        "\n",
        "        Raises:\n",
        "            PipelineConfigurationError: If row counts are inconsistent or\n",
        "                values are outside valid ranges.\n",
        "\n",
        "        Example:\n",
        "            >>> stats = StageStats(\n",
        "            ...     stage=\"bronze\",\n",
        "            ...     step=\"test\",\n",
        "            ...     total_rows=1000,\n",
        "            ...     valid_rows=950,\n",
        "            ...     invalid_rows=50,\n",
        "            ...     validation_rate=95.0,\n",
        "            ...     duration_secs=10.5\n",
        "            ... )\n",
        "            >>> stats.validate()  # Passes\n",
        "        \"\"\"\n",
        "        if self.total_rows != self.valid_rows + self.invalid_rows:\n",
        "            raise PipelineConfigurationError(\n",
        "                f\"Total rows ({self.total_rows}) must equal valid ({self.valid_rows}) + invalid ({self.invalid_rows})\"\n",
        "            )\n",
        "        if not 0 <= self.validation_rate <= 100:\n",
        "            raise PipelineConfigurationError(\n",
        "                f\"Validation rate must be between 0 and 100, got {self.validation_rate}\"\n",
        "            )\n",
        "        if self.duration_secs < 0:\n",
        "            raise PipelineConfigurationError(\n",
        "                f\"Duration must be non-negative, got {self.duration_secs}\"\n",
        "            )\n",
        "\n",
        "    @property\n",
        "    def is_valid(self) -> bool:\n",
        "        \"\"\"Check if the stage passed validation.\n",
        "\n",
        "        Returns:\n",
        "            True if validation_rate >= 95.0%, False otherwise.\n",
        "\n",
        "        Example:\n",
        "            >>> stats = StageStats(..., validation_rate=96.0, ...)\n",
        "            >>> print(stats.is_valid)  # True\n",
        "        \"\"\"\n",
        "        return self.validation_rate >= 95.0  # Default threshold\n",
        "\n",
        "    @property\n",
        "    def error_rate(self) -> float:\n",
        "        \"\"\"Calculate error rate.\n",
        "\n",
        "        Returns:\n",
        "            Percentage of rows that failed validation (0-100). Returns 0.0\n",
        "            if total_rows is 0.\n",
        "\n",
        "        Example:\n",
        "            >>> stats = StageStats(\n",
        "            ...     total_rows=1000,\n",
        "            ...     invalid_rows=50,\n",
        "            ...     ...\n",
        "            ... )\n",
        "            >>> print(f\"Error rate: {stats.error_rate}%\")  # 5.0%\n",
        "        \"\"\"\n",
        "        if self.total_rows == 0:\n",
        "            return 0.0\n",
        "        return (self.invalid_rows / self.total_rows) * 100\n",
        "\n",
        "    @property\n",
        "    def throughput_rows_per_sec(self) -> float:\n",
        "        \"\"\"Calculate throughput in rows per second.\n",
        "\n",
        "        Returns:\n",
        "            Processing throughput in rows per second. Returns 0.0 if\n",
        "            duration_secs is 0.\n",
        "\n",
        "        Example:\n",
        "            >>> stats = StageStats(\n",
        "            ...     total_rows=10000,\n",
        "            ...     duration_secs=10.0,\n",
        "            ...     ...\n",
        "            ... )\n",
        "            >>> print(f\"Throughput: {stats.throughput_rows_per_sec} rows/sec\")  # 1000.0\n",
        "        \"\"\"\n",
        "        if self.duration_secs == 0:\n",
        "            return 0.0\n",
        "        return self.total_rows / self.duration_secs\n",
        "\n",
        "@dataclass\n",
        "class StepResult(BaseModel):\n",
        "    \"\"\"Result of a pipeline step execution.\n",
        "\n",
        "    Tracks the outcome and metrics of a single pipeline step execution,\n",
        "    including success status, timing, row counts, and validation rates.\n",
        "\n",
        "    **Validation Rules:**\n",
        "        - `step_name`: Must be a non-empty string\n",
        "        - `duration_secs`: Must be non-negative\n",
        "        - `rows_processed`: Must be non-negative\n",
        "        - `rows_written`: Must be non-negative\n",
        "        - `validation_rate`: Must be between 0 and 100\n",
        "\n",
        "    Attributes:\n",
        "        step_name: Name of the step that was executed. Identifies which\n",
        "            step these results are for.\n",
        "        phase: Pipeline phase (BRONZE, SILVER, or GOLD) that this step\n",
        "            belongs to.\n",
        "        success: Whether the step execution succeeded. True if the step\n",
        "            completed without errors, False otherwise.\n",
        "        start_time: When step execution started. Required timestamp.\n",
        "        end_time: When step execution ended. Required timestamp.\n",
        "        duration_secs: Execution duration in seconds. Calculated from\n",
        "            start_time and end_time.\n",
        "        rows_processed: Number of rows processed during step execution.\n",
        "            Includes both valid and invalid rows.\n",
        "        rows_written: Number of rows written to the target table. May be\n",
        "            less than rows_processed if validation filtered out some rows.\n",
        "        validation_rate: Validation success rate (0-100). Percentage of\n",
        "            processed rows that passed validation.\n",
        "        error_message: Error message if the step failed. None if the step\n",
        "            succeeded.\n",
        "        step_type: Type of step (bronze, silver, gold) as string. Optional\n",
        "            for compatibility.\n",
        "        table_fqn: Fully qualified table name if step writes to a table\n",
        "            (e.g., \"schema.table_name\"). None if step doesn't write to a table.\n",
        "        write_mode: Write mode used (overwrite, append). None if step\n",
        "            doesn't write to a table.\n",
        "        input_rows: Number of input rows processed. Optional field for\n",
        "            tracking input data size.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.execution import StepResult\n",
        "        >>> from pipeline_builder.models.enums import PipelinePhase\n",
        "        >>> from datetime import datetime, timezone\n",
        "        >>>\n",
        "        >>> # Create success result\n",
        "        >>> result = StepResult.create_success(\n",
        "        ...     step_name=\"bronze_step\",\n",
        "        ...     phase=PipelinePhase.BRONZE,\n",
        "        ...     start_time=datetime.now(timezone.utc),\n",
        "        ...     end_time=datetime.now(timezone.utc),\n",
        "        ...     rows_processed=1000,\n",
        "        ...     rows_written=950,\n",
        "        ...     validation_rate=95.0\n",
        "        ... )\n",
        "        >>> print(f\"Success: {result.success}\")  # True\n",
        "        >>> print(f\"Throughput: {result.throughput_rows_per_sec} rows/sec\")\n",
        "    \"\"\"\n",
        "\n",
        "    step_name: str\n",
        "    phase: PipelinePhase\n",
        "    success: bool\n",
        "    start_time: datetime\n",
        "    end_time: datetime\n",
        "    duration_secs: float\n",
        "    rows_processed: int\n",
        "    rows_written: int\n",
        "    validation_rate: float\n",
        "    error_message: Optional[str] = None\n",
        "    step_type: Optional[str] = None\n",
        "    table_fqn: Optional[str] = None\n",
        "    write_mode: Optional[str] = None\n",
        "    input_rows: Optional[int] = None\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the step result.\n",
        "\n",
        "        Ensures all fields are within valid ranges and required fields are\n",
        "        present. Raises an error if validation fails.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If any field is invalid or out of range.\n",
        "\n",
        "        Example:\n",
        "            >>> result = StepResult.create_success(...)\n",
        "            >>> result.validate()  # Passes\n",
        "        \"\"\"\n",
        "        if not self.step_name:\n",
        "            raise ValueError(\"Step name cannot be empty\")\n",
        "        if self.duration_secs < 0:\n",
        "            raise ValueError(\"Duration cannot be negative\")\n",
        "        if self.rows_processed < 0:\n",
        "            raise ValueError(\"Rows processed cannot be negative\")\n",
        "        if self.rows_written < 0:\n",
        "            raise ValueError(\"Rows written cannot be negative\")\n",
        "        if not 0 <= self.validation_rate <= 100:\n",
        "            raise ValueError(\"Validation rate must be between 0 and 100\")\n",
        "\n",
        "    @property\n",
        "    def is_valid(self) -> bool:\n",
        "        \"\"\"Check if the step result is valid.\n",
        "\n",
        "        Returns:\n",
        "            True if the step succeeded and validation_rate >= 95.0%,\n",
        "            False otherwise.\n",
        "\n",
        "        Example:\n",
        "            >>> result = StepResult(..., success=True, validation_rate=96.0)\n",
        "            >>> print(result.is_valid)  # True\n",
        "        \"\"\"\n",
        "        return self.success and self.validation_rate >= 95.0\n",
        "\n",
        "    @property\n",
        "    def is_high_quality(self) -> bool:\n",
        "        \"\"\"Check if the step result is high quality.\n",
        "\n",
        "        Returns:\n",
        "            True if the step succeeded and validation_rate >= 98.0%,\n",
        "            False otherwise.\n",
        "\n",
        "        Example:\n",
        "            >>> result = StepResult(..., success=True, validation_rate=99.0)\n",
        "            >>> print(result.is_high_quality)  # True\n",
        "        \"\"\"\n",
        "        return self.success and self.validation_rate >= 98.0\n",
        "\n",
        "    @property\n",
        "    def throughput_rows_per_sec(self) -> float:\n",
        "        \"\"\"Calculate throughput in rows per second.\n",
        "\n",
        "        Returns:\n",
        "            Processing throughput in rows per second. Returns 0.0 if\n",
        "            duration_secs is 0.\n",
        "\n",
        "        Example:\n",
        "            >>> result = StepResult(\n",
        "            ...     rows_processed=10000,\n",
        "            ...     duration_secs=10.0,\n",
        "            ...     ...\n",
        "            ... )\n",
        "            >>> print(f\"Throughput: {result.throughput_rows_per_sec} rows/sec\")  # 1000.0\n",
        "        \"\"\"\n",
        "        if self.duration_secs == 0:\n",
        "            return 0.0\n",
        "        return self.rows_processed / self.duration_secs\n",
        "\n",
        "    @classmethod\n",
        "    def create_success(\n",
        "        cls,\n",
        "        step_name: str,\n",
        "        phase: PipelinePhase,\n",
        "        start_time: datetime,\n",
        "        end_time: datetime,\n",
        "        rows_processed: int,\n",
        "        rows_written: int,\n",
        "        validation_rate: float,\n",
        "        step_type: Optional[str] = None,\n",
        "        table_fqn: Optional[str] = None,\n",
        "        write_mode: Optional[str] = None,\n",
        "        input_rows: Optional[int] = None,\n",
        "    ) -> StepResult:\n",
        "        \"\"\"Create a successful step result.\n",
        "\n",
        "        Factory method for creating a StepResult representing a successful\n",
        "        step execution. Automatically calculates duration and sets success=True.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step that was executed.\n",
        "            phase: Pipeline phase (BRONZE, SILVER, or GOLD).\n",
        "            start_time: When step execution started.\n",
        "            end_time: When step execution ended.\n",
        "            rows_processed: Number of rows processed.\n",
        "            rows_written: Number of rows written to table.\n",
        "            validation_rate: Validation success rate (0-100).\n",
        "            step_type: Optional step type string (bronze, silver, gold).\n",
        "            table_fqn: Optional fully qualified table name.\n",
        "            write_mode: Optional write mode (overwrite, append).\n",
        "            input_rows: Optional number of input rows.\n",
        "\n",
        "        Returns:\n",
        "            StepResult instance with success=True and calculated duration.\n",
        "\n",
        "        Example:\n",
        "            >>> from datetime import datetime, timezone\n",
        "            >>> result = StepResult.create_success(\n",
        "            ...     step_name=\"bronze_step\",\n",
        "            ...     phase=PipelinePhase.BRONZE,\n",
        "            ...     start_time=datetime.now(timezone.utc),\n",
        "            ...     end_time=datetime.now(timezone.utc),\n",
        "            ...     rows_processed=1000,\n",
        "            ...     rows_written=950,\n",
        "            ...     validation_rate=95.0\n",
        "            ... )\n",
        "        \"\"\"\n",
        "        duration_secs = (end_time - start_time).total_seconds()\n",
        "        return cls(\n",
        "            step_name=step_name,\n",
        "            phase=phase,\n",
        "            success=True,\n",
        "            start_time=start_time,\n",
        "            end_time=end_time,\n",
        "            duration_secs=duration_secs,\n",
        "            rows_processed=rows_processed,\n",
        "            rows_written=rows_written,\n",
        "            validation_rate=validation_rate,\n",
        "            error_message=None,\n",
        "            step_type=step_type,\n",
        "            table_fqn=table_fqn,\n",
        "            write_mode=write_mode,\n",
        "            input_rows=input_rows,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def create_failure(\n",
        "        cls,\n",
        "        step_name: str,\n",
        "        phase: PipelinePhase,\n",
        "        start_time: datetime,\n",
        "        end_time: datetime,\n",
        "        error_message: str,\n",
        "        step_type: Optional[str] = None,\n",
        "        table_fqn: Optional[str] = None,\n",
        "        write_mode: Optional[str] = None,\n",
        "        input_rows: Optional[int] = None,\n",
        "    ) -> StepResult:\n",
        "        \"\"\"Create a failed step result.\n",
        "\n",
        "        Factory method for creating a StepResult representing a failed\n",
        "        step execution. Automatically calculates duration and sets success=False,\n",
        "        with zero rows processed/written and zero validation rate.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step that was executed.\n",
        "            phase: Pipeline phase (BRONZE, SILVER, or GOLD).\n",
        "            start_time: When step execution started.\n",
        "            end_time: When step execution ended.\n",
        "            error_message: Error message describing the failure.\n",
        "            step_type: Optional step type string (bronze, silver, gold).\n",
        "            table_fqn: Optional fully qualified table name.\n",
        "            write_mode: Optional write mode (overwrite, append).\n",
        "            input_rows: Optional number of input rows.\n",
        "\n",
        "        Returns:\n",
        "            StepResult instance with success=False and zero metrics.\n",
        "\n",
        "        Example:\n",
        "            >>> from datetime import datetime, timezone\n",
        "            >>> result = StepResult.create_failure(\n",
        "            ...     step_name=\"bronze_step\",\n",
        "            ...     phase=PipelinePhase.BRONZE,\n",
        "            ...     start_time=datetime.now(timezone.utc),\n",
        "            ...     end_time=datetime.now(timezone.utc),\n",
        "            ...     error_message=\"Validation failed: threshold not met\"\n",
        "            ... )\n",
        "        \"\"\"\n",
        "        duration_secs = (end_time - start_time).total_seconds()\n",
        "        return cls(\n",
        "            step_name=step_name,\n",
        "            phase=phase,\n",
        "            success=False,\n",
        "            start_time=start_time,\n",
        "            end_time=end_time,\n",
        "            duration_secs=duration_secs,\n",
        "            rows_processed=0,\n",
        "            rows_written=0,\n",
        "            validation_rate=0.0,\n",
        "            error_message=error_message,\n",
        "            step_type=step_type,\n",
        "            table_fqn=table_fqn,\n",
        "            write_mode=write_mode,\n",
        "            input_rows=input_rows,\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def error_rate(self) -> float:\n",
        "        \"\"\"Calculate error rate.\n",
        "\n",
        "        Returns:\n",
        "            Percentage of rows that failed validation (0-100). Returns 0.0\n",
        "            if rows_processed is 0.\n",
        "\n",
        "        Example:\n",
        "            >>> result = StepResult(..., rows_processed=1000, validation_rate=95.0)\n",
        "            >>> print(f\"Error rate: {result.error_rate}%\")  # 5.0%\n",
        "        \"\"\"\n",
        "        if self.rows_processed == 0:\n",
        "            return 0.0\n",
        "        return 100.0 - self.validation_rate\n",
        "\n",
        "@dataclass\n",
        "class ExecutionResult(BaseModel):\n",
        "    \"\"\"Result of pipeline execution.\n",
        "\n",
        "    Aggregates results from an entire pipeline execution, including the\n",
        "    execution context, individual step results, overall metrics, and\n",
        "    overall success status.\n",
        "\n",
        "    **Validation Rules:**\n",
        "        - `context`: Must be an ExecutionContext instance\n",
        "        - `step_results`: Must be a list\n",
        "        - `metrics`: Must be a PipelineMetrics instance\n",
        "        - `success`: Must be a boolean\n",
        "\n",
        "    Attributes:\n",
        "        context: ExecutionContext instance containing execution metadata,\n",
        "            timing, and configuration.\n",
        "        step_results: List of StepResult instances, one for each step\n",
        "            executed in the pipeline.\n",
        "        metrics: PipelineMetrics instance with aggregated metrics from\n",
        "            all steps (total rows, durations, validation rates, etc.).\n",
        "        success: Whether the entire pipeline succeeded. True if all steps\n",
        "            succeeded, False if any step failed.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.execution import ExecutionResult\n",
        "        >>> from pipeline_builder.models.enums import ExecutionMode\n",
        "        >>>\n",
        "        >>> # Create execution result from context and step results\n",
        "        >>> context = ExecutionContext(mode=ExecutionMode.INITIAL, ...)\n",
        "        >>> step_results = [step_result1, step_result2, ...]\n",
        "        >>> result = ExecutionResult.from_context_and_results(context, step_results)\n",
        "        >>> print(f\"Pipeline success: {result.success}\")\n",
        "        >>> print(f\"Total rows: {result.metrics.total_rows_processed}\")\n",
        "    \"\"\"\n",
        "\n",
        "    context: ExecutionContext\n",
        "    step_results: list[StepResult]\n",
        "    metrics: PipelineMetrics\n",
        "    success: bool\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate execution result.\n",
        "\n",
        "        Ensures all fields are of the correct types. Raises an error if\n",
        "        validation fails.\n",
        "\n",
        "        Raises:\n",
        "            PipelineConfigurationError: If any field has an invalid type.\n",
        "\n",
        "        Example:\n",
        "            >>> result = ExecutionResult(...)\n",
        "            >>> result.validate()  # Passes\n",
        "        \"\"\"\n",
        "        if not isinstance(self.context, ExecutionContext):\n",
        "            raise PipelineConfigurationError(\n",
        "                \"Context must be an ExecutionContext instance\"\n",
        "            )\n",
        "        if not isinstance(self.step_results, list):\n",
        "            raise PipelineConfigurationError(\"Step results must be a list\")\n",
        "        if not isinstance(self.metrics, PipelineMetrics):\n",
        "            raise PipelineConfigurationError(\n",
        "                \"Metrics must be a PipelineMetrics instance\"\n",
        "            )\n",
        "        if not isinstance(self.success, bool):\n",
        "            raise PipelineConfigurationError(\"Success must be a boolean\")\n",
        "\n",
        "    @classmethod\n",
        "    def from_context_and_results(\n",
        "        cls, context: ExecutionContext, step_results: list[StepResult]\n",
        "    ) -> ExecutionResult:\n",
        "        \"\"\"Create execution result from context and step results.\n",
        "\n",
        "        Factory method that aggregates step results into pipeline metrics\n",
        "        and determines overall success. This is the recommended way to\n",
        "        create an ExecutionResult after pipeline execution.\n",
        "\n",
        "        Args:\n",
        "            context: ExecutionContext from the pipeline execution.\n",
        "            step_results: List of StepResult instances from all executed steps.\n",
        "\n",
        "        Returns:\n",
        "            ExecutionResult instance with aggregated metrics and success status.\n",
        "\n",
        "        Example:\n",
        "            >>> context = ExecutionContext(mode=ExecutionMode.INITIAL, ...)\n",
        "            >>> step_results = [\n",
        "            ...     StepResult.create_success(...),\n",
        "            ...     StepResult.create_success(...)\n",
        "            ... ]\n",
        "            >>> result = ExecutionResult.from_context_and_results(context, step_results)\n",
        "            >>> print(f\"Success: {result.success}\")  # True\n",
        "            >>> print(f\"Total steps: {result.metrics.total_steps}\")  # 2\n",
        "        \"\"\"\n",
        "        metrics = PipelineMetrics.from_step_results(step_results)\n",
        "        success = all(result.success for result in step_results)\n",
        "        return cls(\n",
        "            context=context, step_results=step_results, metrics=metrics, success=success\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.models.factory (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.models.base, pipeline_builder.models.enums, pipeline_builder.models.exceptions, pipeline_builder.models.execution, pipeline_builder.models.pipeline, pipeline_builder.models.steps\n",
        "\n",
        "\"\"\"\n",
        "Factory functions for creating and managing pipeline models.\n",
        "\n",
        "This module provides factory functions for creating and validating pipeline\n",
        "configuration objects, execution contexts, and step configurations. These\n",
        "functions simplify object creation and ensure consistent initialization.\n",
        "\n",
        "Key Functions:\n",
        "    - **create_pipeline_config**: Create PipelineConfig with custom thresholds\n",
        "    - **create_execution_context**: Create ExecutionContext for pipeline runs\n",
        "    - **validate_pipeline_config**: Validate PipelineConfig instances\n",
        "    - **validate_step_config**: Validate step configurations\n",
        "    - **serialize_pipeline_config**: Serialize config to JSON\n",
        "    - **deserialize_pipeline_config**: Deserialize config from JSON\n",
        "\n",
        "Dependencies:\n",
        "    - models.base: ValidationThresholds\n",
        "    - models.enums: ExecutionMode\n",
        "    - models.exceptions: PipelineConfigurationError, PipelineExecutionError\n",
        "    - models.execution: ExecutionContext\n",
        "    - models.pipeline: PipelineConfig\n",
        "    - models.steps: BronzeStep, SilverStep, GoldStep\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.models.factory import (\n",
        "    ...     create_pipeline_config,\n",
        "    ...     create_execution_context,\n",
        "    ...     validate_pipeline_config\n",
        "    ... )\n",
        "    >>> from pipeline_builder.models.enums import ExecutionMode\n",
        "    >>>\n",
        "    >>> # Create pipeline configuration\n",
        "    >>> config = create_pipeline_config(\n",
        "    ...     schema=\"analytics\",\n",
        "    ...     bronze_threshold=95.0,\n",
        "    ...     silver_threshold=98.0,\n",
        "    ...     gold_threshold=99.0\n",
        "    ... )\n",
        "    >>> validate_pipeline_config(config)\n",
        "    >>>\n",
        "    >>> # Create execution context\n",
        "    >>> context = create_execution_context(ExecutionMode.INITIAL)\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from datetime import datetime, timezone\n",
        "from typing import Union\n",
        "\n",
        "# from .base import ValidationThresholds  # Removed: defined in notebook cells above\n",
        "# from .enums import ExecutionMode  # Removed: defined in notebook cells above\n",
        "# from .exceptions import PipelineConfigurationError, PipelineExecutionError  # Removed: defined in notebook cells above\n",
        "# from .execution import ExecutionContext  # Removed: defined in notebook cells above\n",
        "# from .pipeline import PipelineConfig  # Removed: defined in notebook cells above\n",
        "# from .steps import BronzeStep, GoldStep, SilverStep  # Removed: defined in notebook cells above\n",
        "\n",
        "def create_pipeline_config(\n",
        "    schema: str,\n",
        "    bronze_threshold: float = 95.0,\n",
        "    silver_threshold: float = 98.0,\n",
        "    gold_threshold: float = 99.0,\n",
        "    verbose: bool = True,\n",
        ") -> PipelineConfig:\n",
        "    \"\"\"Factory function to create pipeline configuration.\n",
        "\n",
        "    Creates a PipelineConfig instance with custom validation thresholds.\n",
        "    This is a convenience function that simplifies configuration creation\n",
        "    compared to manually constructing ValidationThresholds and PipelineConfig.\n",
        "\n",
        "    Args:\n",
        "        schema: Database schema name for pipeline tables. Must be a\n",
        "            non-empty string.\n",
        "        bronze_threshold: Minimum validation success rate for Bronze layer\n",
        "            (0-100). Defaults to 95.0.\n",
        "        silver_threshold: Minimum validation success rate for Silver layer\n",
        "            (0-100). Defaults to 98.0.\n",
        "        gold_threshold: Minimum validation success rate for Gold layer\n",
        "            (0-100). Defaults to 99.0.\n",
        "        verbose: Whether to enable verbose logging. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        PipelineConfig instance with the specified settings.\n",
        "\n",
        "    Raises:\n",
        "        PipelineValidationError: If schema is invalid or thresholds are\n",
        "            outside the valid range (0-100).\n",
        "\n",
        "    Example:\n",
        "        >>> config = create_pipeline_config(\n",
        "        ...     schema=\"analytics\",\n",
        "        ...     bronze_threshold=90.0,\n",
        "        ...     silver_threshold=95.0,\n",
        "        ...     gold_threshold=99.0,\n",
        "        ...     verbose=False\n",
        "        ... )\n",
        "        >>> print(config.schema)  # \"analytics\"\n",
        "        >>> print(config.min_bronze_rate)  # 90.0\n",
        "    \"\"\"\n",
        "    thresholds = ValidationThresholds(\n",
        "        bronze=bronze_threshold, silver=silver_threshold, gold=gold_threshold\n",
        "    )\n",
        "    return PipelineConfig(schema=schema, thresholds=thresholds, verbose=verbose)\n",
        "\n",
        "def create_execution_context(mode: ExecutionMode) -> ExecutionContext:\n",
        "    \"\"\"Factory function to create execution context.\n",
        "\n",
        "    Creates an ExecutionContext instance with the specified execution mode\n",
        "    and current timestamp. Automatically generates unique run_id and\n",
        "    execution_id.\n",
        "\n",
        "    Args:\n",
        "        mode: Execution mode (INITIAL, INCREMENTAL, FULL_REFRESH,\n",
        "            VALIDATION_ONLY).\n",
        "\n",
        "    Returns:\n",
        "        ExecutionContext instance initialized with the current timestamp\n",
        "        and a unique run identifier.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.enums import ExecutionMode\n",
        "        >>> context = create_execution_context(ExecutionMode.INITIAL)\n",
        "        >>> print(context.mode)  # ExecutionMode.INITIAL\n",
        "        >>> print(context.run_id)  # Unique UUID string\n",
        "    \"\"\"\n",
        "    return ExecutionContext(mode=mode, start_time=datetime.now(timezone.utc))\n",
        "\n",
        "def validate_pipeline_config(config: PipelineConfig) -> None:\n",
        "    \"\"\"Validate a pipeline configuration.\n",
        "\n",
        "    Validates a PipelineConfig instance and converts PipelineExecutionError\n",
        "    to PipelineConfigurationError for clearer error semantics.\n",
        "\n",
        "    Args:\n",
        "        config: PipelineConfig instance to validate.\n",
        "\n",
        "    Raises:\n",
        "        PipelineConfigurationError: If the configuration is invalid.\n",
        "            Wraps any PipelineExecutionError from the validation process.\n",
        "\n",
        "    Example:\n",
        "        >>> config = create_pipeline_config(schema=\"test\")\n",
        "        >>> validate_pipeline_config(config)  # Passes\n",
        "        >>>\n",
        "        >>> invalid = PipelineConfig(schema=\"\", thresholds=ValidationThresholds.create_default())\n",
        "        >>> validate_pipeline_config(invalid)  # Raises PipelineConfigurationError\n",
        "    \"\"\"\n",
        "    try:\n",
        "        config.validate()\n",
        "    except PipelineExecutionError as e:\n",
        "        raise PipelineConfigurationError(f\"Invalid pipeline configuration: {e}\") from e\n",
        "\n",
        "def validate_step_config(step: Union[BronzeStep, SilverStep, GoldStep]) -> None:\n",
        "    \"\"\"Validate a step configuration.\n",
        "\n",
        "    Validates a step configuration (Bronze, Silver, or Gold) and converts\n",
        "    PipelineExecutionError to PipelineConfigurationError for clearer error\n",
        "    semantics.\n",
        "\n",
        "    Args:\n",
        "        step: Step instance (BronzeStep, SilverStep, or GoldStep) to validate.\n",
        "\n",
        "    Raises:\n",
        "        PipelineConfigurationError: If the step configuration is invalid.\n",
        "            Wraps any PipelineExecutionError from the validation process.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.models.steps import BronzeStep\n",
        "        >>> step = BronzeStep(name=\"test\", rules={\"id\": [F.col(\"id\").isNotNull()]})\n",
        "        >>> validate_step_config(step)  # Passes\n",
        "        >>>\n",
        "        >>> invalid = BronzeStep(name=\"\", rules={})\n",
        "        >>> validate_step_config(invalid)  # Raises PipelineConfigurationError\n",
        "    \"\"\"\n",
        "    try:\n",
        "        step.validate()\n",
        "    except PipelineExecutionError as e:\n",
        "        raise PipelineConfigurationError(f\"Invalid step configuration: {e}\") from e\n",
        "\n",
        "def serialize_pipeline_config(config: PipelineConfig) -> str:\n",
        "    \"\"\"Serialize pipeline configuration to JSON.\n",
        "\n",
        "    Converts a PipelineConfig instance to a JSON string for storage or\n",
        "    transmission. Uses the config's `to_json` method.\n",
        "\n",
        "    Args:\n",
        "        config: PipelineConfig instance to serialize.\n",
        "\n",
        "    Returns:\n",
        "        JSON string representation of the configuration.\n",
        "\n",
        "    Example:\n",
        "        >>> config = create_pipeline_config(schema=\"analytics\")\n",
        "        >>> json_str = serialize_pipeline_config(config)\n",
        "        >>> print(json_str)  # {\"schema\": \"analytics\", ...}\n",
        "    \"\"\"\n",
        "    return config.to_json()\n",
        "\n",
        "def deserialize_pipeline_config(json_str: str) -> PipelineConfig:\n",
        "    \"\"\"Deserialize pipeline configuration from JSON.\n",
        "\n",
        "    Converts a JSON string back to a PipelineConfig instance. This is the\n",
        "    inverse operation of `serialize_pipeline_config`.\n",
        "\n",
        "    Args:\n",
        "        json_str: JSON string representation of a PipelineConfig.\n",
        "\n",
        "    Returns:\n",
        "        PipelineConfig instance reconstructed from the JSON string.\n",
        "\n",
        "    Raises:\n",
        "        json.JSONDecodeError: If the JSON string is invalid.\n",
        "        KeyError: If required fields are missing from the JSON.\n",
        "\n",
        "    Example:\n",
        "        >>> config = create_pipeline_config(schema=\"analytics\")\n",
        "        >>> json_str = serialize_pipeline_config(config)\n",
        "        >>> restored = deserialize_pipeline_config(json_str)\n",
        "        >>> print(restored.schema)  # \"analytics\"\n",
        "    \"\"\"\n",
        "    data = json.loads(json_str)\n",
        "    return PipelineConfig(\n",
        "        schema=data[\"schema\"],\n",
        "        thresholds=ValidationThresholds(\n",
        "            bronze=data[\"thresholds\"][\"bronze\"],\n",
        "            silver=data[\"thresholds\"][\"silver\"],\n",
        "            gold=data[\"thresholds\"][\"gold\"],\n",
        "        ),\n",
        "        verbose=data.get(\"verbose\", True),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.writer.models (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.compat, pipeline_builder.models.execution, pipeline_builder.pipeline.models, pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Writer-specific models and type definitions.\n",
        "\n",
        "This module contains all the dataclasses, TypedDict definitions, and type aliases\n",
        "used by the writer module. It integrates with existing framework models while\n",
        "providing writer-specific functionality.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "from typing import Any, Dict, Literal, Optional, TypedDict, cast\n",
        "# from .models import ExecutionContext, ExecutionResult, StepResult  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import types  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import types  # types from pyspark (not from compat)\n",
        "# from ..pipeline.models import PipelineReport  # Removed: defined in notebook cells above\n",
        "\n",
        "# Import specific types for convenience\n",
        "BooleanType = types.BooleanType\n",
        "FloatType = types.FloatType\n",
        "IntegerType = types.IntegerType\n",
        "StringType = types.StringType\n",
        "# Use the appropriate StructField based on the engine\n",
        "\n",
        "if os.environ.get(\"SPARKFORGE_ENGINE\") == \"mock\":\n",
        "    StructField = types.StructField\n",
        "else:\n",
        "    StructField = types.StructField\n",
        "StructType = types.StructType\n",
        "TimestampType = types.TimestampType\n",
        "\n",
        "# ============================================================================\n",
        "# Enums\n",
        "# ============================================================================\n",
        "\n",
        "class WriteMode(Enum):\n",
        "    \"\"\"Write mode for log operations.\"\"\"\n",
        "\n",
        "    OVERWRITE = \"overwrite\"\n",
        "    APPEND = \"append\"\n",
        "    MERGE = \"merge\"\n",
        "    IGNORE = \"ignore\"\n",
        "\n",
        "class LogLevel(Enum):\n",
        "    \"\"\"Log level for writer operations.\"\"\"\n",
        "\n",
        "    DEBUG = \"DEBUG\"\n",
        "    INFO = \"INFO\"\n",
        "    WARNING = \"WARNING\"\n",
        "    ERROR = \"ERROR\"\n",
        "    CRITICAL = \"CRITICAL\"\n",
        "\n",
        "# ============================================================================\n",
        "# TypedDict Definitions\n",
        "# ============================================================================\n",
        "\n",
        "class LogRow(TypedDict):\n",
        "    \"\"\"\n",
        "    Enhanced log row with full type safety and framework integration.\n",
        "\n",
        "    This replaces the previous MinimalLogRow with proper integration\n",
        "    with framework models and enhanced type safety.\n",
        "    \"\"\"\n",
        "\n",
        "    # Run-level information\n",
        "    run_id: str\n",
        "    run_mode: Literal[\"initial\", \"incremental\", \"full_refresh\", \"validation_only\"]\n",
        "    run_started_at: Optional[datetime]\n",
        "    run_ended_at: Optional[datetime]\n",
        "\n",
        "    # Execution context\n",
        "    execution_id: str\n",
        "    pipeline_id: str\n",
        "    schema: str\n",
        "\n",
        "    # Step-level information\n",
        "    phase: Literal[\"bronze\", \"silver\", \"gold\", \"pipeline\"]\n",
        "    step_name: str\n",
        "    step_type: str\n",
        "\n",
        "    # Timing information\n",
        "    start_time: Optional[datetime]\n",
        "    end_time: Optional[datetime]\n",
        "    duration_secs: float\n",
        "\n",
        "    # Table information\n",
        "    table_fqn: Optional[str]\n",
        "    write_mode: Optional[Literal[\"overwrite\", \"append\"]]\n",
        "\n",
        "    # Data metrics\n",
        "    input_rows: Optional[int]\n",
        "    output_rows: Optional[int]\n",
        "    rows_written: Optional[int]\n",
        "    rows_processed: int\n",
        "    table_total_rows: Optional[int]  # Total rows in table after this write\n",
        "\n",
        "    # Validation metrics\n",
        "    valid_rows: int\n",
        "    invalid_rows: int\n",
        "    validation_rate: float\n",
        "\n",
        "    # Execution status\n",
        "    success: bool\n",
        "    error_message: Optional[str]\n",
        "\n",
        "    # Performance metrics\n",
        "    memory_usage_mb: Optional[float]\n",
        "    cpu_usage_percent: Optional[float]\n",
        "\n",
        "    # Metadata\n",
        "    metadata: Dict[str, Any]\n",
        "\n",
        "class WriterMetrics(TypedDict):\n",
        "    \"\"\"Metrics for writer operations.\"\"\"\n",
        "\n",
        "    total_writes: int\n",
        "    successful_writes: int\n",
        "    failed_writes: int\n",
        "    total_duration_secs: float\n",
        "    avg_write_duration_secs: float\n",
        "    total_rows_written: int\n",
        "    memory_usage_peak_mb: float\n",
        "\n",
        "# ============================================================================\n",
        "# Configuration Models\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class WriterConfig:\n",
        "    \"\"\"\n",
        "    Configuration for the LogWriter.\n",
        "\n",
        "    Provides comprehensive configuration options for the writer module\n",
        "    including table settings, performance tuning, and feature flags.\n",
        "    \"\"\"\n",
        "\n",
        "    # Table configuration\n",
        "    table_schema: str\n",
        "    table_name: str\n",
        "    write_mode: WriteMode = WriteMode.APPEND\n",
        "\n",
        "    # Custom table naming patterns\n",
        "    table_name_pattern: Optional[str] = (\n",
        "        None  # e.g., \"{schema}.{pipeline_id}_{timestamp}\"\n",
        "    )\n",
        "    table_suffix_pattern: Optional[str] = None  # e.g., \"_{run_mode}_{date}\"\n",
        "\n",
        "    # Partitioning and optimization\n",
        "    partition_columns: Optional[list[str]] = None\n",
        "    partition_count: Optional[int] = None\n",
        "    compression: str = \"snappy\"\n",
        "\n",
        "    # Schema options\n",
        "    enable_schema_evolution: bool = True\n",
        "    schema_validation_mode: str = \"strict\"  # strict, lenient, ignore\n",
        "    auto_optimize_schema: bool = True\n",
        "\n",
        "    # Performance settings\n",
        "    batch_size: int = 1000\n",
        "    max_file_size_mb: int = 128\n",
        "    enable_optimization: bool = True\n",
        "    memory_fraction: float = 0.6\n",
        "\n",
        "    # Feature flags\n",
        "    enable_performance_monitoring: bool = True\n",
        "    enable_data_quality_checks: bool = True\n",
        "    enable_validation: bool = True\n",
        "    enable_metrics_collection: bool = True\n",
        "    enable_audit_trail: bool = True\n",
        "    enable_backup_before_write: bool = False\n",
        "\n",
        "    # Logging configuration\n",
        "    log_level: LogLevel = LogLevel.INFO\n",
        "    enable_detailed_logging: bool = False\n",
        "    log_performance_metrics: bool = True\n",
        "    log_data_quality_results: bool = True\n",
        "\n",
        "    # Error handling\n",
        "    max_retries: int = 3\n",
        "    retry_delay_secs: float = 1.0\n",
        "    fail_fast: bool = False\n",
        "    retry_exponential_backoff: bool = True\n",
        "\n",
        "    # Data quality thresholds\n",
        "    min_validation_rate: float = 95.0\n",
        "    max_invalid_rows_percent: float = 5.0\n",
        "    enable_anomaly_detection: bool = False\n",
        "\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"Validate the configuration.\"\"\"\n",
        "        if not self.table_schema or not self.table_schema.strip():\n",
        "            raise ValueError(\"Table schema cannot be empty or whitespace-only\")\n",
        "        if not self.table_name or not self.table_name.strip():\n",
        "            raise ValueError(\"Table name cannot be empty or whitespace-only\")\n",
        "        if self.batch_size <= 0:\n",
        "            raise ValueError(\"Batch size must be positive\")\n",
        "        if self.max_file_size_mb <= 0:\n",
        "            raise ValueError(\"Max file size must be positive\")\n",
        "        if self.max_retries < 0:\n",
        "            raise ValueError(\"Max retries cannot be negative\")\n",
        "        if self.retry_delay_secs < 0:\n",
        "            raise ValueError(\"Retry delay cannot be negative\")\n",
        "        if not 0 < self.memory_fraction <= 1:\n",
        "            raise ValueError(\"Memory fraction must be between 0 and 1\")\n",
        "        if self.schema_validation_mode not in [\"strict\", \"lenient\", \"ignore\"]:\n",
        "            raise ValueError(\n",
        "                \"Schema validation mode must be 'strict', 'lenient', or 'ignore'\"\n",
        "            )\n",
        "        if not 0 <= self.min_validation_rate <= 100:\n",
        "            raise ValueError(\"Min validation rate must be between 0 and 100\")\n",
        "        if not 0 <= self.max_invalid_rows_percent <= 100:\n",
        "            raise ValueError(\"Max invalid rows percent must be between 0 and 100\")\n",
        "\n",
        "    def generate_table_name(\n",
        "        self,\n",
        "        pipeline_id: Optional[str] = None,\n",
        "        run_mode: Optional[str] = None,\n",
        "        timestamp: Optional[str] = None,\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate dynamic table name based on patterns.\n",
        "\n",
        "        Args:\n",
        "            pipeline_id: Pipeline identifier\n",
        "            run_mode: Run mode (initial, incremental, etc.)\n",
        "            timestamp: Timestamp for naming\n",
        "\n",
        "        Returns:\n",
        "            Generated table name\n",
        "        \"\"\"\n",
        "        table_name = self.table_name\n",
        "\n",
        "        # Apply suffix pattern if provided\n",
        "        if self.table_suffix_pattern:\n",
        "            # Use explicit None checking instead of 'or' to avoid masking None values\n",
        "            if run_mode is None:\n",
        "                raise ValueError(\n",
        "                    \"run_mode cannot be None when using table_suffix_pattern\"\n",
        "                )\n",
        "            if timestamp is None:\n",
        "                raise ValueError(\n",
        "                    \"timestamp cannot be None when using table_suffix_pattern\"\n",
        "                )\n",
        "\n",
        "            suffix_vars = {\n",
        "                \"run_mode\": run_mode,\n",
        "                \"date\": timestamp,\n",
        "                \"timestamp\": timestamp,\n",
        "            }\n",
        "            suffix = self.table_suffix_pattern.format(**suffix_vars)\n",
        "            table_name = f\"{table_name}{suffix}\"\n",
        "\n",
        "        # Apply full pattern if provided\n",
        "        if self.table_name_pattern:\n",
        "            # Use explicit None checking instead of 'or' to avoid masking None values\n",
        "            if pipeline_id is None:\n",
        "                raise ValueError(\n",
        "                    \"pipeline_id cannot be None when using table_name_pattern\"\n",
        "                )\n",
        "            if run_mode is None:\n",
        "                raise ValueError(\n",
        "                    \"run_mode cannot be None when using table_name_pattern\"\n",
        "                )\n",
        "            if timestamp is None:\n",
        "                raise ValueError(\n",
        "                    \"timestamp cannot be None when using table_name_pattern\"\n",
        "                )\n",
        "\n",
        "            pattern_vars = {\n",
        "                \"schema\": self.table_schema,\n",
        "                \"table_name\": table_name,\n",
        "                \"pipeline_id\": pipeline_id,\n",
        "                \"run_mode\": run_mode,\n",
        "                \"date\": timestamp,\n",
        "                \"timestamp\": timestamp,\n",
        "            }\n",
        "            return self.table_name_pattern.format(**pattern_vars)\n",
        "\n",
        "        return table_name\n",
        "\n",
        "# ============================================================================\n",
        "# Spark Schema Definitions\n",
        "# ============================================================================\n",
        "\n",
        "# from ..compat import types  # noqa: E402  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import types  # types from pyspark (not from compat)\n",
        "\n",
        "def create_log_schema() -> Any:\n",
        "    \"\"\"\n",
        "    Create the Spark schema for log tables.\n",
        "\n",
        "    Returns:\n",
        "        StructType: Spark schema for log tables with proper types\n",
        "    \"\"\"\n",
        "    return types.StructType(\n",
        "        [\n",
        "            # Run-level fields\n",
        "            types.StructField(\"run_id\", types.StringType(), False),\n",
        "            types.StructField(\"run_mode\", types.StringType(), False),\n",
        "            types.StructField(\"run_started_at\", types.TimestampType(), True),\n",
        "            types.StructField(\"run_ended_at\", types.TimestampType(), True),\n",
        "            # Execution context\n",
        "            types.StructField(\"execution_id\", types.StringType(), False),\n",
        "            types.StructField(\"pipeline_id\", types.StringType(), False),\n",
        "            types.StructField(\"schema\", types.StringType(), False),\n",
        "            # Step-level fields\n",
        "            types.StructField(\"phase\", types.StringType(), False),\n",
        "            types.StructField(\"step_name\", types.StringType(), False),\n",
        "            types.StructField(\"step_type\", types.StringType(), False),\n",
        "            # Timing fields\n",
        "            types.StructField(\"start_time\", types.TimestampType(), True),\n",
        "            types.StructField(\"end_time\", types.TimestampType(), True),\n",
        "            types.StructField(\"duration_secs\", types.FloatType(), False),\n",
        "            # Table fields\n",
        "            types.StructField(\"table_fqn\", types.StringType(), True),\n",
        "            types.StructField(\"write_mode\", types.StringType(), True),\n",
        "            # Data metrics\n",
        "            types.StructField(\"input_rows\", types.IntegerType(), True),\n",
        "            types.StructField(\"output_rows\", types.IntegerType(), True),\n",
        "            types.StructField(\"rows_written\", types.IntegerType(), True),\n",
        "            types.StructField(\"rows_processed\", types.IntegerType(), False),\n",
        "            types.StructField(\"table_total_rows\", types.IntegerType(), True),\n",
        "            # Validation metrics\n",
        "            types.StructField(\"valid_rows\", types.IntegerType(), False),\n",
        "            types.StructField(\"invalid_rows\", types.IntegerType(), False),\n",
        "            types.StructField(\"validation_rate\", types.FloatType(), False),\n",
        "            # Execution status\n",
        "            types.StructField(\"success\", types.BooleanType(), False),\n",
        "            types.StructField(\"error_message\", types.StringType(), True),\n",
        "            # Performance metrics\n",
        "            types.StructField(\"memory_usage_mb\", types.FloatType(), True),\n",
        "            types.StructField(\"cpu_usage_percent\", types.FloatType(), True),\n",
        "            # Metadata (stored as JSON string)\n",
        "            types.StructField(\"metadata\", types.StringType(), True),\n",
        "            # Timestamp fields for tracking\n",
        "            types.StructField(\"created_at\", types.StringType(), True),\n",
        "            types.StructField(\"updated_at\", types.StringType(), True),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# ============================================================================\n",
        "# Factory Functions\n",
        "# ============================================================================\n",
        "\n",
        "def create_log_row_from_step_result(\n",
        "    step_result: StepResult,\n",
        "    execution_context: ExecutionContext,\n",
        "    run_id: str,\n",
        "    run_mode: str,\n",
        "    metadata: Optional[Dict[str, Any]] = None,\n",
        ") -> LogRow:\n",
        "    \"\"\"\n",
        "    Create a LogRow from a StepResult and ExecutionContext.\n",
        "\n",
        "    Args:\n",
        "        step_result: The step result to convert\n",
        "        execution_context: The execution context\n",
        "        run_id: Unique run identifier\n",
        "        run_mode: Mode of the run (initial, incremental, etc.)\n",
        "        metadata: Additional metadata\n",
        "\n",
        "    Returns:\n",
        "        LogRow: Log row with all fields populated\n",
        "    \"\"\"\n",
        "    return LogRow(\n",
        "        # Run-level information\n",
        "        run_id=run_id,\n",
        "        run_mode=run_mode,  # type: ignore[typeddict-item]\n",
        "        run_started_at=execution_context.started_at,\n",
        "        run_ended_at=execution_context.ended_at,\n",
        "        # Execution context\n",
        "        execution_id=execution_context.execution_id,\n",
        "        pipeline_id=execution_context.pipeline_id,\n",
        "        schema=execution_context.schema,\n",
        "        # Step-level information\n",
        "        phase=step_result.phase.value,\n",
        "        step_name=step_result.step_name,\n",
        "        step_type=(\n",
        "            step_result.step_type if step_result.step_type is not None else \"unknown\"\n",
        "        ),\n",
        "        # Timing information\n",
        "        start_time=step_result.start_time,\n",
        "        end_time=step_result.end_time,\n",
        "        duration_secs=step_result.duration_secs,\n",
        "        # Table information\n",
        "        table_fqn=step_result.table_fqn,\n",
        "        write_mode=cast(\n",
        "            Optional[Literal[\"overwrite\", \"append\"]], step_result.write_mode\n",
        "        ),\n",
        "        # Data metrics\n",
        "        input_rows=step_result.input_rows,\n",
        "        output_rows=step_result.rows_processed,\n",
        "        rows_written=step_result.rows_written,\n",
        "        rows_processed=step_result.rows_processed,\n",
        "        table_total_rows=None,\n",
        "        # Validation metrics\n",
        "        valid_rows=int(step_result.rows_processed * step_result.validation_rate / 100),\n",
        "        invalid_rows=int(\n",
        "            step_result.rows_processed * (100 - step_result.validation_rate) / 100\n",
        "        ),\n",
        "        validation_rate=step_result.validation_rate,\n",
        "        # Execution status\n",
        "        success=step_result.success,\n",
        "        error_message=step_result.error_message,\n",
        "        # Performance metrics\n",
        "        memory_usage_mb=getattr(step_result, \"memory_usage_mb\", None),\n",
        "        cpu_usage_percent=getattr(step_result, \"cpu_usage_percent\", None),\n",
        "        # Metadata\n",
        "        metadata=metadata or {},\n",
        "    )\n",
        "\n",
        "def create_log_rows_from_execution_result(\n",
        "    execution_result: ExecutionResult,\n",
        "    run_id: str,\n",
        "    run_mode: str,\n",
        "    metadata: Optional[Dict[str, Any]] = None,\n",
        ") -> list[LogRow]:\n",
        "    \"\"\"\n",
        "    Create multiple LogRows from an ExecutionResult.\n",
        "\n",
        "    Args:\n",
        "        execution_result: The execution result to convert\n",
        "        run_id: Unique run identifier\n",
        "        run_mode: Mode of the run\n",
        "        metadata: Additional metadata\n",
        "\n",
        "    Returns:\n",
        "        List[LogRow]: List of log rows for each step\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    # Process step results from the execution result\n",
        "    for step_result in execution_result.step_results:\n",
        "        row = create_log_row_from_step_result(\n",
        "            step_result=step_result,\n",
        "            execution_context=execution_result.context,\n",
        "            run_id=run_id,\n",
        "            run_mode=run_mode,\n",
        "            metadata=metadata,\n",
        "        )\n",
        "        rows.append(row)\n",
        "    return rows\n",
        "\n",
        "def create_log_rows_from_pipeline_report(\n",
        "    pipeline_report: PipelineReport,\n",
        "    run_id: str,\n",
        "    run_mode: str,\n",
        "    metadata: Optional[Dict[str, Any]] = None,\n",
        ") -> list[LogRow]:\n",
        "    \"\"\"\n",
        "    Create multiple LogRows from a PipelineReport.\n",
        "\n",
        "    Args:\n",
        "        pipeline_report: The pipeline report to convert\n",
        "        run_id: Unique run identifier\n",
        "        run_mode: Mode of the run\n",
        "        metadata: Additional metadata\n",
        "\n",
        "    Returns:\n",
        "        List[LogRow]: List of log rows for each step\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "\n",
        "    # Create a main log row for the pipeline execution\n",
        "    main_row: LogRow = {\n",
        "        \"run_id\": run_id,\n",
        "        \"run_mode\": run_mode,  # type: ignore[typeddict-item]\n",
        "        \"run_started_at\": pipeline_report.start_time,\n",
        "        \"run_ended_at\": pipeline_report.end_time,\n",
        "        \"execution_id\": pipeline_report.execution_id,\n",
        "        \"pipeline_id\": pipeline_report.pipeline_id,\n",
        "        \"schema\": \"default\",  # PipelineReport doesn't have schema\n",
        "        \"phase\": \"pipeline\",\n",
        "        \"step_name\": \"pipeline_execution\",\n",
        "        \"step_type\": \"pipeline\",\n",
        "        \"start_time\": pipeline_report.start_time,\n",
        "        \"end_time\": pipeline_report.end_time,\n",
        "        \"duration_secs\": pipeline_report.duration_seconds,\n",
        "        \"table_fqn\": None,\n",
        "        \"write_mode\": None,\n",
        "        \"input_rows\": 0,\n",
        "        \"output_rows\": 0,\n",
        "        \"rows_written\": 0,\n",
        "        \"rows_processed\": 0,\n",
        "        \"table_total_rows\": None,\n",
        "        \"valid_rows\": 0,\n",
        "        \"invalid_rows\": 0,\n",
        "        \"validation_rate\": 100.0,\n",
        "        \"success\": pipeline_report.success,\n",
        "        \"error_message\": pipeline_report.errors[0] if pipeline_report.errors else None,\n",
        "        \"memory_usage_mb\": None,\n",
        "        \"cpu_usage_percent\": None,\n",
        "        \"metadata\": metadata or {},\n",
        "    }\n",
        "    rows.append(main_row)\n",
        "\n",
        "    # Add step results from bronze, silver, and gold layers\n",
        "    all_results = {}\n",
        "    all_results.update(pipeline_report.bronze_results)\n",
        "    all_results.update(pipeline_report.silver_results)\n",
        "    all_results.update(pipeline_report.gold_results)\n",
        "\n",
        "    for step_name, _step_data in all_results.items():\n",
        "        # Create a simplified step row since we don't have full StepResult objects\n",
        "        step_row: LogRow = {\n",
        "            \"run_id\": run_id,\n",
        "            \"run_mode\": run_mode,  # type: ignore[typeddict-item]\n",
        "            \"run_started_at\": pipeline_report.start_time,\n",
        "            \"run_ended_at\": pipeline_report.end_time,\n",
        "            \"execution_id\": pipeline_report.execution_id,\n",
        "            \"pipeline_id\": pipeline_report.pipeline_id,\n",
        "            \"schema\": \"default\",\n",
        "            \"phase\": \"bronze\"\n",
        "            if step_name in pipeline_report.bronze_results\n",
        "            else \"silver\"\n",
        "            if step_name in pipeline_report.silver_results\n",
        "            else \"gold\",\n",
        "            \"step_name\": step_name,\n",
        "            \"step_type\": \"transform\",\n",
        "            \"start_time\": pipeline_report.start_time,\n",
        "            \"end_time\": pipeline_report.end_time,\n",
        "            \"duration_secs\": 0.0,  # Not available in PipelineReport\n",
        "            \"table_fqn\": None,\n",
        "            \"write_mode\": None,\n",
        "            \"input_rows\": 0,\n",
        "            \"output_rows\": 0,\n",
        "            \"rows_written\": 0,\n",
        "            \"rows_processed\": 0,\n",
        "            \"table_total_rows\": None,\n",
        "            \"valid_rows\": 0,\n",
        "            \"invalid_rows\": 0,\n",
        "            \"validation_rate\": 100.0,\n",
        "            \"success\": True,  # Assume success if in results\n",
        "            \"error_message\": None,\n",
        "            \"memory_usage_mb\": None,\n",
        "            \"cpu_usage_percent\": None,\n",
        "            \"metadata\": metadata or {},\n",
        "        }\n",
        "        rows.append(step_row)\n",
        "\n",
        "    return rows\n",
        "\n",
        "# ============================================================================\n",
        "# Validation Functions\n",
        "# ============================================================================\n",
        "\n",
        "def validate_log_row(row: LogRow) -> None:\n",
        "    \"\"\"\n",
        "    Validate a log row for data quality.\n",
        "\n",
        "    Args:\n",
        "        row: The log row to validate\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the log row is invalid\n",
        "    \"\"\"\n",
        "    # Validate required fields\n",
        "    if not row[\"run_id\"]:\n",
        "        raise ValueError(\"Run ID cannot be empty\")\n",
        "    if not row[\"execution_id\"]:\n",
        "        raise ValueError(\"Execution ID cannot be empty\")\n",
        "    if not row[\"pipeline_id\"]:\n",
        "        raise ValueError(\"Pipeline ID cannot be empty\")\n",
        "    if not row[\"step_name\"]:\n",
        "        raise ValueError(\"Step name cannot be empty\")\n",
        "\n",
        "    # Validate numeric fields\n",
        "    if row[\"duration_secs\"] < 0:\n",
        "        raise ValueError(\"Duration cannot be negative\")\n",
        "    if row[\"rows_processed\"] < 0:\n",
        "        raise ValueError(\"Rows processed cannot be negative\")\n",
        "    if row[\"valid_rows\"] < 0:\n",
        "        raise ValueError(\"Valid rows cannot be negative\")\n",
        "    if row[\"invalid_rows\"] < 0:\n",
        "        raise ValueError(\"Invalid rows cannot be negative\")\n",
        "    if not 0 <= row[\"validation_rate\"] <= 100:\n",
        "        raise ValueError(\"Validation rate must be between 0 and 100\")\n",
        "\n",
        "    # Validate logical consistency\n",
        "    total_rows = row[\"valid_rows\"] + row[\"invalid_rows\"]\n",
        "    if total_rows != row[\"rows_processed\"]:\n",
        "        raise ValueError(\"Valid + invalid rows must equal rows processed\")\n",
        "\n",
        "def validate_log_data(rows: list[LogRow]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Validate a list of log rows.\n",
        "\n",
        "    Args:\n",
        "        rows: List of log rows to validate\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with validation results\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    for i, row in enumerate(rows):\n",
        "        try:\n",
        "            validate_log_row(row)\n",
        "        except ValueError as e:\n",
        "            errors.append(f\"Invalid log row at index {i}: {e}\")\n",
        "\n",
        "    return {\"is_valid\": len(errors) == 0, \"errors\": errors}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.validation.data_validation (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.compat, pipeline_builder.compat_helpers, pipeline_builder.functions, pipeline_builder.functions, pipeline_builder.models, pipeline_builder.models.execution, pipeline_builder.models.types, pipeline_builder_base.errors, pipeline_builder_base.errors, pipeline_builder_base.logging, pipeline_builder_base.logging, pipeline_builder_base.models\n",
        "\n",
        "# mypy: ignore-errors\n",
        "\"\"\"\n",
        "Data validation functions for the framework.\n",
        "\n",
        "This module provides functions for validating data using PySpark expressions,\n",
        "including string rule conversion, column validation, and data quality assessment.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import time\n",
        "from typing import Any, Dict, Optional, Union, cast\n",
        "# from .errors import ValidationError  # Removed: defined in notebook cells above\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .models import StageStats  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import Column, DataFrame  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..compat_helpers import detect_spark_type  # Removed: defined in notebook cells above\n",
        "# from ..functions import FunctionsProtocol, get_default_functions  # Removed: defined in notebook cells above\n",
        "# from ..models import ColumnRules  # Removed: defined in notebook cells above\n",
        "\n",
        "logger = PipelineLogger(\"DataValidation\")\n",
        "\n",
        "def _convert_rule_to_expression(\n",
        "    rule: Union[str, list],\n",
        "    column_name: str,\n",
        "    functions: Optional[FunctionsProtocol] = None,\n",
        ") -> Column:\n",
        "    \"\"\"Convert a string rule to a PySpark Column expression.\"\"\"\n",
        "    if functions is None:\n",
        "        functions = get_default_functions()\n",
        "\n",
        "    # Handle list-based rules like [\"gt\", 0]\n",
        "    if isinstance(rule, list):\n",
        "        if len(rule) == 0:\n",
        "            # Empty rule means no validation\n",
        "            return functions.lit(True)\n",
        "        elif len(rule) == 1:\n",
        "            return _convert_rule_to_expression(rule[0], column_name, functions)\n",
        "        elif len(rule) == 2:\n",
        "            op, value = rule\n",
        "            if op == \"gt\":\n",
        "                result = functions.col(column_name) > value\n",
        "                return cast(Column, result)\n",
        "            elif op == \"gte\":\n",
        "                result = functions.col(column_name) >= value\n",
        "                return cast(Column, result)\n",
        "            elif op == \"lt\":\n",
        "                result = functions.col(column_name) < value\n",
        "                return cast(Column, result)\n",
        "            elif op == \"lte\":\n",
        "                result = functions.col(column_name) <= value\n",
        "                return cast(Column, result)\n",
        "            elif op == \"eq\":\n",
        "                result = functions.col(column_name) == value\n",
        "                return cast(Column, result)\n",
        "            elif op == \"ne\":\n",
        "                result = functions.col(column_name) != value\n",
        "                return cast(Column, result)\n",
        "            elif op == \"in\":\n",
        "                if not isinstance(value, (list, tuple, set)):\n",
        "                    raise ValidationError(\n",
        "                        f\"'in' rule for column '{column_name}' requires list/tuple/set values\"\n",
        "                    )\n",
        "                result = functions.col(column_name).isin(list(value))  # type: ignore[attr-defined]\n",
        "                return cast(Column, result)\n",
        "            elif op == \"not_in\":\n",
        "                if not isinstance(value, (list, tuple, set)):\n",
        "                    raise ValidationError(\n",
        "                        f\"'not_in' rule for column '{column_name}' requires list/tuple/set values\"\n",
        "                    )\n",
        "                result = ~functions.col(column_name).isin(list(value))  # type: ignore[attr-defined]\n",
        "                return cast(Column, result)\n",
        "            elif op == \"like\":\n",
        "                result = functions.col(column_name).like(value)\n",
        "                return cast(Column, result)\n",
        "            else:\n",
        "                # For unknown operators, assume it's a valid PySpark expression\n",
        "                return functions.expr(f\"{column_name} {op} {value}\")\n",
        "        elif len(rule) == 3:\n",
        "            op, min_val, max_val = rule\n",
        "            if op == \"between\":\n",
        "                result = functions.col(column_name).between(min_val, max_val)\n",
        "                return result\n",
        "            else:\n",
        "                # For unknown operators, assume it's a valid PySpark expression\n",
        "                return functions.expr(f\"{column_name} {op} {min_val} {max_val}\")\n",
        "        else:\n",
        "            # For complex rules, assume it's a valid PySpark expression\n",
        "            return functions.expr(str(rule))\n",
        "\n",
        "    # Handle string-based rules\n",
        "    if rule == \"not_null\":\n",
        "        result = functions.col(column_name).isNotNull()\n",
        "        return result\n",
        "    elif rule == \"positive\":\n",
        "        result = functions.col(column_name) > 0\n",
        "        return result\n",
        "    elif rule == \"non_negative\":\n",
        "        result = functions.col(column_name) >= 0\n",
        "        return result\n",
        "    elif rule == \"non_zero\":\n",
        "        return functions.col(column_name) != 0\n",
        "    else:\n",
        "        # For unknown rules, assume it's a valid PySpark expression\n",
        "        return functions.expr(rule)\n",
        "\n",
        "def _convert_rules_to_expressions(\n",
        "    rules: ColumnRules,\n",
        "    functions: Optional[FunctionsProtocol] = None,\n",
        ") -> Dict[str, list[Union[str, Column]]]:\n",
        "    \"\"\"Convert string rules to PySpark Column expressions.\"\"\"\n",
        "    if functions is None:\n",
        "        functions = get_default_functions()\n",
        "\n",
        "    converted_rules: Dict[str, list[Union[str, Column]]] = {}\n",
        "    for column_name, rule_list in rules.items():\n",
        "        converted_rule_list: list[Union[str, Column]] = []\n",
        "        i = 0\n",
        "        while i < len(rule_list):\n",
        "            rule = rule_list[i]\n",
        "            # Doc-style \"in\" rule: [\"in\", [\"a\", \"b\"]] is often written as\n",
        "            # rule_list = [\"in\", [\"a\", \"b\"]] (two elements). Coalesce into one rule.\n",
        "            if (\n",
        "                i + 1 < len(rule_list)\n",
        "                and rule == \"in\"\n",
        "                and isinstance(rule_list[i + 1], (list, tuple, set))\n",
        "            ):\n",
        "                converted_rule_list.append(\n",
        "                    _convert_rule_to_expression(\n",
        "                        [\"in\", rule_list[i + 1]], column_name, functions\n",
        "                    )\n",
        "                )\n",
        "                i += 2\n",
        "            elif isinstance(rule, (str, list)):\n",
        "                converted_rule_list.append(\n",
        "                    _convert_rule_to_expression(rule, column_name, functions)\n",
        "                )\n",
        "                i += 1\n",
        "            else:\n",
        "                converted_rule_list.append(rule)\n",
        "                i += 1\n",
        "        converted_rules[column_name] = converted_rule_list\n",
        "    return converted_rules\n",
        "\n",
        "def and_all_rules(\n",
        "    rules: ColumnRules,\n",
        "    functions: Optional[FunctionsProtocol] = None,\n",
        ") -> Union[Column, bool]:\n",
        "    \"\"\"Combine all validation rules with AND logic.\"\"\"\n",
        "    if not rules:\n",
        "        return True\n",
        "\n",
        "    if functions is None:\n",
        "        functions = get_default_functions()\n",
        "\n",
        "    converted_rules = _convert_rules_to_expressions(rules, functions)\n",
        "    expressions = []\n",
        "    for _, exprs in converted_rules.items():\n",
        "        expressions.extend(exprs)\n",
        "\n",
        "    if not expressions:\n",
        "        return True\n",
        "\n",
        "    # Filter out non-Column expressions and convert strings to Columns\n",
        "    column_expressions = []\n",
        "    for expr in expressions:\n",
        "        # Check if it's a Column-like object (has column operations)\n",
        "        if isinstance(expr, str):\n",
        "            column_expressions.append(functions.expr(expr))\n",
        "        elif hasattr(expr, \"__and__\") and hasattr(expr, \"__invert__\"):\n",
        "            # Column-like object (use duck typing for Python 3.8 compatibility)\n",
        "            column_expressions.append(cast(Column, expr))\n",
        "\n",
        "    if not column_expressions:\n",
        "        return True\n",
        "\n",
        "    pred = column_expressions[0]\n",
        "    for e in column_expressions[1:]:\n",
        "        pred = pred & e\n",
        "\n",
        "    # Note: sparkless 3.17.1+ fixes the bug where combined ColumnOperation expressions\n",
        "    # were treated as column names, so we can return the combined expression directly\n",
        "    return pred\n",
        "\n",
        "def apply_column_rules(\n",
        "    df: DataFrame,\n",
        "    rules: ColumnRules,\n",
        "    stage: str,\n",
        "    step: str,\n",
        "    filter_columns_by_rules: bool = True,\n",
        "    functions: Optional[FunctionsProtocol] = None,\n",
        ") -> tuple[DataFrame, DataFrame, StageStats]:\n",
        "    \"\"\"\n",
        "    Apply validation rules to a DataFrame and return valid/invalid DataFrames with statistics.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to validate\n",
        "        rules: Dictionary mapping column names to validation rules\n",
        "        stage: Pipeline stage name\n",
        "        step: Step name within the stage\n",
        "        filter_columns_by_rules: If True, output DataFrames only contain columns with rules\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (valid_df, invalid_df, stats)\n",
        "    \"\"\"\n",
        "    if rules is None:\n",
        "        raise ValidationError(\"Validation rules cannot be None\")\n",
        "\n",
        "    # Handle empty rules - return all rows as valid\n",
        "    if not rules:\n",
        "        total_rows = df.count()\n",
        "        duration = 0.0\n",
        "        stats = StageStats(\n",
        "            stage=stage,\n",
        "            step=step,\n",
        "            total_rows=total_rows,\n",
        "            valid_rows=total_rows,\n",
        "            invalid_rows=0,\n",
        "            validation_rate=100.0,\n",
        "            duration_secs=duration,\n",
        "        )\n",
        "        return (\n",
        "            df,\n",
        "            df.limit(0),\n",
        "            stats,\n",
        "        )  # Return original df as valid, empty df as invalid\n",
        "\n",
        "    # Validate that all columns referenced in rules exist in the DataFrame\n",
        "    df_columns = set(df.columns)\n",
        "    rule_columns = set(rules.keys())\n",
        "    missing_columns = rule_columns - df_columns\n",
        "\n",
        "    if missing_columns:\n",
        "        available_columns = sorted(df_columns)\n",
        "        missing_columns_list = sorted(missing_columns)\n",
        "\n",
        "        # Filter out rules for non-existent columns with a warning\n",
        "        # This handles cases where transforms drop columns that were in the input\n",
        "        filtered_rules = {col: rules[col] for col in rules.keys() if col in df_columns}\n",
        "\n",
        "        if not filtered_rules:\n",
        "            # All rules reference missing columns - this is an error\n",
        "            raise ValidationError(\n",
        "                f\"All columns referenced in validation rules do not exist in DataFrame. \"\n",
        "                f\"Missing columns: {missing_columns_list}. \"\n",
        "                f\"Available columns: {available_columns}. \"\n",
        "                f\"Stage: {stage}, Step: {step}. \"\n",
        "                f\"This may indicate that the transform function dropped columns that are referenced in validation rules. \"\n",
        "                f\"Please update validation rules to only reference columns that exist after the transform.\"\n",
        "            )\n",
        "\n",
        "        # Log warning about filtered rules\n",
        "        logger.warning(\n",
        "            f\"Validation rules reference columns that do not exist in DataFrame after transform. \"\n",
        "            f\"Filtered out rules for missing columns: {missing_columns_list}. \"\n",
        "            f\"Available columns: {available_columns}. \"\n",
        "            f\"Stage: {stage}, Step: {step}. \"\n",
        "            f\"This may indicate that the transform function dropped columns. \"\n",
        "            f\"Continuing validation with remaining rules for existing columns.\"\n",
        "        )\n",
        "\n",
        "        # Use filtered rules for validation\n",
        "        rules = filtered_rules\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create validation predicate\n",
        "    validation_predicate = and_all_rules(rules, functions)\n",
        "\n",
        "    # Apply validation\n",
        "    if validation_predicate is True:\n",
        "        # No validation rules, return all data as valid\n",
        "        valid_df = df\n",
        "        invalid_df = df.limit(0)  # Empty DataFrame with same schema\n",
        "        total_rows = df.count()\n",
        "        valid_rows = total_rows\n",
        "        invalid_rows = 0\n",
        "    elif (\n",
        "        hasattr(validation_predicate, \"__and__\")\n",
        "        and hasattr(validation_predicate, \"__invert__\")\n",
        "        and not isinstance(validation_predicate, bool)\n",
        "    ):\n",
        "        # Handle PySpark Column expressions\n",
        "        # Note: sparkless 3.17.1+ fixes the bug where combined ColumnOperation expressions\n",
        "        # were treated as column names, so we can use the combined predicate for both\n",
        "        # sparkless and PySpark\n",
        "        if isinstance(validation_predicate, str):\n",
        "            validation_predicate = functions.expr(validation_predicate)\n",
        "        elif not (\n",
        "            hasattr(validation_predicate, \"__and__\")\n",
        "            and hasattr(validation_predicate, \"__invert__\")\n",
        "        ):\n",
        "            # Check if we're in real PySpark mode and predicate is not a PySpark Column\n",
        "            # This can happen when tests use sparkless functions in real PySpark mode\n",
        "            try:\n",
        "                # Try to detect if we're in real PySpark mode\n",
        "                spark_type = detect_spark_type(df.sql_ctx.sparkSession)  # type: ignore[attr-defined]\n",
        "                if spark_type == \"pyspark\":\n",
        "                    # Check if predicate is a PySpark Column by checking for _jc attribute\n",
        "                    if not hasattr(validation_predicate, \"_jc\"):\n",
        "                        # Not a PySpark Column - try to convert via string representation\n",
        "                        # This handles ColumnOperation from sparkless\n",
        "                        try:\n",
        "                            # Try to get string representation and convert\n",
        "                            pred_str = str(validation_predicate)\n",
        "                            validation_predicate = functions.expr(pred_str)\n",
        "                        except Exception:\n",
        "                            # If conversion fails, cast and hope it works\n",
        "                            # This will raise an error if it doesn't work, which is better than silent failure\n",
        "                            validation_predicate = cast(Column, validation_predicate)\n",
        "                    else:\n",
        "                        # It's a PySpark Column, just cast for type checking\n",
        "                        validation_predicate = cast(Column, validation_predicate)\n",
        "                else:\n",
        "                    # Not in real PySpark mode, safe to cast\n",
        "                    validation_predicate = cast(Column, validation_predicate)\n",
        "            except Exception:\n",
        "                # If detection fails, try casting anyway\n",
        "                validation_predicate = cast(Column, validation_predicate)\n",
        "\n",
        "        valid_df = df.filter(validation_predicate)\n",
        "        invalid_df = df.filter(~validation_predicate)\n",
        "        total_rows = df.count()\n",
        "        valid_rows = valid_df.count()\n",
        "        invalid_rows = invalid_df.count()\n",
        "    else:\n",
        "        # Handle boolean False case (shouldn't happen with current logic)\n",
        "        valid_df = df.limit(0)\n",
        "        invalid_df = df\n",
        "        total_rows = df.count()\n",
        "        valid_rows = 0\n",
        "        invalid_rows = total_rows\n",
        "\n",
        "    # Apply column filtering if requested\n",
        "    if filter_columns_by_rules:\n",
        "        # Only keep columns that have validation rules\n",
        "        rule_columns_list: list[str] = list(rules.keys())\n",
        "        valid_df = valid_df.select(*rule_columns_list)\n",
        "        # For invalid_df, also include the _failed_rules column if it exists\n",
        "        invalid_columns: list[str] = rule_columns_list.copy()\n",
        "        if \"_failed_rules\" in invalid_df.columns:\n",
        "            invalid_columns.append(\"_failed_rules\")\n",
        "        invalid_df = invalid_df.select(*invalid_columns)\n",
        "\n",
        "    # Calculate validation rate\n",
        "    validation_rate = (valid_rows / total_rows * 100) if total_rows > 0 else 100.0\n",
        "\n",
        "    # Create statistics\n",
        "    duration = time.time() - start_time\n",
        "    stats = StageStats(\n",
        "        stage=stage,\n",
        "        step=step,\n",
        "        total_rows=total_rows,\n",
        "        valid_rows=valid_rows,\n",
        "        invalid_rows=invalid_rows,\n",
        "        validation_rate=validation_rate,\n",
        "        duration_secs=duration,\n",
        "    )\n",
        "\n",
        "    logger.info(\n",
        "        f\"Validation completed for {stage}.{step}: {validation_rate:.1f}% valid\"\n",
        "    )\n",
        "\n",
        "    return valid_df, invalid_df, stats\n",
        "\n",
        "def validate_dataframe_schema(\n",
        "    df: DataFrame,\n",
        "    expected_columns: list[str],\n",
        ") -> bool:\n",
        "    \"\"\"Validate that DataFrame has expected columns.\"\"\"\n",
        "    actual_columns = set(df.columns)\n",
        "    expected_set = set(expected_columns)\n",
        "    missing_columns = expected_set - actual_columns\n",
        "    return len(missing_columns) == 0\n",
        "\n",
        "def assess_data_quality(\n",
        "    df: DataFrame,\n",
        "    rules: Optional[ColumnRules] = None,\n",
        "    functions: Optional[FunctionsProtocol] = None,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Assess data quality of a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to assess\n",
        "        rules: Optional validation rules\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with quality metrics\n",
        "    \"\"\"\n",
        "    try:\n",
        "        total_rows = df.count()\n",
        "\n",
        "        if total_rows == 0:\n",
        "            return {\n",
        "                \"total_rows\": 0,\n",
        "                \"valid_rows\": 0,\n",
        "                \"invalid_rows\": 0,\n",
        "                \"quality_rate\": 100.0,\n",
        "                \"is_empty\": True,\n",
        "            }\n",
        "\n",
        "        if rules:\n",
        "            valid_df, invalid_df, stats = apply_column_rules(\n",
        "                df, rules, \"test\", \"test\", functions=functions\n",
        "            )\n",
        "            return {\n",
        "                \"total_rows\": stats.total_rows,\n",
        "                \"valid_rows\": stats.valid_rows,\n",
        "                \"invalid_rows\": stats.invalid_rows,\n",
        "                \"quality_rate\": stats.validation_rate,\n",
        "                \"is_empty\": False,\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"total_rows\": total_rows,\n",
        "                \"valid_rows\": total_rows,\n",
        "                \"invalid_rows\": 0,\n",
        "                \"quality_rate\": 100.0,\n",
        "                \"is_empty\": False,\n",
        "            }\n",
        "    except ValidationError as e:\n",
        "        # Re-raise validation errors as they are specific and actionable\n",
        "        raise e\n",
        "    except Exception as e:\n",
        "        # Log the unexpected error and re-raise with context\n",
        "        import logging\n",
        "\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.error(f\"Unexpected error in assess_data_quality: {e}\")\n",
        "        raise ValidationError(\n",
        "            f\"Data quality assessment failed: {e}\",\n",
        "            context={\"function\": \"assess_data_quality\", \"original_error\": str(e)},\n",
        "        ) from e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.validation.pipeline_validation (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.models, pipeline_builder.models.execution, pipeline_builder.models.pipeline, pipeline_builder.models.steps, pipeline_builder_base.logging, pipeline_builder_base.logging, pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Pipeline validation functions for the framework.\n",
        "\n",
        "This module provides functions and classes for validating pipeline configurations,\n",
        "step dependencies, and overall pipeline structure.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, Optional\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .models import ExecutionContext, PipelineConfig  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..models import BronzeStep, GoldStep, SilverStep  # Removed: defined in notebook cells above\n",
        "\n",
        "# Type alias for step names\n",
        "StepName = str\n",
        "\n",
        "class StepValidatorProtocol:\n",
        "    \"\"\"Protocol for custom step validators.\"\"\"\n",
        "\n",
        "    def validate(self, step: Any, context: ExecutionContext) -> list[str]:\n",
        "        \"\"\"Validate a step and return any validation errors.\"\"\"\n",
        "        return []\n",
        "\n",
        "@dataclass\n",
        "class ValidationResult:\n",
        "    \"\"\"Result of validation.\"\"\"\n",
        "\n",
        "    is_valid: bool\n",
        "    errors: list[str]\n",
        "    warnings: list[str]\n",
        "    recommendations: list[str]\n",
        "\n",
        "    def __bool__(self) -> bool:\n",
        "        \"\"\"Return whether validation passed.\"\"\"\n",
        "        return self.is_valid\n",
        "\n",
        "class UnifiedValidator:\n",
        "    \"\"\"\n",
        "    Unified validation system for both data and pipeline validation.\n",
        "\n",
        "    This class provides a single interface for all validation needs,\n",
        "    combining data validation and pipeline validation functionality.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, logger: Optional[PipelineLogger] = None):\n",
        "        \"\"\"Initialize the unified validator.\"\"\"\n",
        "        if logger is None:\n",
        "            self.logger = PipelineLogger()\n",
        "        else:\n",
        "            self.logger = logger\n",
        "        self.custom_validators: list[StepValidator] = []\n",
        "\n",
        "    def add_validator(self, validator: StepValidator) -> None:\n",
        "        \"\"\"Add a custom step validator.\"\"\"\n",
        "        self.custom_validators.append(validator)\n",
        "        self.logger.info(f\"Added custom validator: {validator.__class__.__name__}\")\n",
        "\n",
        "    def validate_schema(self, schema: Any) -> list[str]:\n",
        "        \"\"\"\n",
        "        Validate schema name format.\n",
        "\n",
        "        Same contract as UnifiedValidator.validate_schema so that schema\n",
        "        validation works when the builder uses UnifiedValidator.\n",
        "\n",
        "        Args:\n",
        "            schema: Schema name to validate.\n",
        "\n",
        "        Returns:\n",
        "            List of validation errors (empty if valid).\n",
        "        \"\"\"\n",
        "        errors: list[str] = []\n",
        "        if not schema:\n",
        "            errors.append(\"Schema name cannot be empty\")\n",
        "        elif not isinstance(schema, str):\n",
        "            errors.append(\"Schema name must be a string\")\n",
        "        elif not schema.strip():\n",
        "            errors.append(\"Schema name cannot be whitespace only\")\n",
        "        elif len(schema) > 128:\n",
        "            errors.append(\"Schema name is too long (max 128 characters)\")\n",
        "        return errors\n",
        "\n",
        "    def validate_pipeline(\n",
        "        self,\n",
        "        config: PipelineConfig,\n",
        "        bronze_steps: Dict[StepName, BronzeStep],\n",
        "        silver_steps: Dict[StepName, SilverStep],\n",
        "        gold_steps: Dict[StepName, GoldStep],\n",
        "    ) -> ValidationResult:\n",
        "        \"\"\"\n",
        "        Validate the entire pipeline configuration.\n",
        "\n",
        "        Returns:\n",
        "            ValidationResult object containing:\n",
        "            - errors: List[str] of validation error messages\n",
        "            - warnings: List[str] of validation warnings\n",
        "            - recommendations: List[str] of recommendations\n",
        "            - is_valid: bool indicating if validation passed\n",
        "\n",
        "        Note:\n",
        "            This differs from UnifiedValidator.validate_pipeline() which returns List[str].\n",
        "            The PipelineBuilder.validate_pipeline() method handles both return types\n",
        "            using runtime type checks and type guard functions.\n",
        "        \"\"\"\n",
        "        errors: list[str] = []\n",
        "        warnings: list[str] = []\n",
        "        recommendations: list[str] = []\n",
        "\n",
        "        # Validate configuration\n",
        "        config_errors = self._validate_config(config)\n",
        "        errors.extend(config_errors)\n",
        "\n",
        "        # Validate steps\n",
        "        bronze_errors, bronze_warnings = self._validate_bronze_steps(bronze_steps)\n",
        "        errors.extend(bronze_errors)\n",
        "        warnings.extend(bronze_warnings)\n",
        "\n",
        "        silver_errors, silver_warnings = self._validate_silver_steps(\n",
        "            silver_steps, bronze_steps\n",
        "        )\n",
        "        errors.extend(silver_errors)\n",
        "        warnings.extend(silver_warnings)\n",
        "\n",
        "        gold_errors, gold_warnings = self._validate_gold_steps(gold_steps, silver_steps)\n",
        "        errors.extend(gold_errors)\n",
        "        warnings.extend(gold_warnings)\n",
        "\n",
        "        # Validate dependencies\n",
        "        dep_errors, dep_warnings = self._validate_dependencies(\n",
        "            bronze_steps, silver_steps, gold_steps\n",
        "        )\n",
        "        errors.extend(dep_errors)\n",
        "        warnings.extend(dep_warnings)\n",
        "\n",
        "        is_valid = len(errors) == 0\n",
        "\n",
        "        # Logging is handled by the builder to avoid duplicate messages\n",
        "        return ValidationResult(\n",
        "            is_valid=is_valid,\n",
        "            errors=errors,\n",
        "            warnings=warnings,\n",
        "            recommendations=recommendations,\n",
        "        )\n",
        "\n",
        "    def validate_step(\n",
        "        self, step: Any, step_type: str, context: ExecutionContext\n",
        "    ) -> ValidationResult:\n",
        "        \"\"\"Validate a single step.\"\"\"\n",
        "        errors: list[str] = []\n",
        "        warnings: list[str] = []\n",
        "\n",
        "        # Run custom validators\n",
        "        for validator in self.custom_validators:\n",
        "            try:\n",
        "                validator_errors = validator.validate(step, context)\n",
        "                errors.extend(validator_errors)\n",
        "            except Exception as e:\n",
        "                errors.append(\n",
        "                    f\"Custom validator {validator.__class__.__name__} failed: {e}\"\n",
        "                )\n",
        "\n",
        "        return ValidationResult(\n",
        "            is_valid=len(errors) == 0,\n",
        "            errors=errors,\n",
        "            warnings=warnings,\n",
        "            recommendations=[],\n",
        "        )\n",
        "\n",
        "    def _validate_config(self, config: PipelineConfig) -> list[str]:\n",
        "        \"\"\"Validate pipeline configuration.\"\"\"\n",
        "        errors = []\n",
        "\n",
        "        if not config.schema:\n",
        "            errors.append(\"Pipeline schema is required\")\n",
        "\n",
        "        # Table prefix is optional in simplified config\n",
        "        # if not config.table_prefix:\n",
        "        #     errors.append(\"Table prefix is required\")\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def _validate_bronze_steps(\n",
        "        self, bronze_steps: Dict[StepName, BronzeStep]\n",
        "    ) -> tuple[list[str], list[str]]:\n",
        "        \"\"\"Validate bronze steps.\"\"\"\n",
        "        errors = []\n",
        "        warnings: list[str] = []\n",
        "\n",
        "        for step_name, step in bronze_steps.items():\n",
        "            # Simplified validation - just check that step has required basic attributes\n",
        "            if not step.name:\n",
        "                errors.append(f\"Bronze step {step_name} missing name\")\n",
        "\n",
        "            if not step.rules:\n",
        "                errors.append(f\"Bronze step {step_name} missing validation rules\")\n",
        "\n",
        "        return errors, warnings\n",
        "\n",
        "    def _validate_silver_steps(\n",
        "        self,\n",
        "        silver_steps: Dict[StepName, SilverStep],\n",
        "        bronze_steps: Dict[StepName, BronzeStep],\n",
        "    ) -> tuple[list[str], list[str]]:\n",
        "        \"\"\"Validate silver steps.\"\"\"\n",
        "        errors = []\n",
        "        warnings: list[str] = []\n",
        "\n",
        "        for step_name, step in silver_steps.items():\n",
        "            # Handle validation-only steps (existing=True, transform=None)\n",
        "            if step.existing and step.transform is None:\n",
        "                # Validation-only step - check rules and table_name, but skip source_bronze\n",
        "                if not step.rules:\n",
        "                    errors.append(f\"Silver step '{step_name}' missing validation rules\")\n",
        "                if not step.table_name:\n",
        "                    errors.append(f\"Silver step '{step_name}' missing table_name\")\n",
        "                continue\n",
        "\n",
        "            # SQL-source steps (sql_source set) have no source_bronze\n",
        "            if getattr(step, \"sql_source\", None) is not None:\n",
        "                if not step.rules:\n",
        "                    errors.append(f\"Silver step '{step_name}' missing validation rules\")\n",
        "                if not step.table_name:\n",
        "                    errors.append(f\"Silver step '{step_name}' missing table_name\")\n",
        "                continue\n",
        "\n",
        "            if not step.source_bronze:\n",
        "                errors.append(f\"Silver step {step_name} missing source_bronze\")\n",
        "\n",
        "            # Check source_bronze exists\n",
        "            if step.source_bronze and step.source_bronze not in bronze_steps:\n",
        "                errors.append(\n",
        "                    f\"Silver step {step_name} depends on non-existent bronze step {step.source_bronze}\"\n",
        "                )\n",
        "\n",
        "        return errors, warnings\n",
        "\n",
        "    def _validate_gold_steps(\n",
        "        self,\n",
        "        gold_steps: Dict[StepName, GoldStep],\n",
        "        silver_steps: Dict[StepName, SilverStep],\n",
        "    ) -> tuple[list[str], list[str]]:\n",
        "        \"\"\"Validate gold steps.\"\"\"\n",
        "        errors = []\n",
        "        warnings: list[str] = []\n",
        "\n",
        "        for step_name, step in gold_steps.items():\n",
        "            # Handle validation-only steps (existing=True, transform=None)\n",
        "            if step.existing and step.transform is None:\n",
        "                # Validation-only step - check rules and table_name, but skip source_silvers\n",
        "                if not step.rules:\n",
        "                    errors.append(f\"Gold step '{step_name}' missing validation rules\")\n",
        "                if not step.table_name:\n",
        "                    errors.append(f\"Gold step '{step_name}' missing table_name\")\n",
        "                continue\n",
        "\n",
        "            # SQL-source steps (sql_source set) have no source_silvers\n",
        "            if getattr(step, \"sql_source\", None) is not None:\n",
        "                if not step.rules:\n",
        "                    errors.append(f\"Gold step '{step_name}' missing validation rules\")\n",
        "                if not step.table_name:\n",
        "                    errors.append(f\"Gold step '{step_name}' missing table_name\")\n",
        "                continue\n",
        "\n",
        "            # Check source_silvers exist (if specified)\n",
        "            if step.source_silvers:\n",
        "                for silver_name in step.source_silvers:\n",
        "                    if silver_name not in silver_steps:\n",
        "                        errors.append(\n",
        "                            f\"Gold step {step_name} depends on non-existent silver step {silver_name}\"\n",
        "                        )\n",
        "\n",
        "        return errors, warnings\n",
        "\n",
        "    def _validate_dependencies(\n",
        "        self,\n",
        "        bronze_steps: Dict[StepName, BronzeStep],\n",
        "        silver_steps: Dict[StepName, SilverStep],\n",
        "        gold_steps: Dict[StepName, GoldStep],\n",
        "    ) -> tuple[list[str], list[str]]:\n",
        "        \"\"\"Validate step dependencies.\"\"\"\n",
        "        errors = []\n",
        "        warnings: list[str] = []\n",
        "\n",
        "        # Check for circular dependencies\n",
        "        all_steps = {**bronze_steps, **silver_steps, **gold_steps}\n",
        "\n",
        "        for step_name, step in all_steps.items():\n",
        "            # Check for circular dependencies in non-standard dependencies attribute\n",
        "            # This is only for custom step types that might have a dependencies field\n",
        "            if hasattr(step, \"dependencies\"):\n",
        "                dependencies = getattr(step, \"dependencies\", None)\n",
        "                if dependencies and isinstance(dependencies, (list, tuple, set)):\n",
        "                    for dep in dependencies:\n",
        "                        if hasattr(dep, \"step_name\") and dep.step_name == step_name:\n",
        "                            errors.append(\n",
        "                                f\"Step {step_name} has circular dependency on itself\"\n",
        "                            )\n",
        "\n",
        "        return errors, warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.writer.monitoring (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.compat, pipeline_builder.writer.exceptions, pipeline_builder.writer.models, pipeline_builder.writer.models, pipeline_builder.writer.query_builder, pipeline_builder.writer.query_builder, pipeline_builder_base.logging, pipeline_builder_base.logging, writer.exceptions\n",
        "\n",
        "# mypy: ignore-errors\n",
        "\"\"\"\n",
        "Writer monitoring module for performance tracking and metrics collection.\n",
        "\n",
        "This module handles performance monitoring, metrics collection, and\n",
        "analytics for the writer operations.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import Dict, Optional, TypedDict, cast\n",
        "\n",
        "try:\n",
        "    import psutil\n",
        "\n",
        "    HAS_PSUTIL = True\n",
        "except ImportError:\n",
        "    HAS_PSUTIL = False\n",
        "    psutil = None  # type: ignore[assignment, unused-ignore]\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from .exceptions import WriterError  # Removed: defined in notebook cells above\n",
        "# from .models import WriterMetrics  # Removed: defined in notebook cells above\n",
        "# from .query_builder import QueryBuilder  # Removed: defined in notebook cells above\n",
        "\n",
        "# ============================================================================\n",
        "# TypedDict Definitions\n",
        "# ============================================================================\n",
        "\n",
        "class OperationMetrics(TypedDict):\n",
        "    \"\"\"Metrics for a single operation.\"\"\"\n",
        "\n",
        "    operation_id: str\n",
        "    success: bool\n",
        "    duration_secs: float\n",
        "    rows_written: int\n",
        "    memory_usage_mb: float\n",
        "    error_message: Optional[str]\n",
        "    timestamp: str\n",
        "\n",
        "class SparkMemoryInfo(TypedDict, total=False):\n",
        "    \"\"\"Spark memory configuration.\"\"\"\n",
        "\n",
        "    executor_memory: str\n",
        "    driver_memory: str\n",
        "\n",
        "class MemoryUsageInfo(TypedDict):\n",
        "    \"\"\"Memory usage information structure.\"\"\"\n",
        "\n",
        "    total_mb: float\n",
        "    available_mb: float\n",
        "    used_mb: float\n",
        "    percentage: float\n",
        "    spark_memory: SparkMemoryInfo\n",
        "    psutil_available: bool\n",
        "\n",
        "class SuccessRateTrend(TypedDict):\n",
        "    \"\"\"Success rate trend data point.\"\"\"\n",
        "\n",
        "    date: str\n",
        "    success_rate: float\n",
        "    avg_validation_rate: float\n",
        "    avg_execution_time: float\n",
        "\n",
        "class PerformanceByPhase(TypedDict):\n",
        "    \"\"\"Performance metrics by phase.\"\"\"\n",
        "\n",
        "    phase: str\n",
        "    avg_execution_time: float\n",
        "    avg_validation_rate: float\n",
        "    execution_count: int\n",
        "\n",
        "class DataQualityTrend(TypedDict):\n",
        "    \"\"\"Data quality trend data point.\"\"\"\n",
        "\n",
        "    date: str\n",
        "    avg_validation_rate: float\n",
        "    min_validation_rate: float\n",
        "    max_validation_rate: float\n",
        "\n",
        "class PerformanceTrends(TypedDict):\n",
        "    \"\"\"Execution trends analysis structure.\"\"\"\n",
        "\n",
        "    success_rate_trend: list[SuccessRateTrend]\n",
        "    performance_by_phase: list[PerformanceByPhase]\n",
        "    data_quality_trend: list[DataQualityTrend]\n",
        "\n",
        "class PerformanceAnomaly(TypedDict):\n",
        "    \"\"\"Performance anomaly data point.\"\"\"\n",
        "\n",
        "    step: str\n",
        "    execution_time: float\n",
        "    validation_rate: float\n",
        "    success: bool\n",
        "\n",
        "class QualityAnomaly(TypedDict):\n",
        "    \"\"\"Quality anomaly data point.\"\"\"\n",
        "\n",
        "    step: str\n",
        "    validation_rate: float\n",
        "    valid_rows: int\n",
        "    invalid_rows: int\n",
        "\n",
        "class AnomalyReport(TypedDict):\n",
        "    \"\"\"Anomaly detection results structure.\"\"\"\n",
        "\n",
        "    performance_anomalies: list[PerformanceAnomaly]\n",
        "    quality_anomalies: list[QualityAnomaly]\n",
        "    anomaly_score: float\n",
        "    total_anomalies: int\n",
        "    total_executions: int\n",
        "\n",
        "class OverallStatistics(TypedDict):\n",
        "    \"\"\"Overall performance statistics.\"\"\"\n",
        "\n",
        "    total_executions: int\n",
        "    successful_executions: int\n",
        "    success_rate: float\n",
        "    avg_execution_time: float\n",
        "    avg_validation_rate: float\n",
        "    total_rows_written: int\n",
        "\n",
        "class PhaseStatistics(TypedDict):\n",
        "    \"\"\"Phase-wise performance statistics.\"\"\"\n",
        "\n",
        "    phase: str\n",
        "    execution_count: int\n",
        "    avg_execution_time: float\n",
        "    avg_validation_rate: float\n",
        "    total_rows_written: int\n",
        "\n",
        "class RecentPerformance(TypedDict):\n",
        "    \"\"\"Recent performance data point.\"\"\"\n",
        "\n",
        "    date: str\n",
        "    daily_executions: int\n",
        "    avg_execution_time: float\n",
        "    avg_validation_rate: float\n",
        "\n",
        "class PerformanceReport(TypedDict):\n",
        "    \"\"\"Comprehensive performance report structure.\"\"\"\n",
        "\n",
        "    overall_statistics: OverallStatistics\n",
        "    phase_statistics: list[PhaseStatistics]\n",
        "    recent_performance: list[RecentPerformance]\n",
        "    generated_at: str\n",
        "\n",
        "class PerformanceMonitor:\n",
        "    \"\"\"Handles performance monitoring and metrics collection.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the performance monitor.\"\"\"\n",
        "        self.spark = spark\n",
        "        if logger is None:\n",
        "            self.logger = PipelineLogger(\"PerformanceMonitor\")\n",
        "        else:\n",
        "            self.logger = logger\n",
        "        self.metrics: WriterMetrics = {\n",
        "            \"total_writes\": 0,\n",
        "            \"successful_writes\": 0,\n",
        "            \"failed_writes\": 0,\n",
        "            \"total_duration_secs\": 0.0,\n",
        "            \"avg_write_duration_secs\": 0.0,\n",
        "            \"total_rows_written\": 0,\n",
        "            \"memory_usage_peak_mb\": 0.0,\n",
        "        }\n",
        "        self.operation_start_times: Dict[str, float] = {}\n",
        "\n",
        "    def start_operation(self, operation_id: str, operation_type: str) -> None:\n",
        "        \"\"\"\n",
        "        Start monitoring an operation.\n",
        "\n",
        "        Args:\n",
        "            operation_id: Unique identifier for the operation\n",
        "            operation_type: Type of operation being monitored\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.operation_start_times[operation_id] = time.time()\n",
        "            self.logger.info(\n",
        "                f\"Started monitoring {operation_type} operation: {operation_id}\"\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(\n",
        "                f\"Failed to start monitoring operation {operation_id}: {e}\"\n",
        "            )\n",
        "            raise WriterError(\n",
        "                f\"Failed to start monitoring operation {operation_id}: {e}\"\n",
        "            ) from e\n",
        "\n",
        "    def end_operation(\n",
        "        self,\n",
        "        operation_id: str,\n",
        "        success: bool,\n",
        "        rows_written: int = 0,\n",
        "        error_message: Optional[str] = None,\n",
        "    ) -> OperationMetrics:\n",
        "        \"\"\"\n",
        "        End monitoring an operation and update metrics.\n",
        "\n",
        "        Args:\n",
        "            operation_id: Unique identifier for the operation\n",
        "            success: Whether the operation was successful\n",
        "            rows_written: Number of rows written\n",
        "            error_message: Error message if operation failed\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing operation metrics\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if operation_id not in self.operation_start_times:\n",
        "                self.logger.warning(f\"Operation {operation_id} was not being monitored\")\n",
        "                # Return empty metrics matching the TypedDict\n",
        "                return {\n",
        "                    \"operation_id\": operation_id,\n",
        "                    \"success\": False,\n",
        "                    \"duration_secs\": 0.0,\n",
        "                    \"rows_written\": 0,\n",
        "                    \"memory_usage_mb\": 0.0,\n",
        "                    \"error_message\": \"Operation was not being monitored\",\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                }\n",
        "\n",
        "            # Calculate duration\n",
        "            start_time = self.operation_start_times[operation_id]\n",
        "            duration = time.time() - start_time\n",
        "\n",
        "            # Update metrics\n",
        "            self.metrics[\"total_writes\"] += 1\n",
        "            if success:\n",
        "                self.metrics[\"successful_writes\"] += 1\n",
        "            else:\n",
        "                self.metrics[\"failed_writes\"] += 1\n",
        "\n",
        "            self.metrics[\"total_duration_secs\"] += duration\n",
        "            self.metrics[\"total_rows_written\"] += rows_written\n",
        "\n",
        "            # Calculate average duration\n",
        "            if self.metrics[\"total_writes\"] > 0:\n",
        "                self.metrics[\"avg_write_duration_secs\"] = (\n",
        "                    self.metrics[\"total_duration_secs\"] / self.metrics[\"total_writes\"]\n",
        "                )\n",
        "\n",
        "            # Update peak memory usage\n",
        "            current_memory = self.get_memory_usage()[\"used_mb\"]\n",
        "            if current_memory > self.metrics[\"memory_usage_peak_mb\"]:\n",
        "                self.metrics[\"memory_usage_peak_mb\"] = current_memory\n",
        "\n",
        "            # Create operation metrics\n",
        "            operation_metrics = {\n",
        "                \"operation_id\": operation_id,\n",
        "                \"success\": success,\n",
        "                \"duration_secs\": duration,\n",
        "                \"rows_written\": rows_written,\n",
        "                \"memory_usage_mb\": current_memory,\n",
        "                \"error_message\": error_message,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "            }\n",
        "\n",
        "            # Clean up\n",
        "            del self.operation_start_times[operation_id]\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"Completed monitoring {operation_id}: {duration:.2f}s, {rows_written} rows\"\n",
        "            )\n",
        "            return cast(OperationMetrics, operation_metrics)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to end monitoring operation {operation_id}: {e}\")\n",
        "            raise WriterError(\n",
        "                f\"Failed to end monitoring operation {operation_id}: {e}\"\n",
        "            ) from e\n",
        "\n",
        "    def get_metrics(self) -> WriterMetrics:\n",
        "        \"\"\"Get current performance metrics.\"\"\"\n",
        "        return self.metrics.copy()\n",
        "\n",
        "    def reset_metrics(self) -> None:\n",
        "        \"\"\"Reset performance metrics.\"\"\"\n",
        "        self.metrics = {\n",
        "            \"total_writes\": 0,\n",
        "            \"successful_writes\": 0,\n",
        "            \"failed_writes\": 0,\n",
        "            \"total_duration_secs\": 0.0,\n",
        "            \"avg_write_duration_secs\": 0.0,\n",
        "            \"total_rows_written\": 0,\n",
        "            \"memory_usage_peak_mb\": 0.0,\n",
        "        }\n",
        "        self.logger.info(\"Performance metrics reset\")\n",
        "\n",
        "    def get_memory_usage(self) -> MemoryUsageInfo:\n",
        "        \"\"\"\n",
        "        Get current memory usage information.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing memory usage details\n",
        "        \"\"\"\n",
        "        # Check if psutil is available at all\n",
        "        if not HAS_PSUTIL or psutil is None:\n",
        "            self.logger.warning(\"psutil not available, returning basic memory info\")\n",
        "            return {\n",
        "                \"total_mb\": 0.0,\n",
        "                \"available_mb\": 0.0,\n",
        "                \"used_mb\": 0.0,\n",
        "                \"percentage\": 0.0,\n",
        "                \"spark_memory\": {},\n",
        "                \"psutil_available\": False,\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            # Get system memory info\n",
        "            memory = psutil.virtual_memory()\n",
        "\n",
        "            # Get Spark memory info if available\n",
        "            spark_memory = {}\n",
        "            try:\n",
        "                spark_context = self.spark.sparkContext\n",
        "                spark_memory = {\n",
        "                    \"executor_memory\": spark_context.getConf().get(\n",
        "                        \"spark.executor.memory\", \"N/A\"\n",
        "                    ),\n",
        "                    \"driver_memory\": spark_context.getConf().get(\n",
        "                        \"spark.driver.memory\", \"N/A\"\n",
        "                    ),\n",
        "                }\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            memory_info = {\n",
        "                \"total_mb\": round(memory.total / (1024 * 1024), 2),\n",
        "                \"available_mb\": round(memory.available / (1024 * 1024), 2),\n",
        "                \"used_mb\": round(memory.used / (1024 * 1024), 2),\n",
        "                \"percentage\": memory.percent,\n",
        "                \"spark_memory\": spark_memory,\n",
        "                \"psutil_available\": True,\n",
        "            }\n",
        "\n",
        "            return cast(MemoryUsageInfo, memory_info)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to get memory usage: {e}\")\n",
        "            raise WriterError(f\"Failed to get memory usage: {e}\") from e\n",
        "\n",
        "    def check_performance_thresholds(\n",
        "        self, operation_metrics: OperationMetrics\n",
        "    ) -> list[str]:\n",
        "        \"\"\"\n",
        "        Check if performance thresholds are exceeded.\n",
        "\n",
        "        Args:\n",
        "            operation_metrics: Metrics for the operation\n",
        "\n",
        "        Returns:\n",
        "            List of threshold violations\n",
        "        \"\"\"\n",
        "        violations = []\n",
        "\n",
        "        try:\n",
        "            # Check duration threshold (5 minutes)\n",
        "            if operation_metrics.get(\"duration_secs\", 0) > 300:\n",
        "                violations.append(\"Operation duration exceeded 5 minutes\")\n",
        "\n",
        "            # Check memory usage threshold (8GB)\n",
        "            if operation_metrics.get(\"memory_usage_mb\", 0) > 8192:\n",
        "                violations.append(\"Memory usage exceeded 8GB\")\n",
        "\n",
        "            # Check success rate threshold (95%)\n",
        "            if self.metrics[\"total_writes\"] > 0:\n",
        "                success_rate = (\n",
        "                    self.metrics[\"successful_writes\"] / self.metrics[\"total_writes\"]\n",
        "                ) * 100\n",
        "                if success_rate < 95.0:\n",
        "                    violations.append(f\"Success rate below 95%: {success_rate:.1f}%\")\n",
        "\n",
        "            return violations\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to check performance thresholds: {e}\")\n",
        "            raise WriterError(f\"Failed to check performance thresholds: {e}\") from e\n",
        "\n",
        "class AnalyticsEngine:\n",
        "    \"\"\"Handles analytics and trend analysis for writer operations.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the analytics engine.\"\"\"\n",
        "        self.spark = spark\n",
        "        if logger is None:\n",
        "            self.logger = PipelineLogger(\"AnalyticsEngine\")\n",
        "        else:\n",
        "            self.logger = logger\n",
        "\n",
        "    def analyze_execution_trends(self, df: DataFrame) -> PerformanceTrends:\n",
        "        \"\"\"\n",
        "        Analyze execution trends from log data.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing log data\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing trend analysis\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Analyzing execution trends\")\n",
        "\n",
        "            # Use query builder for all trend analyses\n",
        "            trends = {}\n",
        "\n",
        "            # Success rate trend using query builder\n",
        "            success_trend_df = QueryBuilder.build_daily_trends_query(df, 30)\n",
        "            success_trend = success_trend_df.collect()\n",
        "\n",
        "            trends[\"success_rate_trend\"] = [\n",
        "                {\n",
        "                    \"date\": row[\"date\"],\n",
        "                    \"success_rate\": (\n",
        "                        row[\"successful_executions\"] / row[\"daily_executions\"]\n",
        "                    )\n",
        "                    * 100,\n",
        "                    \"avg_validation_rate\": row.get(\"avg_validation_rate\", 0),\n",
        "                    \"avg_execution_time\": row[\"avg_execution_time\"],\n",
        "                }\n",
        "                for row in success_trend\n",
        "            ]\n",
        "\n",
        "            # Performance trends using query builder\n",
        "            performance_trend_df = QueryBuilder.build_phase_trends_query(df, 30)\n",
        "            performance_trend = performance_trend_df.collect()\n",
        "\n",
        "            trends[\"performance_by_phase\"] = [\n",
        "                {\n",
        "                    \"phase\": row[\"phase\"],\n",
        "                    \"avg_execution_time\": row[\"avg_execution_time\"],\n",
        "                    \"avg_validation_rate\": row[\"avg_validation_rate\"],\n",
        "                    \"execution_count\": row[\"execution_count\"],\n",
        "                }\n",
        "                for row in performance_trend\n",
        "            ]\n",
        "\n",
        "            # Data quality trends using query builder\n",
        "            quality_trend_df = QueryBuilder.build_quality_trends_query(df, 30)\n",
        "            quality_trend = quality_trend_df.collect()\n",
        "\n",
        "            trends[\"data_quality_trend\"] = [\n",
        "                {\n",
        "                    \"date\": row[\"date\"],\n",
        "                    \"avg_validation_rate\": row[\"avg_validation_rate\"],\n",
        "                    \"min_validation_rate\": row[\"min_validation_rate\"],\n",
        "                    \"max_validation_rate\": row[\"max_validation_rate\"],\n",
        "                }\n",
        "                for row in quality_trend\n",
        "            ]\n",
        "\n",
        "            self.logger.info(\"Execution trends analysis completed\")\n",
        "            return cast(PerformanceTrends, trends)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to analyze execution trends: {e}\")\n",
        "            raise WriterError(f\"Failed to analyze execution trends: {e}\") from e\n",
        "\n",
        "    def detect_anomalies(self, df: DataFrame) -> AnomalyReport:\n",
        "        \"\"\"\n",
        "        Detect anomalies in execution data.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing log data\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing anomaly detection results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Detecting anomalies in execution data\")\n",
        "\n",
        "            anomalies: AnomalyReport = {\n",
        "                \"performance_anomalies\": [],\n",
        "                \"quality_anomalies\": [],\n",
        "                \"anomaly_score\": 0.0,\n",
        "                \"total_anomalies\": 0,\n",
        "                \"total_executions\": 0,\n",
        "            }\n",
        "\n",
        "            # Calculate performance thresholds using query builder\n",
        "            performance_stats = QueryBuilder.calculate_statistics(df, \"execution_time\")\n",
        "            performance_threshold = performance_stats[\"avg\"] + (\n",
        "                2 * performance_stats[\"stddev\"]\n",
        "            )\n",
        "\n",
        "            # Detect performance anomalies using query builder\n",
        "            performance_anomalies_df = QueryBuilder.build_performance_anomaly_query(\n",
        "                df, performance_threshold\n",
        "            ).select(\"step\", \"execution_time\", \"validation_rate\", \"success\")\n",
        "\n",
        "            performance_anomalies = performance_anomalies_df.collect()\n",
        "\n",
        "            anomalies[\"performance_anomalies\"] = [\n",
        "                {\n",
        "                    \"step\": row[\"step\"],\n",
        "                    \"execution_time\": row[\"execution_time\"],\n",
        "                    \"validation_rate\": row[\"validation_rate\"],\n",
        "                    \"success\": row[\"success\"],\n",
        "                }\n",
        "                for row in performance_anomalies\n",
        "            ]\n",
        "\n",
        "            # Detect data quality anomalies using query builder\n",
        "            quality_anomalies_df = (\n",
        "                QueryBuilder.build_quality_anomaly_query(df, 90.0)\n",
        "                .select(\"step\", \"validation_rate\", \"valid_rows\", \"invalid_rows\")\n",
        "                .orderBy(\"validation_rate\")\n",
        "            )\n",
        "\n",
        "            quality_anomalies = quality_anomalies_df.collect()\n",
        "\n",
        "            anomalies[\"quality_anomalies\"] = [\n",
        "                {\n",
        "                    \"step\": row[\"step\"],\n",
        "                    \"validation_rate\": row[\"validation_rate\"],\n",
        "                    \"valid_rows\": row[\"valid_rows\"],\n",
        "                    \"invalid_rows\": row[\"invalid_rows\"],\n",
        "                }\n",
        "                for row in quality_anomalies\n",
        "            ]\n",
        "\n",
        "            # Calculate anomaly score\n",
        "            total_executions = df.count()\n",
        "            anomaly_count = len(performance_anomalies) + len(quality_anomalies)\n",
        "            anomaly_score = (\n",
        "                (anomaly_count / total_executions) * 100 if total_executions > 0 else 0\n",
        "            )\n",
        "\n",
        "            anomalies[\"anomaly_score\"] = float(round(anomaly_score, 2))\n",
        "            anomalies[\"total_anomalies\"] = int(anomaly_count)\n",
        "            anomalies[\"total_executions\"] = int(total_executions)\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"Anomaly detection completed: {anomaly_count} anomalies found\"\n",
        "            )\n",
        "            return anomalies\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to detect anomalies: {e}\")\n",
        "            raise WriterError(f\"Failed to detect anomalies: {e}\") from e\n",
        "\n",
        "    def generate_performance_report(self, df: DataFrame) -> PerformanceReport:\n",
        "        \"\"\"\n",
        "        Generate comprehensive performance report.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing log data\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing performance report\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Generating performance report\")\n",
        "\n",
        "            # Overall statistics using query builder\n",
        "            overall_stats_df = df.agg(**QueryBuilder.get_common_aggregations())\n",
        "            overall_stats = overall_stats_df.collect()[0]\n",
        "\n",
        "            # Phase-wise statistics using query builder\n",
        "            phase_stats_df = QueryBuilder.build_phase_trends_query(df, 30)\n",
        "            phase_stats = phase_stats_df.collect()\n",
        "\n",
        "            # Recent performance using query builder\n",
        "            recent_performance_df = QueryBuilder.build_recent_performance_query(df, 7)\n",
        "            recent_performance = recent_performance_df.collect()\n",
        "\n",
        "            report = {\n",
        "                \"overall_statistics\": {\n",
        "                    \"total_executions\": overall_stats[\"total_executions\"],\n",
        "                    \"successful_executions\": overall_stats[\"successful_executions\"],\n",
        "                    \"success_rate\": (\n",
        "                        (\n",
        "                            overall_stats[\"successful_executions\"]\n",
        "                            / overall_stats[\"total_executions\"]\n",
        "                        )\n",
        "                        * 100\n",
        "                        if overall_stats[\"total_executions\"] > 0\n",
        "                        else 0\n",
        "                    ),\n",
        "                    \"avg_execution_time\": overall_stats[\"avg_execution_time\"],\n",
        "                    \"avg_validation_rate\": overall_stats[\"avg_validation_rate\"],\n",
        "                    \"total_rows_written\": overall_stats[\"total_rows_written\"],\n",
        "                },\n",
        "                \"phase_statistics\": [\n",
        "                    {\n",
        "                        \"phase\": row[\"phase\"],\n",
        "                        \"execution_count\": row[\"execution_count\"],\n",
        "                        \"avg_execution_time\": row[\"avg_execution_time\"],\n",
        "                        \"avg_validation_rate\": row[\"avg_validation_rate\"],\n",
        "                        \"total_rows_written\": row[\"total_rows_written\"],\n",
        "                    }\n",
        "                    for row in phase_stats\n",
        "                ],\n",
        "                \"recent_performance\": [\n",
        "                    {\n",
        "                        \"date\": row[\"date\"].strftime(\"%Y-%m-%d\"),\n",
        "                        \"daily_executions\": row[\"daily_executions\"],\n",
        "                        \"avg_execution_time\": row[\"avg_execution_time\"],\n",
        "                        \"avg_validation_rate\": row[\"avg_validation_rate\"],\n",
        "                    }\n",
        "                    for row in recent_performance\n",
        "                ],\n",
        "                \"generated_at\": datetime.now().isoformat(),\n",
        "            }\n",
        "\n",
        "            self.logger.info(\"Performance report generated successfully\")\n",
        "            return cast(PerformanceReport, report)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to generate performance report: {e}\")\n",
        "            raise WriterError(f\"Failed to generate performance report: {e}\") from e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.writer.operations (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.compat, pipeline_builder.functions, pipeline_builder.functions, pipeline_builder.models.execution, pipeline_builder.validation, pipeline_builder.writer.exceptions, pipeline_builder.writer.models, pipeline_builder.writer.models, pipeline_builder_base.logging, pipeline_builder_base.logging, pipeline_builder_base.models, validation.utils, writer.exceptions\n",
        "\n",
        "# mypy: ignore-errors\n",
        "\"\"\"\n",
        "Writer operations module for data processing and transformations.\n",
        "\n",
        "This module contains the core data processing operations for the writer,\n",
        "including data transformation, validation, and quality checks.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Callable, Dict, Optional, TypedDict, Union, cast\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .models import ExecutionResult, StepResult  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..functions import FunctionsProtocol, get_default_functions  # Removed: defined in notebook cells above\n",
        "# from ..validation import get_dataframe_info  # Removed: defined in notebook cells above\n",
        "# from .exceptions import WriterValidationError  # Removed: defined in notebook cells above\n",
        "# from .models import (  # Removed: defined in notebook cells above\n",
        "    # LogRow,\n",
        "    # create_log_rows_from_execution_result,\n",
        "    # create_log_schema,\n",
        "    # validate_log_data,\n",
        "# )\n",
        "\n",
        "# ============================================================================\n",
        "# TypedDict Definitions\n",
        "# ============================================================================\n",
        "\n",
        "class DataQualityReport(TypedDict):\n",
        "    \"\"\"Data quality validation report.\"\"\"\n",
        "\n",
        "    is_valid: bool\n",
        "    total_rows: int\n",
        "    null_counts: Dict[str, int]\n",
        "    validation_issues: list[str]\n",
        "    failed_executions: int\n",
        "    data_quality_score: float\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Handles data processing and transformation operations.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the data processor.\"\"\"\n",
        "        self.spark = spark\n",
        "        self.functions = functions if functions is not None else get_default_functions()\n",
        "        self.logger = logger or PipelineLogger(\"DataProcessor\")\n",
        "\n",
        "    def process_execution_result(\n",
        "        self,\n",
        "        execution_result: ExecutionResult,\n",
        "        run_id: str,\n",
        "        run_mode: str = \"initial\",\n",
        "        metadata: Union[Dict[str, Union[str, int, float, bool]], None] = None,\n",
        "        table_total_rows_provider: Optional[\n",
        "            Callable[[Optional[str]], Optional[int]]\n",
        "        ] = None,\n",
        "    ) -> list[LogRow]:\n",
        "        \"\"\"\n",
        "        Process execution result into log rows.\n",
        "\n",
        "        Args:\n",
        "            execution_result: The execution result to process\n",
        "            run_id: Unique run identifier\n",
        "            run_mode: Mode of the run\n",
        "            metadata: Additional metadata\n",
        "            table_total_rows_provider: Optional callback to supply table row counts\n",
        "\n",
        "        Returns:\n",
        "            List of processed log rows\n",
        "\n",
        "        Raises:\n",
        "            WriterValidationError: If validation fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Processing execution result for run {run_id}\")\n",
        "\n",
        "            # Create log rows from execution result\n",
        "            log_rows = create_log_rows_from_execution_result(\n",
        "                execution_result, run_id, run_mode, metadata\n",
        "            )\n",
        "\n",
        "            # Validate log data\n",
        "            validation_result = validate_log_data(log_rows)\n",
        "            if not validation_result[\"is_valid\"]:\n",
        "                raise WriterValidationError(\n",
        "                    f\"Log data validation failed: {validation_result['errors']}\",\n",
        "                    validation_errors=validation_result[\"errors\"],\n",
        "                    context={\"run_id\": run_id, \"log_rows_count\": len(log_rows)},\n",
        "                    suggestions=[\n",
        "                        \"Check data quality in source execution result\",\n",
        "                        \"Verify all required fields are present\",\n",
        "                        \"Ensure data types are correct\",\n",
        "                    ],\n",
        "                )\n",
        "\n",
        "            # Populate table_total_rows when possible\n",
        "            if table_total_rows_provider is not None:\n",
        "                for row in log_rows:\n",
        "                    if row.get(\"table_total_rows\") is None:\n",
        "                        row[\"table_total_rows\"] = table_total_rows_provider(\n",
        "                            row.get(\"table_fqn\")\n",
        "                        )\n",
        "\n",
        "            self.logger.info(f\"Successfully processed {len(log_rows)} log rows\")\n",
        "            return log_rows\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to process execution result: {e}\")\n",
        "            raise\n",
        "\n",
        "    def process_step_results(\n",
        "        self,\n",
        "        step_results: Dict[str, StepResult],\n",
        "        run_id: str,\n",
        "        run_mode: str = \"initial\",\n",
        "        metadata: Union[Dict[str, Union[str, int, float, bool]], None] = None,\n",
        "    ) -> list[LogRow]:\n",
        "        \"\"\"\n",
        "        Process step results into log rows.\n",
        "\n",
        "        Args:\n",
        "            step_results: Dictionary of step results\n",
        "            run_id: Unique run identifier\n",
        "            run_mode: Mode of the run\n",
        "            metadata: Additional metadata\n",
        "\n",
        "        Returns:\n",
        "            List of processed log rows\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\n",
        "                f\"Processing {len(step_results)} step results for run {run_id}\"\n",
        "            )\n",
        "\n",
        "            log_rows = []\n",
        "            for step_name, step_result in step_results.items():\n",
        "                # Create log row for each step\n",
        "                log_row = LogRow(\n",
        "                    run_id=run_id,\n",
        "                    run_mode=run_mode,  # type: ignore[typeddict-item]\n",
        "                    run_started_at=datetime.now(),\n",
        "                    run_ended_at=datetime.now(),\n",
        "                    execution_id=run_id,\n",
        "                    pipeline_id=run_id,\n",
        "                    schema=\"default\",\n",
        "                    phase=step_result.phase.value,\n",
        "                    step_name=step_name,\n",
        "                    step_type=step_result.phase.value,\n",
        "                    start_time=step_result.start_time,\n",
        "                    end_time=step_result.end_time,\n",
        "                    duration_secs=step_result.duration_secs,\n",
        "                    table_fqn=f\"{step_result.phase.value}_{step_name}\",\n",
        "                    write_mode=\"append\",\n",
        "                    input_rows=step_result.rows_processed,\n",
        "                    output_rows=step_result.rows_written,\n",
        "                    rows_written=step_result.rows_written,\n",
        "                    valid_rows=int(\n",
        "                        step_result.rows_processed * step_result.validation_rate / 100\n",
        "                    ),\n",
        "                    invalid_rows=int(\n",
        "                        step_result.rows_processed\n",
        "                        * (100 - step_result.validation_rate)\n",
        "                        / 100\n",
        "                    ),\n",
        "                    validation_rate=step_result.validation_rate,\n",
        "                    success=step_result.success,\n",
        "                    error_message=step_result.error_message,\n",
        "                    metadata=metadata or {},\n",
        "                    rows_processed=step_result.rows_processed,\n",
        "                    table_total_rows=None,\n",
        "                    memory_usage_mb=0.0,\n",
        "                    cpu_usage_percent=0.0,\n",
        "                )\n",
        "                log_rows.append(log_row)\n",
        "\n",
        "            self.logger.info(f\"Successfully processed {len(log_rows)} step log rows\")\n",
        "            return log_rows\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to process step results: {e}\")\n",
        "            raise\n",
        "\n",
        "    def create_dataframe_from_log_rows(self, log_rows: list[LogRow]) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Create DataFrame from log rows.\n",
        "\n",
        "        Args:\n",
        "            log_rows: List of log rows to convert\n",
        "\n",
        "        Returns:\n",
        "            DataFrame containing the log rows\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Creating DataFrame from {len(log_rows)} log rows\")\n",
        "\n",
        "            # Convert log rows to dictionaries\n",
        "            log_data = []\n",
        "            for row in log_rows:\n",
        "                row_dict = {\n",
        "                    \"run_id\": row[\"run_id\"],\n",
        "                    \"run_mode\": row[\"run_mode\"],\n",
        "                    \"run_started_at\": row[\"run_started_at\"],\n",
        "                    \"run_ended_at\": row[\"run_ended_at\"],\n",
        "                    \"execution_id\": row[\"execution_id\"],\n",
        "                    \"pipeline_id\": row[\"pipeline_id\"],\n",
        "                    \"schema\": row[\"schema\"],\n",
        "                    \"phase\": row[\"phase\"],\n",
        "                    \"step_name\": row[\"step_name\"],\n",
        "                    \"step_type\": row[\"step_type\"],\n",
        "                    \"start_time\": row[\"start_time\"],\n",
        "                    \"end_time\": row[\"end_time\"],\n",
        "                    \"duration_secs\": row[\"duration_secs\"],\n",
        "                    \"table_fqn\": row[\"table_fqn\"],\n",
        "                    \"write_mode\": row[\"write_mode\"],\n",
        "                    \"input_rows\": row[\"input_rows\"],\n",
        "                    \"output_rows\": row[\"output_rows\"],\n",
        "                    \"rows_written\": row[\"rows_written\"],\n",
        "                    \"rows_processed\": row[\"rows_processed\"],\n",
        "                    \"valid_rows\": row[\"valid_rows\"],\n",
        "                    \"invalid_rows\": row[\"invalid_rows\"],\n",
        "                    \"validation_rate\": row[\"validation_rate\"],\n",
        "                    \"success\": row[\"success\"],\n",
        "                    \"error_message\": row[\"error_message\"],\n",
        "                    \"memory_usage_mb\": row[\"memory_usage_mb\"],\n",
        "                    \"cpu_usage_percent\": row[\"cpu_usage_percent\"],\n",
        "                    \"metadata\": (\n",
        "                        json.dumps(row[\"metadata\"]) if row[\"metadata\"] else None\n",
        "                    ),\n",
        "                    \"created_at\": datetime.now().isoformat(),  # Include timestamp directly as string\n",
        "                }\n",
        "                log_data.append(row_dict)\n",
        "\n",
        "            # Create DataFrame with explicit schema for type safety and None value handling\n",
        "            schema = create_log_schema()\n",
        "            df = self.spark.createDataFrame(log_data, schema)  # type: ignore[type-var]\n",
        "\n",
        "            self.logger.info(\"Successfully created DataFrame from log rows\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to create DataFrame from log rows: {e}\")\n",
        "            raise\n",
        "\n",
        "    def validate_data_quality(self, df: DataFrame) -> DataQualityReport:\n",
        "        \"\"\"\n",
        "        Validate data quality of the DataFrame.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to validate\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing validation results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Validating data quality\")\n",
        "\n",
        "            # Get DataFrame info\n",
        "            df_info = get_dataframe_info(df)\n",
        "\n",
        "            # Check for null values in critical columns\n",
        "            critical_columns = [\"run_id\", \"phase\", \"step\", \"success\"]\n",
        "            null_counts = {}\n",
        "\n",
        "            for col_name in critical_columns:\n",
        "                if col_name in df.columns:\n",
        "                    null_count = df.filter(\n",
        "                        self.functions.col(col_name).isNull()\n",
        "                    ).count()\n",
        "                    null_counts[col_name] = null_count\n",
        "\n",
        "            # Check validation rates\n",
        "            validation_issues = []\n",
        "            if \"validation_rate\" in df.columns:\n",
        "                low_validation = df.filter(\n",
        "                    self.functions.col(\"validation_rate\") < 95.0\n",
        "                ).count()\n",
        "                if low_validation > 0:\n",
        "                    validation_issues.append(\n",
        "                        f\"{low_validation} records with validation rate < 95%\"\n",
        "                    )\n",
        "\n",
        "            # Check for failed executions\n",
        "            failed_executions = 0\n",
        "            if \"success\" in df.columns:\n",
        "                failed_executions = df.filter(~self.functions.col(\"success\")).count()\n",
        "\n",
        "            validation_result = {\n",
        "                \"is_valid\": len(validation_issues) == 0 and failed_executions == 0,\n",
        "                \"total_rows\": df_info[\"row_count\"],\n",
        "                \"null_counts\": null_counts,\n",
        "                \"validation_issues\": validation_issues,\n",
        "                \"failed_executions\": failed_executions,\n",
        "                \"data_quality_score\": self._calculate_quality_score(\n",
        "                    df_info, null_counts, validation_issues, failed_executions\n",
        "                ),\n",
        "            }\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"Data quality validation completed: {validation_result['is_valid']}\"\n",
        "            )\n",
        "            return cast(DataQualityReport, validation_result)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to validate data quality: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _calculate_quality_score(\n",
        "        self,\n",
        "        df_info: Dict[str, Union[int, str]],\n",
        "        null_counts: Dict[str, int],\n",
        "        validation_issues: list[str],\n",
        "        failed_executions: int,\n",
        "    ) -> float:\n",
        "        \"\"\"Calculate data quality score.\"\"\"\n",
        "        try:\n",
        "            total_rows = df_info[\"row_count\"]\n",
        "            if total_rows == 0:\n",
        "                return 0.0\n",
        "\n",
        "            # Ensure total_rows is an integer for division\n",
        "            if not isinstance(total_rows, int):\n",
        "                total_rows = int(total_rows) if total_rows else 0\n",
        "            if total_rows == 0:\n",
        "                return 0.0\n",
        "\n",
        "            # Calculate null penalty\n",
        "            null_penalty = sum(null_counts.values()) / total_rows\n",
        "\n",
        "            # Calculate validation penalty\n",
        "            validation_penalty = len(validation_issues) * 0.1\n",
        "\n",
        "            # Calculate failure penalty\n",
        "            failure_penalty = failed_executions / total_rows\n",
        "\n",
        "            # Calculate quality score (0-100)\n",
        "            quality_score = max(\n",
        "                0.0, 100.0 - (null_penalty + validation_penalty + failure_penalty) * 100\n",
        "            )\n",
        "\n",
        "            return float(round(quality_score, 2))\n",
        "\n",
        "        except Exception:\n",
        "            return 0.0\n",
        "\n",
        "    def apply_data_transformations(self, df: DataFrame) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Apply data transformations to the DataFrame.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to transform\n",
        "\n",
        "        Returns:\n",
        "            Transformed DataFrame\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Applying data transformations\")\n",
        "\n",
        "            # Add computed columns\n",
        "            df_transformed = df.withColumn(\n",
        "                \"processing_efficiency\",\n",
        "                self.functions.when(\n",
        "                    self.functions.col(\"input_rows\") > 0,\n",
        "                    self.functions.col(\"output_rows\")  # type: ignore[arg-type]\n",
        "                    / self.functions.col(\"input_rows\")\n",
        "                    * 100,\n",
        "                ).otherwise(0),\n",
        "            ).withColumn(\n",
        "                \"data_quality_score\",\n",
        "                self.functions.when(\n",
        "                    self.functions.col(\"validation_rate\") >= 95.0, \"High\"\n",
        "                )\n",
        "                .when(self.functions.col(\"validation_rate\") >= 80.0, \"Medium\")\n",
        "                .otherwise(\"Low\"),\n",
        "            )\n",
        "\n",
        "            self.logger.info(\"Data transformations applied successfully\")\n",
        "            return df_transformed\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to apply data transformations: {e}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.reporting.execution_reporter (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.execution, pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"Execution reporter for creating execution reports.\n",
        "\n",
        "This module provides a service for creating reports from execution results.\n",
        "The ExecutionReporter separates reporting logic from execution, making it\n",
        "easy to generate summaries and reports from pipeline execution results.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Optional\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..execution import ExecutionResult, StepExecutionResult  # Removed: defined in notebook cells above\n",
        "\n",
        "class ExecutionReporter:\n",
        "    \"\"\"Service for creating execution reports.\n",
        "\n",
        "    Creates reports from execution results, separating reporting from execution.\n",
        "    Provides methods to generate summary dictionaries from ExecutionResult and\n",
        "    StepExecutionResult objects.\n",
        "\n",
        "    Attributes:\n",
        "        logger: PipelineLogger instance for logging.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.reporting.execution_reporter import ExecutionReporter\n",
        "        >>>\n",
        "        >>> reporter = ExecutionReporter()\n",
        "        >>> summary = reporter.create_execution_summary(execution_result)\n",
        "        >>> step_summary = reporter.create_step_summary(step_result)\n",
        "        >>> print(f\"Pipeline status: {summary['status']}\")\n",
        "        >>> print(f\"Total rows processed: {summary['total_rows_processed']}\")\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the execution reporter.\n",
        "\n",
        "        Args:\n",
        "            logger: Optional PipelineLogger instance. If None, creates a\n",
        "                default logger.\n",
        "        \"\"\"\n",
        "        self.logger = logger or PipelineLogger()\n",
        "\n",
        "    def create_execution_summary(\n",
        "        self,\n",
        "        result: ExecutionResult,\n",
        "    ) -> dict:\n",
        "        \"\"\"Create a summary of execution results.\n",
        "\n",
        "        Generates a dictionary summary of pipeline execution results including\n",
        "        status, timing, step counts, and row metrics.\n",
        "\n",
        "        Args:\n",
        "            result: ExecutionResult from pipeline execution.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing:\n",
        "            - execution_id: Unique execution identifier\n",
        "            - mode: Execution mode used\n",
        "            - status: Overall pipeline status\n",
        "            - duration: Total execution duration in seconds\n",
        "            - steps_count: Total number of steps\n",
        "            - completed_steps: Number of successfully completed steps\n",
        "            - failed_steps: Number of failed steps\n",
        "            - total_rows_processed: Sum of rows processed across all steps\n",
        "            - total_rows_written: Sum of rows written across all steps\n",
        "            - error: Error message if pipeline failed (optional)\n",
        "        \"\"\"\n",
        "        summary = {\n",
        "            \"execution_id\": result.execution_id,\n",
        "            \"mode\": result.mode.value\n",
        "            if hasattr(result.mode, \"value\")\n",
        "            else str(result.mode),\n",
        "            \"status\": result.status,\n",
        "            \"duration\": result.duration,\n",
        "            \"steps_count\": len(result.steps) if result.steps else 0,\n",
        "        }\n",
        "\n",
        "        if result.steps:\n",
        "            completed_steps = [s for s in result.steps if s.status.value == \"completed\"]\n",
        "            failed_steps = [s for s in result.steps if s.status.value == \"failed\"]\n",
        "\n",
        "            summary[\"completed_steps\"] = len(completed_steps)\n",
        "            summary[\"failed_steps\"] = len(failed_steps)\n",
        "            summary[\"total_rows_processed\"] = sum(\n",
        "                s.rows_processed or 0 for s in completed_steps\n",
        "            )\n",
        "            summary[\"total_rows_written\"] = sum(\n",
        "                s.rows_written or 0 for s in completed_steps\n",
        "            )\n",
        "\n",
        "        if result.error:\n",
        "            summary[\"error\"] = result.error\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def create_step_summary(\n",
        "        self,\n",
        "        result: StepExecutionResult,\n",
        "    ) -> dict:\n",
        "        \"\"\"Create a summary of a step execution result.\n",
        "\n",
        "        Generates a dictionary summary of individual step execution results\n",
        "        including status, timing, row counts, and validation metrics.\n",
        "\n",
        "        Args:\n",
        "            result: StepExecutionResult from step execution.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing:\n",
        "            - step_name: Name of the step\n",
        "            - step_type: Type of step (BRONZE, SILVER, GOLD)\n",
        "            - status: Step execution status\n",
        "            - duration: Step execution duration in seconds\n",
        "            - rows_processed: Number of rows processed\n",
        "            - rows_written: Number of rows written (None for Bronze steps)\n",
        "            - validation_rate: Percentage of rows that passed validation\n",
        "            - output_table: Fully qualified output table name (None for Bronze steps)\n",
        "            - error: Error message if step failed (optional)\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"step_name\": result.step_name,\n",
        "            \"step_type\": result.step_type.value\n",
        "            if hasattr(result.step_type, \"value\")\n",
        "            else str(result.step_type),\n",
        "            \"status\": result.status.value\n",
        "            if hasattr(result.status, \"value\")\n",
        "            else str(result.status),\n",
        "            \"duration\": result.duration,\n",
        "            \"rows_processed\": result.rows_processed,\n",
        "            \"rows_written\": result.rows_written,\n",
        "            \"validation_rate\": result.validation_rate,\n",
        "            \"output_table\": result.output_table,\n",
        "            \"error\": result.error,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.table_operations (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.errors, pipeline_builder.performance\n",
        "\n",
        "\"\"\"\n",
        "Table operations utilities for the pipeline framework.\n",
        "\n",
        "This module provides comprehensive utilities for reading, writing, and managing\n",
        "tables in the data lake. It includes Delta Lake support, table existence checks,\n",
        "schema validation, and standardized write patterns.\n",
        "\n",
        "**Key Features:**\n",
        "    - **Delta Lake Integration**: Automatic detection and support for Delta tables\n",
        "    - **Standardized Write Patterns**: Consistent write operations across the framework\n",
        "    - **Table Management**: Existence checks, schema validation, and table operations\n",
        "    - **Error Handling**: Comprehensive error handling with custom exceptions\n",
        "    - **Performance Monitoring**: Built-in timing and performance tracking\n",
        "\n",
        "**Common Patterns:**\n",
        "    - Check if table exists before writing\n",
        "    - Prepare Delta tables for overwrite operations\n",
        "    - Create fully qualified table names (FQN)\n",
        "    - Write DataFrames with standardized patterns\n",
        "\n",
        "Dependencies:\n",
        "    - compat: Compatibility layer for Spark/PySpark types\n",
        "    - errors: Custom exception classes\n",
        "    - performance: Performance monitoring decorators\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.table_operations import (\n",
        "    ...     table_exists,\n",
        "    ...     write_overwrite_table,\n",
        "    ...     fqn\n",
        "    ... )\n",
        "    >>> from pipeline_builder.compat import SparkSession\n",
        "    >>>\n",
        "    >>> # Create fully qualified name\n",
        "    >>> table_name = fqn(\"analytics\", \"user_events\")\n",
        "    >>>\n",
        "    >>> # Check if table exists\n",
        "    >>> if table_exists(spark, table_name):\n",
        "    ...     print(f\"Table {table_name} exists\")\n",
        "    >>>\n",
        "    >>> # Write DataFrame\n",
        "    >>> rows = write_overwrite_table(df, table_name)\n",
        "    >>> print(f\"Wrote {rows} rows\")\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import tempfile\n",
        "from typing import Any, Dict, Optional, Union\n",
        "\n",
        "# from .compat import AnalysisException, DataFrame, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from .errors import TableOperationError  # Removed: defined in notebook cells above\n",
        "# from .performance import time_operation  # Removed: defined in notebook cells above\n",
        "# Fallback: time_operation decorator (will be replaced when performance module loads)\n",
        "def time_operation(name):\n",
        "    def decorator(func):\n",
        "        return func\n",
        "    return decorator\n",
        "\n",
        "# Handle optional Delta Lake dependency\n",
        "try:\n",
        "    from delta.tables import DeltaTable\n",
        "\n",
        "    HAS_DELTA = True\n",
        "except (ImportError, AttributeError, RuntimeError):\n",
        "    DeltaTable = None  # type: ignore[misc, assignment]\n",
        "    HAS_DELTA = False\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Cache for Delta Lake availability checks\n",
        "_delta_availability_cache: Dict[str, bool] = {}\n",
        "\n",
        "def is_delta_lake_available(spark: SparkSession) -> bool:  # type: ignore[valid-type]\n",
        "    \"\"\"Check if Delta Lake is available in the Spark session.\n",
        "\n",
        "    Checks whether Delta Lake extensions and catalog are configured in the\n",
        "    Spark session. Uses caching to avoid repeated checks for the same session.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance to check.\n",
        "\n",
        "    Returns:\n",
        "        True if Delta Lake is available (extensions and catalog configured),\n",
        "        False otherwise.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.table_operations import is_delta_lake_available\n",
        "        >>> if is_delta_lake_available(spark):\n",
        "        ...     print(\"Delta Lake is available\")\n",
        "        ...     # Use Delta-specific operations\n",
        "        ... else:\n",
        "        ...     print(\"Delta Lake is not available\")\n",
        "    \"\"\"\n",
        "    # Use session ID as cache key\n",
        "    spark_id = str(id(spark))\n",
        "    if spark_id in _delta_availability_cache:\n",
        "        return _delta_availability_cache[spark_id]\n",
        "\n",
        "    # Check if Delta extensions are configured\n",
        "    try:\n",
        "        extensions = spark.conf.get(\"spark.sql.extensions\", \"\")  # type: ignore[attr-defined]\n",
        "        catalog = spark.conf.get(\"spark.sql.catalog.spark_catalog\", \"\")  # type: ignore[attr-defined]\n",
        "        if (\n",
        "            extensions\n",
        "            and catalog\n",
        "            and \"DeltaSparkSessionExtension\" in extensions\n",
        "            and \"DeltaCatalog\" in catalog\n",
        "        ):\n",
        "            _delta_availability_cache[spark_id] = True\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass  # Config check failed; proceed to lightweight test\n",
        "\n",
        "    # If only extensions are configured, do a lightweight test\n",
        "    try:\n",
        "        extensions = spark.conf.get(\"spark.sql.extensions\", \"\")  # type: ignore[attr-defined]\n",
        "        if extensions and \"DeltaSparkSessionExtension\" in extensions:\n",
        "            # Try a simple test - create a minimal DataFrame and try to write it\n",
        "            test_df = spark.createDataFrame([(1, \"test\")], [\"id\", \"name\"])\n",
        "            # Use a unique temp directory to avoid conflicts\n",
        "            with tempfile.TemporaryDirectory() as temp_dir:\n",
        "                test_path = os.path.join(temp_dir, \"delta_test\")\n",
        "                try:\n",
        "                    test_df.write.format(\"delta\").mode(\"overwrite\").save(test_path)\n",
        "                    _delta_availability_cache[spark_id] = True\n",
        "                    return True\n",
        "                except Exception:\n",
        "                    # Delta format failed - not available\n",
        "                    pass\n",
        "    except Exception:\n",
        "        pass  # Lightweight Delta test failed or config unavailable\n",
        "\n",
        "    # Delta is not available in this Spark session\n",
        "    _delta_availability_cache[spark_id] = False\n",
        "    return False\n",
        "\n",
        "def create_dataframe_writer(\n",
        "    df: DataFrame,\n",
        "    spark: SparkSession,  # type: ignore[valid-type]\n",
        "    mode: str,\n",
        "    table_name: Optional[str] = None,\n",
        "    **options: Any,\n",
        ") -> Any:\n",
        "    \"\"\"Create a DataFrameWriter using the standardized Delta overwrite pattern.\n",
        "\n",
        "    Creates a DataFrameWriter configured with Delta format and appropriate\n",
        "    options. For overwrite mode, uses `overwriteSchema=true` to allow schema\n",
        "    evolution. Always uses Delta format - failures will propagate if Delta\n",
        "    is not available.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to write.\n",
        "        spark: SparkSession instance (used for Delta table preparation if needed).\n",
        "        mode: Write mode string. Common values:\n",
        "            - \"overwrite\": Replace existing data\n",
        "            - \"append\": Add to existing data\n",
        "            - \"ignore\": Skip if table exists\n",
        "            - \"error\": Fail if table exists\n",
        "        table_name: Optional fully qualified table name. If provided and mode\n",
        "            is \"overwrite\", prepares the Delta table for overwrite.\n",
        "        **options: Additional write options to pass to the writer (e.g.,\n",
        "            partitionBy, mergeSchema, etc.).\n",
        "\n",
        "    Returns:\n",
        "        DataFrameWriter instance configured with Delta format and options.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.table_operations import create_dataframe_writer\n",
        "        >>> writer = create_dataframe_writer(\n",
        "        ...     df,\n",
        "        ...     spark,\n",
        "        ...     mode=\"overwrite\",\n",
        "        ...     table_name=\"analytics.events\",\n",
        "        ...     partitionBy=\"date\"\n",
        "        ... )\n",
        "        >>> writer.saveAsTable(\"analytics.events\")\n",
        "    \"\"\"\n",
        "    # Use standardized overwrite pattern: overwrite + overwriteSchema\n",
        "    if mode == \"overwrite\":\n",
        "        # Prepare Delta table for overwrite by dropping it if it exists\n",
        "        # This avoids \"Table does not support truncate in batch mode\" errors\n",
        "        if table_name is not None:\n",
        "            prepare_delta_overwrite(spark, table_name)\n",
        "        writer = (\n",
        "            df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\")\n",
        "        )\n",
        "    else:\n",
        "        # Append or other modes - always use Delta\n",
        "        writer = df.write.format(\"delta\").mode(mode)\n",
        "\n",
        "    for key, value in options.items():\n",
        "        writer = writer.option(key, value)\n",
        "\n",
        "    return writer\n",
        "\n",
        "def prepare_delta_overwrite(\n",
        "    spark: SparkSession,  # type: ignore[valid-type]\n",
        "    table_name: str,\n",
        ") -> None:\n",
        "    \"\"\"Prepare for Delta table overwrite by dropping existing table if it exists.\n",
        "\n",
        "    Delta tables don't support truncate in batch mode, so we must drop the table\n",
        "    before overwriting it. This function safely handles this preparation by\n",
        "    dropping the table if it exists, avoiding \"Table does not support truncate\n",
        "    in batch mode\" errors.\n",
        "\n",
        "    **Important:** This function should be called before any Delta overwrite\n",
        "    operation to ensure compatibility with Delta Lake's limitations.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance for executing SQL commands.\n",
        "        table_name: Fully qualified table name (e.g., \"schema.table\") or\n",
        "            table path. If it's a table name (contains dot and doesn't start\n",
        "            with \"/\"), it will be dropped via SQL. If it's a path, the function\n",
        "            checks if it's a Delta table but cannot drop it (overwrite will\n",
        "            handle it).\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.table_operations import prepare_delta_overwrite\n",
        "        >>> prepare_delta_overwrite(spark, \"analytics.user_events\")\n",
        "        >>> df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"analytics.user_events\")\n",
        "\n",
        "    Note:\n",
        "        This function is safe to call even if the table doesn't exist. It uses\n",
        "        `DROP TABLE IF EXISTS` to avoid errors. If the drop fails for any reason,\n",
        "        a warning is logged but execution continues (the write operation may\n",
        "        still succeed or fail with a more specific error).\n",
        "    \"\"\"\n",
        "    if not HAS_DELTA:\n",
        "        return\n",
        "\n",
        "    # Check if it's a table name (contains dot) or a path\n",
        "    is_table_name = \".\" in table_name and not table_name.startswith(\"/\")\n",
        "\n",
        "    if is_table_name:\n",
        "        # Always try to drop the table if it exists, since we're about to overwrite it\n",
        "        # This is safer than failing later with truncate error for Delta tables\n",
        "        # Delta tables don't support truncate, so we must drop before overwrite\n",
        "        # Use DROP TABLE IF EXISTS to avoid errors if table doesn't exist\n",
        "        try:\n",
        "            # First try using SQL DROP TABLE\n",
        "            spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")  # type: ignore[attr-defined]\n",
        "            logger.debug(f\"Dropped table {table_name} before overwrite (if it existed)\")\n",
        "\n",
        "            # For Delta tables, also try using DeltaTable API if available\n",
        "            # This ensures the table is fully removed, including metadata\n",
        "            if HAS_DELTA:\n",
        "                try:\n",
        "                    # Try to get the table path and delete using DeltaTable\n",
        "                    # This is a more thorough cleanup for Delta tables\n",
        "                    spark.sql(f\"DESCRIBE TABLE EXTENDED {table_name}\").collect()  # type: ignore[attr-defined]\n",
        "                    # If we get here, table still exists - try DeltaTable.delete()\n",
        "                    delta_table = DeltaTable.forName(spark, table_name)  # type: ignore[attr-defined,assignment,arg-type]\n",
        "                    delta_table.delete()  # type: ignore[attr-defined]\n",
        "                    logger.debug(\n",
        "                        f\"Deleted Delta table {table_name} using DeltaTable API\"\n",
        "                    )\n",
        "                except Exception:\n",
        "                    # DeltaTable API might not work or table might not be Delta\n",
        "                    # This is fine - SQL DROP should have worked\n",
        "                    pass\n",
        "        except Exception as e:\n",
        "            # If drop fails, log warning but continue\n",
        "            # The write might still work if table doesn't exist\n",
        "            logger.warning(f\"Could not drop table {table_name} before overwrite: {e}\")\n",
        "    else:\n",
        "        # It's a path - check if Delta table exists at that path\n",
        "        try:\n",
        "            if DeltaTable.isDeltaTable(spark, table_name):  # type: ignore[attr-defined,arg-type]\n",
        "                # For path-based Delta tables, we can't drop via SQL\n",
        "                # The overwrite will handle it, but we log a warning\n",
        "                logger.debug(\n",
        "                    f\"Delta table exists at path {table_name}, overwrite will replace it\"\n",
        "                )\n",
        "        except Exception:\n",
        "            pass  # If we can't check Delta at path, assume and proceed with overwrite\n",
        "\n",
        "# Keep the old function name for backward compatibility, but it now calls the public function\n",
        "def _prepare_delta_overwrite_table_ops(\n",
        "    spark: SparkSession,  # type: ignore[valid-type]\n",
        "    table_name: str,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Legacy function name - use prepare_delta_overwrite() instead.\n",
        "\n",
        "    This function is kept for backward compatibility but now delegates to\n",
        "    the public prepare_delta_overwrite() function.\n",
        "    \"\"\"\n",
        "    prepare_delta_overwrite(spark, table_name)\n",
        "\n",
        "def fqn(schema: str, table: str) -> str:\n",
        "    \"\"\"Create a fully qualified table name (FQN).\n",
        "\n",
        "    Combines schema and table names into a fully qualified table name in the\n",
        "    format \"schema.table\". This is the standard format used throughout the\n",
        "    framework for table references.\n",
        "\n",
        "    Args:\n",
        "        schema: Database schema name. Must be non-empty.\n",
        "        table: Table name. Must be non-empty.\n",
        "\n",
        "    Returns:\n",
        "        Fully qualified table name in the format \"schema.table\".\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If schema or table is empty.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.table_operations import fqn\n",
        "        >>> table_name = fqn(\"analytics\", \"user_events\")\n",
        "        >>> print(table_name)  # \"analytics.user_events\"\n",
        "    \"\"\"\n",
        "    if not schema or not table:\n",
        "        raise ValueError(\"Schema and table names cannot be empty\")\n",
        "    return f\"{schema}.{table}\"\n",
        "\n",
        "@time_operation(\"table write (overwrite)\")\n",
        "def write_overwrite_table(\n",
        "    df: DataFrame,\n",
        "    fqn: str,\n",
        "    **options: Union[str, int] | Union[float, bool],  # type: ignore[valid-type]\n",
        ") -> int:\n",
        "    \"\"\"Write DataFrame to table in overwrite mode using Delta overwrite pattern.\n",
        "\n",
        "    Writes a DataFrame to a table, replacing all existing data. Uses Delta\n",
        "    format with `overwriteSchema=true` to allow schema evolution. Automatically\n",
        "    prepares the Delta table for overwrite by dropping it if it exists (to\n",
        "    avoid truncate errors).\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to write. Will be cached before writing.\n",
        "        fqn: Fully qualified table name (e.g., \"schema.table\").\n",
        "        **options: Additional write options to pass to the writer. Common\n",
        "            options include:\n",
        "            - partitionBy: Column(s) to partition by\n",
        "            - mergeSchema: Whether to merge schemas (default: true via overwriteSchema)\n",
        "\n",
        "    Returns:\n",
        "        Number of rows written to the table.\n",
        "\n",
        "    Raises:\n",
        "        TableOperationError: If write operation fails (e.g., table creation\n",
        "            fails, write fails, or Delta Lake is not available).\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.table_operations import write_overwrite_table\n",
        "        >>> rows = write_overwrite_table(\n",
        "        ...     df,\n",
        "        ...     \"analytics.user_events\",\n",
        "        ...     partitionBy=\"date\"\n",
        "        ... )\n",
        "        >>> print(f\"Wrote {rows} rows\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df.cache()  # type: ignore[attr-defined]\n",
        "        cnt: int = df.count()  # type: ignore[attr-defined]\n",
        "\n",
        "        # Get SparkSession from DataFrame to prepare Delta overwrite\n",
        "        spark = df.sql_ctx.sparkSession  # type: ignore[attr-defined]\n",
        "\n",
        "        # Prepare for Delta overwrite by dropping existing Delta table if it exists\n",
        "        prepare_delta_overwrite(spark, fqn)\n",
        "\n",
        "        # Delta Lake doesn't support append in batch mode\n",
        "        # Always use overwrite mode for Delta tables\n",
        "        # This is safe because we've already dropped the table if it existed\n",
        "        write_mode = \"overwrite\"\n",
        "        writer = (\n",
        "            df.write.format(\"delta\").mode(write_mode).option(\"overwriteSchema\", \"true\")\n",
        "        )  # type: ignore[attr-defined]\n",
        "\n",
        "        for key, value in options.items():\n",
        "            writer = writer.option(key, value)\n",
        "\n",
        "        writer.saveAsTable(fqn)\n",
        "        logger.info(f\"Successfully wrote {cnt} rows to {fqn} in {write_mode} mode\")\n",
        "        return cnt\n",
        "\n",
        "    except Exception as e:\n",
        "        raise TableOperationError(f\"Failed to write table {fqn}: {e}\") from e\n",
        "\n",
        "@time_operation(\"table write (append)\")\n",
        "def write_append_table(\n",
        "    df: DataFrame,\n",
        "    fqn: str,\n",
        "    **options: Union[str, int] | Union[float, bool],  # type: ignore[valid-type]\n",
        ") -> int:\n",
        "    \"\"\"Write DataFrame to table in append mode.\n",
        "\n",
        "    Writes a DataFrame to a table, adding new data to existing data. Uses\n",
        "    Parquet format for append operations. The table will be created if it\n",
        "    doesn't exist.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to write. Will be cached before writing.\n",
        "        fqn: Fully qualified table name (e.g., \"schema.table\").\n",
        "        **options: Additional write options to pass to the writer. Common\n",
        "            options include:\n",
        "            - partitionBy: Column(s) to partition by\n",
        "            - compression: Compression codec (e.g., \"snappy\", \"gzip\")\n",
        "\n",
        "    Returns:\n",
        "        Number of rows written to the table.\n",
        "\n",
        "    Raises:\n",
        "        TableOperationError: If write operation fails (e.g., table creation\n",
        "            fails or write fails).\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.table_operations import write_append_table\n",
        "        >>> rows = write_append_table(\n",
        "        ...     df,\n",
        "        ...     \"analytics.user_events\",\n",
        "        ...     partitionBy=\"date\"\n",
        "        ... )\n",
        "        >>> print(f\"Appended {rows} rows\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Cache DataFrame for potential multiple operations\n",
        "        df.cache()  # type: ignore[attr-defined]\n",
        "        cnt: int = df.count()  # type: ignore[attr-defined]\n",
        "        writer = df.write.format(\"parquet\").mode(\"append\")  # type: ignore[attr-defined]\n",
        "\n",
        "        # Apply additional options\n",
        "        for key, value in options.items():\n",
        "            writer = writer.option(key, value)\n",
        "\n",
        "        writer.saveAsTable(fqn)\n",
        "        logger.info(f\"Successfully wrote {cnt} rows to {fqn} in append mode\")\n",
        "        return cnt\n",
        "\n",
        "    except Exception as e:\n",
        "        raise TableOperationError(f\"Failed to write table {fqn}: {e}\") from e\n",
        "\n",
        "def read_table(\n",
        "    spark: SparkSession,\n",
        "    fqn: str,  # type: ignore[valid-type]\n",
        ") -> DataFrame:  # type: ignore[valid-type]\n",
        "    \"\"\"Read data from a table.\n",
        "\n",
        "    Reads data from a table using Spark's `table()` method. Supports both\n",
        "    regular tables and Delta tables.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance for reading the table.\n",
        "        fqn: Fully qualified table name (e.g., \"schema.table\").\n",
        "\n",
        "    Returns:\n",
        "        DataFrame containing the table data.\n",
        "\n",
        "    Raises:\n",
        "        TableOperationError: If read operation fails. Common causes:\n",
        "            - Table does not exist (wrapped AnalysisException)\n",
        "            - Permission errors\n",
        "            - Table corruption\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.table_operations import read_table\n",
        "        >>> df = read_table(spark, \"analytics.user_events\")\n",
        "        >>> print(f\"Read {df.count()} rows\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = spark.table(fqn)  # type: ignore[attr-defined]\n",
        "        logger.info(f\"Successfully read table {fqn}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        # Check if it's an AnalysisException (table doesn't exist) - use type name check for Python 3.8 compatibility\n",
        "        error_type_name = type(e).__name__\n",
        "        if \"AnalysisException\" in error_type_name:\n",
        "            raise TableOperationError(f\"Table {fqn} does not exist: {e}\") from e\n",
        "        else:\n",
        "            raise TableOperationError(f\"Failed to read table {fqn}: {e}\") from e\n",
        "\n",
        "def table_exists(\n",
        "    spark: SparkSession,\n",
        "    fqn: str,  # type: ignore[valid-type]\n",
        ") -> bool:  # type: ignore[valid-type]\n",
        "    \"\"\"Check if a table exists.\n",
        "\n",
        "    Checks whether a table exists in the Spark catalog. Uses multiple methods\n",
        "    for reliability: first tries the catalog's `tableExists()` method, then\n",
        "    falls back to attempting to read the table.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance for checking table existence.\n",
        "        fqn: Fully qualified table name (e.g., \"schema.table\").\n",
        "\n",
        "    Returns:\n",
        "        True if the table exists and is accessible, False otherwise.\n",
        "        Returns False if the table doesn't exist or an error occurs.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.table_operations import table_exists\n",
        "        >>> if table_exists(spark, \"analytics.user_events\"):\n",
        "        ...     print(\"Table exists\")\n",
        "        ... else:\n",
        "        ...     print(\"Table does not exist\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # If catalog has a fast check, use it first\n",
        "        try:\n",
        "            if hasattr(spark, \"catalog\") and spark.catalog.tableExists(fqn):  # type: ignore[attr-defined]\n",
        "                # Run a lightweight count to mirror legacy behavior/side effects\n",
        "                spark.table(fqn).count()  # type: ignore[attr-defined]\n",
        "                return True\n",
        "        except Exception:\n",
        "            # Fall back to direct table access below\n",
        "            pass\n",
        "\n",
        "        spark.table(fqn).count()  # type: ignore[attr-defined]\n",
        "        return True\n",
        "    except AnalysisException:  # type: ignore[misc]\n",
        "        logger.debug(f\"Table {fqn} does not exist (AnalysisException)\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Error checking if table {fqn} exists: {e}\")\n",
        "        return False\n",
        "\n",
        "def table_schema_is_empty(spark: SparkSession, fqn: str) -> bool:\n",
        "    \"\"\"Check if a table exists but reports an empty schema (struct<>).\n",
        "\n",
        "    Detects catalog synchronization issues where the metastore has a placeholder\n",
        "    entry for a table but the table has no columns (empty schema). This can\n",
        "    happen when table creation is interrupted or when there are catalog sync\n",
        "    issues. Callers can drop and recreate the table to fix this.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance for checking the table schema.\n",
        "        fqn: Fully qualified table name (e.g., \"schema.table\").\n",
        "\n",
        "    Returns:\n",
        "        True if the table exists but has an empty schema (no fields),\n",
        "        False otherwise. Returns False if the table doesn't exist or\n",
        "        an error occurs.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.table_operations import table_schema_is_empty\n",
        "        >>> if table_schema_is_empty(spark, \"analytics.user_events\"):\n",
        "        ...     print(\"Table has empty schema - needs recreation\")\n",
        "        ...     drop_table(spark, \"analytics.user_events\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not table_exists(spark, fqn):\n",
        "            return False\n",
        "        schema = spark.table(fqn).schema  # type: ignore[attr-defined]\n",
        "        if hasattr(schema, \"fields\"):\n",
        "            return len(schema.fields) == 0\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logger.debug(f\"Could not inspect schema for {fqn}: {e}\")\n",
        "        return False\n",
        "\n",
        "def drop_table(\n",
        "    spark: SparkSession,\n",
        "    fqn: str,  # type: ignore[valid-type]\n",
        ") -> bool:  # type: ignore[valid-type]\n",
        "    \"\"\"Drop a table if it exists.\n",
        "\n",
        "    Drops a table from the Spark catalog using the external catalog API.\n",
        "    This is a safe operation that only drops the table if it exists.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance for dropping the table.\n",
        "        fqn: Fully qualified table name (e.g., \"schema.table\"). If the name\n",
        "            doesn't contain a dot, it's assumed to be in the \"default\" schema.\n",
        "\n",
        "    Returns:\n",
        "        True if the table was dropped, False if it didn't exist or an\n",
        "        error occurred (logged as warning).\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.table_operations import drop_table\n",
        "        >>> if drop_table(spark, \"analytics.user_events\"):\n",
        "        ...     print(\"Table dropped successfully\")\n",
        "        ... else:\n",
        "        ...     print(\"Table did not exist or could not be dropped\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if table_exists(spark, fqn):\n",
        "            # Use Java SparkSession to access external catalog\n",
        "            jspark_session = spark._jsparkSession  # type: ignore[attr-defined]\n",
        "            external_catalog = jspark_session.sharedState().externalCatalog()\n",
        "\n",
        "            # Parse fully qualified name\n",
        "            if \".\" in fqn:\n",
        "                database_name, table_name = fqn.split(\".\", 1)\n",
        "            else:\n",
        "                database_name = \"default\"\n",
        "                table_name = fqn\n",
        "\n",
        "            # Drop the table using external catalog\n",
        "            # Parameters: db, table, ignoreIfNotExists, purge\n",
        "            external_catalog.dropTable(database_name, table_name, True, True)\n",
        "            logger.info(f\"Dropped table {fqn}\")\n",
        "            return True\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Failed to drop table {fqn}: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.performance (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.compat, pipeline_builder.table_operations, table_operations\n",
        "\n",
        "\"\"\"\n",
        "Performance monitoring utilities for the pipeline framework.\n",
        "\n",
        "This module contains functions for timing operations, monitoring performance,\n",
        "and managing execution metrics.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "import time\n",
        "from contextlib import contextmanager\n",
        "from datetime import datetime, timezone\n",
        "from functools import wraps\n",
        "from typing import Any, Callable, Generator, Optional\n",
        "\n",
        "# from .compat import DataFrame  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def now_dt() -> datetime:\n",
        "    \"\"\"Get current UTC datetime.\"\"\"\n",
        "    return datetime.now(timezone.utc)\n",
        "\n",
        "def format_duration(seconds: float) -> str:\n",
        "    \"\"\"\n",
        "    Format duration in seconds to human-readable string.\n",
        "\n",
        "    Args:\n",
        "        seconds: Duration in seconds\n",
        "\n",
        "    Returns:\n",
        "        Formatted duration string\n",
        "    \"\"\"\n",
        "    if seconds < 60:\n",
        "        return f\"{seconds:.2f}s\"\n",
        "    elif seconds < 3600:\n",
        "        minutes = seconds / 60\n",
        "        return f\"{minutes:.2f}m\"\n",
        "    else:\n",
        "        hours = seconds / 3600\n",
        "        return f\"{hours:.2f}h\"\n",
        "\n",
        "def time_operation(operation_name: str = \"operation\") -> Callable[[Callable], Callable]:\n",
        "    \"\"\"Decorator to time operations and log performance.\"\"\"\n",
        "\n",
        "    def decorator(func: Callable) -> Callable:\n",
        "        @wraps(func)\n",
        "        def wrapper(*args: Any, **kwargs: Any) -> Any:\n",
        "            start_time = time.time()\n",
        "            logger.info(f\"Starting {operation_name}...\")\n",
        "\n",
        "            try:\n",
        "                result = func(*args, **kwargs)\n",
        "                duration = time.time() - start_time\n",
        "                logger.info(f\"Completed {operation_name} in {duration:.3f}s\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                duration = time.time() - start_time\n",
        "                logger.error(f\"Failed {operation_name} after {duration:.3f}s: {e}\")\n",
        "                raise\n",
        "\n",
        "        return wrapper\n",
        "\n",
        "    return decorator\n",
        "\n",
        "@contextmanager\n",
        "def performance_monitor(\n",
        "    operation_name: str, max_duration: Optional[float] = None\n",
        ") -> Generator[None, None, None]:\n",
        "    \"\"\"Context manager to monitor operation performance.\"\"\"\n",
        "    start_time = time.time()\n",
        "    logger.info(f\"Starting {operation_name}...\")\n",
        "\n",
        "    try:\n",
        "        yield\n",
        "        duration = time.time() - start_time\n",
        "        logger.info(f\"Completed {operation_name} in {duration:.3f}s\")\n",
        "\n",
        "        if max_duration and duration > max_duration:\n",
        "            logger.warning(\n",
        "                f\"{operation_name} took {duration:.3f}s, exceeding threshold of {max_duration}s\"\n",
        "            )\n",
        "\n",
        "    except Exception as e:\n",
        "        duration = time.time() - start_time\n",
        "        logger.error(f\"Failed {operation_name} after {duration:.3f}s: {e}\")\n",
        "        raise\n",
        "\n",
        "@time_operation(\"write operation\")\n",
        "def time_write_operation(\n",
        "    mode: str,\n",
        "    df: DataFrame,\n",
        "    fqn: str,\n",
        "    **options: Any,\n",
        ") -> tuple[int, float, datetime, datetime]:\n",
        "    \"\"\"\n",
        "    Time a write operation and return results with timing info.\n",
        "\n",
        "    Args:\n",
        "        mode: Write mode (overwrite/append)\n",
        "        df: DataFrame to write\n",
        "        fqn: Fully qualified table name\n",
        "        **options: Additional write options\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (rows_written, duration_secs, start_time, end_time)\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If mode is invalid\n",
        "        TableOperationError: If write operation fails\n",
        "    \"\"\"\n",
        "    # from .table_operations import write_append_table, write_overwrite_table  # Removed: defined in notebook cells above\n",
        "\n",
        "    start = now_dt()\n",
        "    t0 = time.time()\n",
        "\n",
        "    try:\n",
        "        if mode == \"overwrite\":\n",
        "            rows = write_overwrite_table(df, fqn, **options)\n",
        "        elif mode == \"append\":\n",
        "            rows = write_append_table(df, fqn, **options)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Unknown write mode '{mode}'. Supported modes: overwrite, append\"\n",
        "            )\n",
        "\n",
        "        t1 = time.time()\n",
        "        end = now_dt()\n",
        "        duration = round(t1 - t0, 3)\n",
        "\n",
        "        logger.info(f\"Write operation completed: {rows} rows in {duration}s to {fqn}\")\n",
        "        return rows, duration, start, end\n",
        "\n",
        "    except Exception as e:\n",
        "        t1 = time.time()\n",
        "        end = now_dt()\n",
        "        duration = round(t1 - t0, 3)\n",
        "        logger.error(f\"Write operation failed after {duration}s: {e}\")\n",
        "        raise\n",
        "\n",
        "def monitor_performance(\n",
        "    operation_name: str, max_duration: Optional[float] = None\n",
        ") -> Callable:\n",
        "    \"\"\"\n",
        "    Decorator factory for performance monitoring.\n",
        "\n",
        "    Args:\n",
        "        operation_name: Name of the operation\n",
        "        max_duration: Maximum allowed duration in seconds\n",
        "\n",
        "    Returns:\n",
        "        Decorator function\n",
        "    \"\"\"\n",
        "\n",
        "    def decorator(func: Callable) -> Callable:\n",
        "        @wraps(func)\n",
        "        def wrapper(*args: Any, **kwargs: Any) -> Any:\n",
        "            with performance_monitor(operation_name, max_duration):\n",
        "                return func(*args, **kwargs)\n",
        "\n",
        "        return wrapper\n",
        "\n",
        "    return decorator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.step_executors.base (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.functions, pipeline_builder.table_operations, pipeline_builder_base.errors, pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"Base step executor with common functionality.\n",
        "\n",
        "This module provides the base class for all step executors with shared logic\n",
        "and a common interface. Step executors handle the execution of specific step\n",
        "types (Bronze, Silver, Gold) in the pipeline execution engine.\n",
        "\n",
        "The base class provides:\n",
        "    - Common initialization with SparkSession, logger, and functions\n",
        "    - Abstract execute() method that must be implemented by subclasses\n",
        "    - Shared infrastructure for all step executors\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import inspect\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Any, Dict, Optional\n",
        "# from .errors import ExecutionError  # Removed: defined in notebook cells above\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..functions import FunctionsProtocol  # Removed: defined in notebook cells above\n",
        "# from ..table_operations import fqn, table_exists  # Removed: defined in notebook cells above\n",
        "\n",
        "# Empty DataFrame for optional validation-only steps (mock Spark needs explicit schema)\n",
        "try:\n",
        "    from pyspark.sql.types import StructType as _EmptyStructType\n",
        "except ImportError:\n",
        "    _EmptyStructType = None  # type: ignore[misc, assignment]\n",
        "\n",
        "class BaseStepExecutor(ABC):\n",
        "    \"\"\"Base class for all step executors.\n",
        "\n",
        "    Provides common functionality and interface for executing pipeline steps.\n",
        "    Each step type (Bronze, Silver, Gold) has a specialized executor that\n",
        "    inherits from this base class.\n",
        "\n",
        "    Attributes:\n",
        "        spark: SparkSession instance for DataFrame operations.\n",
        "        logger: PipelineLogger instance for logging.\n",
        "        functions: FunctionsProtocol instance for PySpark operations.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.step_executors.base import BaseStepExecutor\n",
        "        >>> from pipeline_builder.compat import SparkSession\n",
        "        >>>\n",
        "        >>> class MyStepExecutor(BaseStepExecutor):\n",
        "        ...     def execute(self, step, context, mode=None):\n",
        "        ...         # Implementation here\n",
        "        ...         return output_df\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the base step executor.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance for DataFrame operations.\n",
        "            logger: Optional PipelineLogger instance. If None, creates a\n",
        "                default logger.\n",
        "            functions: Optional FunctionsProtocol instance for PySpark\n",
        "                operations. If None, functions must be provided by subclasses.\n",
        "        \"\"\"\n",
        "        self.spark = spark\n",
        "        self.logger = logger or PipelineLogger()\n",
        "        self.functions = functions\n",
        "\n",
        "    @staticmethod\n",
        "    def _accepts_params(func: Any) -> bool:\n",
        "        \"\"\"Check if a function accepts a 'params' argument or **kwargs.\n",
        "\n",
        "        Args:\n",
        "            func: The function to inspect.\n",
        "\n",
        "        Returns:\n",
        "            True if the function accepts 'params' as a named argument or **kwargs,\n",
        "            False otherwise.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            sig = inspect.signature(func)\n",
        "            for param_name, param in sig.parameters.items():\n",
        "                if param_name == \"params\":\n",
        "                    return True\n",
        "                if param.kind == inspect.Parameter.VAR_KEYWORD:  # **kwargs\n",
        "                    return True\n",
        "            return False\n",
        "        except (ValueError, TypeError):\n",
        "            # If we can't inspect the signature, assume it doesn't accept params\n",
        "            return False\n",
        "\n",
        "    def _handle_validation_only_step(\n",
        "        self, step: Any, step_type: str\n",
        "    ) -> Optional[DataFrame]:\n",
        "        \"\"\"Handle validation-only steps by reading from existing table.\n",
        "\n",
        "        This method checks if a step is validation-only (transform=None, existing=True)\n",
        "        and if so, reads the data from the existing table. Returns None if the step\n",
        "        is not validation-only.\n",
        "\n",
        "        Args:\n",
        "            step: Step instance (SilverStep or GoldStep).\n",
        "            step_type: Step type string for error messages (\"silver\" or \"gold\").\n",
        "\n",
        "        Returns:\n",
        "            DataFrame if step is validation-only and table exists, None otherwise.\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If schema doesn't exist, table doesn't exist, or\n",
        "                reading fails.\n",
        "        \"\"\"\n",
        "        # Check if this is a validation-only step\n",
        "        if not (\n",
        "            hasattr(step, \"transform\")\n",
        "            and step.transform is None\n",
        "            and hasattr(step, \"existing\")\n",
        "            and step.existing\n",
        "        ):\n",
        "            return None  # Not a validation-only step\n",
        "\n",
        "        table_name = getattr(step, \"table_name\", step.name)\n",
        "        schema = getattr(step, \"schema\", None)\n",
        "\n",
        "        if schema is None:\n",
        "            raise ExecutionError(\n",
        "                f\"Validation-only {step_type} step '{step.name}' requires schema to read from table\"\n",
        "            )\n",
        "\n",
        "        # Validate schema exists before checking table\n",
        "        try:\n",
        "            databases = [db.name for db in self.spark.catalog.listDatabases()]\n",
        "            if schema not in databases:\n",
        "                raise ExecutionError(\n",
        "                    f\"Validation-only {step_type} step '{step.name}' requires schema '{schema}', but schema does not exist. \"\n",
        "                    f\"Available schemas: {databases}\"\n",
        "                )\n",
        "        except ExecutionError:\n",
        "            raise  # Re-raise ExecutionError\n",
        "        except Exception as e:\n",
        "            raise ExecutionError(\n",
        "                f\"Failed to check if schema '{schema}' exists for validation-only {step_type} step '{step.name}': {e}\"\n",
        "            ) from e\n",
        "\n",
        "        table_fqn = fqn(schema, table_name)\n",
        "        # Validation-only steps just read the existing table via spark.table().\n",
        "        # Delta's schema check is disabled for the whole run in ExecutionEngine.execute_pipeline().\n",
        "        if table_exists(self.spark, table_fqn):\n",
        "            return self.spark.table(table_fqn)\n",
        "        if getattr(step, \"optional\", False):\n",
        "            self.logger.info(\n",
        "                f\"Validation-only {step_type} step '{step.name}': table '{table_fqn}' does not exist (optional=True), using empty DataFrame\"\n",
        "            )\n",
        "            return self._empty_dataframe()\n",
        "        raise ExecutionError(\n",
        "            f\"Validation-only {step_type} step '{step.name}' requires existing table '{table_fqn}', but table does not exist\"\n",
        "        )\n",
        "\n",
        "    def _empty_dataframe(self) -> DataFrame:\n",
        "        \"\"\"Return an empty DataFrame (zero rows) for optional validation-only steps when table is missing.\"\"\"\n",
        "        # Prefer createDataFrame([], StructType([])) for mock Spark (sparkless) compatibility\n",
        "        if _EmptyStructType is not None:\n",
        "            try:\n",
        "                return self.spark.createDataFrame([], _EmptyStructType())\n",
        "            except (TypeError, ValueError):\n",
        "                pass\n",
        "        try:\n",
        "            return self.spark.range(0, 0).toDF()  # type: ignore[no-any-return,attr-defined]\n",
        "        except (TypeError, ValueError):\n",
        "            return self.spark.range(0).limit(0).toDF()  # type: ignore[no-any-return,attr-defined]\n",
        "\n",
        "    @abstractmethod\n",
        "    def execute(\n",
        "        self,\n",
        "        step: Any,\n",
        "        context: Dict[str, DataFrame],\n",
        "        mode: Any = None,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"Execute a pipeline step.\n",
        "\n",
        "        Abstract method that must be implemented by subclasses. Each step\n",
        "        executor implements step-specific execution logic.\n",
        "\n",
        "        Args:\n",
        "            step: The step to execute (BronzeStep, SilverStep, or GoldStep).\n",
        "            context: Dictionary mapping step names to DataFrames. Contains\n",
        "                source data required for step execution.\n",
        "            mode: Optional execution mode (ExecutionMode enum). Some executors\n",
        "                use this for incremental processing.\n",
        "\n",
        "        Returns:\n",
        "            Output DataFrame after step execution.\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If step execution fails or required data is missing.\n",
        "\n",
        "        Note:\n",
        "            Subclasses must implement this method with step-specific logic.\n",
        "            The method should handle data retrieval from context, apply\n",
        "            transformations, and return the result DataFrame.\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.step_executors.bronze (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.models, pipeline_builder.step_executors.base, pipeline_builder_base.errors\n",
        "\n",
        "\"\"\"Bronze step executor.\n",
        "\n",
        "This module provides the executor for bronze steps, which validate existing\n",
        "data without transformation or writing. Bronze steps are the first layer in\n",
        "the Medallion architecture and serve as data quality gates.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict\n",
        "# from .errors import ExecutionError  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..models import BronzeStep  # Removed: defined in notebook cells above\n",
        "# from .base import BaseStepExecutor  # Removed: defined in notebook cells above\n",
        "\n",
        "class BronzeStepExecutor(BaseStepExecutor):\n",
        "    \"\"\"Executor for bronze steps in the pipeline.\n",
        "\n",
        "    Bronze steps validate existing raw data without transformation or writing.\n",
        "    They serve as data quality gates, ensuring that incoming data meets\n",
        "    basic validation rules before being processed by silver steps.\n",
        "\n",
        "    Bronze steps:\n",
        "        - Validate data according to step rules\n",
        "        - Do not transform data\n",
        "        - Do not write to tables\n",
        "        - Return the same DataFrame (validated but unchanged)\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.step_executors.bronze import BronzeStepExecutor\n",
        "        >>> from pipeline_builder.models import BronzeStep\n",
        "        >>>\n",
        "        >>> executor = BronzeStepExecutor(spark)\n",
        "        >>> result = executor.execute(\n",
        "        ...     step=BronzeStep(name=\"events\", rules={\"id\": [F.col(\"id\").isNotNull()]}),\n",
        "        ...     context={\"events\": source_df}\n",
        "        ... )\n",
        "        >>> # result is the same DataFrame, validated\n",
        "    \"\"\"\n",
        "\n",
        "    def execute(\n",
        "        self,\n",
        "        step: BronzeStep,\n",
        "        context: Dict[str, DataFrame],\n",
        "        mode: Any = None,  # Mode not used for bronze steps\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"Execute a bronze step.\n",
        "\n",
        "        Validates existing data from context without transformation. The step\n",
        "        name must exist in the context dictionary with the source DataFrame.\n",
        "\n",
        "        Args:\n",
        "            step: BronzeStep instance to execute.\n",
        "            context: Dictionary mapping step names to DataFrames. Must contain\n",
        "                the step name as a key with the source DataFrame.\n",
        "            mode: Execution mode (not used for bronze steps, can be None).\n",
        "\n",
        "        Returns:\n",
        "            Output DataFrame (same as input, validated but unchanged).\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If step name not found in context or DataFrame is\n",
        "                invalid.\n",
        "\n",
        "        Note:\n",
        "            - Bronze steps only validate data, they don't transform or write\n",
        "            - Validation is applied separately by the execution engine\n",
        "            - Empty DataFrames are allowed but logged as warnings\n",
        "        \"\"\"\n",
        "        # Bronze steps require data to be provided in context\n",
        "        # This is the expected behavior - bronze steps validate existing data\n",
        "        if step.name not in context:\n",
        "            raise ExecutionError(\n",
        "                f\"Bronze step '{step.name}' requires data to be provided in context. \"\n",
        "                f\"Bronze steps are for validating existing data, not creating it. \"\n",
        "                f\"Please provide data using bronze_sources parameter or context dictionary. \"\n",
        "                f\"Available context keys: {list(context.keys())}\"\n",
        "            )\n",
        "\n",
        "        df: DataFrame = context[step.name]\n",
        "\n",
        "        # Validate that the DataFrame is not empty (optional check)\n",
        "        if df.count() == 0:\n",
        "            self.logger.warning(\n",
        "                f\"Bronze step '{step.name}' received empty DataFrame. \"\n",
        "                f\"This may indicate missing or invalid data source.\"\n",
        "            )\n",
        "\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.step_executors.silver (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.models, pipeline_builder.sql_source, pipeline_builder.step_executors.base, pipeline_builder.table_operations, pipeline_builder_base.errors, pipeline_builder_base.models\n",
        "\n",
        "\"\"\"Silver step executor.\n",
        "\n",
        "This module provides the executor for silver steps, which transform bronze\n",
        "data into cleaned and enriched data. Silver steps can handle incremental\n",
        "processing to only process new data since the last run.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import inspect\n",
        "from typing import Any, Dict, Optional, cast\n",
        "# from .errors import ExecutionError  # Removed: defined in notebook cells above\n",
        "# from .models import ExecutionMode  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame, F  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..models import SilverStep  # Removed: defined in notebook cells above\n",
        "# from ..table_operations import fqn  # Removed: defined in notebook cells above\n",
        "# from .base import BaseStepExecutor  # Removed: defined in notebook cells above\n",
        "\n",
        "class SilverStepExecutor(BaseStepExecutor):\n",
        "    \"\"\"Executor for silver steps in the pipeline.\n",
        "\n",
        "    Silver steps transform bronze data into cleaned and enriched data. They\n",
        "    can handle incremental processing to only process new rows since the last\n",
        "    run, improving efficiency for large datasets.\n",
        "\n",
        "    Silver steps:\n",
        "        - Transform bronze data using step.transform() function\n",
        "        - Support incremental processing via watermark columns\n",
        "        - Write results to Delta Lake tables\n",
        "        - Apply validation rules after transformation\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.step_executors.silver import SilverStepExecutor\n",
        "        >>> from pipeline_builder_base.models import ExecutionMode\n",
        "        >>> from pipeline_builder.models import SilverStep\n",
        "        >>>\n",
        "        >>> executor = SilverStepExecutor(spark)\n",
        "        >>> result = executor.execute(\n",
        "        ...     step=SilverStep(\n",
        "        ...         name=\"clean_events\",\n",
        "        ...         source_bronze=\"events\",\n",
        "        ...         transform=lambda spark, df, silvers: df.filter(F.col(\"status\") == \"active\"),\n",
        "        ...         rules={\"status\": [F.col(\"status\").isNotNull()]},\n",
        "        ...         table_name=\"clean_events\"\n",
        "        ...     ),\n",
        "        ...     context={\"events\": bronze_df},\n",
        "        ...     mode=ExecutionMode.INITIAL\n",
        "        ... )\n",
        "    \"\"\"\n",
        "\n",
        "    def execute(  # type: ignore[override]\n",
        "        self,\n",
        "        step: SilverStep,\n",
        "        context: Dict[str, DataFrame],\n",
        "        mode: ExecutionMode,\n",
        "        step_params: Optional[Dict[str, Any]] = None,\n",
        "        step_types: Optional[Dict[str, str]] = None,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"Execute a silver step.\n",
        "\n",
        "        Transforms bronze data using the step's transform function. For\n",
        "        INCREMENTAL mode, filters bronze input to only process new rows.\n",
        "\n",
        "        Args:\n",
        "            step: SilverStep instance to execute.\n",
        "            context: Dictionary mapping step names to DataFrames. Must contain\n",
        "                the source bronze step name (step.source_bronze).\n",
        "            mode: Execution mode. INCREMENTAL mode triggers incremental filtering\n",
        "                of bronze input.\n",
        "            step_params: Optional dictionary of parameters to pass to the transform\n",
        "                function. If the transform function accepts a 'params' argument or\n",
        "                **kwargs, these will be passed. Otherwise, ignored for backward\n",
        "                compatibility.\n",
        "\n",
        "        Returns:\n",
        "            Transformed DataFrame ready for validation and writing.\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If source bronze step not found in context or\n",
        "                incremental filtering fails.\n",
        "\n",
        "        Note:\n",
        "            - Applies incremental filtering if mode is INCREMENTAL\n",
        "            - Calls step.transform() with bronze DataFrame and prior_silvers dict\n",
        "            - If step_params is provided and transform accepts params/kwargs, passes them\n",
        "            - Transformation logic is defined in the step's transform function\n",
        "        \"\"\"\n",
        "        # SQL-source step: load from JDBC/SQLAlchemy and return (engine validates/writes)\n",
        "        sql_src = getattr(step, \"sql_source\", None)\n",
        "        if sql_src is not None:\n",
        "            # from ..sql_source import read_sql_source  # Removed: defined in notebook cells above\n",
        "\n",
        "            # read_sql_source returns a Spark DataFrame; cast for type checkers.\n",
        "            return cast(DataFrame, read_sql_source(sql_src, self.spark))\n",
        "\n",
        "        # Handle validation-only steps (no transform function) - check this first\n",
        "        if step.transform is None:\n",
        "            if step.existing:\n",
        "                # Use base class method for validation-only step handling\n",
        "                result = self._handle_validation_only_step(step, \"silver\")\n",
        "                if result is not None:\n",
        "                    return result\n",
        "            else:\n",
        "                raise ExecutionError(\n",
        "                    f\"Silver step '{step.name}' has no transform function and is not marked as existing\"\n",
        "                )\n",
        "\n",
        "        # Get source bronze data (only needed for non-validation-only steps)\n",
        "        if step.source_bronze not in context:\n",
        "            raise ExecutionError(\n",
        "                f\"Source bronze step {step.source_bronze} not found in context\"\n",
        "            )\n",
        "\n",
        "        bronze_df: DataFrame = context[step.source_bronze]\n",
        "\n",
        "        if mode == ExecutionMode.INCREMENTAL:\n",
        "            bronze_df = self._filter_incremental_bronze_input(step, bronze_df)\n",
        "\n",
        "        # Build prior_silvers dict from context\n",
        "        # If source_silvers is specified, only include those steps\n",
        "        # Otherwise, include all previously executed steps (excluding bronze and current step)\n",
        "        prior_silvers: Dict[str, DataFrame] = {}\n",
        "        source_silvers = getattr(step, \"source_silvers\", None)\n",
        "\n",
        "        if source_silvers:\n",
        "            # Only include explicitly specified silver steps\n",
        "            for silver_name in source_silvers:\n",
        "                if silver_name in context and silver_name != step.name:\n",
        "                    prior_silvers[silver_name] = context[silver_name]\n",
        "        else:\n",
        "            # Include all previously executed steps (excluding bronze and current step)\n",
        "            # This allows backward compatibility for silver steps that access prior_silvers\n",
        "            # without explicitly declaring dependencies\n",
        "            for key, value in context.items():\n",
        "                if key != step.name and key != step.source_bronze:\n",
        "                    # Only include silver steps (exclude gold steps from prior_silvers)\n",
        "                    if step_types is None or step_types.get(key) != \"gold\":\n",
        "                        prior_silvers[key] = value\n",
        "\n",
        "        # Build prior_golds dict from context (all gold steps that have been executed)\n",
        "        prior_golds: Dict[str, DataFrame] = {}\n",
        "        if step_types is not None:\n",
        "            for key, value in context.items():\n",
        "                if key != step.name and step_types.get(key) == \"gold\":\n",
        "                    prior_golds[key] = value\n",
        "\n",
        "        # From here on transform is set (validation-only path returned or raised above)\n",
        "        transform = step.transform\n",
        "        assert transform is not None\n",
        "\n",
        "        # Detect if transform function accepts prior_golds parameter\n",
        "        has_prior_golds = False\n",
        "        try:\n",
        "            sig = inspect.signature(transform)\n",
        "            has_prior_golds = \"prior_golds\" in sig.parameters\n",
        "        except (ValueError, TypeError):\n",
        "            has_prior_golds = False\n",
        "\n",
        "        # Apply transform with source bronze data, prior silvers dict, and optionally prior_golds\n",
        "        # Support backward-compatible params passing (signatures vary: call-arg ignored)\n",
        "        if step_params is not None and self._accepts_params(transform):\n",
        "            try:\n",
        "                sig = inspect.signature(transform)\n",
        "                if \"params\" in sig.parameters:\n",
        "                    if has_prior_golds:\n",
        "                        return transform(  # type: ignore[call-arg]\n",
        "                            self.spark,\n",
        "                            bronze_df,\n",
        "                            prior_silvers,\n",
        "                            prior_golds,\n",
        "                            params=step_params,\n",
        "                        )\n",
        "                    else:\n",
        "                        return transform(  # type: ignore[call-arg]\n",
        "                            self.spark, bronze_df, prior_silvers, params=step_params\n",
        "                        )\n",
        "                else:\n",
        "                    if has_prior_golds:\n",
        "                        return transform(\n",
        "                            self.spark,\n",
        "                            bronze_df,\n",
        "                            prior_silvers,\n",
        "                            prior_golds,\n",
        "                            **step_params,\n",
        "                        )\n",
        "                    else:\n",
        "                        return transform(  # type: ignore[call-arg]\n",
        "                            self.spark, bronze_df, prior_silvers, **step_params\n",
        "                        )\n",
        "            except Exception:\n",
        "                if has_prior_golds:\n",
        "                    return transform(self.spark, bronze_df, prior_silvers, prior_golds)\n",
        "                else:\n",
        "                    return transform(self.spark, bronze_df, prior_silvers)  # type: ignore[call-arg]\n",
        "        else:\n",
        "            if has_prior_golds:\n",
        "                return transform(self.spark, bronze_df, prior_silvers, prior_golds)\n",
        "            else:\n",
        "                return transform(self.spark, bronze_df, prior_silvers)  # type: ignore[call-arg]\n",
        "\n",
        "    def _filter_incremental_bronze_input(\n",
        "        self,\n",
        "        step: SilverStep,\n",
        "        bronze_df: DataFrame,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"Filter bronze input rows already processed in previous incremental runs.\n",
        "\n",
        "        Filters bronze DataFrame to only include rows that haven't been processed\n",
        "        yet. Uses the source bronze step's incremental column and the silver step's\n",
        "        watermark column to determine which rows to exclude.\n",
        "\n",
        "        Args:\n",
        "            step: SilverStep instance with incremental configuration.\n",
        "            bronze_df: Bronze DataFrame to filter.\n",
        "\n",
        "        Returns:\n",
        "            Filtered DataFrame containing only new rows to process. Returns\n",
        "            original DataFrame if filtering cannot be performed (missing columns,\n",
        "            table doesn't exist, etc.).\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If filtering fails due to column or type issues.\n",
        "\n",
        "        Note:\n",
        "            Filtering logic:\n",
        "            1. Reads existing silver table to get maximum watermark value\n",
        "            2. Filters bronze rows where incremental_col > max_watermark\n",
        "            3. Returns original DataFrame if table doesn't exist (first run)\n",
        "\n",
        "            Requires:\n",
        "            - step.source_incremental_col: Column in bronze DataFrame\n",
        "            - step.watermark_col: Column in existing silver table\n",
        "            - step.schema and step.table_name: To locate existing table\n",
        "\n",
        "            Skips filtering gracefully if requirements not met (returns original DataFrame).\n",
        "        \"\"\"\n",
        "        incremental_col = getattr(step, \"source_incremental_col\", None)\n",
        "        watermark_col = getattr(step, \"watermark_col\", None)\n",
        "        schema = getattr(step, \"schema\", None)\n",
        "        table_name = getattr(step, \"table_name\", step.name)\n",
        "\n",
        "        if not incremental_col or not watermark_col or schema is None:\n",
        "            return bronze_df\n",
        "\n",
        "        if incremental_col not in getattr(bronze_df, \"columns\", []):\n",
        "            self.logger.debug(\n",
        "                f\"Silver step {step.name}: incremental column '{incremental_col}' \"\n",
        "                f\"not present in bronze DataFrame; skipping incremental filter\"\n",
        "            )\n",
        "            return bronze_df\n",
        "\n",
        "        # Validate that incremental column type is appropriate for filtering\n",
        "        try:\n",
        "            df_schema = bronze_df.schema\n",
        "            col_field = df_schema[incremental_col]  # type: ignore[index]\n",
        "            col_type = col_field.dataType\n",
        "            col_type_name = str(col_type)\n",
        "\n",
        "            # Check if type is comparable (numeric, date, timestamp, string)\n",
        "            # Non-comparable types: boolean, array, map, struct\n",
        "            non_comparable_types = [\"boolean\", \"array\", \"map\", \"struct\", \"binary\"]\n",
        "            if any(\n",
        "                non_comp in col_type_name.lower() for non_comp in non_comparable_types\n",
        "            ):\n",
        "                self.logger.warning(\n",
        "                    f\"Silver step {step.name}: incremental column '{incremental_col}' \"\n",
        "                    f\"has type '{col_type_name}' which may not be suitable for comparison operations. \"\n",
        "                    f\"Filtering may fail or produce unexpected results. \"\n",
        "                    f\"Consider using a numeric, date, timestamp, or string column for incremental processing.\"\n",
        "                )\n",
        "        except (KeyError, AttributeError, Exception) as e:\n",
        "            # If we can't inspect the schema, log a warning but continue\n",
        "            self.logger.debug(\n",
        "                f\"Silver step {step.name}: could not validate incremental column type: {e}\"\n",
        "            )\n",
        "\n",
        "        output_table = fqn(schema, table_name)\n",
        "\n",
        "        try:\n",
        "            existing_table = self.spark.table(output_table)\n",
        "        except Exception as exc:\n",
        "            self.logger.debug(\n",
        "                f\"Silver step {step.name}: unable to read existing table {output_table} \"\n",
        "                f\"for incremental filter: {exc}\"\n",
        "            )\n",
        "            return bronze_df\n",
        "\n",
        "        if watermark_col not in getattr(existing_table, \"columns\", []):\n",
        "            self.logger.debug(\n",
        "                f\"Silver step {step.name}: watermark column '{watermark_col}' \"\n",
        "                f\"not present in existing table {output_table}; skipping incremental filter\"\n",
        "            )\n",
        "            return bronze_df\n",
        "\n",
        "        try:\n",
        "            watermark_rows = existing_table.select(watermark_col).collect()\n",
        "        except Exception as exc:\n",
        "            self.logger.warning(\n",
        "                f\"Silver step {step.name}: failed to collect watermark values \"\n",
        "                f\"from {output_table}: {exc}\"\n",
        "            )\n",
        "            return bronze_df\n",
        "\n",
        "        if not watermark_rows:\n",
        "            return bronze_df\n",
        "\n",
        "        cutoff_value = None\n",
        "        for row in watermark_rows:\n",
        "            value = None\n",
        "            if hasattr(row, \"__getitem__\"):\n",
        "                try:\n",
        "                    value = row[watermark_col]\n",
        "                except Exception:\n",
        "                    try:\n",
        "                        value = row[0]\n",
        "                    except Exception:\n",
        "                        value = None\n",
        "            if value is None and hasattr(row, \"asDict\"):\n",
        "                value = row.asDict().get(watermark_col)\n",
        "            if value is None:\n",
        "                continue\n",
        "            cutoff_value = value if cutoff_value is None else max(cutoff_value, value)\n",
        "\n",
        "        if cutoff_value is None:\n",
        "            return bronze_df\n",
        "\n",
        "        try:\n",
        "            filtered_df = bronze_df.filter(F.col(incremental_col) > F.lit(cutoff_value))\n",
        "        except Exception as exc:\n",
        "            # Provide detailed error context for incremental filtering failures\n",
        "            error_msg = str(exc).lower()\n",
        "            if \"cannot resolve\" in error_msg or \"column\" in error_msg:\n",
        "                # Column-related error - provide schema context\n",
        "                available_cols = sorted(getattr(bronze_df, \"columns\", []))\n",
        "                raise ExecutionError(\n",
        "                    f\"Silver step {step.name}: failed to filter bronze rows using incremental column '{incremental_col}'. \"\n",
        "                    f\"Error: {exc!r}. \"\n",
        "                    f\"Available columns in bronze DataFrame: {available_cols}. \"\n",
        "                    f\"This may indicate that the incremental column was dropped or renamed in a previous transform. \"\n",
        "                    f\"Please ensure the incremental column '{incremental_col}' exists in the bronze DataFrame.\"\n",
        "                ) from exc\n",
        "            elif \"type\" in error_msg or \"cast\" in error_msg:\n",
        "                # Type-related error - provide type information\n",
        "                try:\n",
        "                    df_schema = bronze_df.schema\n",
        "                    col_type = df_schema[incremental_col].dataType  # type: ignore[index]\n",
        "                    raise ExecutionError(\n",
        "                        f\"Silver step {step.name}: failed to filter bronze rows using incremental column '{incremental_col}'. \"\n",
        "                        f\"Error: {exc!r}. \"\n",
        "                        f\"Column type: {col_type}. \"\n",
        "                        f\"Cutoff value type: {type(cutoff_value).__name__}. \"\n",
        "                        f\"Incremental columns must be comparable types (numeric, date, timestamp). \"\n",
        "                        f\"Please ensure the incremental column type is compatible with the cutoff value.\"\n",
        "                    ) from exc\n",
        "                except (KeyError, AttributeError, Exception):\n",
        "                    # If we can't get type info, provide generic error\n",
        "                    raise ExecutionError(\n",
        "                        f\"Silver step {step.name}: failed to filter bronze rows using incremental column '{incremental_col}'. \"\n",
        "                        f\"Error: {exc!r}. \"\n",
        "                        f\"This may be a type mismatch between the incremental column and the cutoff value. \"\n",
        "                        f\"Please ensure the incremental column type is compatible with the cutoff value type.\"\n",
        "                    ) from exc\n",
        "            else:\n",
        "                # Generic error with context\n",
        "                raise ExecutionError(\n",
        "                    f\"Silver step {step.name}: failed to filter bronze rows using \"\n",
        "                    f\"{incremental_col} > {cutoff_value}: {exc!r}. \"\n",
        "                    f\"Please check that the incremental column exists and is of a comparable type.\"\n",
        "                ) from exc\n",
        "\n",
        "        self.logger.info(\n",
        "            f\"Silver step {step.name}: filtering bronze rows where \"\n",
        "            f\"{incremental_col} <= {cutoff_value}\"\n",
        "        )\n",
        "        return filtered_df  # type: ignore[no-any-return]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.step_executors.gold (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.models, pipeline_builder.sql_source, pipeline_builder.step_executors.base, pipeline_builder_base.errors\n",
        "\n",
        "\"\"\"Gold step executor.\n",
        "\n",
        "This module provides the executor for gold steps, which aggregate silver data\n",
        "into final business metrics and analytics. Gold steps are the final layer\n",
        "in the Medallion architecture.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import inspect\n",
        "from typing import Any, Dict, Optional, cast\n",
        "# from .errors import ExecutionError  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..models import GoldStep  # Removed: defined in notebook cells above\n",
        "# from .base import BaseStepExecutor  # Removed: defined in notebook cells above\n",
        "\n",
        "class GoldStepExecutor(BaseStepExecutor):\n",
        "    \"\"\"Executor for gold steps in the pipeline.\n",
        "\n",
        "    Gold steps aggregate silver data into final business metrics and analytics.\n",
        "    They typically perform aggregations, joins, and business logic to produce\n",
        "    final reporting tables.\n",
        "\n",
        "    Gold steps:\n",
        "        - Aggregate multiple silver tables\n",
        "        - Perform business logic and calculations\n",
        "        - Write results to Delta Lake tables\n",
        "        - Apply validation rules after transformation\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.step_executors.gold import GoldStepExecutor\n",
        "        >>> from pipeline_builder.models import GoldStep\n",
        "        >>>\n",
        "        >>> executor = GoldStepExecutor(spark)\n",
        "        >>> result = executor.execute(\n",
        "        ...     step=GoldStep(\n",
        "        ...         name=\"daily_metrics\",\n",
        "        ...         transform=lambda spark, silvers: (\n",
        "        ...             silvers[\"clean_events\"]\n",
        "        ...             .groupBy(\"date\")\n",
        "        ...             .agg(F.count(\"*\").alias(\"count\"))\n",
        "        ...         ),\n",
        "        ...         rules={\"count\": [F.col(\"count\") > 0]},\n",
        "        ...         table_name=\"daily_metrics\",\n",
        "        ...         source_silvers=[\"clean_events\"]\n",
        "        ...     ),\n",
        "        ...     context={\"clean_events\": silver_df}\n",
        "        ... )\n",
        "    \"\"\"\n",
        "\n",
        "    def execute(\n",
        "        self,\n",
        "        step: GoldStep,\n",
        "        context: Dict[str, DataFrame],\n",
        "        mode: Any = None,  # Mode not used for gold steps\n",
        "        step_params: Optional[Dict[str, Any]] = None,\n",
        "        step_types: Optional[Dict[str, str]] = None,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"Execute a gold step.\n",
        "\n",
        "        Transforms silver data using the step's transform function. Builds a\n",
        "        dictionary of source silver DataFrames from step.source_silvers.\n",
        "\n",
        "        Args:\n",
        "            step: GoldStep instance to execute.\n",
        "            context: Dictionary mapping step names to DataFrames. Must contain\n",
        "                all source silver step names listed in step.source_silvers.\n",
        "            mode: Execution mode (not used for gold steps, can be None).\n",
        "            step_params: Optional dictionary of parameters to pass to the transform\n",
        "                function. If the transform function accepts a 'params' argument or\n",
        "                **kwargs, these will be passed. Otherwise, ignored for backward\n",
        "                compatibility.\n",
        "\n",
        "        Returns:\n",
        "            Transformed DataFrame ready for validation and writing.\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If any source silver step not found in context.\n",
        "\n",
        "        Note:\n",
        "            - Builds silvers dictionary from step.source_silvers\n",
        "            - Calls step.transform() with SparkSession and silvers dictionary\n",
        "            - If step_params is provided and transform accepts params/kwargs, passes them\n",
        "            - Transformation logic is defined in the step's transform function\n",
        "            - Gold steps typically perform aggregations and business metrics\n",
        "        \"\"\"\n",
        "        # SQL-source step: load from JDBC/SQLAlchemy and return (engine validates/writes)\n",
        "        sql_src = getattr(step, \"sql_source\", None)\n",
        "        if sql_src is not None:\n",
        "            # from ..sql_source import read_sql_source  # Removed: defined in notebook cells above\n",
        "\n",
        "            # read_sql_source returns a Spark DataFrame; cast for type checkers.\n",
        "            return cast(DataFrame, read_sql_source(sql_src, self.spark))\n",
        "\n",
        "        # Handle validation-only steps (no transform function)\n",
        "        if step.transform is None:\n",
        "            if step.existing:\n",
        "                # Use base class method for validation-only step handling\n",
        "                result = self._handle_validation_only_step(step, \"gold\")\n",
        "                if result is not None:\n",
        "                    return result\n",
        "            else:\n",
        "                raise ExecutionError(\n",
        "                    f\"Gold step '{step.name}' has no transform function and is not marked as existing\"\n",
        "                )\n",
        "\n",
        "        # Build silvers dict from source_silvers\n",
        "        silvers = {}\n",
        "        if step.source_silvers is not None:\n",
        "            for silver_name in step.source_silvers:\n",
        "                if silver_name not in context:\n",
        "                    raise ExecutionError(\n",
        "                        f\"Source silver {silver_name} not found in context\"\n",
        "                    )\n",
        "                silvers[silver_name] = context[silver_name]\n",
        "\n",
        "        # Build prior_golds dict from context (all previously executed gold steps)\n",
        "        prior_golds: Dict[str, DataFrame] = {}\n",
        "        if step_types is not None:\n",
        "            for key, value in context.items():\n",
        "                if key != step.name and step_types.get(key) == \"gold\":\n",
        "                    prior_golds[key] = value\n",
        "\n",
        "        # From here on transform is set (we raised above if None)\n",
        "        transform = step.transform\n",
        "        assert transform is not None\n",
        "\n",
        "        # Detect if transform function accepts prior_golds parameter\n",
        "        has_prior_golds = False\n",
        "        try:\n",
        "            sig = inspect.signature(transform)\n",
        "            has_prior_golds = \"prior_golds\" in sig.parameters\n",
        "        except (ValueError, TypeError):\n",
        "            has_prior_golds = False\n",
        "\n",
        "        # Apply transform with silvers dict and optionally prior_golds\n",
        "        # Support backward-compatible params passing (signatures vary: call-arg ignored)\n",
        "        if step_params is not None and self._accepts_params(transform):\n",
        "            try:\n",
        "                sig = inspect.signature(transform)\n",
        "                if \"params\" in sig.parameters:\n",
        "                    if has_prior_golds:\n",
        "                        return transform(  # type: ignore[call-arg]\n",
        "                            self.spark, silvers, prior_golds, params=step_params\n",
        "                        )\n",
        "                    else:\n",
        "                        return transform(self.spark, silvers, params=step_params)  # type: ignore[call-arg]\n",
        "                else:\n",
        "                    if has_prior_golds:\n",
        "                        return transform(\n",
        "                            self.spark, silvers, prior_golds, **step_params\n",
        "                        )\n",
        "                    else:\n",
        "                        return transform(self.spark, silvers, **step_params)  # type: ignore[call-arg]\n",
        "            except Exception:\n",
        "                if has_prior_golds:\n",
        "                    return transform(self.spark, silvers, prior_golds)\n",
        "                else:\n",
        "                    return transform(self.spark, silvers)  # type: ignore[call-arg]\n",
        "        else:\n",
        "            if has_prior_golds:\n",
        "                return transform(self.spark, silvers, prior_golds)\n",
        "            else:\n",
        "                return transform(self.spark, silvers)  # type: ignore[call-arg]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.storage.table_service (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.storage.schema_manager, pipeline_builder.table_operations, pipeline_builder_base.logging\n",
        "\n",
        "\"\"\"Table service for table operations.\n",
        "\n",
        "This module provides centralized table operations including existence checks,\n",
        "schema management, and table lifecycle operations. The TableService acts as\n",
        "a facade for table-related operations, delegating to SchemaManager for\n",
        "schema-specific functionality.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Optional\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import SparkSession  # Removed: defined in notebook cells above\n",
        "# from ..table_operations import fqn, table_exists  # Removed: defined in notebook cells above\n",
        "# from .schema_manager import SchemaManager  # Removed: defined in notebook cells above\n",
        "\n",
        "class TableService:\n",
        "    \"\"\"Service for table operations.\n",
        "\n",
        "    Centralizes all table-related operations including existence checks,\n",
        "    schema management, and table lifecycle operations. Acts as a facade\n",
        "    for table operations, delegating schema management to SchemaManager.\n",
        "\n",
        "    Attributes:\n",
        "        spark: SparkSession instance for table operations.\n",
        "        logger: PipelineLogger instance for logging.\n",
        "        schema_manager: SchemaManager instance for schema operations.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.storage.table_service import TableService\n",
        "        >>> from pipeline_builder.compat import SparkSession\n",
        "        >>>\n",
        "        >>> service = TableService(spark)\n",
        "        >>> service.ensure_schema_exists(\"analytics\")\n",
        "        >>> exists = service.table_exists(\"analytics.events\")\n",
        "        >>> schema = service.get_table_schema(\"analytics.events\")\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the table service.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance for table operations.\n",
        "            logger: Optional PipelineLogger instance. If None, creates a\n",
        "                default logger.\n",
        "        \"\"\"\n",
        "        self.spark = spark\n",
        "        self.logger = logger or PipelineLogger()\n",
        "        self.schema_manager = SchemaManager(spark, logger)\n",
        "\n",
        "    def ensure_schema_exists(self, schema: str) -> None:\n",
        "        \"\"\"Ensure a schema exists, creating it if necessary.\n",
        "\n",
        "        Delegates to SchemaManager to create the schema if it doesn't exist.\n",
        "        Uses idempotent CREATE SCHEMA IF NOT EXISTS.\n",
        "\n",
        "        Args:\n",
        "            schema: Schema name to create or verify.\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If schema creation fails after all attempts.\n",
        "        \"\"\"\n",
        "        self.schema_manager.ensure_schema_exists(schema)\n",
        "\n",
        "    def table_exists(self, table_name: str) -> bool:\n",
        "        \"\"\"Check if a table exists.\n",
        "\n",
        "        Args:\n",
        "            table_name: Fully qualified table name (schema.table).\n",
        "\n",
        "        Returns:\n",
        "            True if table exists, False otherwise.\n",
        "        \"\"\"\n",
        "        return table_exists(self.spark, table_name)\n",
        "\n",
        "    def get_table_schema(\n",
        "        self,\n",
        "        table_name: str,\n",
        "        refresh: bool = False,\n",
        "    ) -> Optional[Any]:\n",
        "        \"\"\"Get the schema of an existing table.\n",
        "\n",
        "        Retrieves the StructType schema of an existing table, optionally\n",
        "        refreshing table metadata first to ensure accurate schema information.\n",
        "\n",
        "        Args:\n",
        "            table_name: Fully qualified table name (schema.table).\n",
        "            refresh: Whether to refresh table metadata before reading schema.\n",
        "                Defaults to False.\n",
        "\n",
        "        Returns:\n",
        "            StructType schema if table exists and schema is readable, None\n",
        "            otherwise. May return empty struct<> if catalog sync issues occur.\n",
        "        \"\"\"\n",
        "        return self.schema_manager.get_table_schema(table_name, refresh)\n",
        "\n",
        "    def validate_schema_match(\n",
        "        self,\n",
        "        table_name: str,\n",
        "        output_schema: Any,\n",
        "        mode: Any,\n",
        "        step_name: str,\n",
        "    ) -> tuple[bool, list[str]]:\n",
        "        \"\"\"Validate that output schema matches existing table schema.\n",
        "\n",
        "        Validates that the output DataFrame schema matches the existing table\n",
        "        schema. Required for INCREMENTAL and FULL_REFRESH modes to prevent\n",
        "        schema drift.\n",
        "\n",
        "        Args:\n",
        "            table_name: Fully qualified table name (schema.table).\n",
        "            output_schema: StructType schema of the output DataFrame.\n",
        "            mode: ExecutionMode enum value.\n",
        "            step_name: Name of the step being validated (for error messages).\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (matches: bool, differences: list[str]) where:\n",
        "            - matches: True if schemas match, False otherwise\n",
        "            - differences: List of human-readable mismatch descriptions\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If schema cannot be read or doesn't match (for\n",
        "                INCREMENTAL/FULL_REFRESH modes).\n",
        "        \"\"\"\n",
        "        return self.schema_manager.validate_schema_match(\n",
        "            table_name, output_schema, mode, step_name\n",
        "        )\n",
        "\n",
        "    def drop_table_if_exists(self, table_name: str) -> None:\n",
        "        \"\"\"Drop a table if it exists.\n",
        "\n",
        "        Safely drops a table, handling cases where the table doesn't exist.\n",
        "        Errors are logged but not raised.\n",
        "\n",
        "        Args:\n",
        "            table_name: Fully qualified table name (schema.table).\n",
        "\n",
        "        Note:\n",
        "            Uses DROP TABLE IF EXISTS for idempotent operation. Errors are\n",
        "            logged at debug level but not raised.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.table_exists(table_name):\n",
        "                self.spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
        "        except Exception as e:\n",
        "            self.logger.debug(f\"Could not drop table {table_name}: {e}\")\n",
        "\n",
        "    def refresh_table(self, table_name: str) -> None:\n",
        "        \"\"\"Refresh table metadata.\n",
        "\n",
        "        Refreshes Spark catalog metadata for a table, ensuring subsequent\n",
        "        operations see the latest schema and data.\n",
        "\n",
        "        Args:\n",
        "            table_name: Fully qualified table name (schema.table).\n",
        "\n",
        "        Note:\n",
        "            Uses REFRESH TABLE SQL command. Errors are logged at debug level\n",
        "            but not raised, as some table types may not support refresh.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.spark.sql(f\"REFRESH TABLE {table_name}\")\n",
        "        except Exception as refresh_error:\n",
        "            # Refresh might fail for some table types - log but continue\n",
        "            self.logger.debug(f\"Could not refresh table {table_name}: {refresh_error}\")\n",
        "\n",
        "    def fqn(self, schema: str, table: str) -> str:\n",
        "        \"\"\"Create a fully qualified table name.\n",
        "\n",
        "        Combines schema and table names into a fully qualified table name\n",
        "        (schema.table).\n",
        "\n",
        "        Args:\n",
        "            schema: Schema name.\n",
        "            table: Table name.\n",
        "\n",
        "        Returns:\n",
        "            Fully qualified table name in format \"schema.table\".\n",
        "        \"\"\"\n",
        "        return fqn(schema, table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.pipeline.debug_session (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.models, pipeline_builder.pipeline.models, pipeline_builder.pipeline.runner, pipeline_builder_base.models\n",
        "\n",
        "\"\"\"Pipeline debug session for interactive stepwise execution.\n",
        "\n",
        "This module provides a PipelineDebugSession class that simplifies interactive\n",
        "debugging and iterative refinement of pipeline steps in notebook environments.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Dict, Optional\n",
        "# from .models import PipelineConfig  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..models import BronzeStep, GoldStep, SilverStep  # Removed: defined in notebook cells above\n",
        "# from .models import PipelineMode, PipelineReport  # Removed: defined in notebook cells above\n",
        "# from .runner import SimplePipelineRunner  # Removed: defined in notebook cells above\n",
        "\n",
        "class PipelineDebugSession:\n",
        "    \"\"\"Interactive debug session for stepwise pipeline execution.\n",
        "\n",
        "    Provides a convenient interface for running individual steps, overriding\n",
        "    parameters, and iteratively refining pipeline logic without re-running\n",
        "    the entire pipeline.\n",
        "\n",
        "    Attributes:\n",
        "        runner: SimplePipelineRunner instance for execution.\n",
        "        steps: List of all pipeline steps.\n",
        "        mode: Current execution mode.\n",
        "        context: Execution context dictionary mapping step names to DataFrames.\n",
        "        step_params: Dictionary mapping step names to parameter dictionaries.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.pipeline.debug_session import PipelineDebugSession\n",
        "        >>> from pipeline_builder_base.models import PipelineConfig\n",
        "        >>>\n",
        "        >>> # Create session\n",
        "        >>> config = PipelineConfig.create_default(schema=\"my_schema\")\n",
        "        >>> session = PipelineDebugSession(spark, config, steps=[bronze, silver, gold])\n",
        "        >>>\n",
        "        >>> # Run until a specific step\n",
        "        >>> report, context = session.run_until(\"clean_events\")\n",
        "        >>>\n",
        "        >>> # Run a single step\n",
        "        >>> report, context = session.run_step(\"clean_events\")\n",
        "        >>>\n",
        "        >>> # Rerun with parameter override\n",
        "        >>> session.step_params[\"clean_events\"] = {\"threshold\": 0.9}\n",
        "        >>> report, context = session.rerun_step(\"clean_events\")\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: Any,  # SparkSession\n",
        "        config: PipelineConfig,\n",
        "        steps: list[BronzeStep | SilverStep | GoldStep],\n",
        "        mode: PipelineMode = PipelineMode.INITIAL,\n",
        "        bronze_sources: Optional[Dict[str, DataFrame]] = None,\n",
        "        logger: Optional[Any] = None,  # PipelineLogger\n",
        "        functions: Optional[Any] = None,  # FunctionsProtocol\n",
        "    ):\n",
        "        \"\"\"Initialize the debug session.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance.\n",
        "            config: Pipeline configuration.\n",
        "            steps: List of pipeline steps (Bronze, Silver, Gold).\n",
        "            mode: Initial execution mode. Defaults to INITIAL.\n",
        "            bronze_sources: Optional bronze source data dictionary.\n",
        "            logger: Optional logger instance.\n",
        "            functions: Optional functions protocol instance.\n",
        "        \"\"\"\n",
        "        # Group steps by type for runner\n",
        "        bronze_steps: Dict[str, BronzeStep] = {}\n",
        "        silver_steps: Dict[str, SilverStep] = {}\n",
        "        gold_steps: Dict[str, GoldStep] = {}\n",
        "\n",
        "        for step in steps:\n",
        "            if step.step_type.value == \"bronze\":\n",
        "                bronze_steps[step.name] = step  # type: ignore[assignment]\n",
        "            elif step.step_type.value == \"silver\":\n",
        "                silver_steps[step.name] = step  # type: ignore[assignment]\n",
        "            elif step.step_type.value == \"gold\":\n",
        "                gold_steps[step.name] = step  # type: ignore[assignment]\n",
        "\n",
        "        self.runner = SimplePipelineRunner(\n",
        "            spark=spark,\n",
        "            config=config,\n",
        "            bronze_steps=bronze_steps,\n",
        "            silver_steps=silver_steps,\n",
        "            gold_steps=gold_steps,\n",
        "            logger=logger,\n",
        "            functions=functions,\n",
        "        )\n",
        "        self.steps = steps\n",
        "        self.mode = mode\n",
        "        self.context: Dict[str, DataFrame] = {}\n",
        "        self.step_params: Dict[str, Dict[str, Any]] = {}\n",
        "\n",
        "        # Initialize context with bronze sources if provided\n",
        "        if bronze_sources:\n",
        "            self.context.update(bronze_sources)\n",
        "\n",
        "    def run_until(\n",
        "        self,\n",
        "        step_name: str,\n",
        "        write_outputs: bool = True,\n",
        "    ) -> tuple[PipelineReport, Dict[str, DataFrame]]:\n",
        "        \"\"\"Run pipeline until a specific step completes (inclusive).\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step to stop after (inclusive).\n",
        "            write_outputs: If True, write outputs to tables. If False, skip writes.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (PipelineReport, context dictionary). Context is updated\n",
        "            with all step outputs and stored in self.context.\n",
        "\n",
        "        Example:\n",
        "            >>> report, context = session.run_until(\"clean_events\")\n",
        "            >>> # Context now contains outputs up to clean_events\n",
        "        \"\"\"\n",
        "        # Extract bronze sources from self.context for bronze steps\n",
        "        bronze_sources = {}\n",
        "        for step in self.steps:\n",
        "            if step.step_type.value == \"bronze\" and step.name in self.context:\n",
        "                bronze_sources[step.name] = self.context[step.name]\n",
        "\n",
        "        report, context = self.runner.run_until(\n",
        "            step_name=step_name,\n",
        "            steps=self.steps,\n",
        "            mode=self.mode,\n",
        "            bronze_sources=bronze_sources if bronze_sources else None,\n",
        "            step_params=self.step_params,\n",
        "            write_outputs=write_outputs,\n",
        "        )\n",
        "        self.context = context\n",
        "        return report, context\n",
        "\n",
        "    def run_step(\n",
        "        self,\n",
        "        step_name: str,\n",
        "        write_outputs: bool = True,\n",
        "    ) -> tuple[PipelineReport, Dict[str, DataFrame]]:\n",
        "        \"\"\"Run a single step, loading dependencies from context or tables.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step to execute.\n",
        "            write_outputs: If True, write outputs to tables. If False, skip writes.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (PipelineReport, context dictionary). Context is updated\n",
        "            with the step output and stored in self.context.\n",
        "\n",
        "        Example:\n",
        "            >>> report, context = session.run_step(\"clean_events\")\n",
        "            >>> # Step executed, context updated\n",
        "        \"\"\"\n",
        "        report, context = self.runner.run_step(\n",
        "            step_name=step_name,\n",
        "            steps=self.steps,\n",
        "            mode=self.mode,\n",
        "            context=self.context,\n",
        "            step_params=self.step_params,\n",
        "            write_outputs=write_outputs,\n",
        "        )\n",
        "        self.context = context\n",
        "        return report, context\n",
        "\n",
        "    def rerun_step(\n",
        "        self,\n",
        "        step_name: str,\n",
        "        invalidate_downstream: bool = True,\n",
        "        write_outputs: bool = True,\n",
        "    ) -> tuple[PipelineReport, Dict[str, DataFrame]]:\n",
        "        \"\"\"Rerun a step with current parameter overrides.\n",
        "\n",
        "        Uses self.step_params for parameter overrides. To change parameters,\n",
        "        modify self.step_params before calling this method.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step to rerun.\n",
        "            invalidate_downstream: If True, remove downstream outputs from context.\n",
        "            write_outputs: If True, write outputs to tables. If False, skip writes.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (PipelineReport, context dictionary). Context is updated\n",
        "            with the step output and stored in self.context.\n",
        "\n",
        "        Example:\n",
        "            >>> # Set parameter override\n",
        "            >>> session.step_params[\"clean_events\"] = {\"threshold\": 0.9}\n",
        "            >>> # Rerun with override\n",
        "            >>> report, context = session.rerun_step(\"clean_events\")\n",
        "        \"\"\"\n",
        "        report, context = self.runner.rerun_step(\n",
        "            step_name=step_name,\n",
        "            steps=self.steps,\n",
        "            mode=self.mode,\n",
        "            context=self.context,\n",
        "            step_params=self.step_params,\n",
        "            invalidate_downstream=invalidate_downstream,\n",
        "            write_outputs=write_outputs,\n",
        "        )\n",
        "        self.context = context\n",
        "        return report, context\n",
        "\n",
        "    def set_step_params(self, step_name: str, params: Dict[str, Any]) -> None:\n",
        "        \"\"\"Set parameters for a step.\n",
        "\n",
        "        Convenience method to update step_params.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step.\n",
        "            params: Parameter dictionary to pass to the step's transform function.\n",
        "\n",
        "        Example:\n",
        "            >>> session.set_step_params(\"clean_events\", {\"threshold\": 0.9})\n",
        "        \"\"\"\n",
        "        self.step_params[step_name] = params\n",
        "\n",
        "    def clear_step_params(self, step_name: Optional[str] = None) -> None:\n",
        "        \"\"\"Clear parameter overrides for a step or all steps.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step. If None, clears all step params.\n",
        "\n",
        "        Example:\n",
        "            >>> session.clear_step_params(\"clean_events\")  # Clear one step\n",
        "            >>> session.clear_step_params()  # Clear all steps\n",
        "        \"\"\"\n",
        "        if step_name is None:\n",
        "            self.step_params.clear()\n",
        "        else:\n",
        "            self.step_params.pop(step_name, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder_base.reporting (pipeline_builder_base)\n",
        "#\n",
        "# Dependencies: models.execution, performance, pipeline_builder_base.models, pipeline_builder_base.validation, validation.utils\n",
        "\n",
        "\"\"\"\n",
        "Reporting utilities for the pipeline framework.\n",
        "\n",
        "This module contains functions for creating reports, statistics, and summaries\n",
        "for pipeline execution.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import Optional, TypedDict\n",
        "\n",
        "# from .models import StageStats  # Removed: defined in notebook cells above\n",
        "# from .validation import safe_divide  # Removed: defined in notebook cells above\n",
        "\n",
        "# ============================================================================\n",
        "# TypedDict Definitions\n",
        "# ============================================================================\n",
        "\n",
        "class ValidationReport(TypedDict):\n",
        "    \"\"\"Validation report structure.\"\"\"\n",
        "\n",
        "    stage: Optional[str]\n",
        "    step: Optional[str]\n",
        "    total_rows: int\n",
        "    valid_rows: int\n",
        "    invalid_rows: int\n",
        "    validation_rate: float\n",
        "    duration_secs: float\n",
        "    start_at: datetime\n",
        "    end_at: datetime\n",
        "\n",
        "class TransformReport(TypedDict):\n",
        "    \"\"\"Transform operation report structure.\"\"\"\n",
        "\n",
        "    input_rows: int\n",
        "    output_rows: int\n",
        "    duration_secs: float\n",
        "    skipped: bool\n",
        "    start_at: datetime\n",
        "    end_at: datetime\n",
        "\n",
        "class WriteReport(TypedDict):\n",
        "    \"\"\"Write operation report structure.\"\"\"\n",
        "\n",
        "    mode: str\n",
        "    rows_written: int\n",
        "    duration_secs: float\n",
        "    table_fqn: str\n",
        "    skipped: bool\n",
        "    start_at: datetime\n",
        "    end_at: datetime\n",
        "\n",
        "class ExecutionSummary(TypedDict):\n",
        "    \"\"\"Execution summary nested structure.\"\"\"\n",
        "\n",
        "    total_steps: int\n",
        "    successful_steps: int\n",
        "    failed_steps: int\n",
        "    success_rate: float\n",
        "    failure_rate: float\n",
        "\n",
        "class PerformanceMetrics(TypedDict):\n",
        "    \"\"\"Performance metrics nested structure.\"\"\"\n",
        "\n",
        "    total_duration_secs: float\n",
        "    formatted_duration: str\n",
        "    avg_validation_rate: float\n",
        "\n",
        "class DataMetrics(TypedDict):\n",
        "    \"\"\"Data metrics nested structure.\"\"\"\n",
        "\n",
        "    total_rows_processed: int\n",
        "    total_rows_written: int\n",
        "    processing_efficiency: float\n",
        "\n",
        "class SummaryReport(TypedDict):\n",
        "    \"\"\"Complete summary report structure.\"\"\"\n",
        "\n",
        "    execution_summary: ExecutionSummary\n",
        "    performance_metrics: PerformanceMetrics\n",
        "    data_metrics: DataMetrics\n",
        "\n",
        "def create_validation_dict(\n",
        "    stats: Optional[StageStats], *, start_at: datetime, end_at: datetime\n",
        ") -> ValidationReport:\n",
        "    \"\"\"\n",
        "    Create a validation report dictionary from stage stats.\n",
        "\n",
        "    Args:\n",
        "        stats: Stage statistics\n",
        "        start_at: Start time\n",
        "        end_at: End time\n",
        "\n",
        "    Returns:\n",
        "        Validation report dictionary\n",
        "    \"\"\"\n",
        "    if stats is None:\n",
        "        return {\n",
        "            \"stage\": None,\n",
        "            \"step\": None,\n",
        "            \"total_rows\": 0,\n",
        "            \"valid_rows\": 0,\n",
        "            \"invalid_rows\": 0,\n",
        "            \"validation_rate\": 0.0,\n",
        "            \"duration_secs\": (end_at - start_at).total_seconds(),\n",
        "            \"start_at\": start_at,\n",
        "            \"end_at\": end_at,\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"stage\": stats.stage,\n",
        "        \"step\": stats.step,\n",
        "        \"total_rows\": stats.total_rows,\n",
        "        \"valid_rows\": stats.valid_rows,\n",
        "        \"invalid_rows\": stats.invalid_rows,\n",
        "        \"validation_rate\": stats.validation_rate,\n",
        "        \"duration_secs\": stats.duration_secs,\n",
        "        \"start_at\": start_at,\n",
        "        \"end_at\": end_at,\n",
        "    }\n",
        "\n",
        "def create_transform_dict(\n",
        "    *,\n",
        "    input_rows: int,\n",
        "    output_rows: int,\n",
        "    start_at: datetime,\n",
        "    end_at: datetime,\n",
        "    skipped: bool = False,\n",
        ") -> TransformReport:\n",
        "    \"\"\"\n",
        "    Create a transform report dictionary.\n",
        "\n",
        "    Args:\n",
        "        input_rows: Number of input rows\n",
        "        output_rows: Number of output rows\n",
        "        start_at: Start time\n",
        "        end_at: End time\n",
        "        skipped: Whether the transform was skipped\n",
        "\n",
        "    Returns:\n",
        "        Transform report dictionary\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"input_rows\": input_rows,\n",
        "        \"output_rows\": output_rows,\n",
        "        \"duration_secs\": (end_at - start_at).total_seconds(),\n",
        "        \"skipped\": skipped,\n",
        "        \"start_at\": start_at,\n",
        "        \"end_at\": end_at,\n",
        "    }\n",
        "\n",
        "def create_write_dict(\n",
        "    *,\n",
        "    mode: str,\n",
        "    rows_written: int,\n",
        "    table_fqn: str,\n",
        "    start_at: datetime,\n",
        "    end_at: datetime,\n",
        "    skipped: bool = False,\n",
        ") -> WriteReport:\n",
        "    \"\"\"\n",
        "    Create a write report dictionary.\n",
        "\n",
        "    Args:\n",
        "        mode: Write mode\n",
        "        rows_written: Number of rows written\n",
        "        table_fqn: Fully qualified table name\n",
        "        start_at: Start time\n",
        "        end_at: End time\n",
        "        skipped: Whether the write was skipped\n",
        "\n",
        "    Returns:\n",
        "        Write report dictionary\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"mode\": mode,\n",
        "        \"rows_written\": rows_written,\n",
        "        \"duration_secs\": (end_at - start_at).total_seconds(),\n",
        "        \"table_fqn\": table_fqn,\n",
        "        \"skipped\": skipped,\n",
        "        \"start_at\": start_at,\n",
        "        \"end_at\": end_at,\n",
        "    }\n",
        "\n",
        "def format_duration(seconds: float) -> str:\n",
        "    \"\"\"\n",
        "    Format duration in seconds to human-readable string.\n",
        "\n",
        "    Args:\n",
        "        seconds: Duration in seconds\n",
        "\n",
        "    Returns:\n",
        "        Formatted duration string\n",
        "    \"\"\"\n",
        "    if seconds < 60:\n",
        "        return f\"{seconds:.2f}s\"\n",
        "    elif seconds < 3600:\n",
        "        minutes = int(seconds // 60)\n",
        "        secs = seconds % 60\n",
        "        return f\"{minutes}m {secs:.2f}s\"\n",
        "    else:\n",
        "        hours = int(seconds // 3600)\n",
        "        minutes = int((seconds % 3600) // 60)\n",
        "        secs = seconds % 60\n",
        "        return f\"{hours}h {minutes}m {secs:.2f}s\"\n",
        "\n",
        "def create_summary_report(\n",
        "    *,\n",
        "    total_steps: int,\n",
        "    successful_steps: int,\n",
        "    failed_steps: int,\n",
        "    total_duration_secs: float,\n",
        "    total_rows_processed: int,\n",
        "    total_rows_written: int,\n",
        "    avg_validation_rate: float,\n",
        ") -> SummaryReport:\n",
        "    \"\"\"\n",
        "    Create a complete summary report.\n",
        "\n",
        "    Args:\n",
        "        total_steps: Total number of steps\n",
        "        successful_steps: Number of successful steps\n",
        "        failed_steps: Number of failed steps\n",
        "        total_duration_secs: Total duration in seconds\n",
        "        total_rows_processed: Total rows processed\n",
        "        total_rows_written: Total rows written\n",
        "        avg_validation_rate: Average validation rate\n",
        "\n",
        "    Returns:\n",
        "        Complete summary report\n",
        "    \"\"\"\n",
        "    success_rate = safe_divide(successful_steps, total_steps, 0.0) * 100\n",
        "    failure_rate = 100.0 - success_rate\n",
        "    processing_efficiency = (\n",
        "        safe_divide(total_rows_written, total_rows_processed, 0.0) * 100\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"execution_summary\": {\n",
        "            \"total_steps\": total_steps,\n",
        "            \"successful_steps\": successful_steps,\n",
        "            \"failed_steps\": failed_steps,\n",
        "            \"success_rate\": success_rate,\n",
        "            \"failure_rate\": failure_rate,\n",
        "        },\n",
        "        \"performance_metrics\": {\n",
        "            \"total_duration_secs\": total_duration_secs,\n",
        "            \"formatted_duration\": format_duration(total_duration_secs),\n",
        "            \"avg_validation_rate\": avg_validation_rate,\n",
        "        },\n",
        "        \"data_metrics\": {\n",
        "            \"total_rows_processed\": total_rows_processed,\n",
        "            \"total_rows_written\": total_rows_written,\n",
        "            \"processing_efficiency\": processing_efficiency,\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.storage.write_service (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.storage.table_service, pipeline_builder.table_operations, pipeline_builder_base.errors, pipeline_builder_base.logging, pipeline_builder_base.models\n",
        "\n",
        "\"\"\"Write service for handling all write operations.\n",
        "\n",
        "This module provides a service for writing DataFrames to tables with proper\n",
        "handling of write modes, schema overrides, and Delta Lake operations. The\n",
        "WriteService centralizes all write logic, making it testable and maintainable.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Optional\n",
        "# from .errors import ExecutionError  # Removed: defined in notebook cells above\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .models import ExecutionMode  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..table_operations import (  # Removed: defined in notebook cells above\n",
        "    # create_dataframe_writer,\n",
        "# )\n",
        "# from .table_service import TableService  # Removed: defined in notebook cells above\n",
        "\n",
        "class WriteService:\n",
        "    \"\"\"Service for writing DataFrames to tables.\n",
        "\n",
        "    Handles write modes, schema validation, schema overrides, and Delta Lake\n",
        "    operations. Centralizes all write logic for Silver and Gold steps.\n",
        "\n",
        "    Attributes:\n",
        "        spark: SparkSession instance for DataFrame operations.\n",
        "        table_service: TableService instance for table operations.\n",
        "        logger: PipelineLogger instance for logging.\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.storage.write_service import WriteService\n",
        "        >>> from pipeline_builder.storage.table_service import TableService\n",
        "        >>> from pipeline_builder_base.models import ExecutionMode\n",
        "        >>>\n",
        "        >>> table_service = TableService(spark)\n",
        "        >>> write_service = WriteService(spark, table_service)\n",
        "        >>> rows = write_service.write_step_output(\n",
        "        ...     df=output_df,\n",
        "        ...     step=silver_step,\n",
        "        ...     schema=\"analytics\",\n",
        "        ...     table_name=\"clean_events\",\n",
        "        ...     mode=ExecutionMode.INITIAL\n",
        "        ... )\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        table_service: TableService,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the write service.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance for DataFrame operations.\n",
        "            table_service: TableService instance for table operations.\n",
        "            logger: Optional PipelineLogger instance. If None, creates a\n",
        "                default logger.\n",
        "        \"\"\"\n",
        "        self.spark = spark\n",
        "        self.table_service = table_service\n",
        "        self.logger = logger or PipelineLogger()\n",
        "\n",
        "    def write_step_output(\n",
        "        self,\n",
        "        df: DataFrame,\n",
        "        step: Any,\n",
        "        schema: str,\n",
        "        table_name: str,\n",
        "        mode: ExecutionMode,\n",
        "    ) -> int:\n",
        "        \"\"\"Write step output to a table.\n",
        "\n",
        "        Writes a DataFrame to a Delta Lake table with proper handling of write\n",
        "        modes, schema validation, and schema overrides. Handles all the\n",
        "        complexity of Delta Lake writes including overwrite semantics.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to write.\n",
        "            step: Step object (SilverStep or GoldStep) containing step\n",
        "                configuration.\n",
        "            schema: Schema name for the target table.\n",
        "            table_name: Table name (without schema).\n",
        "            mode: ExecutionMode enum value (INITIAL, INCREMENTAL, FULL_REFRESH,\n",
        "                VALIDATION_ONLY).\n",
        "\n",
        "        Returns:\n",
        "            Number of rows written to the table.\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If write fails, schema validation fails, or schema\n",
        "                override application fails.\n",
        "\n",
        "        Note:\n",
        "            - Ensures schema exists before writing\n",
        "            - Validates schema match for INCREMENTAL and FULL_REFRESH modes\n",
        "            - Drops table in INITIAL mode for clean start\n",
        "            - Applies schema override if provided in step\n",
        "            - Handles Delta Lake overwrite semantics correctly\n",
        "        \"\"\"\n",
        "        output_table = self.table_service.fqn(schema, table_name)\n",
        "\n",
        "        # Ensure schema exists\n",
        "        self.table_service.ensure_schema_exists(schema)\n",
        "\n",
        "        # Determine write mode\n",
        "        write_mode_str = self._determine_write_mode(step, mode)\n",
        "\n",
        "        # Validate schema if needed\n",
        "        if mode in (ExecutionMode.INCREMENTAL, ExecutionMode.FULL_REFRESH):\n",
        "            self._validate_schema_for_mode(df, output_table, mode, step.name)\n",
        "\n",
        "        # NOTE: We intentionally do NOT drop existing tables in INITIAL mode.\n",
        "        # Dropping is destructive and can leave users with missing tables if a run fails\n",
        "        # after the drop but before the overwrite commit. Delta overwrite is transactional.\n",
        "\n",
        "        # Handle schema override if provided\n",
        "        schema_override = getattr(step, \"schema_override\", None)\n",
        "        if schema_override is not None:\n",
        "            df = self._apply_schema_override(\n",
        "                df, schema_override, step, output_table, write_mode_str\n",
        "            )\n",
        "\n",
        "        # Handle write based on step type and mode\n",
        "        rows_written = self._execute_write(df, step, output_table, write_mode_str, mode)\n",
        "\n",
        "        return rows_written\n",
        "\n",
        "    def _determine_write_mode(\n",
        "        self,\n",
        "        step: Any,\n",
        "        mode: ExecutionMode,\n",
        "    ) -> str:\n",
        "        \"\"\"Determine the write mode for a step.\n",
        "\n",
        "        Determines the appropriate write mode based on step type and execution\n",
        "        mode. Gold steps always use overwrite, Silver steps use append for\n",
        "        incremental mode and overwrite otherwise.\n",
        "\n",
        "        Args:\n",
        "            step: Step object (SilverStep or GoldStep).\n",
        "            mode: ExecutionMode enum value.\n",
        "\n",
        "        Returns:\n",
        "            Write mode string (\"overwrite\" or \"append\").\n",
        "        \"\"\"\n",
        "        # Gold steps always use overwrite to prevent duplicate aggregates\n",
        "        if step.__class__.__name__ == \"GoldStep\":\n",
        "            return \"overwrite\"\n",
        "        elif mode == ExecutionMode.INCREMENTAL:\n",
        "            return \"append\"\n",
        "        else:  # INITIAL or FULL_REFRESH\n",
        "            return \"overwrite\"\n",
        "\n",
        "    def _validate_schema_for_mode(\n",
        "        self,\n",
        "        df: DataFrame,\n",
        "        table_name: str,\n",
        "        mode: ExecutionMode,\n",
        "        step_name: str,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Validate schema for INCREMENTAL and FULL_REFRESH modes.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to validate\n",
        "            table_name: Fully qualified table name\n",
        "            mode: Execution mode\n",
        "            step_name: Name of the step\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If schema validation fails\n",
        "        \"\"\"\n",
        "        if not self.table_service.table_exists(table_name):\n",
        "            return\n",
        "\n",
        "        # Refresh table metadata\n",
        "        self.table_service.refresh_table(table_name)\n",
        "\n",
        "        # Validate schema match\n",
        "        output_schema = df.schema\n",
        "        self.table_service.validate_schema_match(\n",
        "            table_name, output_schema, mode, step_name\n",
        "        )\n",
        "\n",
        "    def _apply_schema_override(\n",
        "        self,\n",
        "        df: DataFrame,\n",
        "        schema_override: Any,\n",
        "        step: Any,\n",
        "        output_table: str,\n",
        "        write_mode_str: str,\n",
        "    ) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Apply schema override to DataFrame.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to apply schema to\n",
        "            schema_override: Schema to apply\n",
        "            step: Step object\n",
        "            output_table: Fully qualified table name\n",
        "            write_mode_str: Write mode string\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with schema override applied\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Cast DataFrame to the override schema\n",
        "            df = self.spark.createDataFrame(df.rdd, schema_override)  # type: ignore[attr-defined]\n",
        "        except Exception as e:\n",
        "            raise ExecutionError(\n",
        "                f\"Failed to apply schema_override to step '{step.name}': {e}\",\n",
        "                context={\n",
        "                    \"step_name\": step.name,\n",
        "                    \"table\": output_table,\n",
        "                    \"schema_override\": str(schema_override),\n",
        "                },\n",
        "                suggestions=[\n",
        "                    \"Verify that the schema_override matches the DataFrame structure\",\n",
        "                    \"Check that all required columns are present in the DataFrame\",\n",
        "                    \"Ensure data types are compatible\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _execute_write(\n",
        "        self,\n",
        "        df: DataFrame,\n",
        "        step: Any,\n",
        "        output_table: str,\n",
        "        write_mode_str: str,\n",
        "        mode: ExecutionMode,\n",
        "    ) -> int:\n",
        "        \"\"\"\n",
        "        Execute the actual write operation.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to write\n",
        "            step: Step object\n",
        "            output_table: Fully qualified table name\n",
        "            write_mode_str: Write mode string\n",
        "            mode: Execution mode\n",
        "\n",
        "        Returns:\n",
        "            Number of rows written\n",
        "        \"\"\"\n",
        "        # For overwrite mode with Delta tables, ensure table is dropped before writing\n",
        "        # This prevents \"Table does not support truncate in batch mode\" errors\n",
        "        if write_mode_str == \"overwrite\":\n",
        "            # from ..table_operations import prepare_delta_overwrite  # Removed: defined in notebook cells above\n",
        "\n",
        "            prepare_delta_overwrite(self.spark, output_table)\n",
        "\n",
        "        writer = create_dataframe_writer(\n",
        "            df, self.spark, write_mode_str, table_name=output_table\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            writer.saveAsTable(output_table)\n",
        "            rows_written = df.count()\n",
        "            return rows_written\n",
        "        except Exception as e:\n",
        "            # If write fails with truncate error, try dropping table and writing again\n",
        "            error_msg = str(e).lower()\n",
        "            if \"truncate\" in error_msg and \"batch mode\" in error_msg:\n",
        "                self.logger.warning(\n",
        "                    f\"Write failed with truncate error for Delta table, \"\n",
        "                    f\"dropping table and retrying: {e}\"\n",
        "                )\n",
        "                try:\n",
        "                    # Force drop the table (without CASCADE - not supported in all Spark versions)\n",
        "                    self.spark.sql(f\"DROP TABLE IF EXISTS {output_table}\")\n",
        "                    # Small delay to ensure catalog is updated\n",
        "                    import time\n",
        "\n",
        "                    time.sleep(0.1)\n",
        "                    # Retry the write - table should not exist now\n",
        "                    writer = create_dataframe_writer(\n",
        "                        df, self.spark, write_mode_str, table_name=output_table\n",
        "                    )\n",
        "                    writer.saveAsTable(output_table)\n",
        "                    rows_written = df.count()\n",
        "                    self.logger.info(\n",
        "                        f\"Successfully wrote {rows_written} rows after retry\"\n",
        "                    )\n",
        "                    return rows_written\n",
        "                except Exception as retry_error:\n",
        "                    raise ExecutionError(\n",
        "                        f\"Failed to write table '{output_table}' even after retry: {retry_error}\",\n",
        "                        context={\n",
        "                            \"step_name\": step.name,\n",
        "                            \"table\": output_table,\n",
        "                            \"mode\": mode.value,\n",
        "                            \"write_mode\": write_mode_str,\n",
        "                            \"original_error\": str(e),\n",
        "                        },\n",
        "                    ) from retry_error\n",
        "\n",
        "            raise ExecutionError(\n",
        "                f\"Failed to write table '{output_table}': {e}\",\n",
        "                context={\n",
        "                    \"step_name\": step.name,\n",
        "                    \"table\": output_table,\n",
        "                    \"mode\": mode.value,\n",
        "                    \"write_mode\": write_mode_str,\n",
        "                },\n",
        "            ) from e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.execution (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.functions, pipeline_builder.models, pipeline_builder.step_executors, pipeline_builder.storage, pipeline_builder.table_operations, pipeline_builder.validation.execution_validator, pipeline_builder_base.dependencies, pipeline_builder_base.errors, pipeline_builder_base.logging, pipeline_builder_base.models\n",
        "\n",
        "# mypy: ignore-errors\n",
        "\"\"\"Production-ready execution system for pipeline execution.\n",
        "\n",
        "This module provides a robust execution engine that handles pipeline execution\n",
        "with comprehensive error handling, step-by-step processing, and detailed reporting.\n",
        "The engine uses a service-oriented architecture with dedicated step executors,\n",
        "validation services, and storage services for clean separation of concerns.\n",
        "\n",
        "Key Features:\n",
        "    - Step-by-Step Execution: Process pipeline steps individually with detailed tracking\n",
        "    - Comprehensive Error Handling: Detailed error messages with context and suggestions\n",
        "    - Multiple Execution Modes: Initial load, incremental, full refresh, and validation-only\n",
        "    - Dependency-Aware Execution: Automatically analyzes step dependencies and executes\n",
        "      in correct order\n",
        "    - Detailed Reporting: Comprehensive execution reports with metrics and timing\n",
        "    - Validation Integration: Built-in validation with configurable thresholds\n",
        "    - Service-Oriented Architecture: Clean separation with step executors, validators,\n",
        "      and storage services\n",
        "\n",
        "Execution Modes:\n",
        "    INITIAL: First-time pipeline execution with full data processing. Allows schema\n",
        "        changes and creates tables from scratch.\n",
        "    INCREMENTAL: Process only new data based on watermark columns. Requires exact\n",
        "        schema matching with existing tables.\n",
        "    FULL_REFRESH: Reprocess all data, overwriting existing results. Requires exact\n",
        "        schema matching.\n",
        "    VALIDATION_ONLY: Validate data without writing results. Useful for testing\n",
        "        validation rules.\n",
        "\n",
        "Dependency Analysis:\n",
        "    The engine automatically analyzes step dependencies and executes steps\n",
        "    sequentially in the correct order using topological sort. Steps execute\n",
        "    one at a time in dependency order to respect dependency constraints.\n",
        "\n",
        "Service Architecture:\n",
        "    The execution engine delegates to specialized services:\n",
        "    - Step Executors: BronzeStepExecutor, SilverStepExecutor, GoldStepExecutor\n",
        "        handle step-specific execution logic\n",
        "    - ExecutionValidator: Validates data according to step rules\n",
        "    - TableService: Manages table operations and schema management\n",
        "    - WriteService: Handles all write operations to Delta Lake\n",
        "\n",
        "Example:\n",
        "    Basic usage with a single step:\n",
        "\n",
        "    >>> from pipeline_builder.execution import ExecutionEngine\n",
        "    >>> from pipeline_builder_base.models import ExecutionMode, PipelineConfig\n",
        "    >>> from pipeline_builder.models import BronzeStep\n",
        "    >>> from pipeline_builder.functions import get_default_functions\n",
        "    >>> F = get_default_functions()\n",
        "    >>>\n",
        "    >>> # Create execution engine\n",
        "    >>> config = PipelineConfig.create_default(schema=\"my_schema\")\n",
        "    >>> engine = ExecutionEngine(spark, config)\n",
        "    >>>\n",
        "    >>> # Execute a single step\n",
        "    >>> result = engine.execute_step(\n",
        "    ...     step=BronzeStep(name=\"events\", rules={\"id\": [F.col(\"id\").isNotNull()]}),\n",
        "    ...     context={\"events\": source_df},\n",
        "    ...     mode=ExecutionMode.INITIAL\n",
        "    ... )\n",
        "    >>> print(f\"Step completed: {result.status}, rows: {result.rows_processed}\")\n",
        "\n",
        "    Full pipeline execution:\n",
        "\n",
        "    >>> result = engine.execute_pipeline(\n",
        "    ...     steps=[bronze_step, silver_step, gold_step],\n",
        "    ...     mode=ExecutionMode.INITIAL,\n",
        "    ...     context={\"events\": source_df}\n",
        "    ... )\n",
        "    >>> print(f\"Pipeline completed: {result.status}\")\n",
        "    >>> print(f\"Steps executed: {len(result.steps) if result.steps else 0}\")\n",
        "\n",
        "Note:\n",
        "    This module depends on:\n",
        "    - compat: Spark compatibility layer\n",
        "    - dependencies: Dependency analysis\n",
        "    - errors: Error handling\n",
        "    - functions: PySpark function protocols\n",
        "    - logging: Pipeline logging\n",
        "    - models.pipeline: Pipeline configuration models\n",
        "    - models.steps: Step models\n",
        "    - table_operations: Table utility functions\n",
        "    - validation.data_validation: Data validation logic\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "import uuid\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "from typing import Any, Dict, Optional, Union, cast\n",
        "\n",
        "try:\n",
        "    import psutil\n",
        "\n",
        "    HAS_PSUTIL = True\n",
        "except ImportError:\n",
        "    HAS_PSUTIL = False\n",
        "    psutil = None  # type: ignore[assignment, unused-ignore]\n",
        "# from .dependencies import DependencyAnalyzer  # Removed: defined in notebook cells above\n",
        "# from .errors import ExecutionError  # Removed: defined in notebook cells above\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .models import (  # Removed: defined in notebook cells above\n",
        "    # ExecutionMode,\n",
        "    # PipelineConfig,\n",
        "# )\n",
        "\n",
        "# from .compat import DataFrame, F, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from .functions import FunctionsProtocol  # Removed: defined in notebook cells above\n",
        "# from .models import BronzeStep, GoldStep, SilverStep  # Removed: defined in notebook cells above\n",
        "# from .step_executors import (  # Removed: defined in notebook cells above\n",
        "    # BronzeStepExecutor,\n",
        "    # GoldStepExecutor,\n",
        "    # SilverStepExecutor,\n",
        "# )\n",
        "# from .storage import TableService, WriteService  # Removed: defined in notebook cells above\n",
        "# from .table_operations import fqn, table_exists, table_schema_is_empty  # Removed: defined in notebook cells above\n",
        "# from .validation.execution_validator import ExecutionValidator  # Removed: defined in notebook cells above\n",
        "\n",
        "# Handle optional Delta Lake dependency\n",
        "try:\n",
        "    from delta.tables import DeltaTable\n",
        "\n",
        "    HAS_DELTA = True\n",
        "except (ImportError, AttributeError, RuntimeError):\n",
        "    DeltaTable = None  # type: ignore[misc, assignment]\n",
        "    HAS_DELTA = False\n",
        "\n",
        "# Cache for Delta Lake availability per Spark session\n",
        "_delta_availability_cache_execution: Dict[str, bool] = {}\n",
        "\n",
        "def _is_delta_lake_available_execution(spark: SparkSession) -> bool:  # type: ignore[valid-type]\n",
        "    \"\"\"Check if Delta Lake is available and working in the Spark session.\n",
        "\n",
        "    This function checks Spark configuration and optionally tests Delta\n",
        "    functionality by attempting to write a test DataFrame. Results are cached\n",
        "    per Spark session for performance.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance to test for Delta Lake availability.\n",
        "\n",
        "    Returns:\n",
        "        True if Delta Lake is available and working, False otherwise.\n",
        "\n",
        "    Note:\n",
        "        The function checks:\n",
        "        1. If delta package is installed\n",
        "        2. Spark configuration for Delta extensions and catalog\n",
        "        3. Actual Delta write capability via test write operation\n",
        "\n",
        "        Results are cached per Spark session using the session's JVM ID.\n",
        "    \"\"\"\n",
        "    # Use Spark session's underlying SparkContext ID as cache key\n",
        "    try:\n",
        "        spark_id = (\n",
        "            str(id(spark._jsparkSession))\n",
        "            if hasattr(spark, \"_jsparkSession\")\n",
        "            else str(id(spark))\n",
        "        )\n",
        "    except Exception:\n",
        "        # Fallback: use Python id if JVM/session id unavailable\n",
        "        spark_id = str(id(spark))\n",
        "\n",
        "    # Check cache first\n",
        "    if spark_id in _delta_availability_cache_execution:\n",
        "        return _delta_availability_cache_execution[spark_id]\n",
        "\n",
        "    # If delta package is not installed, can't be available\n",
        "    if not HAS_DELTA:\n",
        "        _delta_availability_cache_execution[spark_id] = False\n",
        "        return False\n",
        "\n",
        "    # Check Spark configuration first (fast check)\n",
        "    try:\n",
        "        extensions = spark.conf.get(\"spark.sql.extensions\", \"\")  # type: ignore[attr-defined]\n",
        "        catalog = spark.conf.get(\"spark.sql.catalog.spark_catalog\", \"\")  # type: ignore[attr-defined]\n",
        "\n",
        "        # If both extensions and catalog are configured for Delta, assume it works\n",
        "        if (\n",
        "            extensions\n",
        "            and catalog\n",
        "            and \"DeltaSparkSessionExtension\" in extensions\n",
        "            and \"DeltaCatalog\" in catalog\n",
        "        ):\n",
        "            _delta_availability_cache_execution[spark_id] = True\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass  # Config check failed; proceed to lightweight test\n",
        "\n",
        "    # If only extensions are configured, do a lightweight test\n",
        "    try:\n",
        "        extensions = spark.conf.get(\"spark.sql.extensions\", \"\")  # type: ignore[attr-defined]\n",
        "        if extensions and \"DeltaSparkSessionExtension\" in extensions:\n",
        "            # Try a simple test - create a minimal DataFrame and try to write it\n",
        "            test_df = spark.createDataFrame([(1, \"test\")], [\"id\", \"name\"])\n",
        "            # Use a unique temp directory to avoid conflicts\n",
        "            with tempfile.TemporaryDirectory() as temp_dir:\n",
        "                test_path = os.path.join(temp_dir, \"delta_test\")\n",
        "                try:\n",
        "                    test_df.write.format(\"delta\").mode(\"overwrite\").save(test_path)\n",
        "                    _delta_availability_cache_execution[spark_id] = True\n",
        "                    return True\n",
        "                except Exception:\n",
        "                    # Delta format failed - not available\n",
        "                    pass\n",
        "    except Exception:\n",
        "        pass  # Lightweight Delta test failed or config unavailable\n",
        "\n",
        "    # Delta is not available in this Spark session\n",
        "    _delta_availability_cache_execution[spark_id] = False\n",
        "    return False\n",
        "\n",
        "# Removed _check_batch_mode_with_delta() - Delta Lake does support batch operations\n",
        "# in real Spark mode. The previous restriction was incorrect.\n",
        "\n",
        "def _create_dataframe_writer(\n",
        "    df: DataFrame,\n",
        "    spark: SparkSession,  # type: ignore[valid-type]\n",
        "    mode: str,\n",
        "    table_name: Optional[str] = None,\n",
        "    **options: Any,\n",
        ") -> Any:\n",
        "    \"\"\"Create a DataFrameWriter using the standardized Delta write pattern.\n",
        "\n",
        "    Creates a DataFrameWriter configured for Delta Lake format with appropriate\n",
        "    options based on the write mode. For overwrite mode, includes\n",
        "    overwriteSchema option to allow schema evolution.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to write.\n",
        "        spark: SparkSession instance (used for Delta overwrite preparation).\n",
        "        mode: Write mode (\"overwrite\", \"append\", etc.).\n",
        "        table_name: Optional fully qualified table name for preparing Delta\n",
        "            overwrite operations.\n",
        "        **options: Additional write options to apply to the writer.\n",
        "\n",
        "    Returns:\n",
        "        Configured DataFrameWriter instance ready for saveAsTable().\n",
        "\n",
        "    Note:\n",
        "        Always uses Delta format. Failures will propagate if Delta is not\n",
        "        available. For overwrite mode, uses format(\"delta\").mode(\"overwrite\")\n",
        "        .option(\"overwriteSchema\", \"true\").\n",
        "    \"\"\"\n",
        "    # Use standardized overwrite pattern: overwrite + overwriteSchema\n",
        "    if mode == \"overwrite\":\n",
        "        writer = (\n",
        "            df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\")\n",
        "        )\n",
        "    else:\n",
        "        # Append or other modes - always use Delta\n",
        "        writer = df.write.format(\"delta\").mode(mode)\n",
        "\n",
        "    for key, value in options.items():\n",
        "        writer = writer.option(key, value)\n",
        "\n",
        "    return writer\n",
        "\n",
        "def _get_existing_schema_safe(spark: Any, table_name: str) -> Optional[Any]:\n",
        "    \"\"\"Safely get the schema of an existing table.\n",
        "\n",
        "    Attempts multiple methods to retrieve the table schema, handling catalog\n",
        "    sync issues where Spark may report empty schemas. Tries progressively\n",
        "    more expensive methods until schema is found or all methods are exhausted.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance.\n",
        "        table_name: Fully qualified table name (schema.table).\n",
        "\n",
        "    Returns:\n",
        "        StructType schema if table exists and schema is readable (may be\n",
        "        empty struct<>), None if table doesn't exist or schema can't be read.\n",
        "\n",
        "    Note:\n",
        "        Tries methods in order:\n",
        "        1. Direct schema from spark.table()\n",
        "        2. If empty schema (catalog sync issue), try DESCRIBE TABLE\n",
        "        3. If still empty, try reading a sample row to infer schema\n",
        "\n",
        "        Returns empty struct<> if table exists but schema cannot be determined,\n",
        "        allowing callers to handle catalog sync issues appropriately.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        table_df = spark.table(table_name)  # type: ignore[attr-defined]\n",
        "        schema = table_df.schema  # type: ignore[attr-defined]\n",
        "\n",
        "        # If schema is empty (catalog sync issue), try DESCRIBE TABLE as fallback\n",
        "        if not schema.fields or len(schema.fields) == 0:\n",
        "            try:\n",
        "                # Try DESCRIBE TABLE to get schema information\n",
        "                describe_df = spark.sql(f\"DESCRIBE TABLE {table_name}\")  # type: ignore[attr-defined]\n",
        "                describe_rows = describe_df.collect()  # type: ignore[attr-defined]\n",
        "\n",
        "                # If DESCRIBE returns rows with column info, try to read schema from data\n",
        "                if describe_rows and len(describe_rows) > 0:\n",
        "                    # Try reading a sample row to infer schema\n",
        "                    try:\n",
        "                        sample_df = spark.sql(f\"SELECT * FROM {table_name} LIMIT 1\")  # type: ignore[attr-defined]\n",
        "                        inferred_schema = sample_df.schema  # type: ignore[attr-defined]\n",
        "                        if inferred_schema.fields and len(inferred_schema.fields) > 0:\n",
        "                            return inferred_schema\n",
        "                    except Exception:\n",
        "                        pass  # Schema inference from sample failed\n",
        "            except Exception:\n",
        "                pass  # DESCRIBE or sample read failed\n",
        "\n",
        "        # Return schema even if empty (struct<>) - caller will handle empty schemas specially\n",
        "        return schema\n",
        "    except Exception:\n",
        "        pass  # Schema recovery failed; caller gets None\n",
        "    return None\n",
        "\n",
        "def _schemas_match(existing_schema: Any, output_schema: Any) -> tuple[bool, list[str]]:\n",
        "    \"\"\"Compare two schemas and determine if they match exactly.\n",
        "\n",
        "    Compares field names, types, and nullability between existing and output\n",
        "    schemas. Returns detailed information about any mismatches found.\n",
        "\n",
        "    Args:\n",
        "        existing_schema: StructType schema of the existing table.\n",
        "        output_schema: StructType schema of the output DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (matches: bool, differences: list[str]) where:\n",
        "        - matches: True if schemas match exactly, False otherwise\n",
        "        - differences: List of human-readable descriptions of mismatches\n",
        "\n",
        "    Note:\n",
        "        Checks for:\n",
        "        - Missing columns in output\n",
        "        - New columns in output\n",
        "        - Type mismatches in common columns\n",
        "        - Nullable changes (informational only - doesn't fail validation)\n",
        "\n",
        "        Column order differences are noted but don't affect the match result.\n",
        "    \"\"\"\n",
        "    differences = []\n",
        "\n",
        "    # Extract field dictionaries\n",
        "    existing_fields = (\n",
        "        {f.name: f for f in existing_schema.fields} if existing_schema.fields else {}\n",
        "    )\n",
        "    output_fields = (\n",
        "        {f.name: f for f in output_schema.fields} if output_schema.fields else {}\n",
        "    )\n",
        "\n",
        "    existing_columns = set(existing_fields.keys())\n",
        "    output_columns = set(output_fields.keys())\n",
        "\n",
        "    # Check for missing columns in output\n",
        "    missing_in_output = existing_columns - output_columns\n",
        "    if missing_in_output:\n",
        "        differences.append(f\"Missing columns in output: {sorted(missing_in_output)}\")\n",
        "\n",
        "    # Check for new columns in output\n",
        "    new_in_output = output_columns - existing_columns\n",
        "    if new_in_output:\n",
        "        differences.append(\n",
        "            f\"New columns in output (not in existing table): {sorted(new_in_output)}\"\n",
        "        )\n",
        "\n",
        "    # Check for type mismatches and nullable changes in common columns\n",
        "    common_columns = existing_columns & output_columns\n",
        "    type_mismatches = []\n",
        "    nullable_changes = []\n",
        "    for col in common_columns:\n",
        "        existing_field = existing_fields[col]\n",
        "        output_field = output_fields[col]\n",
        "\n",
        "        # Check type mismatch\n",
        "        if existing_field.dataType != output_field.dataType:\n",
        "            type_mismatches.append(\n",
        "                f\"{col}: existing={existing_field.dataType}, \"\n",
        "                f\"output={output_field.dataType}\"\n",
        "            )\n",
        "\n",
        "        # Check nullable changes (nullable -> non-nullable is stricter, non-nullable -> nullable is more lenient)\n",
        "        existing_nullable = getattr(existing_field, \"nullable\", True)\n",
        "        output_nullable = getattr(output_field, \"nullable\", True)\n",
        "        if existing_nullable != output_nullable:\n",
        "            if not existing_nullable and output_nullable:\n",
        "                # Existing is non-nullable, output is nullable - this is usually OK (more lenient)\n",
        "                nullable_changes.append(\n",
        "                    f\"{col}: nullable changed from False to True (more lenient - usually OK)\"\n",
        "                )\n",
        "            else:\n",
        "                # Existing is nullable, output is non-nullable - this is stricter and may cause issues\n",
        "                nullable_changes.append(\n",
        "                    f\"{col}: nullable changed from True to False (stricter - may cause issues if data has nulls)\"\n",
        "                )\n",
        "\n",
        "    if type_mismatches:\n",
        "        differences.append(f\"Type mismatches: {', '.join(type_mismatches)}\")\n",
        "\n",
        "    if nullable_changes:\n",
        "        # Note nullable changes but don't fail validation for them (Delta Lake handles this)\n",
        "        differences.append(\n",
        "            f\"Nullable changes (informational): {', '.join(nullable_changes)}\"\n",
        "        )\n",
        "\n",
        "    # Check for column order differences (informational only - order doesn't affect functionality)\n",
        "    existing_order = list(existing_fields.keys())\n",
        "    output_order = list(output_fields.keys())\n",
        "    if (\n",
        "        existing_order != output_order\n",
        "        and common_columns == existing_columns == output_columns\n",
        "    ):\n",
        "        # All columns match, just order is different\n",
        "        differences.append(\n",
        "            f\"Column order differs (informational - order doesn't affect functionality): \"\n",
        "            f\"existing={existing_order}, output={output_order}\"\n",
        "        )\n",
        "\n",
        "    return len(\n",
        "        [d for d in differences if \"informational\" not in d.lower()]\n",
        "    ) == 0, differences\n",
        "\n",
        "def _recover_table_schema(spark: Any, table_name: str) -> Optional[Any]:\n",
        "    \"\"\"Attempt to recover table schema when catalog shows empty schema.\n",
        "\n",
        "    Attempts to recover schema information when Spark catalog reports an\n",
        "    empty schema (struct<>), which can occur due to catalog sync issues\n",
        "    with Delta Lake tables.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance.\n",
        "        table_name: Fully qualified table name (schema.table).\n",
        "\n",
        "    Returns:\n",
        "        Recovered StructType schema if recovery succeeds, None if all\n",
        "        recovery methods fail.\n",
        "\n",
        "    Note:\n",
        "        Tries methods in order:\n",
        "        1. REFRESH TABLE and re-read schema\n",
        "        2. DESCRIBE TABLE to get column information\n",
        "        3. Read sample data to force schema resolution\n",
        "        4. Force schema evaluation by reading a row\n",
        "\n",
        "        This is a best-effort recovery - may return None if table doesn't\n",
        "        exist or all recovery methods fail.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Method 1: Try DESCRIBE TABLE and REFRESH to force catalog sync\n",
        "        try:\n",
        "            spark.sql(f\"REFRESH TABLE {table_name}\")  # type: ignore[attr-defined]\n",
        "        except Exception:\n",
        "            pass  # Ignore refresh errors\n",
        "\n",
        "        # Re-read table after refresh\n",
        "        table_df = spark.table(table_name)  # type: ignore[attr-defined]\n",
        "        df_schema = table_df.schema  # type: ignore[attr-defined]\n",
        "\n",
        "        # Check if schema now has fields\n",
        "        if (\n",
        "            hasattr(df_schema, \"fields\")\n",
        "            and df_schema.fields\n",
        "            and len(df_schema.fields) > 0\n",
        "        ):\n",
        "            return df_schema\n",
        "\n",
        "        # Method 2: Even if schema.fields is empty, check if DataFrame has columns\n",
        "        # This indicates the table exists and has data, just catalog is out of sync\n",
        "        if table_df.columns and len(table_df.columns) > 0:\n",
        "            # DataFrame has columns - try DESCRIBE TABLE to get schema information\n",
        "            try:\n",
        "                describe_df = spark.sql(f\"DESCRIBE TABLE {table_name}\")  # type: ignore[attr-defined]\n",
        "                describe_rows = describe_df.collect()  # type: ignore[attr-defined]\n",
        "\n",
        "                # If DESCRIBE returns column information, try to re-read the table\n",
        "                # Sometimes DESCRIBE helps Spark refresh its understanding of the schema\n",
        "                if describe_rows and len(describe_rows) > 0:\n",
        "                    # Try reading the table again after DESCRIBE\n",
        "                    table_df_retry = spark.table(table_name)  # type: ignore[attr-defined]\n",
        "                    df_schema_retry = table_df_retry.schema  # type: ignore[attr-defined]\n",
        "                    if (\n",
        "                        hasattr(df_schema_retry, \"fields\")\n",
        "                        and df_schema_retry.fields\n",
        "                        and len(df_schema_retry.fields) > 0\n",
        "                    ):\n",
        "                        return df_schema_retry\n",
        "            except Exception:\n",
        "                # DESCRIBE or re-read failed\n",
        "                pass\n",
        "\n",
        "            # If DESCRIBE didn't help, try to force schema resolution by reading data\n",
        "            try:\n",
        "                # Attempt to read a row to force Spark to resolve schema\n",
        "                sample = table_df.limit(1)\n",
        "                sample.collect()  # Force execution\n",
        "\n",
        "                # Re-read schema after forcing execution\n",
        "                df_schema_retry = table_df.schema  # type: ignore[attr-defined]\n",
        "                if (\n",
        "                    hasattr(df_schema_retry, \"fields\")\n",
        "                    and df_schema_retry.fields\n",
        "                    and len(df_schema_retry.fields) > 0\n",
        "                ):\n",
        "                    return df_schema_retry\n",
        "            except Exception:\n",
        "                # Schema recovery via data read failed\n",
        "                pass\n",
        "    except Exception:\n",
        "        # Schema recovery failed\n",
        "        pass\n",
        "\n",
        "    return None\n",
        "\n",
        "class StepStatus(Enum):\n",
        "    \"\"\"Execution status of a pipeline step.\n",
        "\n",
        "    Attributes:\n",
        "        PENDING: Step is queued but not yet started.\n",
        "        RUNNING: Step is currently executing.\n",
        "        COMPLETED: Step completed successfully.\n",
        "        FAILED: Step execution failed with an error.\n",
        "        SKIPPED: Step was skipped (e.g., due to dependencies).\n",
        "    \"\"\"\n",
        "\n",
        "    PENDING = \"pending\"\n",
        "    RUNNING = \"running\"\n",
        "    COMPLETED = \"completed\"\n",
        "    FAILED = \"failed\"\n",
        "    SKIPPED = \"skipped\"\n",
        "\n",
        "class StepType(Enum):\n",
        "    \"\"\"Types of pipeline steps in the Medallion architecture.\n",
        "\n",
        "    Attributes:\n",
        "        BRONZE: Raw data ingestion and validation step.\n",
        "        SILVER: Cleaned and enriched data step.\n",
        "        GOLD: Business analytics and aggregation step.\n",
        "    \"\"\"\n",
        "\n",
        "    BRONZE = \"bronze\"\n",
        "    SILVER = \"silver\"\n",
        "    GOLD = \"gold\"\n",
        "\n",
        "@dataclass\n",
        "class StepExecutionResult:\n",
        "    \"\"\"Result of a single pipeline step execution.\n",
        "\n",
        "    Contains comprehensive information about step execution including timing,\n",
        "    validation metrics, resource usage, and output details.\n",
        "\n",
        "    Attributes:\n",
        "        step_name: Name of the executed step.\n",
        "        step_type: Type of step (BRONZE, SILVER, or GOLD).\n",
        "        status: Execution status (PENDING, RUNNING, COMPLETED, FAILED, SKIPPED).\n",
        "        start_time: Timestamp when step execution started.\n",
        "        end_time: Timestamp when step execution completed (None if still running).\n",
        "        duration: Execution duration in seconds (calculated from start/end times).\n",
        "        error: Error message if step failed (None if successful).\n",
        "        rows_processed: Number of rows processed by the step.\n",
        "        output_table: Fully qualified name of output table (None for Bronze steps).\n",
        "        write_mode: Write mode used (\"overwrite\", \"append\", or None).\n",
        "        validation_rate: Percentage of rows that passed validation (0-100).\n",
        "        rows_written: Number of rows written to output table (None for Bronze steps).\n",
        "        input_rows: Number of input rows (same as rows_processed for most steps).\n",
        "        memory_usage_mb: Peak memory usage in megabytes (if psutil available).\n",
        "        cpu_usage_percent: CPU usage percentage (if psutil available).\n",
        "\n",
        "    Note:\n",
        "        Duration is automatically calculated in __post_init__ if both start_time\n",
        "        and end_time are provided. Bronze steps don't write to tables, so\n",
        "        output_table and rows_written will be None for them.\n",
        "    \"\"\"\n",
        "\n",
        "    step_name: str\n",
        "    step_type: StepType\n",
        "    status: StepStatus\n",
        "    start_time: datetime\n",
        "    end_time: Optional[datetime] = None\n",
        "    duration: Optional[float] = None\n",
        "    error: Optional[str] = None\n",
        "    rows_processed: Optional[int] = None\n",
        "    output_table: Optional[str] = None\n",
        "    write_mode: Optional[str] = None\n",
        "    validation_rate: float = 100.0\n",
        "    rows_written: Optional[int] = None\n",
        "    input_rows: Optional[int] = None\n",
        "    memory_usage_mb: Optional[float] = None\n",
        "    cpu_usage_percent: Optional[float] = None\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        \"\"\"Calculate duration if both start and end times are available.\"\"\"\n",
        "        if self.end_time and self.start_time:\n",
        "            self.duration = (self.end_time - self.start_time).total_seconds()\n",
        "\n",
        "@dataclass\n",
        "class ExecutionResult:\n",
        "    \"\"\"Result of complete pipeline execution.\n",
        "\n",
        "    Contains comprehensive information about pipeline execution including\n",
        "    all step results, timing, dependency analysis results, and overall status.\n",
        "\n",
        "    Attributes:\n",
        "        execution_id: Unique identifier for this execution run.\n",
        "        mode: Execution mode used (INITIAL, INCREMENTAL, FULL_REFRESH, VALIDATION_ONLY).\n",
        "        start_time: Timestamp when pipeline execution started.\n",
        "        end_time: Timestamp when pipeline execution completed (None if still running).\n",
        "        duration: Total execution duration in seconds (calculated from start/end times).\n",
        "        status: Overall pipeline status (\"running\", \"completed\", \"failed\").\n",
        "        steps: List of StepExecutionResult for each step in the pipeline.\n",
        "        error: Error message if pipeline failed (None if successful).\n",
        "\n",
        "    Note:\n",
        "        Duration is automatically calculated in __post_init__ if both start_time\n",
        "        and end_time are provided. Steps list is initialized to empty list if None.\n",
        "        The status field tracks overall pipeline status based on individual step results.\n",
        "    \"\"\"\n",
        "\n",
        "    execution_id: str\n",
        "    mode: ExecutionMode\n",
        "    start_time: datetime\n",
        "    end_time: Optional[datetime] = None\n",
        "    duration: Optional[float] = None\n",
        "    status: str = \"running\"\n",
        "    steps: Optional[list[StepExecutionResult]] = None\n",
        "    error: Optional[str] = None\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        \"\"\"Initialize steps list and calculate duration if times are available.\"\"\"\n",
        "        if self.steps is None:\n",
        "            self.steps = []\n",
        "        if self.end_time and self.start_time:\n",
        "            self.duration = (self.end_time - self.start_time).total_seconds()\n",
        "\n",
        "class ExecutionEngine:\n",
        "    \"\"\"Execution engine for pipeline execution with service-oriented architecture.\n",
        "\n",
        "    This engine orchestrates pipeline execution using specialized services for\n",
        "    clean separation of concerns. It handles both individual step execution and\n",
        "    full pipeline execution with dependency-aware sequential processing.\n",
        "\n",
        "    The engine uses a service-oriented architecture:\n",
        "    - Step Executors: BronzeStepExecutor, SilverStepExecutor, GoldStepExecutor\n",
        "      handle step-specific execution logic\n",
        "    - ExecutionValidator: Validates data according to step rules\n",
        "    - TableService: Manages table operations and schema management\n",
        "    - WriteService: Handles all write operations to Delta Lake\n",
        "\n",
        "    Key Features:\n",
        "        - Dependency-aware execution: Automatically analyzes and respects step\n",
        "          dependencies\n",
        "        - Sequential execution: Steps execute in correct dependency order (topological sort)\n",
        "        - Comprehensive validation: Built-in validation with configurable thresholds\n",
        "        - Error handling: Detailed error messages with context and suggestions\n",
        "        - Resource tracking: Monitors memory and CPU usage (if psutil available)\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.execution import ExecutionEngine\n",
        "        >>> from pipeline_builder_base.models import PipelineConfig, ExecutionMode\n",
        "        >>>\n",
        "        >>> config = PipelineConfig.create_default(schema=\"analytics\")\n",
        "        >>> engine = ExecutionEngine(spark, config)\n",
        "        >>>\n",
        "        >>> # Execute a single step\n",
        "        >>> result = engine.execute_step(\n",
        "        ...     step=bronze_step,\n",
        "        ...     context={\"events\": source_df},\n",
        "        ...     mode=ExecutionMode.INITIAL\n",
        "        ... )\n",
        "        >>>\n",
        "        >>> # Execute full pipeline\n",
        "        >>> result = engine.execute_pipeline(\n",
        "        ...     steps=[bronze, silver, gold],\n",
        "        ...     mode=ExecutionMode.INITIAL,\n",
        "        ...     context={\"events\": source_df}\n",
        "        ... )\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,  # type: ignore[valid-type]\n",
        "        config: PipelineConfig,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the execution engine.\n",
        "\n",
        "        Creates an ExecutionEngine instance with all required services. The\n",
        "        engine initializes step executors, validation service, and storage\n",
        "        services for handling pipeline execution.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance for DataFrame operations.\n",
        "            config: PipelineConfig containing pipeline configuration including\n",
        "                schema, validation thresholds, and other settings.\n",
        "            logger: Optional PipelineLogger instance. If None, creates a default\n",
        "                logger.\n",
        "            functions: Optional FunctionsProtocol instance for PySpark operations.\n",
        "                If None, uses get_default_functions() to get appropriate functions\n",
        "                based on engine configuration.\n",
        "\n",
        "        Note:\n",
        "            All services are initialized during construction. The engine is ready\n",
        "            to execute steps immediately after initialization.\n",
        "        \"\"\"\n",
        "        self.spark: SparkSession = spark  # type: ignore[valid-type]\n",
        "        self.config = config\n",
        "        if logger is None:\n",
        "            self.logger = PipelineLogger()\n",
        "        else:\n",
        "            self.logger = logger\n",
        "\n",
        "        # Store functions for validation\n",
        "        if functions is None:\n",
        "            # from .functions import get_default_functions  # Removed: defined in notebook cells above\n",
        "\n",
        "            self.functions = get_default_functions()\n",
        "        else:\n",
        "            self.functions = functions\n",
        "\n",
        "        # Initialize step executors\n",
        "        self.bronze_executor = BronzeStepExecutor(spark, self.logger, self.functions)\n",
        "        self.silver_executor = SilverStepExecutor(spark, self.logger, self.functions)\n",
        "        self.gold_executor = GoldStepExecutor(spark, self.logger, self.functions)\n",
        "\n",
        "        # Initialize validation service\n",
        "        self.validator = ExecutionValidator(self.logger, self.functions)\n",
        "\n",
        "        # Initialize storage services\n",
        "        self.table_service = TableService(spark, self.logger)\n",
        "        self.write_service = WriteService(spark, self.table_service, self.logger)\n",
        "\n",
        "    def _ensure_schema_exists(self, schema: str) -> None:\n",
        "        \"\"\"Ensure a schema exists, creating it if necessary.\n",
        "\n",
        "        Attempts to create the specified schema if it doesn't already exist.\n",
        "        Uses SQL CREATE SCHEMA IF NOT EXISTS for idempotent creation.\n",
        "\n",
        "        Args:\n",
        "            schema: Schema name to create or verify.\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If schema creation fails after all attempts.\n",
        "\n",
        "        Note:\n",
        "            First checks if schema exists in catalog, then attempts creation\n",
        "            using SQL. If creation fails, raises ExecutionError with context.\n",
        "        \"\"\"\n",
        "        # Check if schema already exists\n",
        "        try:\n",
        "            databases = [db.name for db in self.spark.catalog.listDatabases()]\n",
        "            if schema in databases:\n",
        "                return  # Schema already exists, nothing to do\n",
        "        except Exception:\n",
        "            pass  # If we can't check, try to create anyway\n",
        "\n",
        "        try:\n",
        "            # Use SQL CREATE SCHEMA (works for both PySpark and mock-spark)\n",
        "            self.spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema}\")  # type: ignore[attr-defined]\n",
        "            # Verify it was created\n",
        "            databases = [db.name for db in self.spark.catalog.listDatabases()]  # type: ignore[attr-defined]\n",
        "            if schema not in databases:\n",
        "                raise ExecutionError(\n",
        "                    f\"Schema '{schema}' creation via SQL failed - schema not in catalog. \"\n",
        "                    f\"Available databases: {databases}\"\n",
        "                )\n",
        "        except ExecutionError:\n",
        "            raise  # Re-raise ExecutionError\n",
        "        except Exception as e:\n",
        "            # Wrap other exceptions\n",
        "            raise ExecutionError(f\"Failed to create schema '{schema}': {str(e)}\") from e\n",
        "\n",
        "    @staticmethod\n",
        "    def _collect_resource_metrics() -> tuple[Optional[float], Optional[float]]:\n",
        "        \"\"\"Collect current memory and CPU usage metrics.\n",
        "\n",
        "        Uses psutil to collect resource usage metrics for the current process.\n",
        "        Returns None values if psutil is not available.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (memory_usage_mb, cpu_usage_percent) where:\n",
        "            - memory_usage_mb: Memory usage in megabytes (RSS)\n",
        "            - cpu_usage_percent: CPU usage percentage\n",
        "\n",
        "            Returns (None, None) if psutil is unavailable or metrics collection fails.\n",
        "\n",
        "        Note:\n",
        "            Memory is measured as RSS (Resident Set Size) in megabytes.\n",
        "            CPU usage is measured over a 0.1 second interval.\n",
        "        \"\"\"\n",
        "        if not HAS_PSUTIL:\n",
        "            return None, None\n",
        "\n",
        "        try:\n",
        "            process = psutil.Process()\n",
        "            memory_info = process.memory_info()\n",
        "            memory_mb = memory_info.rss / (1024 * 1024)  # Convert bytes to MB\n",
        "            cpu_percent = process.cpu_percent(interval=0.1)\n",
        "            return memory_mb, cpu_percent\n",
        "        except Exception:\n",
        "            # If metrics collection fails, return None values\n",
        "            return None, None\n",
        "\n",
        "    def execute_step(\n",
        "        self,\n",
        "        step: Union[BronzeStep, SilverStep, GoldStep],\n",
        "        context: Dict[str, DataFrame],  # type: ignore[valid-type]\n",
        "        mode: ExecutionMode = ExecutionMode.INITIAL,\n",
        "        step_params: Optional[Dict[str, Any]] = None,\n",
        "        write_outputs: bool = True,\n",
        "        step_types: Optional[Dict[str, str]] = None,\n",
        "    ) -> StepExecutionResult:\n",
        "        \"\"\"Execute a single pipeline step.\n",
        "\n",
        "        Executes a single step (Bronze, Silver, or Gold) with validation,\n",
        "        transformation, and optional table writing. Uses specialized step\n",
        "        executors for step-specific logic.\n",
        "\n",
        "        Args:\n",
        "            step: The step to execute (BronzeStep, SilverStep, or GoldStep).\n",
        "            context: Dictionary mapping step names to DataFrames. Must contain\n",
        "                required source data for the step (e.g., bronze data for Silver\n",
        "                steps, silver data for Gold steps).\n",
        "            mode: Execution mode (INITIAL, INCREMENTAL, FULL_REFRESH,\n",
        "                VALIDATION_ONLY). Defaults to INITIAL.\n",
        "            step_params: Optional dictionary of parameters to pass to the step's\n",
        "                transform function. Only used for Silver and Gold steps. If the\n",
        "                transform function accepts a 'params' argument or **kwargs,\n",
        "                these will be passed. Otherwise, ignored for backward compatibility.\n",
        "            write_outputs: If True, write step outputs to Delta Lake tables.\n",
        "                If False, skip writing (useful for debugging/iteration).\n",
        "                Defaults to True.\n",
        "            step_types: Optional dictionary mapping step names to step types\n",
        "                (\"bronze\", \"silver\", \"gold\"). Used to build prior_golds for\n",
        "                transform functions. If None, prior_golds will not be built.\n",
        "\n",
        "        Returns:\n",
        "            StepExecutionResult containing execution details including:\n",
        "            - Status (COMPLETED, FAILED)\n",
        "            - Timing information\n",
        "            - Row counts (processed, written)\n",
        "            - Validation metrics\n",
        "            - Resource usage (if available)\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If step execution fails for any reason.\n",
        "\n",
        "        Example:\n",
        "            >>> result = engine.execute_step(\n",
        "            ...     step=silver_step,\n",
        "            ...     context={\"events\": bronze_df},\n",
        "            ...     mode=ExecutionMode.INITIAL\n",
        "            ... )\n",
        "            >>> print(f\"Status: {result.status}, Rows: {result.rows_processed}\")\n",
        "\n",
        "        Note:\n",
        "            - Bronze steps only validate data, they don't write to tables\n",
        "            - Silver and Gold steps write to Delta Lake tables\n",
        "            - Validation is applied according to step rules\n",
        "            - Schema validation is performed for INCREMENTAL and FULL_REFRESH modes\n",
        "        \"\"\"\n",
        "        start_time = datetime.now()\n",
        "        # Collect initial resource metrics\n",
        "        start_memory, start_cpu = self._collect_resource_metrics()\n",
        "\n",
        "        # Determine step type using step_type property (avoids isinstance issues in Python 3.8)\n",
        "        # Initialize step_type to None to ensure it's always defined for exception handling\n",
        "        step_type = None\n",
        "        try:\n",
        "            phase = step.step_type\n",
        "            if phase.value == \"bronze\":\n",
        "                step_type = StepType.BRONZE\n",
        "            elif phase.value == \"silver\":\n",
        "                step_type = StepType.SILVER\n",
        "            elif phase.value == \"gold\":\n",
        "                step_type = StepType.GOLD\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown step type: {phase.value}\")\n",
        "        except AttributeError as err:\n",
        "            raise ValueError(\n",
        "                f\"Unknown step type: Step must have step_type property (BronzeStep, SilverStep, or GoldStep), got {type(step)}\"\n",
        "            ) from err\n",
        "\n",
        "        result = StepExecutionResult(\n",
        "            step_name=step.name,\n",
        "            step_type=step_type,\n",
        "            status=StepStatus.RUNNING,\n",
        "            start_time=start_time,\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            # Use logger's step_start method for consistent formatting with emoji and uppercase\n",
        "            self.logger.step_start(step_type.value, step.name)\n",
        "\n",
        "            # Execute the step based on type using executors\n",
        "            output_df: DataFrame  # type: ignore[valid-type]\n",
        "            if step_type == StepType.BRONZE:\n",
        "                output_df = self.bronze_executor.execute(step, context, mode)  # type: ignore[arg-type]\n",
        "            elif step_type == StepType.SILVER:\n",
        "                output_df = self.silver_executor.execute(\n",
        "                    step, context, mode, step_params=step_params, step_types=step_types\n",
        "                )  # type: ignore[arg-type]\n",
        "                # Store output DataFrame in context immediately after execution for downstream steps\n",
        "                # This ensures prior_silvers is populated for subsequent silver steps\n",
        "                context[step.name] = output_df  # type: ignore[assignment]\n",
        "            elif step_type == StepType.GOLD:\n",
        "                output_df = self.gold_executor.execute(\n",
        "                    step, context, mode, step_params=step_params, step_types=step_types\n",
        "                )  # type: ignore[arg-type]\n",
        "                # Store output DataFrame in context immediately after execution for downstream steps\n",
        "                context[step.name] = output_df  # type: ignore[assignment]\n",
        "            else:\n",
        "                raise ExecutionError(f\"Unknown step type: {step_type}\")\n",
        "\n",
        "            # Apply validation if not in validation-only mode\n",
        "            validation_rate = 100.0\n",
        "            invalid_rows = 0\n",
        "            if mode != ExecutionMode.VALIDATION_ONLY:\n",
        "                # All step types (Bronze, Silver, Gold) have rules attribute\n",
        "                if step.rules:\n",
        "                    # Use validation service for validation\n",
        "                    output_df, _, validation_stats = (\n",
        "                        self.validator.validate_step_output(\n",
        "                            output_df,\n",
        "                            step.name,\n",
        "                            step.rules,\n",
        "                            \"pipeline\",\n",
        "                        )\n",
        "                    )\n",
        "                    # Extract validation metrics\n",
        "                    validation_rate, invalid_rows = (\n",
        "                        self.validator.get_validation_metrics(validation_stats)\n",
        "                    )\n",
        "\n",
        "            # Write output if not in validation-only mode and write_outputs is True\n",
        "            # Note: Bronze steps only validate data, they don't write to tables\n",
        "            # Validation-only steps (with_silver_rules / with_gold_rules) only read existing tables\n",
        "            _is_validation_only_step = (\n",
        "                getattr(step, \"existing\", False) and step.transform is None\n",
        "            )\n",
        "            if (\n",
        "                mode != ExecutionMode.VALIDATION_ONLY\n",
        "                and step_type != StepType.BRONZE\n",
        "                and write_outputs\n",
        "                and not _is_validation_only_step\n",
        "            ):\n",
        "                # Use table_name attribute for SilverStep and GoldStep\n",
        "                table_name = getattr(step, \"table_name\", step.name)\n",
        "                schema = getattr(step, \"schema\", None)\n",
        "\n",
        "                # Validate schema is provided\n",
        "                if schema is None:\n",
        "                    raise ExecutionError(\n",
        "                        f\"Step '{step.name}' requires a schema to be specified. \"\n",
        "                        f\"Silver and Gold steps must have a valid schema for table operations. \"\n",
        "                        f\"Please provide a schema when creating the step.\"\n",
        "                    )\n",
        "\n",
        "                output_table = fqn(schema, table_name)\n",
        "\n",
        "                # Ensure schema exists before creating table\n",
        "                # Use SQL CREATE SCHEMA (works for both PySpark and mock-spark)\n",
        "                try:\n",
        "                    self.spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema}\")  # type: ignore[attr-defined]\n",
        "                except Exception as e:\n",
        "                    # Schema might already exist, continue\n",
        "                    # If all methods fail, raise error - schema creation is critical\n",
        "                    # Check if it's a schema already exists error\n",
        "                    error_msg = str(e).lower()\n",
        "                    if (\n",
        "                        \"already exists\" not in error_msg\n",
        "                        and \"duplicate\" not in error_msg\n",
        "                    ):\n",
        "                        raise ExecutionError(\n",
        "                            f\"Failed to create schema '{schema}' before table creation: {e}\"\n",
        "                        ) from e\n",
        "\n",
        "                # Determine write mode\n",
        "                # - Gold steps always use overwrite to prevent duplicate aggregates\n",
        "                # - Silver steps append during incremental runs to preserve history\n",
        "                # - INITIAL mode uses overwrite\n",
        "                # - FULL_REFRESH uses overwrite\n",
        "                if step_type == StepType.GOLD:\n",
        "                    write_mode_str = \"overwrite\"\n",
        "                elif mode == ExecutionMode.INCREMENTAL:\n",
        "                    write_mode_str = \"append\"\n",
        "                else:  # INITIAL or FULL_REFRESH\n",
        "                    write_mode_str = \"overwrite\"\n",
        "\n",
        "                # Validate schema based on execution mode\n",
        "                # For INCREMENTAL and FULL_REFRESH modes, schema must match exactly\n",
        "                # For INITIAL mode, schema changes are allowed\n",
        "                if mode in (ExecutionMode.INCREMENTAL, ExecutionMode.FULL_REFRESH):\n",
        "                    if table_exists(self.spark, output_table):\n",
        "                        # Refresh table metadata to ensure catalog is in sync (especially important for Delta tables)\n",
        "                        try:\n",
        "                            self.spark.sql(f\"REFRESH TABLE {output_table}\")  # type: ignore[attr-defined]\n",
        "                        except Exception as refresh_error:\n",
        "                            # Refresh might fail for some table types - log but continue\n",
        "                            self.logger.debug(\n",
        "                                f\"Could not refresh table {output_table} before schema validation: {refresh_error}\"\n",
        "                            )\n",
        "\n",
        "                        existing_schema = _get_existing_schema_safe(\n",
        "                            self.spark, output_table\n",
        "                        )\n",
        "                        if existing_schema is None:\n",
        "                            # Cannot read schema - raise error\n",
        "                            raise ExecutionError(\n",
        "                                f\"Cannot read schema for table '{output_table}' in {mode} mode. \"\n",
        "                                \"Schema validation is required for INCREMENTAL and FULL_REFRESH modes.\",\n",
        "                                context={\n",
        "                                    \"step_name\": step.name,\n",
        "                                    \"table\": output_table,\n",
        "                                    \"mode\": mode.value,\n",
        "                                },\n",
        "                                suggestions=[\n",
        "                                    \"Ensure the table exists and is accessible\",\n",
        "                                    \"Check that the table schema is readable\",\n",
        "                                    \"Use INITIAL mode if you need to recreate the table\",\n",
        "                                ],\n",
        "                            )\n",
        "\n",
        "                        # If catalog reports empty schema, treat as mismatch with explicit guidance\n",
        "                        schema_is_empty = (\n",
        "                            not existing_schema.fields\n",
        "                            or len(existing_schema.fields) == 0\n",
        "                        )\n",
        "                        if schema_is_empty:\n",
        "                            output_schema = output_df.schema  # type: ignore[attr-defined]\n",
        "                            raise ExecutionError(\n",
        "                                f\"Schema mismatch for table '{output_table}' in {mode} mode. \"\n",
        "                                f\"Catalog reports empty schema (struct<>), but output schema has {len(output_schema.fields)} fields: {[f.name for f in output_schema.fields]}. \"\n",
        "                                f\"Use INITIAL mode to recreate the table or provide schema_override explicitly.\",\n",
        "                                context={\n",
        "                                    \"step_name\": step.name,\n",
        "                                    \"table\": output_table,\n",
        "                                    \"mode\": mode.value,\n",
        "                                    \"existing_schema\": \"struct<> (empty - catalog sync issue)\",\n",
        "                                    \"output_schema\": str(output_schema),\n",
        "                                },\n",
        "                                suggestions=[\n",
        "                                    \"Run initial_load/full_refresh to recreate the table with the desired schema\",\n",
        "                                    \"Provide schema_override to force the schema in allowed modes\",\n",
        "                                ],\n",
        "                            )\n",
        "\n",
        "                        output_schema = output_df.schema  # type: ignore[attr-defined]\n",
        "                        schemas_match, differences = _schemas_match(\n",
        "                            existing_schema, output_schema\n",
        "                        )\n",
        "\n",
        "                        if not schemas_match:\n",
        "                            raise ExecutionError(\n",
        "                                f\"Schema mismatch for table '{output_table}' in {mode} mode. \"\n",
        "                                f\"Schema changes are only allowed in INITIAL mode.\\n\"\n",
        "                                f\"{chr(10).join(differences)}\\n\\n\"\n",
        "                                f\"Existing table schema: {existing_schema}\\n\"\n",
        "                                f\"Output DataFrame schema: {output_schema}\",\n",
        "                                context={\n",
        "                                    \"step_name\": step.name,\n",
        "                                    \"table\": output_table,\n",
        "                                    \"mode\": mode.value,\n",
        "                                    \"existing_schema\": str(existing_schema),\n",
        "                                    \"output_schema\": str(output_schema),\n",
        "                                },\n",
        "                                suggestions=[\n",
        "                                    \"Ensure the output schema matches the existing table schema exactly\",\n",
        "                                    \"Run with INITIAL mode to recreate the table with the new schema\",\n",
        "                                    \"Manually update the existing table schema to match the new schema\",\n",
        "                                ],\n",
        "                            )\n",
        "\n",
        "                # NOTE: We intentionally do NOT drop existing tables in INITIAL mode.\n",
        "                # Dropping is destructive and can leave downstream users with missing tables\n",
        "                # if a pipeline run fails after the drop but before the overwrite commit.\n",
        "                # Delta overwrite is transactional; prefer `.mode(\"overwrite\")` + schema options.\n",
        "\n",
        "                # Handle schema override if provided\n",
        "                schema_override = getattr(step, \"schema_override\", None)\n",
        "                should_apply_schema_override = False\n",
        "\n",
        "                if schema_override is not None:\n",
        "                    # Determine when to apply schema override:\n",
        "                    # - Gold steps: Always apply (always use overwrite mode)\n",
        "                    # - Silver steps in initial/full refresh: Always apply\n",
        "                    # - Silver steps in incremental: Only if table doesn't exist\n",
        "                    if step_type == StepType.GOLD:\n",
        "                        should_apply_schema_override = True\n",
        "                    elif step_type == StepType.SILVER:\n",
        "                        if mode != ExecutionMode.INCREMENTAL:\n",
        "                            should_apply_schema_override = True\n",
        "                        else:\n",
        "                            should_apply_schema_override = not table_exists(\n",
        "                                self.spark, output_table\n",
        "                            )\n",
        "\n",
        "                # Apply schema override if needed\n",
        "                if should_apply_schema_override:\n",
        "                    try:\n",
        "                        # Cast DataFrame to the override schema\n",
        "                        output_df = self.spark.createDataFrame(  # type: ignore[attr-defined]\n",
        "                            output_df.rdd, schema_override\n",
        "                        )  # type: ignore[attr-defined]\n",
        "                        # For overwrite mode, use DELETE + INSERT pattern\n",
        "                        if write_mode_str == \"overwrite\":\n",
        "                            # Delete existing data if table exists\n",
        "                            delete_succeeded = False\n",
        "                            if table_exists(self.spark, output_table):\n",
        "                                try:\n",
        "                                    self.spark.sql(f\"DELETE FROM {output_table}\")  # type: ignore[attr-defined]\n",
        "                                    delete_succeeded = True\n",
        "                                except Exception as e:\n",
        "                                    # DELETE might fail for non-Delta tables\n",
        "                                    error_msg = str(e).lower()\n",
        "                                    if (\n",
        "                                        \"does not support delete\" in error_msg\n",
        "                                        or \"unsupported_feature\" in error_msg\n",
        "                                    ):\n",
        "                                        self.logger.info(\n",
        "                                            f\"Table '{output_table}' does not support DELETE. \"\n",
        "                                            f\"Using overwrite mode instead.\"\n",
        "                                        )\n",
        "                                    else:\n",
        "                                        self.logger.warning(\n",
        "                                            f\"Could not delete from table '{output_table}' before overwrite: {e}\"\n",
        "                                        )\n",
        "\n",
        "                            if delete_succeeded:\n",
        "                                # Write with overwrite mode and overwriteSchema option\n",
        "                                # Note: Delta Lake doesn't support append in batch mode\n",
        "                                try:\n",
        "                                    (\n",
        "                                        output_df.write.format(\"delta\")\n",
        "                                        .mode(\"overwrite\")\n",
        "                                        .option(\"overwriteSchema\", \"true\")\n",
        "                                        .saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                    )\n",
        "                                except Exception as write_error:\n",
        "                                    # Handle truncate error for Delta tables\n",
        "                                    error_msg = str(write_error).lower()\n",
        "                                    if (\n",
        "                                        \"truncate\" in error_msg\n",
        "                                        and \"batch mode\" in error_msg\n",
        "                                    ):\n",
        "                                        # Delta table doesn't support truncate - drop and retry\n",
        "                                        self.logger.warning(\n",
        "                                            f\"Delta table truncate error, dropping table and retrying: {write_error}\"\n",
        "                                        )\n",
        "                                        try:\n",
        "                                            self.spark.sql(\n",
        "                                                f\"DROP TABLE IF EXISTS {output_table}\"\n",
        "                                            )  # type: ignore[attr-defined]\n",
        "                                            import time\n",
        "\n",
        "                                            time.sleep(\n",
        "                                                0.1\n",
        "                                            )  # Brief delay for catalog sync\n",
        "                                            (\n",
        "                                                output_df.write.format(\"delta\")\n",
        "                                                .mode(\"overwrite\")\n",
        "                                                .option(\"overwriteSchema\", \"true\")\n",
        "                                                .saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                            )\n",
        "                                            # Successfully wrote after retry\n",
        "                                            write_error = None\n",
        "                                        except Exception as retry_error:\n",
        "                                            raise ExecutionError(\n",
        "                                                f\"Failed to write table '{output_table}' even after retry: {retry_error}\",\n",
        "                                                context={\n",
        "                                                    \"step_name\": step.name,\n",
        "                                                    \"table\": output_table,\n",
        "                                                    \"mode\": mode.value,\n",
        "                                                    \"original_error\": str(write_error),\n",
        "                                                },\n",
        "                                            ) from retry_error\n",
        "\n",
        "                                    # If we handled truncate error successfully, skip other error handling\n",
        "                                    if write_error is None:\n",
        "                                        pass  # Write succeeded after retry, continue execution\n",
        "                                    # Handle race condition where table might be created by another thread\n",
        "                                    elif (\n",
        "                                        \"already exists\" in error_msg\n",
        "                                        or \"table_or_view_already_exists\" in error_msg\n",
        "                                    ):\n",
        "                                        # Table was created by another thread - verify it exists and retry with overwrite mode\n",
        "                                        if table_exists(self.spark, output_table):\n",
        "                                            self.logger.debug(\n",
        "                                                f\"Table {output_table} was created by another thread, retrying with overwrite mode\"\n",
        "                                            )\n",
        "                                            # Retry with overwrite mode (original mode) and overwriteSchema\n",
        "                                            retry_writer = _create_dataframe_writer(\n",
        "                                                output_df,\n",
        "                                                self.spark,\n",
        "                                                \"overwrite\",\n",
        "                                                table_name=output_table,\n",
        "                                                overwriteSchema=\"true\",\n",
        "                                            )\n",
        "                                            retry_writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                        else:\n",
        "                                            raise\n",
        "                                    else:\n",
        "                                        raise\n",
        "                            else:\n",
        "                                # DELETE failed - use overwrite mode directly\n",
        "                                try:\n",
        "                                    writer = _create_dataframe_writer(\n",
        "                                        output_df,\n",
        "                                        self.spark,\n",
        "                                        \"overwrite\",\n",
        "                                        table_name=output_table,\n",
        "                                        overwriteSchema=\"true\",\n",
        "                                    )\n",
        "                                    writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                except Exception as write_error:\n",
        "                                    # Handle truncate error for Delta tables\n",
        "                                    error_msg = str(write_error).lower()\n",
        "                                    if (\n",
        "                                        \"truncate\" in error_msg\n",
        "                                        and \"batch mode\" in error_msg\n",
        "                                    ):\n",
        "                                        # Delta table doesn't support truncate - drop and retry\n",
        "                                        self.logger.warning(\n",
        "                                            f\"Delta table truncate error, dropping table and retrying: {write_error}\"\n",
        "                                        )\n",
        "                                        try:\n",
        "                                            self.spark.sql(\n",
        "                                                f\"DROP TABLE IF EXISTS {output_table}\"\n",
        "                                            )  # type: ignore[attr-defined]\n",
        "                                            import time\n",
        "\n",
        "                                            time.sleep(\n",
        "                                                0.1\n",
        "                                            )  # Brief delay for catalog sync\n",
        "                                            retry_writer = _create_dataframe_writer(\n",
        "                                                output_df,\n",
        "                                                self.spark,\n",
        "                                                \"overwrite\",\n",
        "                                                table_name=output_table,\n",
        "                                                overwriteSchema=\"true\",\n",
        "                                            )\n",
        "                                            retry_writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                        except Exception as retry_error:\n",
        "                                            raise ExecutionError(\n",
        "                                                f\"Failed to write table '{output_table}' even after retry: {retry_error}\",\n",
        "                                                context={\n",
        "                                                    \"step_name\": step.name,\n",
        "                                                    \"table\": output_table,\n",
        "                                                    \"mode\": mode.value,\n",
        "                                                    \"original_error\": str(write_error),\n",
        "                                                },\n",
        "                                            ) from retry_error\n",
        "                                        # Successfully wrote after retry - exit exception handler\n",
        "                                        write_error = None\n",
        "\n",
        "                                    # If we handled truncate error successfully, skip other error handling\n",
        "                                    if write_error is None:\n",
        "                                        pass  # Write succeeded after retry, continue execution\n",
        "                                    # Handle race condition where table might be created by another thread\n",
        "                                    elif (\n",
        "                                        \"already exists\" in error_msg\n",
        "                                        or \"table_or_view_already_exists\" in error_msg\n",
        "                                    ):\n",
        "                                        # Table was created by another thread - verify it exists and retry with overwrite mode\n",
        "                                        if table_exists(self.spark, output_table):\n",
        "                                            self.logger.debug(\n",
        "                                                f\"Table {output_table} was created by another thread, retrying with overwrite mode\"\n",
        "                                            )\n",
        "                                            # Retry with overwrite mode (original mode) and overwriteSchema\n",
        "                                            retry_writer = _create_dataframe_writer(\n",
        "                                                output_df,\n",
        "                                                self.spark,\n",
        "                                                \"overwrite\",\n",
        "                                                table_name=output_table,\n",
        "                                                overwriteSchema=\"true\",\n",
        "                                            )\n",
        "                                            retry_writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                        else:\n",
        "                                            raise\n",
        "                                    else:\n",
        "                                        raise\n",
        "                        else:\n",
        "                            # For append mode, use normal write\n",
        "                            try:\n",
        "                                writer = _create_dataframe_writer(\n",
        "                                    output_df,\n",
        "                                    self.spark,\n",
        "                                    write_mode_str,\n",
        "                                    table_name=output_table,\n",
        "                                    overwriteSchema=\"true\",\n",
        "                                )\n",
        "                                writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                            except Exception as write_error:\n",
        "                                # Handle race condition where table might be created by another thread\n",
        "                                error_msg = str(write_error).lower()\n",
        "                                if (\n",
        "                                    \"already exists\" in error_msg\n",
        "                                    or \"table_or_view_already_exists\" in error_msg\n",
        "                                ):\n",
        "                                    # Table was created by another thread - verify it exists and retry\n",
        "                                    if table_exists(self.spark, output_table):\n",
        "                                        self.logger.debug(\n",
        "                                            f\"Table {output_table} was created by another thread, retrying with overwrite mode\"\n",
        "                                        )\n",
        "                                        # Retry with overwrite mode (append not supported in batch mode for Delta)\n",
        "                                        retry_writer = _create_dataframe_writer(\n",
        "                                            output_df,\n",
        "                                            self.spark,\n",
        "                                            \"overwrite\",\n",
        "                                            overwriteSchema=\"true\",\n",
        "                                        )\n",
        "                                        retry_writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                    else:\n",
        "                                        raise\n",
        "                                else:\n",
        "                                    raise\n",
        "                    except Exception as e:\n",
        "                        raise ExecutionError(\n",
        "                            f\"Failed to write table '{output_table}' with schema override: {e}\",\n",
        "                            context={\n",
        "                                \"step_name\": step.name,\n",
        "                                \"table\": output_table,\n",
        "                                \"schema_override\": str(schema_override),\n",
        "                            },\n",
        "                            suggestions=[\n",
        "                                \"Verify that the schema_override matches the DataFrame structure\",\n",
        "                                \"Check that all required columns are present in the DataFrame\",\n",
        "                                \"Ensure data types are compatible\",\n",
        "                            ],\n",
        "                        ) from e\n",
        "                else:\n",
        "                    # Normal write without schema override\n",
        "                    # Handle INITIAL mode schema changes - allow schema changes via CREATE OR REPLACE TABLE\n",
        "                    # For INCREMENTAL/FULL_REFRESH, schema validation already done above\n",
        "                    if mode == ExecutionMode.INITIAL and write_mode_str == \"append\":\n",
        "                        existing_schema = _get_existing_schema_safe(\n",
        "                            self.spark, output_table\n",
        "                        )\n",
        "                        if existing_schema is not None:\n",
        "                            # Check if schema is empty (catalog sync issue)\n",
        "                            schema_is_empty = (\n",
        "                                not existing_schema.fields\n",
        "                                or len(existing_schema.fields) == 0\n",
        "                            )\n",
        "                            output_schema = output_df.schema  # type: ignore[attr-defined]\n",
        "\n",
        "                            if schema_is_empty:\n",
        "                                # Catalog reports empty schema but table exists - use CREATE OR REPLACE TABLE\n",
        "                                self.logger.info(\n",
        "                                    f\"Table '{output_table}' exists but catalog reports empty schema. \"\n",
        "                                    f\"Using CREATE OR REPLACE TABLE for atomic schema replacement.\"\n",
        "                                )\n",
        "                                temp_view_name = (\n",
        "                                    f\"_temp_{step.name}_{uuid.uuid4().hex[:8]}\"\n",
        "                                )\n",
        "                                output_df.createOrReplaceTempView(temp_view_name)  # type: ignore[attr-defined]\n",
        "\n",
        "                                # For Delta tables, DROP then CREATE (CREATE OR REPLACE doesn't work with Delta)\n",
        "                                self.spark.sql(f\"DROP TABLE IF EXISTS {output_table}\")  # type: ignore[attr-defined]\n",
        "                                self.spark.sql(f\"\"\"\n",
        "                                    CREATE TABLE {output_table}\n",
        "                                    USING DELTA\n",
        "                                    AS SELECT * FROM {temp_view_name}\n",
        "                                \"\"\")  # type: ignore[attr-defined]\n",
        "\n",
        "                                try:\n",
        "                                    self.spark.sql(\n",
        "                                        f\"DROP VIEW IF EXISTS {temp_view_name}\"\n",
        "                                    )  # type: ignore[attr-defined]\n",
        "                                except Exception:\n",
        "                                    pass  # DROP VIEW cleanup best-effort; ignore failure\n",
        "\n",
        "                                # Skip normal write path - table already written\n",
        "                                writer = None\n",
        "                            else:\n",
        "                                # Schema exists and is not empty - check if it matches\n",
        "                                schemas_match, differences = _schemas_match(\n",
        "                                    existing_schema, output_schema\n",
        "                                )\n",
        "                                if not schemas_match:\n",
        "                                    # Schema differs - INITIAL mode allows schema changes via CREATE OR REPLACE TABLE\n",
        "                                    self.logger.info(\n",
        "                                        f\"Schema change detected for '{output_table}' in INITIAL mode. \"\n",
        "                                        f\"Using CREATE OR REPLACE TABLE for atomic schema replacement.\"\n",
        "                                    )\n",
        "                                    temp_view_name = (\n",
        "                                        f\"_temp_{step.name}_{uuid.uuid4().hex[:8]}\"\n",
        "                                    )\n",
        "                                    output_df.createOrReplaceTempView(temp_view_name)  # type: ignore[attr-defined]\n",
        "\n",
        "                                    # For Delta tables, DROP then CREATE (CREATE OR REPLACE doesn't work with Delta)\n",
        "                                    self.spark.sql(\n",
        "                                        f\"DROP TABLE IF EXISTS {output_table}\"\n",
        "                                    )  # type: ignore[attr-defined]\n",
        "                                    self.spark.sql(f\"\"\"\n",
        "                                        CREATE TABLE {output_table}\n",
        "                                        USING DELTA\n",
        "                                        AS SELECT * FROM {temp_view_name}\n",
        "                                    \"\"\")  # type: ignore[attr-defined]\n",
        "\n",
        "                                    try:\n",
        "                                        self.spark.sql(\n",
        "                                            f\"DROP VIEW IF EXISTS {temp_view_name}\"\n",
        "                                        )  # type: ignore[attr-defined]\n",
        "                                    except Exception:\n",
        "                                        pass  # DROP VIEW cleanup best-effort; ignore failure\n",
        "\n",
        "                                    # Skip normal write path - table already written\n",
        "                                    writer = None\n",
        "                                else:\n",
        "                                    # Schema matches - use DELETE + overwrite for Delta tables\n",
        "                                    # or CREATE OR REPLACE TABLE for atomic replacement\n",
        "                                    # Note: Delta Lake doesn't support append in batch mode, so we use overwrite\n",
        "                                    if _is_delta_lake_available_execution(self.spark):\n",
        "                                        # For Delta tables, use DELETE + overwrite (append not supported in batch mode)\n",
        "                                        try:\n",
        "                                            self.spark.sql(\n",
        "                                                f\"DELETE FROM {output_table}\"\n",
        "                                            )  # type: ignore[attr-defined]\n",
        "                                            # DELETE succeeded, use overwrite mode (append not supported in batch mode)\n",
        "                                            writer = _create_dataframe_writer(\n",
        "                                                output_df,\n",
        "                                                self.spark,\n",
        "                                                \"overwrite\",\n",
        "                                                table_name=output_table,\n",
        "                                            )\n",
        "                                        except Exception as delete_error:\n",
        "                                            # If DELETE fails, fall back to CREATE OR REPLACE TABLE\n",
        "                                            self.logger.warning(\n",
        "                                                f\"DELETE FROM failed for '{output_table}': {delete_error}. \"\n",
        "                                                f\"Using CREATE OR REPLACE TABLE instead.\"\n",
        "                                            )\n",
        "                                            temp_view_name = f\"_temp_{step.name}_{uuid.uuid4().hex[:8]}\"\n",
        "                                            output_df.createOrReplaceTempView(\n",
        "                                                temp_view_name\n",
        "                                            )  # type: ignore[attr-defined]\n",
        "                                            self.spark.sql(f\"\"\"\n",
        "                                                CREATE OR REPLACE TABLE {output_table}\n",
        "                                                USING DELTA\n",
        "                                                AS SELECT * FROM {temp_view_name}\n",
        "                                            \"\"\")  # type: ignore[attr-defined]\n",
        "                                            try:\n",
        "                                                self.spark.sql(\n",
        "                                                    f\"DROP VIEW IF EXISTS {temp_view_name}\"\n",
        "                                                )  # type: ignore[attr-defined]\n",
        "                                            except Exception:\n",
        "                                                pass  # DROP VIEW cleanup best-effort\n",
        "                                            writer = None\n",
        "                                    else:\n",
        "                                        # Not Delta table, use normal overwrite\n",
        "                                        writer = _create_dataframe_writer(\n",
        "                                            output_df,\n",
        "                                            self.spark,\n",
        "                                            \"overwrite\",\n",
        "                                            table_name=output_table,\n",
        "                                        )\n",
        "                        else:\n",
        "                            # Table doesn't exist - proceed with normal write\n",
        "                            writer = _create_dataframe_writer(\n",
        "                                output_df,\n",
        "                                self.spark,\n",
        "                                write_mode_str,\n",
        "                                table_name=output_table,\n",
        "                            )\n",
        "                    # Heal catalog entries that report empty schema (struct<>) before choosing writer\n",
        "                    if table_exists(self.spark, output_table) and table_schema_is_empty(\n",
        "                        self.spark, output_table\n",
        "                    ):\n",
        "                        self.logger.warning(\n",
        "                            f\"Catalog reports empty schema for '{output_table}'. Dropping table to recreate with correct schema.\"\n",
        "                        )\n",
        "                        try:\n",
        "                            self.spark.sql(f\"DROP TABLE IF EXISTS {output_table}\")  # type: ignore[attr-defined]\n",
        "                        except Exception:\n",
        "                            pass  # DROP TABLE best-effort before overwrite; write may still succeed\n",
        "\n",
        "                    # Create writer with appropriate mode\n",
        "                    writer = _create_dataframe_writer(\n",
        "                        output_df, self.spark, write_mode_str, table_name=output_table\n",
        "                    )\n",
        "\n",
        "                    # Execute write\n",
        "                    if writer is not None:\n",
        "                        try:\n",
        "                            writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                        except Exception as write_error:\n",
        "                            error_msg = str(write_error).lower()\n",
        "                            # Handle catalog sync issues where Spark reports empty schema (struct<>)\n",
        "                            if (\n",
        "                                \"struct<>\" in error_msg\n",
        "                                or \"column number of the existing table\" in error_msg\n",
        "                            ):\n",
        "                                # This is a catalog sync issue - try refreshing the table and retrying\n",
        "                                self.logger.warning(\n",
        "                                    f\"Catalog sync issue detected for table '{output_table}'. \"\n",
        "                                    f\"Refreshing table and retrying write.\"\n",
        "                                )\n",
        "                                try:\n",
        "                                    # Refresh table and force schema re-read by reading actual data\n",
        "                                    self.spark.sql(f\"REFRESH TABLE {output_table}\")  # type: ignore[attr-defined]\n",
        "                                    # Force Spark to re-read schema by reading a sample row\n",
        "                                    try:\n",
        "                                        sample_df = self.spark.sql(\n",
        "                                            f\"SELECT * FROM {output_table} LIMIT 1\"\n",
        "                                        )  # type: ignore[attr-defined]\n",
        "                                        _ = sample_df.schema  # Force schema evaluation\n",
        "                                    except Exception:\n",
        "                                        pass  # Ignore errors when reading sample\n",
        "\n",
        "                                    # Try SQL-based INSERT for Delta tables (works even with catalog sync issues)\n",
        "                                    if (\n",
        "                                        _is_delta_lake_available_execution(self.spark)\n",
        "                                        and write_mode_str == \"append\"\n",
        "                                    ):\n",
        "                                        temp_view_name = (\n",
        "                                            f\"_temp_{step.name}_{uuid.uuid4().hex[:8]}\"\n",
        "                                        )\n",
        "                                        output_df.createOrReplaceTempView(\n",
        "                                            temp_view_name\n",
        "                                        )  # type: ignore[attr-defined]\n",
        "                                        try:\n",
        "                                            self.spark.sql(\n",
        "                                                f\"INSERT INTO {output_table} SELECT * FROM {temp_view_name}\"\n",
        "                                            )  # type: ignore[attr-defined]\n",
        "                                            # Success - clean up and skip normal write path\n",
        "                                            try:\n",
        "                                                self.spark.sql(\n",
        "                                                    f\"DROP VIEW IF EXISTS {temp_view_name}\"\n",
        "                                                )  # type: ignore[attr-defined]\n",
        "                                            except Exception:\n",
        "                                                pass  # DROP VIEW cleanup best-effort\n",
        "                                            writer = None  # Mark writer as None to skip normal write\n",
        "                                            # Exit the retry block - write succeeded via SQL INSERT\n",
        "                                        except Exception:\n",
        "                                            # SQL INSERT also failed - try normal write as fallback\n",
        "                                            try:\n",
        "                                                self.spark.sql(\n",
        "                                                    f\"DROP VIEW IF EXISTS {temp_view_name}\"\n",
        "                                                )  # type: ignore[attr-defined]\n",
        "                                            except Exception:\n",
        "                                                pass  # DROP VIEW cleanup best-effort before fallback write\n",
        "                                            writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                    else:\n",
        "                                        # Retry the write after refresh\n",
        "                                        writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                except Exception as retry_error:\n",
        "                                    # Attempt to heal catalog by recreating table with existing + new data\n",
        "                                    healed = False\n",
        "                                    # For Gold steps, we can safely rebuild the table from the fresh output\n",
        "                                    if step_type == StepType.GOLD:\n",
        "                                        try:\n",
        "                                            self.spark.sql(\n",
        "                                                f\"DROP TABLE IF EXISTS {output_table}\"\n",
        "                                            )  # type: ignore[attr-defined]\n",
        "                                            direct_writer = _create_dataframe_writer(\n",
        "                                                output_df,\n",
        "                                                self.spark,\n",
        "                                                \"overwrite\",\n",
        "                                                table_name=output_table,\n",
        "                                                overwriteSchema=\"true\",\n",
        "                                            )\n",
        "                                            direct_writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                            healed = True\n",
        "                                            writer = None\n",
        "                                        except Exception:\n",
        "                                            healed = False\n",
        "\n",
        "                                    if not healed:\n",
        "                                        try:\n",
        "                                            base_df = None\n",
        "                                            if _is_delta_lake_available_execution(\n",
        "                                                self.spark\n",
        "                                            ):\n",
        "                                                try:\n",
        "                                                    delta_tbl = DeltaTable.forName(\n",
        "                                                        self.spark, output_table\n",
        "                                                    )  # type: ignore[attr-defined]\n",
        "                                                    base_df = delta_tbl.toDF()\n",
        "                                                except Exception:\n",
        "                                                    base_df = None\n",
        "                                            if base_df is not None:\n",
        "                                                combined_df = base_df.unionByName(  # type: ignore[attr-defined]\n",
        "                                                    output_df, allowMissingColumns=True\n",
        "                                                )\n",
        "                                            else:\n",
        "                                                combined_df = output_df\n",
        "\n",
        "                                            temp_view_name = f\"_heal_{step.name}_{uuid.uuid4().hex[:8]}\"\n",
        "                                            combined_df.createOrReplaceTempView(\n",
        "                                                temp_view_name\n",
        "                                            )  # type: ignore[attr-defined]\n",
        "                                            try:\n",
        "                                                # Always drop then create to avoid truncate/replace limitations\n",
        "                                                self.spark.sql(\n",
        "                                                    f\"DROP TABLE IF EXISTS {output_table}\"\n",
        "                                                )  # type: ignore[attr-defined]\n",
        "                                                if _is_delta_lake_available_execution(\n",
        "                                                    self.spark\n",
        "                                                ):\n",
        "                                                    self.spark.sql(  # type: ignore[attr-defined]\n",
        "                                                        f\"CREATE TABLE {output_table} USING DELTA AS SELECT * FROM {temp_view_name}\"\n",
        "                                                    )\n",
        "                                                else:\n",
        "                                                    self.spark.sql(  # type: ignore[attr-defined]\n",
        "                                                        f\"CREATE TABLE {output_table} USING PARQUET AS SELECT * FROM {temp_view_name}\"\n",
        "                                                    )\n",
        "                                                healed = True\n",
        "                                            finally:\n",
        "                                                try:\n",
        "                                                    self.spark.sql(\n",
        "                                                        f\"DROP VIEW IF EXISTS {temp_view_name}\"\n",
        "                                                    )  # type: ignore[attr-defined]\n",
        "                                                except Exception:\n",
        "                                                    pass  # DROP VIEW cleanup best-effort\n",
        "                                        except Exception:\n",
        "                                            healed = False\n",
        "\n",
        "                                    if not healed:\n",
        "                                        # Last-resort fix for catalog sync issues: drop and recreate the table when safe.\n",
        "                                        try:\n",
        "                                            if mode == ExecutionMode.INITIAL:\n",
        "                                                self.spark.sql(\n",
        "                                                    f\"DROP TABLE IF EXISTS {output_table}\"\n",
        "                                                )  # type: ignore[attr-defined]\n",
        "                                                writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                            else:\n",
        "                                                raise retry_error\n",
        "                                        except Exception as drop_error:\n",
        "                                            # If drop+rewrite fails, convert to ExecutionError with helpful message\n",
        "                                            raise ExecutionError(\n",
        "                                                f\"Schema validation failed for table '{output_table}' in {mode} mode. \"\n",
        "                                                f\"Catalog reports empty schema (struct<>), indicating a catalog sync issue. \"\n",
        "                                                f\"Original error: {write_error}\",\n",
        "                                                context={\n",
        "                                                    \"step_name\": step.name,\n",
        "                                                    \"table\": output_table,\n",
        "                                                    \"mode\": mode.value,\n",
        "                                                    \"original_error\": str(write_error),\n",
        "                                                    \"retry_error\": str(retry_error),\n",
        "                                                    \"drop_error\": str(drop_error),\n",
        "                                                },\n",
        "                                                suggestions=[\n",
        "                                                    \"This may be a Spark/Delta Lake catalog sync issue\",\n",
        "                                                    \"Try running the pipeline again\",\n",
        "                                                    \"If the issue persists, use INITIAL mode to recreate the table\",\n",
        "                                                ],\n",
        "                                            ) from drop_error\n",
        "                                    else:\n",
        "                                        # Table healed via recreate; skip normal writer path\n",
        "                                        writer = None\n",
        "                            # Handle race condition where table might be created by another thread\n",
        "                            elif (\n",
        "                                \"already exists\" in error_msg\n",
        "                                or \"table_or_view_already_exists\" in error_msg\n",
        "                            ):\n",
        "                                # Table was created by another thread - verify it exists and retry with overwrite mode\n",
        "                                if table_exists(self.spark, output_table):\n",
        "                                    self.logger.debug(\n",
        "                                        f\"Table {output_table} was created by another thread, retrying with overwrite mode\"\n",
        "                                    )\n",
        "                                    # Retry with overwrite mode (append not supported in batch mode for Delta)\n",
        "                                    retry_writer = _create_dataframe_writer(\n",
        "                                        output_df,\n",
        "                                        self.spark,\n",
        "                                        \"overwrite\",\n",
        "                                        table_name=output_table,\n",
        "                                    )\n",
        "                                    retry_writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                                else:\n",
        "                                    raise\n",
        "                            else:\n",
        "                                # Different error - re-raise\n",
        "                                raise\n",
        "                        finally:\n",
        "                            pass\n",
        "\n",
        "                        # Refresh table metadata after write to ensure subsequent reads see the latest data\n",
        "                        try:\n",
        "                            self.spark.sql(f\"REFRESH TABLE {output_table}\")  # type: ignore[attr-defined]\n",
        "                        except Exception as refresh_error:\n",
        "                            # Refresh might fail for some table types or if table doesn't exist - log but don't fail\n",
        "                            self.logger.debug(\n",
        "                                f\"Could not refresh table {output_table} after write: {refresh_error}\"\n",
        "                            )\n",
        "\n",
        "                result.output_table = output_table\n",
        "                result.rows_processed = output_df.count()  # type: ignore[attr-defined]\n",
        "\n",
        "                # Set write mode in result for tracking\n",
        "                result.write_mode = write_mode_str  # type: ignore[attr-defined]\n",
        "            elif step_type == StepType.BRONZE:\n",
        "                # Bronze steps only validate data, don't write to tables\n",
        "                result.rows_processed = output_df.count()  # type: ignore[attr-defined]\n",
        "                result.write_mode = None  # type: ignore[attr-defined]\n",
        "            else:\n",
        "                # No write: VALIDATION_ONLY execution mode or validation-only step (with_silver_rules / with_gold_rules)\n",
        "                result.rows_processed = output_df.count()  # type: ignore[attr-defined]\n",
        "                result.write_mode = None  # type: ignore[attr-defined]\n",
        "\n",
        "            # Validation-only steps (with_silver_rules / with_gold_rules) never write; ensure report reflects that\n",
        "            if _is_validation_only_step:\n",
        "                result.write_mode = None  # type: ignore[attr-defined]\n",
        "                result.output_table = None  # type: ignore[attr-defined]\n",
        "\n",
        "            # Collect final resource metrics\n",
        "            end_memory, end_cpu = self._collect_resource_metrics()\n",
        "\n",
        "            # Calculate metrics (use end values, or delta if both available)\n",
        "            if end_memory is not None:\n",
        "                if start_memory is not None:\n",
        "                    # Use peak memory (difference) or end memory\n",
        "                    result.memory_usage_mb = max(end_memory - start_memory, end_memory)\n",
        "                else:\n",
        "                    result.memory_usage_mb = end_memory\n",
        "            if end_cpu is not None:\n",
        "                result.cpu_usage_percent = end_cpu\n",
        "\n",
        "            result.status = StepStatus.COMPLETED\n",
        "            result.end_time = datetime.now()\n",
        "            result.duration = (result.end_time - result.start_time).total_seconds()\n",
        "\n",
        "            # Populate result fields\n",
        "            rows_processed = result.rows_processed or 0\n",
        "            # For Silver/Gold steps that write, rows_written equals rows_processed\n",
        "            # Bronze and validation-only steps (with_silver_rules / with_gold_rules) don't write\n",
        "            if step_type == StepType.BRONZE or _is_validation_only_step:\n",
        "                rows_written = None\n",
        "            else:\n",
        "                rows_written = rows_processed\n",
        "\n",
        "            result.rows_written = rows_written\n",
        "            result.input_rows = rows_processed\n",
        "            result.validation_rate = (\n",
        "                validation_rate if validation_rate is not None else 100.0\n",
        "            )\n",
        "\n",
        "            # Note: output_df is already stored in context immediately after execution\n",
        "            # (for Silver and Gold steps) to ensure prior_silvers is populated for downstream steps\n",
        "\n",
        "            # Use logger's step_complete method for consistent formatting with emoji and uppercase\n",
        "            # rows_written can be None for Bronze steps, but logger expects int, so use 0 as fallback\n",
        "            self.logger.step_complete(\n",
        "                step_type.value,\n",
        "                step.name,\n",
        "                result.duration,\n",
        "                rows_processed=rows_processed,\n",
        "                rows_written=rows_written if rows_written is not None else 0,\n",
        "                invalid_rows=invalid_rows,\n",
        "                validation_rate=validation_rate,\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle truncate error for Delta tables - retry with table drop\n",
        "            error_msg = str(e).lower()\n",
        "            if (\n",
        "                \"truncate\" in error_msg\n",
        "                and \"batch mode\" in error_msg\n",
        "                and step_type != StepType.BRONZE\n",
        "            ):\n",
        "                # This is a Delta table truncate error - try to fix it\n",
        "                table_name = getattr(step, \"table_name\", step.name)\n",
        "                schema = getattr(step, \"schema\", None)\n",
        "                if (\n",
        "                    schema is not None\n",
        "                    and hasattr(self, \"write_service\")\n",
        "                    and output_df is not None\n",
        "                ):\n",
        "                    output_table = fqn(schema, table_name)\n",
        "                    self.logger.warning(\n",
        "                        f\"Delta table truncate error for {output_table}, attempting to drop and retry write\"\n",
        "                    )\n",
        "                    try:\n",
        "                        # Drop the table (without CASCADE - not supported in all Spark versions)\n",
        "                        self.spark.sql(f\"DROP TABLE IF EXISTS {output_table}\")  # type: ignore[attr-defined]\n",
        "                        import time\n",
        "\n",
        "                        time.sleep(0.2)  # Brief delay for catalog sync\n",
        "                        # Retry the write using append mode (since table is dropped, append will create it)\n",
        "                        # This avoids the truncate issue entirely\n",
        "                        writer = _create_dataframe_writer(\n",
        "                            output_df,\n",
        "                            self.spark,\n",
        "                            \"append\",  # Use append after drop to avoid truncate\n",
        "                            table_name=output_table,\n",
        "                        )\n",
        "                        writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "                        rows_written = output_df.count()  # type: ignore[attr-defined]\n",
        "                        # If we get here, the retry succeeded - update result and continue\n",
        "                        result.status = StepStatus.COMPLETED\n",
        "                        result.rows_written = rows_written\n",
        "                        result.rows_processed = rows_written\n",
        "                        result.end_time = datetime.now()\n",
        "                        result.duration = (\n",
        "                            result.end_time - result.start_time\n",
        "                        ).total_seconds()\n",
        "                        self.logger.info(\n",
        "                            f\"\u2705 Completed {step_type.value.upper()} step: {step.name} ({result.duration:.2f}s) - {rows_written} rows written (after truncate retry)\"\n",
        "                        )\n",
        "                        return result\n",
        "                    except Exception as retry_error:\n",
        "                        # Retry also failed - fall through to normal error handling\n",
        "                        self.logger.error(\n",
        "                            f\"Retry after truncate error also failed: {retry_error}\"\n",
        "                        )\n",
        "                        e = retry_error  # Use retry error for final error message\n",
        "\n",
        "            # Collect final resource metrics even on failure\n",
        "            end_memory, end_cpu = self._collect_resource_metrics()\n",
        "\n",
        "            # Calculate metrics (use end values, or delta if both available)\n",
        "            if end_memory is not None:\n",
        "                if start_memory is not None:\n",
        "                    # Use peak memory (difference) or end memory\n",
        "                    result.memory_usage_mb = max(end_memory - start_memory, end_memory)\n",
        "                else:\n",
        "                    result.memory_usage_mb = end_memory\n",
        "            if end_cpu is not None:\n",
        "                result.cpu_usage_percent = end_cpu\n",
        "\n",
        "            result.status = StepStatus.FAILED\n",
        "            result.error = str(e)\n",
        "            result.end_time = datetime.now()\n",
        "            result.duration = (result.end_time - result.start_time).total_seconds()\n",
        "\n",
        "            # Log step failure\n",
        "            self.logger.error(\n",
        "                f\"\u274c Failed {step_type.value.upper()} step: {step.name} ({result.duration:.2f}s) - {str(e)}\"\n",
        "            )\n",
        "            raise ExecutionError(f\"Step execution failed: {e}\") from e\n",
        "\n",
        "        return result\n",
        "\n",
        "    def execute_pipeline(\n",
        "        self,\n",
        "        steps: list[Union[BronzeStep, SilverStep, GoldStep]],\n",
        "        mode: ExecutionMode = ExecutionMode.INITIAL,\n",
        "        context: Optional[Dict[str, DataFrame]] = None,  # type: ignore[valid-type]\n",
        "        step_params: Optional[Dict[str, Dict[str, Any]]] = None,\n",
        "        stop_after_step: Optional[str] = None,\n",
        "        start_at_step: Optional[str] = None,\n",
        "        write_outputs: bool = True,\n",
        "        execution_order: Optional[list[str]] = None,\n",
        "    ) -> ExecutionResult:\n",
        "        \"\"\"Execute a complete pipeline with dependency-aware sequential execution.\n",
        "\n",
        "        Analyzes step dependencies and executes steps sequentially in the correct\n",
        "        order using topological sort. Steps execute one at a time in dependency\n",
        "        order to respect dependency constraints.\n",
        "\n",
        "        Args:\n",
        "            steps: List of steps to execute. Can include Bronze, Silver, and\n",
        "                Gold steps in any order - dependencies are automatically analyzed.\n",
        "            mode: Execution mode (INITIAL, INCREMENTAL, FULL_REFRESH,\n",
        "                VALIDATION_ONLY). Defaults to INITIAL.\n",
        "            context: Optional initial execution context dictionary mapping step\n",
        "                names to DataFrames. Must contain bronze source data. If None,\n",
        "                empty dictionary is used.\n",
        "            step_params: Optional dictionary mapping step names to parameter\n",
        "                dictionaries. These parameters will be passed to the step's\n",
        "                transform function if it accepts a 'params' argument or **kwargs.\n",
        "            stop_after_step: Optional step name. If provided, execution stops\n",
        "                after this step completes (inclusive). Useful for debugging\n",
        "                or partial pipeline execution.\n",
        "            start_at_step: Optional step name. If provided, execution begins\n",
        "                at this step, skipping earlier steps. Earlier step outputs\n",
        "                must exist in context or be readable from tables.\n",
        "            write_outputs: If True, write step outputs to Delta Lake tables.\n",
        "                If False, skip writing (useful for debugging/iteration).\n",
        "                Defaults to True.\n",
        "            execution_order: Optional pre-computed step order (e.g. from PipelineBuilder).\n",
        "                When provided, this order is used so execution matches to_pipeline() report.\n",
        "\n",
        "        Returns:\n",
        "            ExecutionResult containing:\n",
        "            - Overall pipeline status\n",
        "            - List of StepExecutionResult for each step\n",
        "            - Execution timing\n",
        "            - Dependency analysis results\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If pipeline execution fails.\n",
        "            TypeError: If context is not a dictionary.\n",
        "\n",
        "        Example:\n",
        "            >>> config = PipelineConfig.create_default(schema=\"my_schema\")\n",
        "            >>> engine = ExecutionEngine(spark, config)\n",
        "            >>> result = engine.execute_pipeline(\n",
        "            ...     steps=[bronze, silver1, silver2, gold],\n",
        "            ...     mode=ExecutionMode.INITIAL,\n",
        "            ...     context={\"events\": source_df}\n",
        "            ... )\n",
        "            >>> print(f\"Status: {result.status}\")\n",
        "            >>> print(f\"Steps executed: {len(result.steps) if result.steps else 0}\")\n",
        "            >>> print(f\"Execution order: {[s.step_name for s in result.steps] if result.steps else []}\")\n",
        "            >>> print(f\"Steps completed: {len([s for s in result.steps if s.status == StepStatus.COMPLETED])}\")\n",
        "\n",
        "        Note:\n",
        "            - All required schemas are created upfront before execution\n",
        "            - Steps are ordered by dependencies using DependencyAnalyzer (topological sort)\n",
        "            - Steps execute sequentially one at a time in dependency order\n",
        "            - Context is updated after each step completion for downstream steps\n",
        "            - Failed steps are recorded but don't stop execution of remaining steps\n",
        "        \"\"\"\n",
        "        execution_id = str(uuid.uuid4())\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        result = ExecutionResult(\n",
        "            execution_id=execution_id,\n",
        "            mode=mode,\n",
        "            start_time=start_time,\n",
        "            status=\"running\",\n",
        "        )\n",
        "\n",
        "        # Disable Delta's strict schema-on-read check for the whole run so validation-only\n",
        "        # steps (with_silver_rules / with_gold_rules) can read existing tables even if\n",
        "        # schema evolved. Restored in finally.\n",
        "        _delta_check_key = \"spark.databricks.delta.checkLatestSchemaOnRead\"\n",
        "        _delta_check_prev = None\n",
        "        try:\n",
        "            _delta_check_prev = self.spark.conf.get(_delta_check_key)  # type: ignore[attr-defined]\n",
        "        except Exception:\n",
        "            pass  # Spark config get may not exist; use set/unset only\n",
        "        try:\n",
        "            self.spark.conf.set(_delta_check_key, \"false\")  # type: ignore[attr-defined]\n",
        "        except Exception:\n",
        "            pass  # Disable Delta constraint check best-effort\n",
        "        try:\n",
        "            self.spark.sql(f\"SET {_delta_check_key}=false\")  # type: ignore[attr-defined]\n",
        "        except Exception:\n",
        "            pass  # SQL SET may not be supported; continue\n",
        "\n",
        "        try:\n",
        "            # Logging is handled by the runner to avoid duplicate messages\n",
        "            # Ensure all required schemas exist before execution\n",
        "            # Collect unique schemas from all steps\n",
        "            required_schemas = set()\n",
        "            for step in steps:\n",
        "                if hasattr(step, \"schema\") and step.schema:  # type: ignore[attr-defined]\n",
        "                    schema_value = step.schema  # type: ignore[attr-defined]\n",
        "                    # Handle both string schemas and Mock objects (for tests)\n",
        "                    if isinstance(schema_value, str):\n",
        "                        required_schemas.add(schema_value)\n",
        "            # Create all required schemas upfront - always try to create, don't rely on catalog checks\n",
        "            for schema in required_schemas:\n",
        "                try:\n",
        "                    # Always try to create schema - CREATE SCHEMA IF NOT EXISTS is idempotent\n",
        "                    self.spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema}\")  # type: ignore[attr-defined]\n",
        "                    # Also use _ensure_schema_exists as backup (tries multiple methods)\n",
        "                    self._ensure_schema_exists(schema)\n",
        "                except Exception as e:\n",
        "                    # Log but don't fail - schema might already exist or creation might work later\n",
        "                    self.logger.debug(f\"Schema '{schema}' pre-creation attempt: {e}\")\n",
        "\n",
        "            # Validate context parameter\n",
        "            if context is None:\n",
        "                context = {}\n",
        "            elif not isinstance(context, dict):\n",
        "                raise TypeError(f\"context must be a dictionary, got {type(context)}\")\n",
        "\n",
        "            # Create a mapping of step names to step objects (needed for start_at_step handling)\n",
        "            step_map = {s.name: s for s in steps}\n",
        "\n",
        "            # Use provided execution order (from builder) or compute via dependency analysis\n",
        "            if execution_order:\n",
        "                # Restrict to steps actually in this run; use only if it covers all steps\n",
        "                ordered = [n for n in execution_order if n in step_map]\n",
        "                if set(ordered) != set(step_map):\n",
        "                    execution_order = None  # subset or mismatch: fall back to analyzer\n",
        "                else:\n",
        "                    execution_order = ordered\n",
        "            if not execution_order:\n",
        "                # Group steps by type for dependency analysis\n",
        "                bronze_steps = [s for s in steps if s.step_type.value == \"bronze\"]\n",
        "                silver_steps = [s for s in steps if s.step_type.value == \"silver\"]\n",
        "                gold_steps = [s for s in steps if s.step_type.value == \"gold\"]\n",
        "                analyzer = DependencyAnalyzer()\n",
        "                analysis = analyzer.analyze_dependencies(\n",
        "                    bronze_steps={s.name: s for s in bronze_steps},\n",
        "                    silver_steps={s.name: s for s in silver_steps},\n",
        "                    gold_steps={s.name: s for s in gold_steps},\n",
        "                )\n",
        "                execution_order = analysis.execution_order\n",
        "\n",
        "            # Create a mapping of step names to step types (needed for prior_golds building)\n",
        "            step_types = {s.name: s.step_type.value for s in steps}\n",
        "\n",
        "            # Handle start_at_step: filter execution order and load earlier outputs\n",
        "            if start_at_step is not None:\n",
        "                if start_at_step not in execution_order:\n",
        "                    raise ExecutionError(\n",
        "                        f\"start_at_step '{start_at_step}' not found in execution order. \"\n",
        "                        f\"Available steps: {execution_order}\"\n",
        "                    )\n",
        "                start_index = execution_order.index(start_at_step)\n",
        "                skipped_steps = execution_order[:start_index]\n",
        "                execution_order = execution_order[start_index:]\n",
        "\n",
        "                # Try to load outputs from skipped steps if not in context\n",
        "                for skipped_name in skipped_steps:\n",
        "                    if skipped_name not in context:\n",
        "                        skipped_step = step_map.get(skipped_name)\n",
        "                        if skipped_step is not None:\n",
        "                            # Try to read from table if it's a Silver/Gold step\n",
        "                            if skipped_step.step_type.value in (\"silver\", \"gold\"):\n",
        "                                table_name = getattr(\n",
        "                                    skipped_step, \"table_name\", skipped_name\n",
        "                                )\n",
        "                                schema = getattr(skipped_step, \"schema\", None)\n",
        "                                if schema is not None:\n",
        "                                    table_fqn = fqn(schema, table_name)\n",
        "                                    try:\n",
        "                                        if table_exists(self.spark, table_fqn):\n",
        "                                            context[skipped_name] = self.spark.table(\n",
        "                                                table_fqn\n",
        "                                            )  # type: ignore[attr-defined,valid-type]\n",
        "                                            self.logger.info(\n",
        "                                                f\"Loaded output for skipped step '{skipped_name}' from table '{table_fqn}'\"\n",
        "                                            )\n",
        "                                        else:\n",
        "                                            self.logger.warning(\n",
        "                                                f\"Step '{skipped_name}' output not in context and table '{table_fqn}' does not exist. \"\n",
        "                                                f\"Downstream steps may fail.\"\n",
        "                                            )\n",
        "                                    except Exception as e:\n",
        "                                        self.logger.warning(\n",
        "                                            f\"Could not load output for skipped step '{skipped_name}' from table '{table_fqn}': {e}\"\n",
        "                                        )\n",
        "                            else:\n",
        "                                # Bronze step - must be in context\n",
        "                                self.logger.warning(\n",
        "                                    f\"Bronze step '{skipped_name}' output not in context. \"\n",
        "                                    f\"Bronze steps must be provided in context when using start_at_step.\"\n",
        "                                )\n",
        "\n",
        "                self.logger.info(\n",
        "                    f\"Starting execution at step '{start_at_step}' (skipped {len(skipped_steps)} earlier steps)\"\n",
        "                )\n",
        "\n",
        "            # Log dependency analysis results\n",
        "            self.logger.info(\n",
        "                f\"Dependency analysis complete: {len(execution_order)} steps to execute\"\n",
        "            )\n",
        "\n",
        "            # Execute steps in dependency order\n",
        "            for step_name in execution_order:\n",
        "                if step_name not in step_map:\n",
        "                    self.logger.warning(\n",
        "                        f\"Step {step_name} in execution order but not found in step list\"\n",
        "                    )\n",
        "                    continue\n",
        "\n",
        "                step = step_map[step_name]\n",
        "                try:\n",
        "                    # Get step-specific params if provided\n",
        "                    current_step_params = None\n",
        "                    if step_params is not None and step_name in step_params:\n",
        "                        current_step_params = step_params[step_name]\n",
        "\n",
        "                    step_result = self.execute_step(\n",
        "                        step,\n",
        "                        context,\n",
        "                        mode,\n",
        "                        step_params=current_step_params,\n",
        "                        write_outputs=write_outputs,\n",
        "                        step_types=step_types,\n",
        "                    )\n",
        "                    if result.steps is not None:\n",
        "                        result.steps.append(step_result)\n",
        "\n",
        "                    # Update context with step output for downstream steps\n",
        "                    # Note: output_df is already stored in context by execute_step after completion\n",
        "                    # If write_outputs is True, refresh from table to ensure we have the latest persisted data\n",
        "                    # If write_outputs is False, keep the in-memory DataFrame (no table was written)\n",
        "                    if (\n",
        "                        step_result.status == StepStatus.COMPLETED\n",
        "                        and step_result.step_type != StepType.BRONZE\n",
        "                        and write_outputs\n",
        "                    ):\n",
        "                        table_name = getattr(step, \"table_name\", step.name)\n",
        "                        schema = getattr(step, \"schema\", None)\n",
        "                        if schema is not None:\n",
        "                            table_fqn = fqn(schema, table_name)\n",
        "                            try:\n",
        "                                # Refresh table first to ensure we see the latest data\n",
        "                                try:\n",
        "                                    self.spark.sql(f\"REFRESH TABLE {table_fqn}\")  # type: ignore[attr-defined]\n",
        "                                except Exception:\n",
        "                                    pass  # Refresh might fail for some table types - continue anyway\n",
        "                                # Read table and add to context (overwrites output_df with table data)\n",
        "                                # Only update if read succeeds - if it fails, keep the output_df from execute_step\n",
        "                                table_df = self.spark.table(table_fqn)  # type: ignore[attr-defined,valid-type]\n",
        "                                context[step.name] = table_df  # type: ignore[valid-type]\n",
        "                            except Exception as e:\n",
        "                                # If reading fails, the output_df stored by execute_step is still in context\n",
        "                                # This is fine - we'll use the output_df that was stored during execution\n",
        "                                # Only log if the step name is not already in context (meaning execute_step didn't store it)\n",
        "                                if step.name not in context:\n",
        "                                    self.logger.warning(\n",
        "                                        f\"Could not read table '{table_fqn}' to add to context, \"\n",
        "                                        f\"and execute_step did not store output_df. \"\n",
        "                                        f\"Downstream steps may not have access to this step's output. Error: {e}\"\n",
        "                                    )\n",
        "                                else:\n",
        "                                    self.logger.debug(\n",
        "                                        f\"Could not read table '{table_fqn}' to refresh context. \"\n",
        "                                        f\"Using output_df stored during execution. Error: {e}\"\n",
        "                                    )\n",
        "                    elif (\n",
        "                        step_result.status == StepStatus.COMPLETED\n",
        "                        and step_result.step_type != StepType.BRONZE\n",
        "                        and not write_outputs\n",
        "                    ):\n",
        "                        # When write_outputs is False, ensure context has the in-memory DataFrame\n",
        "                        # (execute_step already stored it, but we want to make sure it's there)\n",
        "                        if step.name not in context:\n",
        "                            self.logger.warning(\n",
        "                                f\"Step '{step.name}' completed but output not in context. \"\n",
        "                                f\"This may indicate an issue with execute_step.\"\n",
        "                            )\n",
        "\n",
        "                    if step_result.status == StepStatus.FAILED:\n",
        "                        self.logger.error(\n",
        "                            f\"Step {step_name} failed: {step_result.error}\"\n",
        "                        )\n",
        "\n",
        "                    # Check if we should stop after this step\n",
        "                    if stop_after_step is not None and step_name == stop_after_step:\n",
        "                        self.logger.info(\n",
        "                            f\"Stopping execution after step '{stop_after_step}' as requested\"\n",
        "                        )\n",
        "                        # Mark result as completed (even if some steps were skipped)\n",
        "                        result.status = \"completed\"\n",
        "                        result.end_time = datetime.now()\n",
        "                        return result\n",
        "\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Exception executing step {step_name}: {e}\")\n",
        "                    # Determine correct step type\n",
        "                    step_obj = step_map.get(step_name)\n",
        "                    if step_obj is not None:\n",
        "                        phase = step_obj.step_type\n",
        "                        if phase.value == \"bronze\":\n",
        "                            step_type_enum = StepType.BRONZE\n",
        "                        elif phase.value == \"silver\":\n",
        "                            step_type_enum = StepType.SILVER\n",
        "                        elif phase.value == \"gold\":\n",
        "                            step_type_enum = StepType.GOLD\n",
        "                        else:\n",
        "                            step_type_enum = StepType.BRONZE  # fallback\n",
        "                    else:\n",
        "                        step_type_enum = StepType.BRONZE  # fallback\n",
        "\n",
        "                    step_result = StepExecutionResult(\n",
        "                        step_name=step_name,\n",
        "                        step_type=step_type_enum,\n",
        "                        status=StepStatus.FAILED,\n",
        "                        error=str(e),\n",
        "                        start_time=datetime.now(),\n",
        "                        end_time=datetime.now(),\n",
        "                        duration=0.0,\n",
        "                    )\n",
        "                    if result.steps is not None:\n",
        "                        result.steps.append(step_result)\n",
        "\n",
        "            # Determine overall pipeline status based on step results\n",
        "            if result.steps is None:\n",
        "                result.steps = []\n",
        "            step_results: list[StepExecutionResult] = result.steps\n",
        "            failed_steps = [s for s in step_results if s.status == StepStatus.FAILED]\n",
        "\n",
        "            if failed_steps:\n",
        "                result.status = \"failed\"\n",
        "                self.logger.error(\n",
        "                    f\"Pipeline execution failed: {len(failed_steps)} steps failed\"\n",
        "                )\n",
        "            else:\n",
        "                result.status = \"completed\"\n",
        "                self.logger.info(f\"Completed pipeline execution: {execution_id}\")\n",
        "\n",
        "            result.end_time = datetime.now()\n",
        "\n",
        "        except Exception as e:\n",
        "            result.status = \"failed\"\n",
        "            result.error = str(e)\n",
        "            result.end_time = datetime.now()\n",
        "            self.logger.error(f\"Pipeline execution failed: {e}\")\n",
        "            raise ExecutionError(f\"Pipeline execution failed: {e}\") from e\n",
        "        finally:\n",
        "            if _delta_check_prev is not None:\n",
        "                try:\n",
        "                    self.spark.conf.set(_delta_check_key, _delta_check_prev)  # type: ignore[attr-defined]\n",
        "                except Exception:\n",
        "                    pass  # Restore config best-effort; test isolation may not need it\n",
        "            else:\n",
        "                try:\n",
        "                    self.spark.conf.unset(_delta_check_key)  # type: ignore[attr-defined]\n",
        "                except Exception:\n",
        "                    pass  # Unset config best-effort\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _execute_bronze_step(\n",
        "        self,\n",
        "        step: BronzeStep,\n",
        "        context: Dict[str, DataFrame],  # type: ignore[valid-type]  # type: ignore[valid-type]\n",
        "    ) -> DataFrame:  # type: ignore[valid-type]\n",
        "        \"\"\"Execute a bronze step.\n",
        "\n",
        "        Bronze steps validate existing data but don't transform or write it.\n",
        "        The step name must exist in the context dictionary with the source DataFrame.\n",
        "\n",
        "        Args:\n",
        "            step: BronzeStep instance to execute.\n",
        "            context: Dictionary mapping step names to DataFrames. Must contain\n",
        "                the step name as a key.\n",
        "\n",
        "        Returns:\n",
        "            DataFrame from context (validated but unchanged).\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If step name not found in context or DataFrame is\n",
        "                invalid.\n",
        "\n",
        "        Note:\n",
        "            Bronze steps are for validating raw data. They don't write to tables\n",
        "            or perform transformations. Validation is applied separately by the\n",
        "            execution engine.\n",
        "        \"\"\"\n",
        "        # Bronze steps require data to be provided in context\n",
        "        # This is the expected behavior - bronze steps validate existing data\n",
        "        if step.name not in context:\n",
        "            raise ExecutionError(\n",
        "                f\"Bronze step '{step.name}' requires data to be provided in context. \"\n",
        "                f\"Bronze steps are for validating existing data, not creating it. \"\n",
        "                f\"Please provide data using bronze_sources parameter or context dictionary. \"\n",
        "                f\"Available context keys: {list(context.keys())}\"\n",
        "            )\n",
        "\n",
        "        df: DataFrame = context[step.name]  # type: ignore[valid-type]\n",
        "\n",
        "        # Validate that the DataFrame is not empty (optional check)\n",
        "        if df.count() == 0:  # type: ignore[attr-defined]\n",
        "            self.logger.warning(\n",
        "                f\"Bronze step '{step.name}' received empty DataFrame. \"\n",
        "                f\"This may indicate missing or invalid data source.\"\n",
        "            )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _execute_silver_step(\n",
        "        self,\n",
        "        step: SilverStep,\n",
        "        context: Dict[str, DataFrame],  # type: ignore[valid-type]\n",
        "        mode: ExecutionMode,\n",
        "    ) -> DataFrame:  # type: ignore[valid-type]\n",
        "        \"\"\"Execute a silver step.\n",
        "\n",
        "        Silver steps transform bronze data into cleaned and enriched data.\n",
        "        For INCREMENTAL mode, filters bronze input to only process new rows.\n",
        "\n",
        "        Args:\n",
        "            step: SilverStep instance to execute.\n",
        "            context: Dictionary mapping step names to DataFrames. Must contain\n",
        "                the source bronze step name.\n",
        "            mode: Execution mode. INCREMENTAL mode triggers incremental filtering.\n",
        "\n",
        "        Returns:\n",
        "            Transformed DataFrame ready for validation and writing.\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If source bronze step not found in context.\n",
        "\n",
        "        Note:\n",
        "            - Applies incremental filtering if mode is INCREMENTAL\n",
        "            - Calls step.transform() with bronze DataFrame and empty silvers dict\n",
        "            - Transformation logic is defined in the step's transform function\n",
        "        \"\"\"\n",
        "\n",
        "        # Get source bronze data\n",
        "        if step.source_bronze not in context:\n",
        "            raise ExecutionError(\n",
        "                f\"Source bronze step {step.source_bronze} not found in context\"\n",
        "            )\n",
        "\n",
        "        bronze_df: DataFrame = context[step.source_bronze]  # type: ignore[valid-type]\n",
        "\n",
        "        if mode == ExecutionMode.INCREMENTAL:\n",
        "            bronze_df = self._filter_incremental_bronze_input(step, bronze_df)\n",
        "\n",
        "        # Build prior_silvers dict from context\n",
        "        # If source_silvers is specified, only include those steps\n",
        "        # Otherwise, include all previously executed steps (excluding bronze and current step)\n",
        "        prior_silvers: Dict[str, DataFrame] = {}  # type: ignore[valid-type]\n",
        "        source_silvers = getattr(step, \"source_silvers\", None)\n",
        "\n",
        "        if source_silvers:\n",
        "            # Only include explicitly specified silver steps\n",
        "            for silver_name in source_silvers:\n",
        "                if silver_name in context and silver_name != step.name:\n",
        "                    prior_silvers[silver_name] = context[silver_name]  # type: ignore[assignment]\n",
        "                elif silver_name not in context:\n",
        "                    # Log warning if expected silver step is not in context\n",
        "                    # This helps debug dependency issues\n",
        "                    available_keys = [\n",
        "                        k\n",
        "                        for k in context.keys()\n",
        "                        if k != step.name and k != step.source_bronze\n",
        "                    ]\n",
        "                    self.logger.warning(\n",
        "                        f\"Silver step {step.name} expects {silver_name} in prior_silvers \"\n",
        "                        f\"(via source_silvers), but it's not in context. \"\n",
        "                        f\"Available keys: {list(context.keys())}, \"\n",
        "                        f\"Other silver steps in context: {available_keys}\"\n",
        "                    )\n",
        "        else:\n",
        "            # Include all previously executed steps (excluding bronze and current step)\n",
        "            # This allows backward compatibility for silver steps that access prior_silvers\n",
        "            # without explicitly declaring dependencies\n",
        "            for key, value in context.items():\n",
        "                if key != step.name and key != step.source_bronze:\n",
        "                    prior_silvers[key] = value  # type: ignore[assignment]\n",
        "\n",
        "        # Apply transform with source bronze data and prior silvers dict\n",
        "        return step.transform(self.spark, bronze_df, prior_silvers)\n",
        "\n",
        "    def _filter_incremental_bronze_input(\n",
        "        self,\n",
        "        step: SilverStep,\n",
        "        bronze_df: DataFrame,  # type: ignore[valid-type]  # type: ignore[valid-type]\n",
        "    ) -> DataFrame:  # type: ignore[valid-type]\n",
        "        \"\"\"Filter bronze input rows already processed in previous incremental runs.\n",
        "\n",
        "        Filters bronze DataFrame to only include rows that haven't been processed\n",
        "        yet. Uses the source bronze step's incremental column and the silver step's\n",
        "        watermark column to determine which rows to exclude.\n",
        "\n",
        "        Args:\n",
        "            step: SilverStep instance with incremental configuration.\n",
        "            bronze_df: Bronze DataFrame to filter.\n",
        "\n",
        "        Returns:\n",
        "            Filtered DataFrame containing only new rows to process. Returns\n",
        "            original DataFrame if filtering cannot be performed (missing columns,\n",
        "            table doesn't exist, etc.).\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If filtering fails due to column or type issues.\n",
        "\n",
        "        Note:\n",
        "            Filtering logic:\n",
        "            1. Reads existing silver table to get maximum watermark value\n",
        "            2. Filters bronze rows where incremental_col > max_watermark\n",
        "            3. Returns original DataFrame if table doesn't exist (first run)\n",
        "\n",
        "            Requires:\n",
        "            - step.source_incremental_col: Column in bronze DataFrame\n",
        "            - step.watermark_col: Column in existing silver table\n",
        "            - step.schema and step.table_name: To locate existing table\n",
        "\n",
        "            Skips filtering gracefully if requirements not met (returns original DataFrame).\n",
        "        \"\"\"\n",
        "\n",
        "        incremental_col = getattr(step, \"source_incremental_col\", None)\n",
        "        watermark_col = getattr(step, \"watermark_col\", None)\n",
        "        schema = getattr(step, \"schema\", None)\n",
        "        table_name = getattr(step, \"table_name\", step.name)\n",
        "\n",
        "        if not incremental_col or not watermark_col or schema is None:\n",
        "            return bronze_df\n",
        "\n",
        "        if incremental_col not in getattr(bronze_df, \"columns\", []):\n",
        "            self.logger.debug(\n",
        "                f\"Silver step {step.name}: incremental column '{incremental_col}' \"\n",
        "                f\"not present in bronze DataFrame; skipping incremental filter\"\n",
        "            )\n",
        "            return bronze_df\n",
        "\n",
        "        # Validate that incremental column type is appropriate for filtering\n",
        "        try:\n",
        "            schema = bronze_df.schema  # type: ignore[attr-defined]\n",
        "            col_field = schema[incremental_col]  # type: ignore[index]\n",
        "            col_type = col_field.dataType  # type: ignore[attr-defined]\n",
        "            col_type_name = str(col_type)\n",
        "\n",
        "            # Check if type is comparable (numeric, date, timestamp, string)\n",
        "            # Non-comparable types: boolean, array, map, struct\n",
        "            non_comparable_types = [\"boolean\", \"array\", \"map\", \"struct\", \"binary\"]\n",
        "            if any(\n",
        "                non_comp in col_type_name.lower() for non_comp in non_comparable_types\n",
        "            ):\n",
        "                self.logger.warning(\n",
        "                    f\"Silver step {step.name}: incremental column '{incremental_col}' \"\n",
        "                    f\"has type '{col_type_name}' which may not be suitable for comparison operations. \"\n",
        "                    f\"Filtering may fail or produce unexpected results. \"\n",
        "                    f\"Consider using a numeric, date, timestamp, or string column for incremental processing.\"\n",
        "                )\n",
        "        except (KeyError, AttributeError, Exception) as e:\n",
        "            # If we can't inspect the schema, log a warning but continue\n",
        "            self.logger.debug(\n",
        "                f\"Silver step {step.name}: could not validate incremental column type: {e}\"\n",
        "            )\n",
        "\n",
        "        output_table = fqn(schema, table_name)\n",
        "\n",
        "        try:\n",
        "            existing_table = self.spark.table(output_table)  # type: ignore[attr-defined]\n",
        "        except Exception as exc:\n",
        "            self.logger.debug(\n",
        "                f\"Silver step {step.name}: unable to read existing table {output_table} \"\n",
        "                f\"for incremental filter: {exc}\"\n",
        "            )\n",
        "            return bronze_df\n",
        "\n",
        "        if watermark_col not in getattr(existing_table, \"columns\", []):\n",
        "            self.logger.debug(\n",
        "                f\"Silver step {step.name}: watermark column '{watermark_col}' \"\n",
        "                f\"not present in existing table {output_table}; skipping incremental filter\"\n",
        "            )\n",
        "            return bronze_df\n",
        "\n",
        "        try:\n",
        "            watermark_rows = existing_table.select(watermark_col).collect()  # type: ignore[attr-defined]\n",
        "        except Exception as exc:\n",
        "            self.logger.warning(\n",
        "                f\"Silver step {step.name}: failed to collect watermark values \"\n",
        "                f\"from {output_table}: {exc}\"\n",
        "            )\n",
        "            return bronze_df\n",
        "\n",
        "        if not watermark_rows:\n",
        "            return bronze_df\n",
        "\n",
        "        cutoff_value = None\n",
        "        for row in watermark_rows:\n",
        "            value = None\n",
        "            if hasattr(row, \"__getitem__\"):\n",
        "                try:\n",
        "                    value = row[watermark_col]\n",
        "                except Exception:\n",
        "                    try:\n",
        "                        value = row[0]\n",
        "                    except Exception:\n",
        "                        value = None\n",
        "            if value is None and hasattr(row, \"asDict\"):\n",
        "                value = row.asDict().get(watermark_col)\n",
        "            if value is None:\n",
        "                continue\n",
        "            cutoff_value = value if cutoff_value is None else max(cutoff_value, value)\n",
        "\n",
        "        if cutoff_value is None:\n",
        "            return bronze_df\n",
        "\n",
        "        try:\n",
        "            filtered_df = bronze_df.filter(F.col(incremental_col) > F.lit(cutoff_value))  # type: ignore[attr-defined]\n",
        "        except Exception as exc:\n",
        "            # Provide detailed error context for incremental filtering failures\n",
        "            error_msg = str(exc).lower()\n",
        "            if \"cannot resolve\" in error_msg or \"column\" in error_msg:\n",
        "                # Column-related error - provide schema context\n",
        "                available_cols = sorted(getattr(bronze_df, \"columns\", []))\n",
        "                raise ExecutionError(\n",
        "                    f\"Silver step {step.name}: failed to filter bronze rows using incremental column '{incremental_col}'. \"\n",
        "                    f\"Error: {exc!r}. \"\n",
        "                    f\"Available columns in bronze DataFrame: {available_cols}. \"\n",
        "                    f\"This may indicate that the incremental column was dropped or renamed in a previous transform. \"\n",
        "                    f\"Please ensure the incremental column '{incremental_col}' exists in the bronze DataFrame.\"\n",
        "                ) from exc\n",
        "            elif \"type\" in error_msg or \"cast\" in error_msg:\n",
        "                # Type-related error - provide type information\n",
        "                try:\n",
        "                    col_type = bronze_df.schema[incremental_col].dataType  # type: ignore[attr-defined]\n",
        "                    raise ExecutionError(\n",
        "                        f\"Silver step {step.name}: failed to filter bronze rows using incremental column '{incremental_col}'. \"\n",
        "                        f\"Error: {exc!r}. \"\n",
        "                        f\"Column type: {col_type}. \"\n",
        "                        f\"Cutoff value type: {type(cutoff_value).__name__}. \"\n",
        "                        f\"Incremental columns must be comparable types (numeric, date, timestamp). \"\n",
        "                        f\"Please ensure the incremental column type is compatible with the cutoff value.\"\n",
        "                    ) from exc\n",
        "                except (KeyError, AttributeError, Exception):\n",
        "                    # If we can't get type info, provide generic error\n",
        "                    raise ExecutionError(\n",
        "                        f\"Silver step {step.name}: failed to filter bronze rows using incremental column '{incremental_col}'. \"\n",
        "                        f\"Error: {exc!r}. \"\n",
        "                        f\"This may be a type mismatch between the incremental column and the cutoff value. \"\n",
        "                        f\"Please ensure the incremental column type is compatible with the cutoff value type.\"\n",
        "                    ) from exc\n",
        "            else:\n",
        "                # Generic error with context\n",
        "                raise ExecutionError(\n",
        "                    f\"Silver step {step.name}: failed to filter bronze rows using \"\n",
        "                    f\"{incremental_col} > {cutoff_value}: {exc!r}. \"\n",
        "                    f\"Please check that the incremental column exists and is of a comparable type.\"\n",
        "                ) from exc\n",
        "\n",
        "        self.logger.info(\n",
        "            f\"Silver step {step.name}: filtering bronze rows where \"\n",
        "            f\"{incremental_col} <= {cutoff_value}\"\n",
        "        )\n",
        "        return filtered_df\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_row_value(row: Any, column: str) -> Optional[object]:\n",
        "        \"\"\"Safely extract a column value from a Row-like object.\n",
        "\n",
        "        Attempts multiple methods to extract a column value from Spark Row objects,\n",
        "        handling different Row implementations and access patterns.\n",
        "\n",
        "        Args:\n",
        "            row: Row-like object (Spark Row, dict, or similar).\n",
        "            column: Column name to extract.\n",
        "\n",
        "        Returns:\n",
        "            Extracted value if found, None otherwise.\n",
        "\n",
        "        Note:\n",
        "            Tries methods in order:\n",
        "            1. Direct indexing: row[column]\n",
        "            2. Positional indexing: row[0]\n",
        "            3. Dictionary access: row.asDict().get(column)\n",
        "\n",
        "            Returns None if all methods fail or value is not found.\n",
        "        \"\"\"\n",
        "        if hasattr(row, \"__getitem__\"):\n",
        "            try:\n",
        "                result: Optional[object] = row[column]  # type: ignore[assignment]\n",
        "                return result\n",
        "            except Exception:\n",
        "                try:\n",
        "                    result = row[0]  # type: ignore[assignment]\n",
        "                    return cast(Optional[object], result)\n",
        "                except Exception:\n",
        "                    pass  # Row may not support asDict; try other access\n",
        "        if hasattr(row, \"asDict\"):\n",
        "            try:\n",
        "                result = row.asDict().get(column)  # type: ignore[assignment]\n",
        "                return cast(Optional[object], result)\n",
        "            except Exception:\n",
        "                return None\n",
        "        return None\n",
        "\n",
        "    def _execute_gold_step(\n",
        "        self,\n",
        "        step: GoldStep,\n",
        "        context: Dict[str, DataFrame],  # type: ignore[valid-type]  # type: ignore[valid-type]\n",
        "    ) -> DataFrame:  # type: ignore[valid-type]\n",
        "        \"\"\"Execute a gold step.\n",
        "\n",
        "        Gold steps transform silver data into business analytics and aggregations.\n",
        "        Builds a dictionary of source silver DataFrames from step.source_silvers.\n",
        "\n",
        "        Args:\n",
        "            step: GoldStep instance to execute.\n",
        "            context: Dictionary mapping step names to DataFrames. Must contain\n",
        "                all source silver step names listed in step.source_silvers.\n",
        "\n",
        "        Returns:\n",
        "            Transformed DataFrame ready for validation and writing.\n",
        "\n",
        "        Raises:\n",
        "            ExecutionError: If any source silver step not found in context.\n",
        "\n",
        "        Note:\n",
        "            - Builds silvers dictionary from step.source_silvers\n",
        "            - Calls step.transform() with SparkSession and silvers dictionary\n",
        "            - Transformation logic is defined in the step's transform function\n",
        "            - Gold steps typically perform aggregations and business metrics\n",
        "        \"\"\"\n",
        "\n",
        "        # Build silvers dict from source_silvers\n",
        "        silvers = {}\n",
        "        if step.source_silvers is not None:\n",
        "            for silver_name in step.source_silvers:\n",
        "                if silver_name not in context:\n",
        "                    raise ExecutionError(\n",
        "                        f\"Source silver {silver_name} not found in context\"\n",
        "                    )\n",
        "                silvers[silver_name] = context[silver_name]  # type: ignore[valid-type]\n",
        "\n",
        "        return step.transform(self.spark, silvers)\n",
        "\n",
        "# Backward compatibility aliases\n",
        "UnifiedExecutionEngine = ExecutionEngine\n",
        "UnifiedStepExecutionResult = StepExecutionResult"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.writer.storage (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.compat, pipeline_builder.functions, pipeline_builder.functions, pipeline_builder.table_operations, pipeline_builder.table_operations, pipeline_builder.writer.exceptions, pipeline_builder.writer.models, pipeline_builder.writer.models, pipeline_builder_base.logging, pipeline_builder_base.logging, writer.exceptions\n",
        "\n",
        "# mypy: ignore-errors\n",
        "\"\"\"\n",
        "Writer storage module for Delta Lake and table operations.\n",
        "\n",
        "This module handles all storage-related operations including Delta Lake\n",
        "integration, table management, and data persistence.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "from datetime import datetime\n",
        "from typing import Dict, Optional, TypedDict, Union, cast\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame, SparkSession, types  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "from pyspark.sql import types  # types from pyspark (not from compat)\n",
        "# from ..functions import FunctionsProtocol, get_default_functions  # Removed: defined in notebook cells above\n",
        "# from ..table_operations import (  # Removed: defined in notebook cells above\n",
        "    # prepare_delta_overwrite,\n",
        "    # table_exists,\n",
        "    # table_schema_is_empty,\n",
        "# )\n",
        "# from .exceptions import WriterTableError  # Removed: defined in notebook cells above\n",
        "# from .models import LogRow, WriteMode, WriterConfig, create_log_schema  # Removed: defined in notebook cells above\n",
        "\n",
        "# Handle optional Delta Lake dependency\n",
        "try:\n",
        "    from delta.tables import DeltaTable\n",
        "\n",
        "    HAS_DELTA = True\n",
        "except (ImportError, AttributeError, RuntimeError):\n",
        "    # Catch ImportError, AttributeError (delta-spark compatibility issues),\n",
        "    # and RuntimeError (Spark session not initialized)\n",
        "    DeltaTable = None  # type: ignore[misc, assignment]\n",
        "    HAS_DELTA = False\n",
        "\n",
        "# Cache for Delta Lake availability per Spark session\n",
        "# Key: Spark session id, Value: boolean indicating if Delta works\n",
        "_delta_availability_cache: Dict[str, bool] = {}\n",
        "\n",
        "# Legacy function - use prepare_delta_overwrite from table_operations instead\n",
        "def _prepare_delta_overwrite_storage(\n",
        "    spark: SparkSession,  # type: ignore[valid-type]\n",
        "    table_name: str,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Legacy function - delegates to prepare_delta_overwrite() from table_operations.\n",
        "\n",
        "    This function is kept for backward compatibility but now uses the centralized\n",
        "    prepare_delta_overwrite() function from table_operations module.\n",
        "    \"\"\"\n",
        "    # Only prepare if Delta is available\n",
        "    if HAS_DELTA and _is_delta_lake_available(spark):\n",
        "        prepare_delta_overwrite(spark, table_name)\n",
        "\n",
        "def _is_delta_lake_available(spark: SparkSession) -> bool:  # type: ignore[valid-type]\n",
        "    \"\"\"\n",
        "    Check if Delta Lake is actually available and working in the Spark session.\n",
        "\n",
        "    This function checks configuration and optionally tests Delta functionality.\n",
        "    Results are cached per Spark session for performance.\n",
        "\n",
        "    Args:\n",
        "        spark: Spark session to test\n",
        "\n",
        "    Returns:\n",
        "        True if Delta Lake is available and working, False otherwise\n",
        "    \"\"\"\n",
        "\n",
        "    # Use Spark session's underlying SparkContext ID as cache key\n",
        "    try:\n",
        "        spark_id = (\n",
        "            str(id(spark._jsparkSession))\n",
        "            if hasattr(spark, \"_jsparkSession\")\n",
        "            else str(id(spark))\n",
        "        )\n",
        "    except Exception:\n",
        "        # Fallback: use Python id if JVM/session id unavailable\n",
        "        spark_id = str(id(spark))\n",
        "\n",
        "    # Log session identity and configs before checking\n",
        "    print(\"\ud83d\udd0d _is_delta_lake_available: Checking Delta availability\")\n",
        "    print(f\"\ud83d\udd0d _is_delta_lake_available: PID={os.getpid()}\")\n",
        "    print(f\"\ud83d\udd0d _is_delta_lake_available: Session ID (Python)={id(spark)}\")\n",
        "    try:\n",
        "        if hasattr(spark, \"_jsparkSession\"):\n",
        "            print(\n",
        "                f\"\ud83d\udd0d _is_delta_lake_available: Session ID (JVM)={id(spark._jsparkSession)}\"\n",
        "            )\n",
        "    except Exception:\n",
        "        pass  # Session has no JVM; skip JVM id log\n",
        "\n",
        "    # Check cache first\n",
        "    if spark_id in _delta_availability_cache:\n",
        "        cached_result = _delta_availability_cache[spark_id]\n",
        "        print(f\"\ud83d\udd0d _is_delta_lake_available: Using cached result: {cached_result}\")\n",
        "        return cached_result\n",
        "\n",
        "    # If delta package is not installed, can't be available\n",
        "    if not HAS_DELTA:\n",
        "        print(\n",
        "            \"\u26a0\ufe0f _is_delta_lake_available: Delta package not installed (HAS_DELTA=False)\"\n",
        "        )\n",
        "        _delta_availability_cache[spark_id] = False\n",
        "        return False\n",
        "\n",
        "    # Check Spark configuration first (fast check)\n",
        "    try:\n",
        "        extensions = spark.conf.get(\"spark.sql.extensions\", \"\")  # type: ignore[attr-defined]\n",
        "        catalog = spark.conf.get(\"spark.sql.catalog.spark_catalog\", \"\")  # type: ignore[attr-defined]\n",
        "\n",
        "        print(\n",
        "            f\"\ud83d\udd0d _is_delta_lake_available: Config check - Extensions: '{extensions}', Catalog: '{catalog}'\"\n",
        "        )\n",
        "\n",
        "        # If both extensions and catalog are configured for Delta, assume it works\n",
        "        if (\n",
        "            extensions\n",
        "            and catalog\n",
        "            and \"DeltaSparkSessionExtension\" in extensions\n",
        "            and \"DeltaCatalog\" in catalog\n",
        "        ):\n",
        "            print(\"\u2705 _is_delta_lake_available: Delta configured via config check\")\n",
        "            _delta_availability_cache[spark_id] = True\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0\ufe0f _is_delta_lake_available: Error checking config: {e}\")\n",
        "        pass  # Config check failed; proceed to lightweight test\n",
        "\n",
        "    # If only extensions are configured, do a lightweight test\n",
        "    try:\n",
        "        extensions = spark.conf.get(\"spark.sql.extensions\", \"\")  # type: ignore[attr-defined]\n",
        "        if extensions and \"DeltaSparkSessionExtension\" in extensions:\n",
        "            print(\n",
        "                \"\ud83d\udd0d _is_delta_lake_available: Extension found, testing with actual write...\"\n",
        "            )\n",
        "            # Try a simple test - create a minimal DataFrame and try to write it\n",
        "            test_df = spark.createDataFrame([(1, \"test\")], [\"id\", \"name\"])\n",
        "            # Use a unique temp directory to avoid conflicts\n",
        "            with tempfile.TemporaryDirectory() as temp_dir:\n",
        "                test_path = os.path.join(temp_dir, \"delta_test\")\n",
        "                try:\n",
        "                    test_df.write.format(\"delta\").mode(\"overwrite\").save(test_path)\n",
        "                    print(\"\u2705 _is_delta_lake_available: Delta test write succeeded\")\n",
        "                    _delta_availability_cache[spark_id] = True\n",
        "                    return True\n",
        "                except Exception as test_error:\n",
        "                    # Delta format failed - not available\n",
        "                    print(\n",
        "                        f\"\u26a0\ufe0f _is_delta_lake_available: Delta test write failed: {test_error}\"\n",
        "                    )\n",
        "                    pass\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0\ufe0f _is_delta_lake_available: Error during test write: {e}\")\n",
        "        pass  # Lightweight Delta test failed; assume Delta not available\n",
        "\n",
        "    # Delta is not available in this Spark session\n",
        "    print(\"\u274c _is_delta_lake_available: Delta NOT available in this session\")\n",
        "    _delta_availability_cache[spark_id] = False\n",
        "    return False\n",
        "\n",
        "# ============================================================================\n",
        "# TypedDict Definitions\n",
        "# ============================================================================\n",
        "\n",
        "class WriteResult(TypedDict):\n",
        "    \"\"\"Write operation result structure.\"\"\"\n",
        "\n",
        "    table_name: str\n",
        "    write_mode: str\n",
        "    rows_written: int\n",
        "    timestamp: str\n",
        "    success: bool\n",
        "\n",
        "class OptimizeResultSkipped(TypedDict):\n",
        "    \"\"\"Optimize operation result when skipped.\"\"\"\n",
        "\n",
        "    table_name: str\n",
        "    optimization_completed: bool  # False\n",
        "    skipped: bool  # True\n",
        "    reason: str\n",
        "    timestamp: str\n",
        "\n",
        "class TableInfo(TypedDict, total=False):\n",
        "    \"\"\"Table information structure.\"\"\"\n",
        "\n",
        "    table_name: str\n",
        "    row_count: int\n",
        "    details: list[dict[str, Union[str, int, float, Optional[bool]]]]\n",
        "    history_count: int\n",
        "    last_modified: Optional[str]\n",
        "    history: list[dict[str, Union[str, int, float, Optional[bool]]]]\n",
        "    timestamp: str\n",
        "\n",
        "class OptimizeResultCompleted(TypedDict):\n",
        "    \"\"\"Optimize operation result when completed.\"\"\"\n",
        "\n",
        "    table_name: str\n",
        "    optimization_completed: bool  # True\n",
        "    timestamp: str\n",
        "    table_info: TableInfo\n",
        "\n",
        "# Union type for optimize result\n",
        "OptimizeResult = Union[OptimizeResultSkipped, OptimizeResultCompleted]\n",
        "\n",
        "class VacuumResultSkipped(TypedDict):\n",
        "    \"\"\"Vacuum operation result when skipped.\"\"\"\n",
        "\n",
        "    table_name: str\n",
        "    vacuum_completed: bool  # False\n",
        "    skipped: bool  # True\n",
        "    reason: str\n",
        "    retention_hours: int\n",
        "    timestamp: str\n",
        "\n",
        "class VacuumResultCompleted(TypedDict):\n",
        "    \"\"\"Vacuum operation result when completed.\"\"\"\n",
        "\n",
        "    table_name: str\n",
        "    vacuum_completed: bool  # True\n",
        "    retention_hours: int\n",
        "    timestamp: str\n",
        "\n",
        "# Union type for vacuum result\n",
        "VacuumResult = Union[VacuumResultSkipped, VacuumResultCompleted]\n",
        "\n",
        "class StorageManager:\n",
        "    \"\"\"Handles storage operations for the writer.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,  # type: ignore[valid-type]\n",
        "        config: WriterConfig,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize the storage manager.\"\"\"\n",
        "        self.spark = spark\n",
        "        self.config = config\n",
        "        self.functions = functions if functions is not None else get_default_functions()\n",
        "        if logger is None:\n",
        "            self.logger = PipelineLogger(\"StorageManager\")\n",
        "        else:\n",
        "            self.logger = logger\n",
        "        self.table_fqn = f\"{config.table_schema}.{config.table_name}\"\n",
        "\n",
        "    def create_table_if_not_exists(self, schema: types.StructType) -> None:\n",
        "        \"\"\"\n",
        "        Create the log table if it doesn't exist.\n",
        "\n",
        "        Args:\n",
        "            schema: Spark schema for the table\n",
        "\n",
        "        Raises:\n",
        "            WriterTableError: If table creation fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Creating table if not exists: {self.table_fqn}\")\n",
        "\n",
        "            # Extract schema name from table_fqn (format: \"schema.table\")\n",
        "            schema_name = (\n",
        "                self.table_fqn.split(\".\")[0] if \".\" in self.table_fqn else None\n",
        "            )\n",
        "\n",
        "            # Ensure schema exists before creating table\n",
        "            # This is especially important for LogWriter which creates tables in different schemas\n",
        "            if schema_name:\n",
        "                try:\n",
        "                    # Use SQL to ensure schema exists (works for both PySpark and mock-spark)\n",
        "                    self.spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_name}\")  # type: ignore[attr-defined]\n",
        "                except Exception as e:\n",
        "                    # If SQL fails, log warning but continue (schema might already exist)\n",
        "                    self.logger.debug(f\"Could not create schema '{schema_name}': {e}\")\n",
        "\n",
        "            # Check if table exists and is a Delta table\n",
        "            table_is_delta = False\n",
        "            if table_exists(self.spark, self.table_fqn):\n",
        "                # Heal catalog entries that report empty schema (struct<>)\n",
        "                if table_schema_is_empty(self.spark, self.table_fqn):\n",
        "                    self.logger.warning(\n",
        "                        f\"Table {self.table_fqn} reports empty schema; dropping and recreating.\"\n",
        "                    )\n",
        "                    self.spark.sql(f\"DROP TABLE IF EXISTS {self.table_fqn}\")  # type: ignore[attr-defined]\n",
        "                try:\n",
        "                    # Check if table is a Delta table by checking table properties\n",
        "                    if HAS_DELTA:\n",
        "                        try:\n",
        "                            # Try to get table details using DESCRIBE DETAIL (more reliable)\n",
        "                            detail_df = self.spark.sql(\n",
        "                                f\"DESCRIBE DETAIL {self.table_fqn}\"\n",
        "                            )  # type: ignore[attr-defined]\n",
        "                            detail_rows = detail_df.collect()\n",
        "                            if detail_rows:\n",
        "                                # Check if provider is delta\n",
        "                                provider = detail_rows[0].get(\"provider\", \"\")\n",
        "                                if provider == \"delta\":\n",
        "                                    table_is_delta = True\n",
        "                                    self.logger.info(\n",
        "                                        f\"Table {self.table_fqn} exists and is a Delta table\"\n",
        "                                    )\n",
        "                                else:\n",
        "                                    # Table exists but is not a Delta table - drop it\n",
        "                                    self.logger.warning(\n",
        "                                        f\"Table {self.table_fqn} exists but is not a Delta table (provider: {provider}). Dropping and recreating.\"\n",
        "                                    )\n",
        "                                    self.spark.sql(\n",
        "                                        f\"DROP TABLE IF EXISTS {self.table_fqn}\"\n",
        "                                    )  # type: ignore[attr-defined]\n",
        "                            else:\n",
        "                                # Could not get details, try DeltaTable.forName as fallback\n",
        "                                try:\n",
        "                                    DeltaTable.forName(self.spark, self.table_fqn)  # type: ignore[attr-defined]\n",
        "                                    table_is_delta = True\n",
        "                                    self.logger.info(\n",
        "                                        f\"Table {self.table_fqn} exists and is a Delta table (verified via DeltaTable)\"\n",
        "                                    )\n",
        "                                except Exception:\n",
        "                                    # If both methods fail, assume it's not a Delta table\n",
        "                                    self.logger.warning(\n",
        "                                        f\"Table {self.table_fqn} exists but could not verify as Delta table. Dropping and recreating.\"\n",
        "                                    )\n",
        "                                    self.spark.sql(\n",
        "                                        f\"DROP TABLE IF EXISTS {self.table_fqn}\"\n",
        "                                    )  # type: ignore[attr-defined]\n",
        "                        except Exception as e:\n",
        "                            # DESCRIBE DETAIL failed, try DeltaTable.forName as fallback\n",
        "                            try:\n",
        "                                DeltaTable.forName(self.spark, self.table_fqn)  # type: ignore[attr-defined]\n",
        "                                table_is_delta = True\n",
        "                                self.logger.info(\n",
        "                                    f\"Table {self.table_fqn} exists and is a Delta table (verified via DeltaTable)\"\n",
        "                                )\n",
        "                            except Exception:\n",
        "                                # If both methods fail, log warning but don't drop - might be a temporary issue\n",
        "                                self.logger.warning(\n",
        "                                    f\"Could not verify if table {self.table_fqn} is Delta: {e}. Assuming it's valid and continuing.\"\n",
        "                                )\n",
        "                                table_is_delta = True  # Assume it's valid to avoid dropping existing data\n",
        "                    else:\n",
        "                        # Delta Lake not available, but table exists - assume it's okay\n",
        "                        table_is_delta = True\n",
        "                except Exception as e:\n",
        "                    # If all checks fail, assume table is valid to avoid data loss\n",
        "                    self.logger.warning(\n",
        "                        f\"Could not verify table {self.table_fqn} Delta status: {e}. Assuming valid and continuing.\"\n",
        "                    )\n",
        "                    table_is_delta = True\n",
        "\n",
        "            if not table_exists(self.spark, self.table_fqn):\n",
        "                # Create empty DataFrame with schema\n",
        "                empty_df = self.spark.createDataFrame([], schema)  # type: ignore[attr-defined]\n",
        "\n",
        "                # Ensure schema exists RIGHT BEFORE saveAsTable\n",
        "                if schema_name:\n",
        "                    try:\n",
        "                        self.spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_name}\")  # type: ignore[attr-defined]\n",
        "                    except Exception:\n",
        "                        pass  # Schema might already exist; continue\n",
        "\n",
        "                # Always use Delta format - failures will propagate if Delta is not available\n",
        "                # This ensures we know when Delta fails rather than silently falling back\n",
        "                # Note: Delta Lake doesn't support append in batch mode, so use overwrite\n",
        "                try:\n",
        "                    (\n",
        "                        empty_df.write.format(\"delta\")\n",
        "                        .mode(\"overwrite\")\n",
        "                        .option(\"overwriteSchema\", \"true\")\n",
        "                        .saveAsTable(self.table_fqn)  # type: ignore[attr-defined]\n",
        "                    )\n",
        "                    self.logger.info(\n",
        "                        f\"Delta table created successfully: {self.table_fqn}\"\n",
        "                    )\n",
        "                except Exception as create_error:\n",
        "                    # Handle race condition - table might already exist\n",
        "                    error_msg = str(create_error).lower()\n",
        "                    # Check for various \"table already exists\" error formats\n",
        "                    if (\n",
        "                        \"already exists\" in error_msg\n",
        "                        or \"table_or_view_already_exists\" in error_msg\n",
        "                    ):\n",
        "                        self.logger.debug(\n",
        "                            f\"Table {self.table_fqn} already exists, continuing...\"\n",
        "                        )\n",
        "                        # Verify table exists and has correct schema - if not, re-raise\n",
        "                        if not table_exists(self.spark, self.table_fqn):\n",
        "                            raise  # Table should exist but doesn't - re-raise\n",
        "                    else:\n",
        "                        # Re-raise if it's a different error - this will propagate Delta failures\n",
        "                        raise\n",
        "\n",
        "                try:\n",
        "                    self.spark.sql(f\"REFRESH TABLE {self.table_fqn}\")  # type: ignore[attr-defined]\n",
        "                except Exception:\n",
        "                    pass  # Refresh optional; table created\n",
        "                self.logger.info(f\"Table created successfully: {self.table_fqn}\")\n",
        "            elif not table_is_delta:\n",
        "                # Table exists but wasn't verified as Delta - this shouldn't happen after the check above\n",
        "                self.logger.warning(\n",
        "                    f\"Table {self.table_fqn} exists but Delta status unclear\"\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            raise WriterTableError(\n",
        "                f\"Failed to create table {self.table_fqn}: {e}\",\n",
        "                table_name=self.table_fqn,\n",
        "                operation=\"create_table\",\n",
        "                context={\"schema\": str(schema)},\n",
        "                suggestions=[\n",
        "                    \"Check table permissions\",\n",
        "                    \"Verify schema configuration\",\n",
        "                    \"Ensure Delta Lake is properly configured\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "    def write_dataframe(\n",
        "        self,\n",
        "        df: DataFrame,  # type: ignore[valid-type]\n",
        "        write_mode: WriteMode = WriteMode.APPEND,\n",
        "        partition_columns: Optional[list[str]] = None,\n",
        "    ) -> WriteResult:\n",
        "        \"\"\"\n",
        "        Write DataFrame to the log table.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to write\n",
        "            write_mode: Write mode for the operation\n",
        "            partition_columns: Columns to partition by\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing write results\n",
        "\n",
        "        Raises:\n",
        "            WriterTableError: If write operation fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\n",
        "                f\"Writing DataFrame to {self.table_fqn} with mode {write_mode.value}\"\n",
        "            )\n",
        "\n",
        "            df_prepared = self._prepare_dataframe_for_write(df)\n",
        "\n",
        "            if table_exists(self.spark, self.table_fqn) and table_schema_is_empty(\n",
        "                self.spark, self.table_fqn\n",
        "            ):\n",
        "                self.logger.warning(\n",
        "                    f\"Table {self.table_fqn} reports empty schema before write; dropping and recreating.\"\n",
        "                )\n",
        "                self.spark.sql(f\"DROP TABLE IF EXISTS {self.table_fqn}\")  # type: ignore[attr-defined]\n",
        "\n",
        "            # Check if table exists and has format mismatch (e.g., Parquet table but we want Delta)\n",
        "            if table_exists(self.spark, self.table_fqn):\n",
        "                try:\n",
        "                    # Get table provider/format\n",
        "                    detail_df = self.spark.sql(\n",
        "                        f\"DESCRIBE DETAIL {self.table_fqn}\"\n",
        "                    ).collect()  # type: ignore[attr-defined]\n",
        "                    if detail_df:\n",
        "                        provider = detail_df[0].get(\"provider\", \"\").lower()  # type: ignore[index]\n",
        "                        # If table is Parquet but we're trying to write Delta, drop and recreate\n",
        "                        if (\n",
        "                            provider\n",
        "                            and \"parquet\" in provider\n",
        "                            and \"delta\" not in provider\n",
        "                        ):\n",
        "                            self.logger.warning(\n",
        "                                f\"Table {self.table_fqn} is Parquet but we need Delta format. \"\n",
        "                                f\"Dropping and will recreate as Delta.\"\n",
        "                            )\n",
        "                            self.spark.sql(f\"DROP TABLE IF EXISTS {self.table_fqn}\")  # type: ignore[attr-defined]\n",
        "                except Exception as e:\n",
        "                    # If we can't check format, log warning but continue\n",
        "                    self.logger.debug(f\"Could not check table format: {e}\")\n",
        "\n",
        "            # Verify Delta configuration before write operation\n",
        "            import os\n",
        "\n",
        "            print(f\"\ud83d\udd0d write_dataframe: About to write Delta table {self.table_fqn}\")\n",
        "            print(f\"\ud83d\udd0d write_dataframe: PID={os.getpid()}\")\n",
        "            print(f\"\ud83d\udd0d write_dataframe: Session ID (Python)={id(self.spark)}\")\n",
        "            try:\n",
        "                if hasattr(self.spark, \"_jsparkSession\"):\n",
        "                    print(\n",
        "                        f\"\ud83d\udd0d write_dataframe: Session ID (JVM)={id(self.spark._jsparkSession)}\"\n",
        "                    )\n",
        "            except Exception:\n",
        "                pass  # Session/config log optional for diagnostics\n",
        "\n",
        "            # Check configs before Delta operation\n",
        "            try:\n",
        "                ext = self.spark.conf.get(\"spark.sql.extensions\", \"\")  # type: ignore[attr-defined]\n",
        "                cat = self.spark.conf.get(\"spark.sql.catalog.spark_catalog\", \"\")  # type: ignore[attr-defined]\n",
        "                print(\n",
        "                    f\"\ud83d\udd0d write_dataframe: Pre-write config check - Extensions: '{ext}', Catalog: '{cat}'\"\n",
        "                )\n",
        "                if \"DeltaSparkSessionExtension\" not in ext or \"DeltaCatalog\" not in cat:\n",
        "                    print(\n",
        "                        \"\u26a0\ufe0f write_dataframe: WARNING - Delta configs missing before write!\"\n",
        "                    )\n",
        "                    print(\n",
        "                        \"\u26a0\ufe0f write_dataframe: This will likely cause DeltaAnalysisException\"\n",
        "                    )\n",
        "            except Exception as config_error:\n",
        "                print(f\"\u26a0\ufe0f write_dataframe: Could not check configs: {config_error}\")\n",
        "\n",
        "            # Standardize Delta overwrite pattern for overwrite; append uses mergeSchema\n",
        "            # Always uses Delta format - failures will propagate if Delta is not available\n",
        "            if write_mode == WriteMode.OVERWRITE:\n",
        "                # Prepare for Delta overwrite by dropping existing Delta table if it exists\n",
        "                prepare_delta_overwrite(self.spark, self.table_fqn)\n",
        "                writer = (\n",
        "                    df_prepared.write.format(\"delta\")\n",
        "                    .mode(\"overwrite\")\n",
        "                    .option(\"overwriteSchema\", \"true\")\n",
        "                )  # type: ignore[attr-defined]\n",
        "            else:\n",
        "                # Append mode - use mergeSchema for schema evolution\n",
        "                writer = (\n",
        "                    df_prepared.write.format(\"delta\")\n",
        "                    .mode(write_mode.value)\n",
        "                    .option(\"mergeSchema\", \"true\")\n",
        "                )  # type: ignore[attr-defined]\n",
        "\n",
        "            if partition_columns:\n",
        "                writer = writer.partitionBy(*partition_columns)\n",
        "\n",
        "            try:\n",
        "                print(f\"\ud83d\udd0d write_dataframe: Executing saveAsTable({self.table_fqn})\")\n",
        "                writer.saveAsTable(self.table_fqn)  # type: ignore[attr-defined]\n",
        "                print(\"\u2705 write_dataframe: saveAsTable succeeded\")\n",
        "            except Exception as write_error:\n",
        "                import traceback\n",
        "\n",
        "                error_msg = str(write_error).lower()\n",
        "\n",
        "                # Log full error context for DeltaAnalysisException\n",
        "                if \"delta\" in error_msg.lower() or \"DELTA_CONFIGURE\" in str(\n",
        "                    write_error\n",
        "                ):\n",
        "                    print(\"\u274c write_dataframe: Delta error occurred!\")\n",
        "                    print(\n",
        "                        f\"\u274c write_dataframe: Error type: {type(write_error).__name__}\"\n",
        "                    )\n",
        "                    print(f\"\u274c write_dataframe: Error message: {write_error}\")\n",
        "                    print(f\"\u274c write_dataframe: Session ID (Python)={id(self.spark)}\")\n",
        "                    try:\n",
        "                        if hasattr(self.spark, \"_jsparkSession\"):\n",
        "                            print(\n",
        "                                f\"\u274c write_dataframe: Session ID (JVM)={id(self.spark._jsparkSession)}\"\n",
        "                            )\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                    try:\n",
        "                        ext = self.spark.conf.get(\"spark.sql.extensions\", \"\")  # type: ignore[attr-defined]\n",
        "                        cat = self.spark.conf.get(\"spark.sql.catalog.spark_catalog\", \"\")  # type: ignore[attr-defined]\n",
        "                        print(\n",
        "                            f\"\u274c write_dataframe: Configs at error time - Extensions: '{ext}', Catalog: '{cat}'\"\n",
        "                        )\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                    print(\"\u274c write_dataframe: Stack trace:\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "                if (\n",
        "                    \"already exists\" in error_msg\n",
        "                    or \"table_or_view_already_exists\" in error_msg\n",
        "                ):\n",
        "                    if table_exists(self.spark, self.table_fqn):\n",
        "                        self.logger.debug(\n",
        "                            f\"Table {self.table_fqn} was created by another thread, retrying with overwrite mode\"\n",
        "                        )\n",
        "                        # Always use Delta format\n",
        "                        # Note: Delta Lake doesn't support append in batch mode, so use overwrite\n",
        "                        retry_writer = (\n",
        "                            df_prepared.write.format(\"delta\")\n",
        "                            .mode(\"overwrite\")\n",
        "                            .option(\"overwriteSchema\", \"true\")\n",
        "                        )  # type: ignore[attr-defined]\n",
        "                        if partition_columns:\n",
        "                            retry_writer = retry_writer.partitionBy(*partition_columns)\n",
        "                        retry_writer.saveAsTable(self.table_fqn)  # type: ignore[attr-defined]\n",
        "                    else:\n",
        "                        raise\n",
        "                else:\n",
        "                    raise\n",
        "\n",
        "            row_count = df_prepared.count()  # type: ignore[attr-defined]\n",
        "\n",
        "            write_result = {\n",
        "                \"table_name\": self.table_fqn,\n",
        "                \"write_mode\": write_mode.value,\n",
        "                \"rows_written\": row_count,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"success\": True,\n",
        "            }\n",
        "\n",
        "            self.logger.info(f\"Successfully wrote {row_count} rows to {self.table_fqn}\")\n",
        "            return cast(WriteResult, write_result)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Safely get row count for error context\n",
        "            try:\n",
        "                row_count = df.count() if hasattr(df, \"count\") else 0  # type: ignore[attr-defined]\n",
        "            except Exception:\n",
        "                row_count = 0\n",
        "\n",
        "            raise WriterTableError(\n",
        "                f\"Failed to write DataFrame to {self.table_fqn}: {e}\",\n",
        "                table_name=self.table_fqn,\n",
        "                operation=\"write_dataframe\",\n",
        "                context={\"write_mode\": write_mode.value, \"row_count\": row_count},\n",
        "                suggestions=[\n",
        "                    \"Check table permissions\",\n",
        "                    \"Verify DataFrame schema matches table schema\",\n",
        "                    \"Ensure sufficient storage space\",\n",
        "                    \"Check for schema evolution conflicts\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "    def write_batch(\n",
        "        self, log_rows: list[LogRow], write_mode: WriteMode = WriteMode.APPEND\n",
        "    ) -> WriteResult:\n",
        "        \"\"\"\n",
        "        Write a batch of log rows to the table.\n",
        "\n",
        "        Args:\n",
        "            log_rows: List of log rows to write\n",
        "            write_mode: Write mode for the operation\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing write results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Writing batch of {len(log_rows)} log rows\")\n",
        "\n",
        "            # Convert log rows to DataFrame and write\n",
        "            df = self._create_dataframe_from_log_rows(log_rows)\n",
        "            # Write DataFrame\n",
        "            return self.write_dataframe(df, write_mode)  # type: ignore[attr-defined]\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to write batch: {e}\")\n",
        "            raise\n",
        "\n",
        "    def optimize_table(self) -> OptimizeResult:\n",
        "        \"\"\"\n",
        "        Optimize the Delta table for better performance.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing optimization results\n",
        "        \"\"\"\n",
        "        if not HAS_DELTA:\n",
        "            self.logger.warning(\n",
        "                f\"Delta Lake not available, optimize operation skipped for {self.table_fqn}\"\n",
        "            )\n",
        "            return {\n",
        "                \"table_name\": self.table_fqn,\n",
        "                \"optimization_completed\": False,\n",
        "                \"skipped\": True,\n",
        "                \"reason\": \"Delta Lake not available\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            self.logger.info(f\"Optimizing table: {self.table_fqn}\")\n",
        "\n",
        "            # Run OPTIMIZE command using Delta Lake Python API\n",
        "            delta_table = DeltaTable.forName(self.spark, self.table_fqn)\n",
        "            # Note: optimize() method may not be available in all Delta Lake versions\n",
        "            if hasattr(delta_table, \"optimize\"):\n",
        "                delta_table.optimize()\n",
        "            else:\n",
        "                # Fallback: use SQL command\n",
        "                self.spark.sql(f\"OPTIMIZE {self.table_fqn}\")  # type: ignore[attr-defined]\n",
        "\n",
        "            # Get table statistics\n",
        "            table_info = self.get_table_info()\n",
        "\n",
        "            optimization_result = {\n",
        "                \"table_name\": self.table_fqn,\n",
        "                \"optimization_completed\": True,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"table_info\": table_info,\n",
        "            }\n",
        "\n",
        "            self.logger.info(f\"Table optimization completed: {self.table_fqn}\")\n",
        "            return cast(OptimizeResult, optimization_result)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to optimize table {self.table_fqn}: {e}\")\n",
        "            raise WriterTableError(\n",
        "                f\"Failed to optimize table {self.table_fqn}: {e}\",\n",
        "                table_name=self.table_fqn,\n",
        "                operation=\"optimize_table\",\n",
        "                suggestions=[\n",
        "                    \"Check table permissions\",\n",
        "                    \"Verify table exists\",\n",
        "                    \"Ensure sufficient resources for optimization\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "    def vacuum_table(self, retention_hours: int = 168) -> VacuumResult:\n",
        "        \"\"\"\n",
        "        Vacuum the Delta table to remove old files.\n",
        "\n",
        "        Args:\n",
        "            retention_hours: Hours of retention for old files\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing vacuum results\n",
        "        \"\"\"\n",
        "        if not HAS_DELTA:\n",
        "            self.logger.warning(\n",
        "                f\"Delta Lake not available, vacuum operation skipped for {self.table_fqn}\"\n",
        "            )\n",
        "            return {\n",
        "                \"table_name\": self.table_fqn,\n",
        "                \"vacuum_completed\": False,\n",
        "                \"skipped\": True,\n",
        "                \"reason\": \"Delta Lake not available\",\n",
        "                \"retention_hours\": retention_hours,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            self.logger.info(\n",
        "                f\"Vacuuming table: {self.table_fqn} (retention: {retention_hours}h)\"\n",
        "            )\n",
        "\n",
        "            # Run VACUUM command using Delta Lake API\n",
        "            delta_table = DeltaTable.forName(self.spark, self.table_fqn)\n",
        "            delta_table.vacuum(retentionHours=retention_hours)\n",
        "\n",
        "            vacuum_result = {\n",
        "                \"table_name\": self.table_fqn,\n",
        "                \"vacuum_completed\": True,\n",
        "                \"retention_hours\": retention_hours,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "            }\n",
        "\n",
        "            self.logger.info(f\"Table vacuum completed: {self.table_fqn}\")\n",
        "            return cast(VacuumResult, vacuum_result)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to vacuum table {self.table_fqn}: {e}\")\n",
        "            raise WriterTableError(\n",
        "                f\"Failed to vacuum table {self.table_fqn}: {e}\",\n",
        "                table_name=self.table_fqn,\n",
        "                operation=\"vacuum_table\",\n",
        "                suggestions=[\n",
        "                    \"Check table permissions\",\n",
        "                    \"Verify retention period is valid\",\n",
        "                    \"Ensure table exists\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "    def get_table_info(self) -> TableInfo:\n",
        "        \"\"\"\n",
        "        Get information about the log table.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing table information\n",
        "        \"\"\"\n",
        "        if not HAS_DELTA:\n",
        "            self.logger.warning(\n",
        "                f\"Delta Lake not available, using basic table info for {self.table_fqn}\"\n",
        "            )\n",
        "            # Get basic info without Delta Lake\n",
        "            row_count = self.spark.table(self.table_fqn).count()  # type: ignore[attr-defined]\n",
        "            return {\n",
        "                \"table_name\": self.table_fqn,\n",
        "                \"row_count\": row_count,\n",
        "                \"details\": [],\n",
        "                \"history\": [],\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            self.logger.info(f\"Getting table info for: {self.table_fqn}\")\n",
        "\n",
        "            # Get table details using Delta Lake API\n",
        "            delta_table = DeltaTable.forName(self.spark, self.table_fqn)\n",
        "\n",
        "            # Get table details using Delta Lake Python API\n",
        "            # Note: detail() method may not be available in all Delta Lake versions\n",
        "            if hasattr(delta_table, \"detail\"):\n",
        "                table_details = delta_table.detail().collect()\n",
        "            else:\n",
        "                # Fallback: use SQL command\n",
        "                table_details = self.spark.sql(\n",
        "                    f\"DESCRIBE DETAIL {self.table_fqn}\"\n",
        "                ).collect()  # type: ignore[attr-defined]\n",
        "\n",
        "            # Get table history\n",
        "            table_history = delta_table.history().collect()\n",
        "\n",
        "            # Get row count\n",
        "            row_count = self.spark.table(self.table_fqn).count()  # type: ignore[attr-defined]\n",
        "\n",
        "            table_info = {\n",
        "                \"table_name\": self.table_fqn,\n",
        "                \"row_count\": row_count,\n",
        "                \"details\": [dict(row.asDict()) for row in table_details],\n",
        "                \"history_count\": len(table_history),\n",
        "                \"last_modified\": (\n",
        "                    table_history[0][\"timestamp\"] if table_history else None\n",
        "                ),\n",
        "            }\n",
        "\n",
        "            self.logger.info(f\"Table info retrieved: {row_count} rows\")\n",
        "            return cast(TableInfo, table_info)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to get table info for {self.table_fqn}: {e}\")\n",
        "            raise WriterTableError(\n",
        "                f\"Failed to get table info for {self.table_fqn}: {e}\",\n",
        "                table_name=self.table_fqn,\n",
        "                operation=\"get_table_info\",\n",
        "            ) from e\n",
        "\n",
        "    def query_logs(\n",
        "        self,\n",
        "        limit: Optional[int] = None,\n",
        "        filters: Union[Dict[str, Union[str, int, float, bool]], None] = None,\n",
        "    ) -> DataFrame:  # type: ignore[valid-type]\n",
        "        \"\"\"\n",
        "        Query logs from the table.\n",
        "\n",
        "        Args:\n",
        "            limit: Maximum number of rows to return\n",
        "            filters: Filters to apply to the query\n",
        "\n",
        "        Returns:\n",
        "            DataFrame containing query results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Querying logs from: {self.table_fqn}\")\n",
        "\n",
        "            # Start with the base table\n",
        "            result_df = self.spark.table(self.table_fqn)  # type: ignore[attr-defined]\n",
        "\n",
        "            # Apply filters if provided using PySpark functions\n",
        "            if filters:\n",
        "                for column, value in filters.items():\n",
        "                    if isinstance(value, str):\n",
        "                        result_df = result_df.filter(\n",
        "                            self.functions.col(column) == self.functions.lit(value)  # type: ignore[attr-defined]\n",
        "                        )\n",
        "                    else:\n",
        "                        result_df = result_df.filter(\n",
        "                            self.functions.col(column) == value  # type: ignore[attr-defined]\n",
        "                        )\n",
        "\n",
        "            # Add ordering using PySpark functions\n",
        "            # from ..compat import desc  # Removed: defined in notebook cells above\n",
        "\n",
        "            result_df = result_df.orderBy(desc(\"created_at\"))\n",
        "\n",
        "            # Apply limit if specified\n",
        "            if limit:\n",
        "                result_df = result_df.limit(limit)  # type: ignore[attr-defined]\n",
        "\n",
        "            self.logger.info(f\"Query executed successfully: {result_df.count()} rows\")  # type: ignore[attr-defined]\n",
        "\n",
        "            return result_df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to query logs from {self.table_fqn}: {e}\")\n",
        "            raise WriterTableError(\n",
        "                f\"Failed to query logs: {e}\",\n",
        "                table_name=self.table_fqn,\n",
        "                operation=\"query_logs\",\n",
        "                suggestions=[\n",
        "                    \"Check table exists\",\n",
        "                    \"Verify query syntax\",\n",
        "                    \"Check column names in filters\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "    def _prepare_dataframe_for_write(self, df: DataFrame) -> DataFrame:  # type: ignore[valid-type]\n",
        "        \"\"\"Prepare DataFrame for writing to Delta table.\"\"\"\n",
        "        try:\n",
        "            # Add metadata columns if not present\n",
        "            from datetime import datetime\n",
        "\n",
        "            current_time_str = datetime.now().isoformat()\n",
        "\n",
        "            if \"created_at\" not in df.columns:  # type: ignore[attr-defined]\n",
        "                df = df.withColumn(\"created_at\", self.functions.lit(current_time_str))\n",
        "\n",
        "            if \"updated_at\" not in df.columns:  # type: ignore[attr-defined]\n",
        "                df = df.withColumn(\"updated_at\", self.functions.lit(current_time_str))\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to prepare DataFrame for write: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _create_dataframe_from_log_rows(self, log_rows: list[LogRow]) -> DataFrame:  # type: ignore[valid-type]\n",
        "        \"\"\"Create DataFrame from log rows.\"\"\"\n",
        "        try:\n",
        "            # Convert log rows to dictionaries\n",
        "            from datetime import datetime\n",
        "\n",
        "            current_time_str = datetime.now().isoformat()\n",
        "\n",
        "            log_data = []\n",
        "            for row in log_rows:\n",
        "                row_dict = {\n",
        "                    \"run_id\": row[\"run_id\"],\n",
        "                    \"run_mode\": row[\"run_mode\"],\n",
        "                    \"run_started_at\": row[\"run_started_at\"],\n",
        "                    \"run_ended_at\": row[\"run_ended_at\"],\n",
        "                    \"execution_id\": row[\"execution_id\"],\n",
        "                    \"pipeline_id\": row[\"pipeline_id\"],\n",
        "                    \"schema\": row[\"schema\"],\n",
        "                    \"phase\": row[\"phase\"],\n",
        "                    \"step_name\": row[\"step_name\"],\n",
        "                    \"step_type\": row[\"step_type\"],\n",
        "                    \"start_time\": row[\"start_time\"],\n",
        "                    \"end_time\": row[\"end_time\"],\n",
        "                    \"duration_secs\": row[\"duration_secs\"],\n",
        "                    \"table_fqn\": row[\"table_fqn\"],\n",
        "                    \"write_mode\": row[\"write_mode\"],\n",
        "                    \"input_rows\": row[\"input_rows\"],\n",
        "                    \"output_rows\": row[\"output_rows\"],\n",
        "                    \"rows_written\": row[\"rows_written\"],\n",
        "                    \"rows_processed\": row[\"rows_processed\"],\n",
        "                    \"table_total_rows\": row.get(\n",
        "                        \"table_total_rows\"\n",
        "                    ),  # Include table_total_rows metric\n",
        "                    \"valid_rows\": row[\"valid_rows\"],\n",
        "                    \"invalid_rows\": row[\"invalid_rows\"],\n",
        "                    \"validation_rate\": row[\"validation_rate\"],\n",
        "                    \"success\": row[\"success\"],\n",
        "                    \"error_message\": row[\"error_message\"],\n",
        "                    \"memory_usage_mb\": row[\"memory_usage_mb\"],\n",
        "                    \"cpu_usage_percent\": row[\"cpu_usage_percent\"],\n",
        "                    \"metadata\": row[\"metadata\"],\n",
        "                    \"created_at\": current_time_str,  # Include timestamp directly as string\n",
        "                }\n",
        "                log_data.append(row_dict)\n",
        "\n",
        "            # Create DataFrame with explicit schema for type safety and None value handling\n",
        "            schema = create_log_schema()\n",
        "            df = self.spark.createDataFrame(log_data, schema)  # type: ignore[attr-defined,type-var]\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to create DataFrame from log rows: {e}\")\n",
        "            raise\n",
        "\n",
        "    @property\n",
        "    def table_schema(self) -> str:\n",
        "        \"\"\"Get the table schema.\"\"\"\n",
        "        return self.config.table_schema\n",
        "\n",
        "    @property\n",
        "    def table_name(self) -> str:\n",
        "        \"\"\"Get the table name.\"\"\"\n",
        "        return self.config.table_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.engine.spark_engine (pipeline_builder)\n",
        "#\n",
        "# Dependencies: abstracts.engine, abstracts.reports.transform, abstracts.reports.validation, abstracts.reports.write, abstracts.source, abstracts.step, pipeline_builder.execution, pipeline_builder.functions, pipeline_builder.models, pipeline_builder.protocols, pipeline_builder.table_operations, pipeline_builder.validation, pipeline_builder_base.logging\n",
        "\n",
        "# mypy: ignore-errors\n",
        "\"\"\"\n",
        "SparkEngine implementation of abstracts.Engine.\n",
        "\n",
        "This engine wraps ExecutionEngine and adapts between the abstracts interface\n",
        "and the concrete pipeline_builder implementation.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Optional, Union\n",
        "# from .engine import Engine  # Removed: defined in notebook cells above\n",
        "# from .reports.transform import TransformReport  # Removed: defined in notebook cells above\n",
        "# from .reports.validation import ValidationReport  # Removed: defined in notebook cells above\n",
        "# from .reports.write import WriteReport  # Removed: defined in notebook cells above\n",
        "# from .source import Source  # Removed: defined in notebook cells above\n",
        "# from .step import Step  # Removed: defined in notebook cells above\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..execution import ExecutionEngine, _create_dataframe_writer  # Removed: defined in notebook cells above\n",
        "# from ..functions import FunctionsProtocol  # Removed: defined in notebook cells above\n",
        "# from ..models import BronzeStep, GoldStep, SilverStep  # Removed: defined in notebook cells above\n",
        "# from ..protocols import (  # Removed: defined in notebook cells above\n",
        "    # DataFrameProtocol as DataFrame,\n",
        "# )\n",
        "# from ..protocols import (  # Removed: defined in notebook cells above\n",
        "    # SparkSessionProtocol as SparkSession,\n",
        "# )\n",
        "# from ..table_operations import fqn  # Removed: defined in notebook cells above\n",
        "# from ..validation import apply_column_rules  # Removed: defined in notebook cells above\n",
        "\n",
        "class SparkEngine(Engine):\n",
        "    \"\"\"\n",
        "    SparkEngine implements abstracts.Engine using ExecutionEngine.\n",
        "\n",
        "    This engine adapts between the abstracts interface (Step, Source protocols)\n",
        "    and the concrete pipeline_builder types (BronzeStep/SilverStep/GoldStep, DataFrame).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,  # type: ignore[valid-type]\n",
        "        config: Any,  # PipelineConfig\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize SparkEngine.\n",
        "\n",
        "        Args:\n",
        "            spark: SparkSession instance\n",
        "            config: PipelineConfig instance\n",
        "            logger: Optional logger instance\n",
        "            functions: Optional functions protocol for PySpark operations\n",
        "        \"\"\"\n",
        "        self.spark = spark\n",
        "        self.config = config\n",
        "        self.logger = logger or PipelineLogger()\n",
        "        self.functions = functions\n",
        "        self._execution_engine = ExecutionEngine(spark, config, self.logger, functions)\n",
        "\n",
        "    def validate_source(self, step: Step, source: Source) -> ValidationReport:\n",
        "        \"\"\"\n",
        "        Validate a data source according to step rules.\n",
        "\n",
        "        Args:\n",
        "            step: Step with validation rules\n",
        "            source: Source data to validate (DataFrame)\n",
        "\n",
        "        Returns:\n",
        "            ValidationReport with validation results\n",
        "        \"\"\"\n",
        "        # Duck-type: must expose DataFrameProtocol surface\n",
        "        if not hasattr(source, \"schema\") or not hasattr(source, \"count\"):\n",
        "            raise TypeError(f\"Source must be DataFrame-like, got {type(source)}\")\n",
        "\n",
        "        df: DataFrame = source  # type: ignore[valid-type]\n",
        "\n",
        "        concrete_step: Union[BronzeStep, SilverStep, GoldStep] = step  # type: ignore[assignment]\n",
        "\n",
        "        # Apply validation rules\n",
        "        try:\n",
        "            # Rules type compatibility - Step Protocol uses Rules, concrete steps use ColumnRules\n",
        "            # mypy doesn't understand Protocol structural typing here, so we use Any\n",
        "            rules: Any = concrete_step.rules\n",
        "            valid_df, invalid_df, validation_stats = apply_column_rules(\n",
        "                df,\n",
        "                rules,\n",
        "                \"pipeline\",\n",
        "                concrete_step.name,\n",
        "                functions=self.functions,\n",
        "            )\n",
        "\n",
        "            valid_rows = valid_df.count()  # type: ignore[attr-defined]\n",
        "            invalid_rows = invalid_df.count()  # type: ignore[attr-defined]\n",
        "\n",
        "            return ValidationReport(\n",
        "                source=valid_df,  # Return validated source\n",
        "                valid_rows=valid_rows,\n",
        "                invalid_rows=invalid_rows,\n",
        "                error=None,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            return ValidationReport(\n",
        "                source=df,\n",
        "                valid_rows=0,\n",
        "                invalid_rows=df.count() if df is not None else 0,  # type: ignore[attr-defined]\n",
        "                error=e,\n",
        "            )\n",
        "\n",
        "    def transform_source(self, step: Step, source: Source) -> TransformReport:\n",
        "        \"\"\"\n",
        "        Transform a data source according to step transformation logic.\n",
        "\n",
        "        Args:\n",
        "            step: Step with transformation function\n",
        "            source: Source data to transform (DataFrame)\n",
        "\n",
        "        Returns:\n",
        "            TransformReport with transformed source\n",
        "        \"\"\"\n",
        "        if not hasattr(source, \"schema\") or not hasattr(source, \"count\"):\n",
        "            raise TypeError(f\"Source must be DataFrame-like, got {type(source)}\")\n",
        "\n",
        "        df: DataFrame = source  # type: ignore[valid-type]\n",
        "\n",
        "        concrete_step: Union[BronzeStep, SilverStep, GoldStep] = step  # type: ignore[assignment]\n",
        "\n",
        "        try:\n",
        "            # Bronze steps: no transformation, just return source\n",
        "            step_phase = concrete_step.step_type\n",
        "            if step_phase.value == \"bronze\":\n",
        "                return TransformReport(source=df, error=None)\n",
        "\n",
        "            elif step_phase.value == \"silver\":\n",
        "                if concrete_step.transform is None:  # type: ignore[attr-defined]\n",
        "                    raise ValueError(\n",
        "                        f\"Silver step '{concrete_step.name}' requires a transform function\"\n",
        "                    )\n",
        "                transformed_df = concrete_step.transform(self.spark, df, {})  # type: ignore[attr-defined]\n",
        "                return TransformReport(source=transformed_df, error=None)\n",
        "\n",
        "            # Gold steps: transform with silvers dict\n",
        "            # Note: For gold steps, the \"source\" parameter is actually a dict of silvers\n",
        "            # This is a limitation of the abstracts.Engine interface for gold steps\n",
        "            elif step_phase.value == \"gold\":\n",
        "                if concrete_step.transform is None:  # type: ignore[attr-defined]\n",
        "                    raise ValueError(\n",
        "                        f\"Gold step '{concrete_step.name}' requires a transform function\"\n",
        "                    )\n",
        "                # For gold steps, source should be a dict of silvers (Dict[str, DataFrame]  # type: ignore[valid-type])\n",
        "                # The abstracts interface expects Source, but we accept dict for gold steps\n",
        "                if type(source) is dict:\n",
        "                    silvers = source\n",
        "                else:\n",
        "                    # If single DataFrame, this is an error for gold steps\n",
        "                    raise TypeError(\n",
        "                        f\"Gold step '{concrete_step.name}' requires a dict of silvers, got {type(source)}\"\n",
        "                    )\n",
        "                transformed_df = concrete_step.transform(self.spark, silvers)\n",
        "                return TransformReport(source=transformed_df, error=None)\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown step type: {type(step)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            return TransformReport(source=df, error=e)\n",
        "\n",
        "    def write_target(self, step: Step, source: Source) -> WriteReport:\n",
        "        \"\"\"\n",
        "        Write a data source to target table.\n",
        "\n",
        "        Args:\n",
        "            step: Step with target configuration\n",
        "            source: Source data to write (DataFrame)\n",
        "\n",
        "        Returns:\n",
        "            WriteReport with write results\n",
        "        \"\"\"\n",
        "        # Duck-type: must expose DataFrameProtocol surface (avoids isinstance issues in Python 3.8)\n",
        "        if not hasattr(source, \"schema\") or not hasattr(source, \"count\"):\n",
        "            raise TypeError(f\"Source must be DataFrame-like, got {type(source)}\")\n",
        "\n",
        "        df: DataFrame = source  # type: ignore[valid-type]\n",
        "\n",
        "        # Type check: step should have step_type property (avoids isinstance issues in Python 3.8)\n",
        "        if not hasattr(step, \"step_type\"):\n",
        "            raise TypeError(\n",
        "                f\"Step must have step_type property (BronzeStep, SilverStep, or GoldStep), got {type(step)}\"\n",
        "            )\n",
        "        # Cast to help mypy - we know it's one of the concrete types after checking step_type\n",
        "        concrete_step: Union[BronzeStep, SilverStep, GoldStep] = step  # type: ignore[assignment]\n",
        "\n",
        "        # Bronze steps don't write to tables\n",
        "        step_phase = concrete_step.step_type\n",
        "        if step_phase.value == \"bronze\":\n",
        "            rows_written = df.count()  # type: ignore[attr-defined]\n",
        "            return WriteReport(\n",
        "                source=df,\n",
        "                written_rows=rows_written,\n",
        "                failed_rows=0,\n",
        "                error=None,\n",
        "            )\n",
        "\n",
        "        # Get table name and schema\n",
        "        table_name = getattr(concrete_step, \"table_name\", None) or getattr(\n",
        "            concrete_step, \"target\", concrete_step.name\n",
        "        )\n",
        "        schema = getattr(concrete_step, \"schema\", None) or getattr(\n",
        "            concrete_step, \"write_schema\", None\n",
        "        )\n",
        "\n",
        "        if schema is None:\n",
        "            raise ValueError(\n",
        "                f\"Step '{concrete_step.name}' requires a schema to be specified for writing\"\n",
        "            )\n",
        "\n",
        "        if table_name is None:\n",
        "            raise ValueError(\n",
        "                f\"Step '{concrete_step.name}' requires a table_name or target to be specified\"\n",
        "            )\n",
        "\n",
        "        output_table = fqn(schema, table_name)\n",
        "\n",
        "        # Determine write mode\n",
        "        write_mode = getattr(concrete_step, \"write_mode\", \"overwrite\")\n",
        "        if write_mode is None:\n",
        "            write_mode = \"overwrite\"\n",
        "\n",
        "        # Create schema if needed\n",
        "        try:\n",
        "            self.spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema}\")  # type: ignore[attr-defined]\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to create schema '{schema}': {e}\") from e\n",
        "\n",
        "        # Write to table\n",
        "        try:\n",
        "            rows_before = df.count()  # type: ignore[attr-defined]\n",
        "            # Use helper function to ensure correct format (delta or parquet) based on availability\n",
        "            writer = _create_dataframe_writer(df, self.spark, write_mode)\n",
        "            writer.saveAsTable(output_table)  # type: ignore[attr-defined]\n",
        "            rows_written = rows_before  # Assuming all rows were written successfully\n",
        "            return WriteReport(\n",
        "                source=df,\n",
        "                written_rows=rows_written,\n",
        "                failed_rows=0,\n",
        "                error=None,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            return WriteReport(\n",
        "                source=df,\n",
        "                written_rows=0,\n",
        "                failed_rows=df.count() if df is not None else 0,  # type: ignore[attr-defined]\n",
        "                error=e,\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.writer.core (pipeline_builder)\n",
        "#\n",
        "# Dependencies: pipeline_builder.compat, pipeline_builder.functions, pipeline_builder.pipeline.models, pipeline_builder.table_operations, pipeline_builder.validation.utils, pipeline_builder.writer.analytics, pipeline_builder.writer.exceptions, pipeline_builder.writer.models, pipeline_builder.writer.monitoring, pipeline_builder.writer.operations, pipeline_builder.writer.storage, pipeline_builder_base.logging, pipeline_builder_base.models\n",
        "\n",
        "\"\"\"\n",
        "Refactored LogWriter implementation with modular architecture.\n",
        "\n",
        "This module contains the main LogWriter class that orchestrates the various\n",
        "writer components for comprehensive logging functionality. The LogWriter\n",
        "provides a simplified API for writing pipeline execution results to Delta\n",
        "Lake tables.\n",
        "\n",
        "**New Simplified API:**\n",
        "    The LogWriter now supports a simplified initialization API using `schema`\n",
        "    and `table_name` parameters directly, replacing the previous `WriterConfig`\n",
        "    approach. The old API is still supported but deprecated.\n",
        "\n",
        "**Key Features:**\n",
        "    - Simplified initialization with schema and table_name\n",
        "    - Modular architecture with dedicated components\n",
        "    - Comprehensive error handling and validation\n",
        "    - Performance monitoring and optimization\n",
        "    - Data quality analysis and trend detection\n",
        "    - Delta Lake integration for persistent logging\n",
        "\n",
        "**Migration Guide:**\n",
        "    Old API (deprecated):\n",
        "        >>> config = WriterConfig(table_schema=\"analytics\", table_name=\"logs\")\n",
        "        >>> writer = LogWriter(spark, config=config)\n",
        "\n",
        "    New API (recommended):\n",
        "        >>> writer = LogWriter(spark, schema=\"analytics\", table_name=\"logs\")\n",
        "\n",
        "Dependencies:\n",
        "    - compat: Spark/PySpark compatibility layer\n",
        "    - functions: Functions protocol for DataFrame operations\n",
        "    - logging: Pipeline logging utilities\n",
        "    - models.execution: ExecutionResult and StepResult models\n",
        "    - validation.utils: Data validation utilities\n",
        "    - writer.analytics: Analytics and trend analysis\n",
        "    - writer.exceptions: Writer-specific exceptions\n",
        "    - writer.models: Writer models and type definitions\n",
        "    - writer.monitoring: Performance monitoring\n",
        "    - writer.operations: Data processing operations\n",
        "    - writer.storage: Delta Lake storage management\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.writer import LogWriter\n",
        "    >>> from pipeline_builder.models.execution import ExecutionResult\n",
        "    >>>\n",
        "    >>> # Initialize with new simplified API\n",
        "    >>> writer = LogWriter(spark, schema=\"analytics\", table_name=\"pipeline_logs\")\n",
        "    >>>\n",
        "    >>> # Write execution result\n",
        "    >>> result = writer.write_execution_result(execution_result)\n",
        "    >>> print(f\"Wrote {result['rows_written']} rows\")\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, Optional\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .models import ExecutionResult, StepResult  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import SparkSession  # Removed: defined in notebook cells above\n",
        "# from ..functions import FunctionsProtocol, get_default_functions  # Removed: defined in notebook cells above\n",
        "# from ..pipeline.models import PipelineReport  # Removed: defined in notebook cells above\n",
        "# from ..table_operations import table_exists  # Removed: defined in notebook cells above\n",
        "# from .analytics import (  # Removed: defined in notebook cells above\n",
        "    # DataQualityAnalyzer,\n",
        "    # ExecutionTrends,\n",
        "    # QualityAnomalies,\n",
        "    # QualityTrends,\n",
        "    # TrendAnalyzer,\n",
        "# )\n",
        "# from .exceptions import WriterConfigurationError, WriterError  # Removed: defined in notebook cells above\n",
        "# from .models import LogRow, WriteMode, WriterConfig, WriterMetrics, create_log_schema  # Removed: defined in notebook cells above\n",
        "# from .monitoring import (  # Removed: defined in notebook cells above\n",
        "    # AnalyticsEngine,\n",
        "    # AnomalyReport,\n",
        "    # MemoryUsageInfo,\n",
        "    # PerformanceMonitor,\n",
        "    # PerformanceReport,\n",
        "# )\n",
        "# from .operations import DataProcessor, DataQualityReport  # Removed: defined in notebook cells above\n",
        "# from .storage import (  # Removed: defined in notebook cells above\n",
        "    # OptimizeResult,\n",
        "    # StorageManager,\n",
        "    # TableInfo,\n",
        "    # VacuumResult,\n",
        "    # WriteResult,\n",
        "# )\n",
        "\n",
        "def time_write_operation(\n",
        "    operation_func: Any, *args: Any, **kwargs: Any\n",
        ") -> tuple[int, float, Any, Any]:\n",
        "    \"\"\"\n",
        "    Time a write operation and return metrics.\n",
        "\n",
        "    Args:\n",
        "        operation_func: Function to time\n",
        "        *args: Arguments for the function\n",
        "        **kwargs: Keyword arguments for the function\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (rows_written, duration_secs, start_time, end_time)\n",
        "    \"\"\"\n",
        "    import time\n",
        "    from datetime import datetime\n",
        "\n",
        "    start_time = datetime.now()\n",
        "    start_ts = time.time()\n",
        "\n",
        "    try:\n",
        "        result = operation_func(*args, **kwargs)\n",
        "        rows_written = result.get(\"rows_written\", 0) if isinstance(result, dict) else 0\n",
        "    except Exception:\n",
        "        rows_written = 0\n",
        "\n",
        "    end_time = datetime.now()\n",
        "    duration_secs = time.time() - start_ts\n",
        "\n",
        "    return rows_written, duration_secs, start_time, end_time\n",
        "\n",
        "def validate_log_data(log_rows: list[LogRow]) -> None:\n",
        "    \"\"\"\n",
        "    Validate log data for quality and consistency.\n",
        "\n",
        "    Args:\n",
        "        log_rows: List of log rows to validate\n",
        "\n",
        "    Raises:\n",
        "        WriterValidationError: If validation fails\n",
        "    \"\"\"\n",
        "    if not log_rows:\n",
        "        return\n",
        "\n",
        "    # Basic validation - check required fields\n",
        "    required_fields = {\"run_id\", \"phase\", \"step_name\"}\n",
        "    for i, row in enumerate(log_rows):\n",
        "        missing_fields = required_fields - set(row.keys())\n",
        "        if missing_fields:\n",
        "            # from .exceptions import WriterValidationError  # Removed: defined in notebook cells above\n",
        "\n",
        "            raise WriterValidationError(\n",
        "                f\"Log row {i} missing required fields: {missing_fields}\",\n",
        "                validation_errors=[f\"Missing fields: {missing_fields}\"],\n",
        "                context={\"row_index\": i, \"row\": row},\n",
        "            )\n",
        "\n",
        "def create_log_rows_from_execution_result(\n",
        "    execution_result: ExecutionResult,\n",
        "    run_id: str,\n",
        "    run_mode: str = \"initial\",\n",
        "    metadata: Optional[Dict[str, Any]] = None,\n",
        ") -> list[LogRow]:\n",
        "    \"\"\"\n",
        "    Create log rows from an execution result.\n",
        "\n",
        "    Args:\n",
        "        execution_result: The execution result\n",
        "        run_id: Run identifier\n",
        "        run_mode: Mode of the run\n",
        "        metadata: Additional metadata\n",
        "\n",
        "    Returns:\n",
        "        List of log rows\n",
        "    \"\"\"\n",
        "\n",
        "    log_rows = []\n",
        "\n",
        "    # Create a main log row for the execution\n",
        "    main_row: LogRow = {\n",
        "        \"run_id\": run_id,\n",
        "        \"run_mode\": run_mode,  # type: ignore[typeddict-item]\n",
        "        \"run_started_at\": getattr(execution_result, \"start_time\", None),\n",
        "        \"run_ended_at\": getattr(execution_result, \"end_time\", None),\n",
        "        \"execution_id\": getattr(execution_result, \"execution_id\", run_id),\n",
        "        \"pipeline_id\": getattr(execution_result, \"pipeline_id\", \"unknown\"),\n",
        "        \"schema\": getattr(execution_result, \"schema\", \"default\"),\n",
        "        \"phase\": \"bronze\",\n",
        "        \"step_name\": \"pipeline_execution\",\n",
        "        \"step_type\": \"pipeline\",\n",
        "        \"start_time\": getattr(execution_result, \"start_time\", None),\n",
        "        \"end_time\": getattr(execution_result, \"end_time\", None),\n",
        "        \"duration_secs\": getattr(execution_result, \"duration\", 0.0) or 0.0,\n",
        "        \"table_fqn\": None,\n",
        "        \"write_mode\": None,\n",
        "        \"input_rows\": 0,\n",
        "        \"output_rows\": 0,\n",
        "        \"rows_written\": 0,\n",
        "        \"rows_processed\": 0,\n",
        "        \"table_total_rows\": None,\n",
        "        \"valid_rows\": 0,\n",
        "        \"invalid_rows\": 0,\n",
        "        \"validation_rate\": 100.0,\n",
        "        \"success\": getattr(execution_result, \"status\", \"unknown\") == \"completed\",\n",
        "        \"error_message\": getattr(execution_result, \"error\", None),\n",
        "        \"memory_usage_mb\": 0.0,\n",
        "        \"cpu_usage_percent\": 0.0,\n",
        "        \"metadata\": {},\n",
        "    }\n",
        "\n",
        "    log_rows.append(main_row)\n",
        "\n",
        "    # Add step results if available\n",
        "    if hasattr(execution_result, \"steps\"):\n",
        "        steps = getattr(execution_result, \"steps\", None)\n",
        "        if steps and isinstance(steps, (list, tuple)):\n",
        "            for step in steps:\n",
        "                step_row: LogRow = {\n",
        "                    \"run_id\": run_id,\n",
        "                    \"run_mode\": run_mode,  # type: ignore[typeddict-item]\n",
        "                    \"run_started_at\": getattr(execution_result, \"start_time\", None),\n",
        "                    \"run_ended_at\": getattr(execution_result, \"end_time\", None),\n",
        "                    \"execution_id\": getattr(execution_result, \"execution_id\", run_id),\n",
        "                    \"pipeline_id\": getattr(execution_result, \"pipeline_id\", \"unknown\"),\n",
        "                    \"schema\": getattr(execution_result, \"schema\", \"default\"),\n",
        "                    \"phase\": getattr(step, \"step_type\", \"bronze\").lower(),  # type: ignore[typeddict-item]\n",
        "                    \"step_name\": getattr(step, \"step_name\", \"unknown\"),\n",
        "                    \"step_type\": getattr(step, \"step_type\", \"unknown\"),\n",
        "                    \"start_time\": getattr(step, \"start_time\", None),\n",
        "                    \"end_time\": getattr(step, \"end_time\", None),\n",
        "                    \"duration_secs\": getattr(step, \"duration\", 0.0),\n",
        "                    \"table_fqn\": getattr(step, \"output_table\", None),\n",
        "                    \"write_mode\": getattr(step, \"write_mode\", None),\n",
        "                    \"input_rows\": getattr(step, \"input_rows\", 0),\n",
        "                    \"output_rows\": getattr(step, \"rows_processed\", 0),\n",
        "                    \"rows_written\": getattr(step, \"rows_written\", 0),\n",
        "                    \"rows_processed\": getattr(step, \"rows_processed\", 0),\n",
        "                    \"table_total_rows\": None,\n",
        "                    \"valid_rows\": 0,\n",
        "                    \"invalid_rows\": 0,\n",
        "                    \"validation_rate\": 100.0,\n",
        "                    \"success\": getattr(step, \"status\", \"unknown\") == \"completed\",\n",
        "                    \"error_message\": getattr(step, \"error\", None),\n",
        "                    \"memory_usage_mb\": 0.0,\n",
        "                    \"cpu_usage_percent\": 0.0,\n",
        "                    \"metadata\": {},\n",
        "                }\n",
        "                log_rows.append(step_row)\n",
        "\n",
        "    return log_rows\n",
        "\n",
        "class LogWriter:\n",
        "    \"\"\"Refactored LogWriter with modular architecture.\n",
        "\n",
        "    Main class for writing pipeline execution results to Delta Lake tables.\n",
        "    Provides a simplified API for logging pipeline runs, steps, and metrics\n",
        "    with comprehensive error handling, performance monitoring, and data quality\n",
        "    analysis.\n",
        "\n",
        "    **New Simplified API:**\n",
        "        The LogWriter now supports direct initialization with `schema` and\n",
        "        `table_name` parameters, making it easier to use:\n",
        "\n",
        "        >>> writer = LogWriter(spark, schema=\"analytics\", table_name=\"logs\")\n",
        "\n",
        "    **Deprecated API:**\n",
        "        The old API using `WriterConfig` is still supported but deprecated:\n",
        "\n",
        "        >>> config = WriterConfig(table_schema=\"analytics\", table_name=\"logs\")\n",
        "        >>> writer = LogWriter(spark, config=config)  # Deprecated\n",
        "\n",
        "    **Components:**\n",
        "        - **DataProcessor**: Handles data processing and transformations\n",
        "        - **StorageManager**: Manages Delta Lake storage operations\n",
        "        - **PerformanceMonitor**: Tracks performance metrics\n",
        "        - **AnalyticsEngine**: Provides analytics and trend analysis\n",
        "        - **DataQualityAnalyzer**: Analyzes data quality metrics\n",
        "        - **TrendAnalyzer**: Analyzes execution trends\n",
        "\n",
        "    **Key Methods:**\n",
        "        - `write_execution_result()`: Write ExecutionResult to log table\n",
        "        - `write_step_results()`: Write StepResult dictionary to log table\n",
        "        - `write_log_rows()`: Write raw LogRow list to log table\n",
        "        - `create_table()`: Create/overwrite table from PipelineReport\n",
        "        - `append()`: Append PipelineReport to existing table\n",
        "        - `optimize_table()`: Optimize Delta table for performance\n",
        "        - `vacuum_table()`: Vacuum Delta table to remove old files\n",
        "        - `analyze_quality_trends()`: Analyze data quality trends\n",
        "        - `analyze_execution_trends()`: Analyze execution trends\n",
        "\n",
        "    Example:\n",
        "        >>> from pipeline_builder.writer import LogWriter\n",
        "        >>> from pipeline_builder.models.execution import ExecutionResult\n",
        "        >>>\n",
        "        >>> # Initialize with new simplified API\n",
        "        >>> writer = LogWriter(spark, schema=\"analytics\", table_name=\"logs\")\n",
        "        >>>\n",
        "        >>> # Write execution result\n",
        "        >>> result = writer.write_execution_result(execution_result)\n",
        "        >>> print(f\"Success: {result['success']}\")\n",
        "        >>> print(f\"Rows written: {result['rows_written']}\")\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,\n",
        "        schema: Optional[str] = None,\n",
        "        table_name: Optional[str] = None,\n",
        "        config: Optional[WriterConfig] = None,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize the LogWriter with modular components.\n",
        "\n",
        "        Creates a new LogWriter instance with the specified schema and table\n",
        "        name. The writer will automatically create the log table if it doesn't\n",
        "        exist when data is first written.\n",
        "\n",
        "        **New Simplified API (Recommended):**\n",
        "            Use `schema` and `table_name` parameters directly:\n",
        "\n",
        "            >>> writer = LogWriter(spark, schema=\"analytics\", table_name=\"logs\")\n",
        "\n",
        "        **Deprecated API:**\n",
        "            The old API using `WriterConfig` is still supported but will emit\n",
        "            a deprecation warning:\n",
        "\n",
        "            >>> config = WriterConfig(table_schema=\"analytics\", table_name=\"logs\")\n",
        "            >>> writer = LogWriter(spark, config=config)  # Deprecated\n",
        "\n",
        "        Args:\n",
        "            spark: SparkSession instance for DataFrame operations. Required.\n",
        "            schema: Database schema name for the log table. Required if using\n",
        "                new API. Must be a non-empty string.\n",
        "            table_name: Table name for the log table. Required if using new API.\n",
        "                Must be a non-empty string.\n",
        "            config: WriterConfig instance (deprecated). Use `schema` and\n",
        "                `table_name` instead. If provided, `schema` and `table_name`\n",
        "                are ignored.\n",
        "            functions: FunctionsProtocol instance for DataFrame operations.\n",
        "                Optional. Uses default functions if not provided.\n",
        "            logger: PipelineLogger instance for logging. Optional. Creates a\n",
        "                new logger if not provided.\n",
        "\n",
        "        Raises:\n",
        "            WriterConfigurationError: If configuration is invalid, such as:\n",
        "                - Neither `config` nor both `schema` and `table_name` provided\n",
        "                - Schema or table_name is empty\n",
        "                - WriterConfig validation fails\n",
        "\n",
        "        Example:\n",
        "            >>> from pipeline_builder.writer import LogWriter\n",
        "            >>>\n",
        "            >>> # New simplified API (recommended)\n",
        "            >>> writer = LogWriter(\n",
        "            ...     spark,\n",
        "            ...     schema=\"analytics\",\n",
        "            ...     table_name=\"pipeline_logs\"\n",
        "            ... )\n",
        "            >>>\n",
        "            >>> # Old API (deprecated, emits warning)\n",
        "            >>> from pipeline_builder.writer import WriterConfig, WriteMode\n",
        "            >>> config = WriterConfig(\n",
        "            ...     table_schema=\"analytics\",\n",
        "            ...     table_name=\"pipeline_logs\",\n",
        "            ...     write_mode=WriteMode.APPEND\n",
        "            ... )\n",
        "            >>> writer = LogWriter(spark, config=config)  # DeprecationWarning\n",
        "        \"\"\"\n",
        "        self.spark = spark\n",
        "\n",
        "        # Handle both old and new API\n",
        "        if config is not None:\n",
        "            # Old API: config provided\n",
        "            import warnings\n",
        "\n",
        "            warnings.warn(\n",
        "                \"Passing WriterConfig is deprecated. Use LogWriter(spark, schema='...', table_name='...') instead.\",\n",
        "                DeprecationWarning,\n",
        "                stacklevel=2,\n",
        "            )\n",
        "            self.config = config\n",
        "        elif schema is not None and table_name is not None:\n",
        "            # New API: schema and table_name provided\n",
        "            self.config = WriterConfig(\n",
        "                table_schema=schema, table_name=table_name, write_mode=WriteMode.APPEND\n",
        "            )\n",
        "        else:\n",
        "            raise WriterConfigurationError(\n",
        "                \"Must provide either (schema and table_name) or config parameter\",\n",
        "                config_errors=[\"Missing required parameters\"],\n",
        "                suggestions=[\n",
        "                    \"Use: LogWriter(spark, schema='my_schema', table_name='my_table')\",\n",
        "                    \"Or: LogWriter(spark, config=WriterConfig(...))\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        self.functions = functions if functions is not None else get_default_functions()\n",
        "        if logger is None:\n",
        "            self.logger = PipelineLogger(\"LogWriter\")\n",
        "        else:\n",
        "            self.logger = logger\n",
        "\n",
        "        # Validate configuration\n",
        "        try:\n",
        "            self.config.validate()\n",
        "        except ValueError as e:\n",
        "            raise WriterConfigurationError(\n",
        "                f\"Invalid writer configuration: {e}\",\n",
        "                config_errors=[str(e)],\n",
        "                context={\"config\": self.config.__dict__},\n",
        "                suggestions=[\n",
        "                    \"Check configuration values\",\n",
        "                    \"Ensure all required fields are provided\",\n",
        "                    \"Verify numeric values are positive\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "        # Initialize components\n",
        "        self._initialize_components()\n",
        "\n",
        "        # Initialize metrics\n",
        "        self.metrics: WriterMetrics = {\n",
        "            \"total_writes\": 0,\n",
        "            \"successful_writes\": 0,\n",
        "            \"failed_writes\": 0,\n",
        "            \"total_duration_secs\": 0.0,\n",
        "            \"avg_write_duration_secs\": 0.0,\n",
        "            \"total_rows_written\": 0,\n",
        "            \"memory_usage_peak_mb\": 0.0,\n",
        "        }\n",
        "\n",
        "        # Initialize schema\n",
        "        self.schema = create_log_schema()\n",
        "\n",
        "        # Set table FQN for compatibility\n",
        "        self.table_fqn = f\"{self.config.table_schema}.{self.config.table_name}\"\n",
        "\n",
        "        # Cache table row counts to avoid repeated counts within a single write operation\n",
        "        self._table_total_rows_cache: dict[str, Optional[int]] = {}\n",
        "\n",
        "        self.logger.info(f\"LogWriter initialized for table: {self.table_fqn}\")\n",
        "\n",
        "    def _initialize_components(self) -> None:\n",
        "        \"\"\"Initialize all writer components.\"\"\"\n",
        "        # Data processing component\n",
        "        self.data_processor = DataProcessor(self.spark, self.functions, self.logger)\n",
        "\n",
        "        # Storage management component\n",
        "        self.storage_manager = StorageManager(\n",
        "            self.spark, self.config, self.functions, self.logger\n",
        "        )\n",
        "\n",
        "        # Performance monitoring component\n",
        "        self.performance_monitor = PerformanceMonitor(self.spark, self.logger)\n",
        "\n",
        "        # Analytics components\n",
        "        self.analytics_engine = AnalyticsEngine(self.spark, self.logger)\n",
        "        self.quality_analyzer = DataQualityAnalyzer(self.spark, self.logger)\n",
        "        self.trend_analyzer = TrendAnalyzer(self.spark, self.logger)\n",
        "\n",
        "    def write_execution_result(\n",
        "        self,\n",
        "        execution_result: ExecutionResult,\n",
        "        run_id: Optional[str] = None,\n",
        "        run_mode: str = \"initial\",\n",
        "        metadata: Optional[Dict[str, Any]] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Write execution result to log table.\n",
        "\n",
        "        Writes an ExecutionResult instance to the log table, creating one log\n",
        "        row per step in the execution. The table is automatically created if\n",
        "        it doesn't exist.\n",
        "\n",
        "        Args:\n",
        "            execution_result: ExecutionResult instance containing execution\n",
        "                context, step results, and metrics. Required.\n",
        "            run_id: Unique run identifier. Optional. If not provided, a UUID\n",
        "                is automatically generated.\n",
        "            run_mode: Execution mode string. Defaults to \"initial\". Valid values:\n",
        "                - \"initial\": First-time execution\n",
        "                - \"incremental\": Incremental processing\n",
        "                - \"full_refresh\": Full refresh execution\n",
        "                - \"validation_only\": Validation-only execution\n",
        "            metadata: Additional metadata dictionary to include in log rows.\n",
        "                Optional. Can contain any key-value pairs.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing write results with the following keys:\n",
        "                - `success`: Boolean indicating if write succeeded\n",
        "                - `run_id`: The run identifier used\n",
        "                - `operation_id`: Unique operation identifier\n",
        "                - `rows_written`: Number of rows written to the table\n",
        "                - `write_result`: WriteResult dictionary with detailed results\n",
        "                - `operation_metrics`: Performance metrics for the operation\n",
        "                - `threshold_violations`: List of performance threshold violations\n",
        "\n",
        "        Raises:\n",
        "            WriterValidationError: If log data validation fails (e.g., missing\n",
        "                required fields, invalid data types)\n",
        "            WriterTableError: If table operations fail (e.g., table creation,\n",
        "                write operation)\n",
        "            WriterPerformanceError: If performance thresholds are exceeded\n",
        "                (if enabled in configuration)\n",
        "\n",
        "        Example:\n",
        "            >>> from pipeline_builder.writer import LogWriter\n",
        "            >>> from pipeline_builder.models.execution import ExecutionResult\n",
        "            >>>\n",
        "            >>> writer = LogWriter(spark, schema=\"analytics\", table_name=\"logs\")\n",
        "            >>> result = writer.write_execution_result(\n",
        "            ...     execution_result=execution_result,\n",
        "            ...     run_id=\"run_123\",\n",
        "            ...     run_mode=\"incremental\",\n",
        "            ...     metadata={\"environment\": \"production\", \"version\": \"1.0\"}\n",
        "            ... )\n",
        "            >>> print(f\"Wrote {result['rows_written']} rows\")\n",
        "            >>> print(f\"Success: {result['success']}\")\n",
        "        \"\"\"\n",
        "        operation_id = str(uuid.uuid4())\n",
        "        if run_id is None:\n",
        "            run_id = str(uuid.uuid4())\n",
        "\n",
        "        try:\n",
        "            # Reset per-operation cache\n",
        "            self._reset_table_total_rows_cache()\n",
        "\n",
        "            # Start performance monitoring\n",
        "            self.performance_monitor.start_operation(\n",
        "                operation_id, \"write_execution_result\"\n",
        "            )\n",
        "\n",
        "            # Log operation start\n",
        "            self.logger.info(f\"Writing execution result for run {run_id}\")\n",
        "\n",
        "            # Process execution result\n",
        "            log_rows = self.data_processor.process_execution_result(\n",
        "                execution_result,\n",
        "                run_id,\n",
        "                run_mode,\n",
        "                metadata,\n",
        "                table_total_rows_provider=self._get_table_total_rows,\n",
        "            )\n",
        "\n",
        "            # Create table if not exists\n",
        "            self.storage_manager.create_table_if_not_exists(self.schema)\n",
        "\n",
        "            # Write to storage\n",
        "            write_result = self.storage_manager.write_batch(\n",
        "                log_rows, self.config.write_mode\n",
        "            )\n",
        "\n",
        "            # Update metrics\n",
        "            self._update_metrics(write_result, True)\n",
        "\n",
        "            # End performance monitoring\n",
        "            operation_metrics = self.performance_monitor.end_operation(\n",
        "                operation_id, True, write_result.get(\"rows_written\", 0)\n",
        "            )\n",
        "\n",
        "            # Check performance thresholds\n",
        "            threshold_violations = (\n",
        "                self.performance_monitor.check_performance_thresholds(operation_metrics)\n",
        "            )\n",
        "            if threshold_violations:\n",
        "                self.logger.warning(\n",
        "                    f\"Performance threshold violations: {threshold_violations}\"\n",
        "                )\n",
        "\n",
        "            result = {\n",
        "                \"success\": True,\n",
        "                \"run_id\": run_id,\n",
        "                \"operation_id\": operation_id,\n",
        "                \"rows_written\": write_result.get(\"rows_written\", 0),\n",
        "                \"write_result\": write_result,\n",
        "                \"operation_metrics\": operation_metrics,\n",
        "                \"threshold_violations\": threshold_violations,\n",
        "            }\n",
        "\n",
        "            self.logger.info(f\"Successfully wrote execution result for run {run_id}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            # End performance monitoring with failure\n",
        "            self.performance_monitor.end_operation(operation_id, False, 0, str(e))\n",
        "            # Create empty WriteResult for error case\n",
        "            empty_result: WriteResult = {\n",
        "                \"table_name\": self.storage_manager.table_fqn,\n",
        "                \"write_mode\": self.config.write_mode.value,\n",
        "                \"rows_written\": 0,\n",
        "                \"timestamp\": \"\",\n",
        "                \"success\": False,\n",
        "            }\n",
        "            self._update_metrics(empty_result, False)\n",
        "\n",
        "            self.logger.error(f\"Failed to write execution result for run {run_id}: {e}\")\n",
        "            raise\n",
        "\n",
        "    def write_step_results(\n",
        "        self,\n",
        "        step_results: Dict[str, StepResult],\n",
        "        run_id: Optional[str] = None,\n",
        "        run_mode: str = \"initial\",\n",
        "        metadata: Optional[Dict[str, Any]] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Write step results to log table.\n",
        "\n",
        "        Args:\n",
        "            step_results: Dictionary of step results\n",
        "            run_id: Unique run identifier (generated if not provided)\n",
        "            run_mode: Mode of the run\n",
        "            metadata: Additional metadata\n",
        "\n",
        "        Returns:\n",
        "            Dict containing write results and metrics\n",
        "        \"\"\"\n",
        "        operation_id = str(uuid.uuid4())\n",
        "        if run_id is None:\n",
        "            run_id = str(uuid.uuid4())\n",
        "\n",
        "        try:\n",
        "            # Start performance monitoring\n",
        "            self.performance_monitor.start_operation(operation_id, \"write_step_results\")\n",
        "\n",
        "            # Log operation start\n",
        "            self.logger.info(\n",
        "                f\"Writing {len(step_results)} step results for run {run_id}\"\n",
        "            )\n",
        "\n",
        "            # Process step results\n",
        "            log_rows = self.data_processor.process_step_results(\n",
        "                step_results, run_id, run_mode, metadata\n",
        "            )\n",
        "\n",
        "            # Create table if not exists\n",
        "            self.storage_manager.create_table_if_not_exists(self.schema)\n",
        "\n",
        "            # Write to storage\n",
        "            write_result = self.storage_manager.write_batch(\n",
        "                log_rows, self.config.write_mode\n",
        "            )\n",
        "\n",
        "            # Update metrics\n",
        "            self._update_metrics(write_result, True)\n",
        "\n",
        "            # End performance monitoring\n",
        "            operation_metrics = self.performance_monitor.end_operation(\n",
        "                operation_id, True, write_result.get(\"rows_written\", 0)\n",
        "            )\n",
        "\n",
        "            result = {\n",
        "                \"success\": True,\n",
        "                \"run_id\": run_id,\n",
        "                \"operation_id\": operation_id,\n",
        "                \"rows_written\": write_result.get(\"rows_written\", 0),\n",
        "                \"write_result\": write_result,\n",
        "                \"operation_metrics\": operation_metrics,\n",
        "            }\n",
        "\n",
        "            self.logger.info(f\"Successfully wrote step results for run {run_id}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            # End performance monitoring with failure\n",
        "            self.performance_monitor.end_operation(operation_id, False, 0, str(e))\n",
        "            # Create empty WriteResult for error case\n",
        "            empty_result: WriteResult = {\n",
        "                \"table_name\": self.storage_manager.table_fqn,\n",
        "                \"write_mode\": self.config.write_mode.value,\n",
        "                \"rows_written\": 0,\n",
        "                \"timestamp\": \"\",\n",
        "                \"success\": False,\n",
        "            }\n",
        "            self._update_metrics(empty_result, False)\n",
        "\n",
        "            self.logger.error(f\"Failed to write step results for run {run_id}: {e}\")\n",
        "            raise\n",
        "\n",
        "    def write_log_rows(\n",
        "        self,\n",
        "        log_rows: list[LogRow],\n",
        "        run_id: Optional[str] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Write log rows directly to the table.\n",
        "\n",
        "        Args:\n",
        "            log_rows: List of log rows to write\n",
        "            run_id: Unique run identifier (generated if not provided)\n",
        "\n",
        "        Returns:\n",
        "            Dict containing write results and metrics\n",
        "        \"\"\"\n",
        "        operation_id = str(uuid.uuid4())\n",
        "        if run_id is None:\n",
        "            run_id = str(uuid.uuid4())\n",
        "\n",
        "        try:\n",
        "            # Start performance monitoring\n",
        "            self.performance_monitor.start_operation(operation_id, \"write_log_rows\")\n",
        "\n",
        "            # Log operation start\n",
        "            self.logger.info(f\"Writing {len(log_rows)} log rows for run {run_id}\")\n",
        "\n",
        "            # Create table if not exists\n",
        "            self.storage_manager.create_table_if_not_exists(self.schema)\n",
        "\n",
        "            # Write to storage\n",
        "            write_result = self.storage_manager.write_batch(\n",
        "                log_rows, self.config.write_mode\n",
        "            )\n",
        "\n",
        "            # Update metrics\n",
        "            self._update_metrics(write_result, True)\n",
        "\n",
        "            # End performance monitoring\n",
        "            operation_metrics = self.performance_monitor.end_operation(\n",
        "                operation_id, True, write_result.get(\"rows_written\", 0)\n",
        "            )\n",
        "\n",
        "            result = {\n",
        "                \"success\": True,\n",
        "                \"run_id\": run_id,\n",
        "                \"operation_id\": operation_id,\n",
        "                \"rows_written\": write_result.get(\"rows_written\", 0),\n",
        "                \"write_result\": write_result,\n",
        "                \"operation_metrics\": operation_metrics,\n",
        "            }\n",
        "\n",
        "            self.logger.info(f\"Successfully wrote log rows for run {run_id}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            # End performance monitoring with failure\n",
        "            self.performance_monitor.end_operation(operation_id, False, 0, str(e))\n",
        "            # Create empty WriteResult for error case\n",
        "            empty_result: WriteResult = {\n",
        "                \"table_name\": self.storage_manager.table_fqn,\n",
        "                \"write_mode\": self.config.write_mode.value,\n",
        "                \"rows_written\": 0,\n",
        "                \"timestamp\": \"\",\n",
        "                \"success\": False,\n",
        "            }\n",
        "            self._update_metrics(empty_result, False)\n",
        "\n",
        "            self.logger.error(f\"Failed to write log rows for run {run_id}: {e}\")\n",
        "            raise\n",
        "\n",
        "    def write_execution_result_batch(\n",
        "        self,\n",
        "        execution_results: list[ExecutionResult],\n",
        "        run_ids: Optional[list[str]] = None,\n",
        "        run_mode: str = \"initial\",\n",
        "        metadata: Optional[Dict[str, Any]] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Write multiple execution results in batch.\n",
        "\n",
        "        Args:\n",
        "            execution_results: List of execution results to write\n",
        "            run_ids: List of run identifiers (generated if not provided)\n",
        "            run_mode: Mode of the runs\n",
        "            metadata: Additional metadata\n",
        "\n",
        "        Returns:\n",
        "            Dict containing batch write results and metrics\n",
        "        \"\"\"\n",
        "        operation_id = str(uuid.uuid4())\n",
        "        if run_ids is None:\n",
        "            run_ids = [str(uuid.uuid4()) for _ in execution_results]\n",
        "\n",
        "        try:\n",
        "            # Start performance monitoring\n",
        "            self.performance_monitor.start_operation(\n",
        "                operation_id, \"write_execution_result_batch\"\n",
        "            )\n",
        "\n",
        "            # Log operation start\n",
        "            self.logger.info(\n",
        "                f\"Writing batch of {len(execution_results)} execution results\"\n",
        "            )\n",
        "\n",
        "            # Process all execution results\n",
        "            all_log_rows = []\n",
        "            self._reset_table_total_rows_cache()\n",
        "            for i, execution_result in enumerate(execution_results):\n",
        "                run_id = run_ids[i] if i < len(run_ids) else str(uuid.uuid4())\n",
        "                log_rows = self.data_processor.process_execution_result(\n",
        "                    execution_result,\n",
        "                    run_id,\n",
        "                    run_mode,\n",
        "                    metadata,\n",
        "                    table_total_rows_provider=self._get_table_total_rows,\n",
        "                )\n",
        "                all_log_rows.extend(log_rows)\n",
        "\n",
        "            # Create table if not exists\n",
        "            self.storage_manager.create_table_if_not_exists(self.schema)\n",
        "\n",
        "            # Write to storage\n",
        "            write_result = self.storage_manager.write_batch(\n",
        "                all_log_rows, self.config.write_mode\n",
        "            )\n",
        "\n",
        "            # Update metrics\n",
        "            self._update_metrics(write_result, True)\n",
        "\n",
        "            # End performance monitoring\n",
        "            operation_metrics = self.performance_monitor.end_operation(\n",
        "                operation_id, True, write_result.get(\"rows_written\", 0)\n",
        "            )\n",
        "\n",
        "            result = {\n",
        "                \"success\": True,\n",
        "                \"operation_id\": operation_id,\n",
        "                \"execution_results_count\": len(execution_results),\n",
        "                \"total_rows_written\": write_result.get(\"rows_written\", 0),\n",
        "                \"write_result\": write_result,\n",
        "                \"operation_metrics\": operation_metrics,\n",
        "            }\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"Successfully wrote batch of {len(execution_results)} execution results\"\n",
        "            )\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            # End performance monitoring with failure\n",
        "            self.performance_monitor.end_operation(operation_id, False, 0, str(e))\n",
        "            # Create empty WriteResult for error case\n",
        "            empty_result: WriteResult = {\n",
        "                \"table_name\": self.storage_manager.table_fqn,\n",
        "                \"write_mode\": self.config.write_mode.value,\n",
        "                \"rows_written\": 0,\n",
        "                \"timestamp\": \"\",\n",
        "                \"success\": False,\n",
        "            }\n",
        "            self._update_metrics(empty_result, False)\n",
        "\n",
        "            self.logger.error(f\"Failed to write execution result batch: {e}\")\n",
        "            raise\n",
        "\n",
        "    def show_logs(self, limit: Optional[int] = None) -> None:\n",
        "        \"\"\"\n",
        "        Display logs from the table.\n",
        "\n",
        "        Args:\n",
        "            limit: Maximum number of rows to display\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\n",
        "                f\"Displaying logs from {self.config.table_schema}.{self.config.table_name}\"\n",
        "            )\n",
        "\n",
        "            # Query logs using spark.table for compatibility\n",
        "            df = self.spark.table(\n",
        "                f\"{self.config.table_schema}.{self.config.table_name}\"\n",
        "            )\n",
        "\n",
        "            # Show DataFrame\n",
        "            if limit is not None:\n",
        "                df.show(limit)\n",
        "            else:\n",
        "                df.show()\n",
        "\n",
        "            self.logger.info(\"Logs displayed successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to display logs: {e}\")\n",
        "            raise\n",
        "\n",
        "    def get_table_info(self) -> TableInfo:\n",
        "        \"\"\"\n",
        "        Get information about the log table.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing table information\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.storage_manager.get_table_info()\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to get table info: {e}\")\n",
        "            raise WriterError(f\"Failed to get table info: {e}\") from e\n",
        "\n",
        "    def _reset_table_total_rows_cache(self) -> None:\n",
        "        \"\"\"Clear cached table counts so subsequent operations refresh totals.\"\"\"\n",
        "        self._table_total_rows_cache.clear()\n",
        "\n",
        "    def _get_table_total_rows(self, table_fqn: Optional[str]) -> Optional[int]:\n",
        "        \"\"\"\n",
        "        Determine the total number of rows for a given table.\n",
        "\n",
        "        Args:\n",
        "            table_fqn: Fully qualified table name.\n",
        "\n",
        "        Returns:\n",
        "            Row count if available, otherwise None.\n",
        "        \"\"\"\n",
        "        if not table_fqn:\n",
        "            return None\n",
        "\n",
        "        if table_fqn in self._table_total_rows_cache:\n",
        "            return self._table_total_rows_cache[table_fqn]\n",
        "\n",
        "        try:\n",
        "            table_accessor = getattr(self.spark, \"table\", None)\n",
        "            if not callable(table_accessor):\n",
        "                self.logger.debug(\n",
        "                    \"table_total_rows: spark session does not expose table(); skipping count\"\n",
        "                )\n",
        "                self._table_total_rows_cache[table_fqn] = None\n",
        "                return None\n",
        "\n",
        "            if not table_exists(self.spark, table_fqn):\n",
        "                self.logger.debug(\n",
        "                    f\"table_total_rows: table {table_fqn} does not exist; leaving value as None\"\n",
        "                )\n",
        "                self._table_total_rows_cache[table_fqn] = None\n",
        "                return None\n",
        "\n",
        "            table_df = table_accessor(table_fqn)\n",
        "            count_method = getattr(table_df, \"count\", None)\n",
        "            if not callable(count_method):\n",
        "                self.logger.debug(\n",
        "                    f\"table_total_rows: object for {table_fqn} lacks count(); skipping\"\n",
        "                )\n",
        "                self._table_total_rows_cache[table_fqn] = None\n",
        "                return None\n",
        "\n",
        "            raw_count = count_method()\n",
        "            if isinstance(raw_count, (int, float)):\n",
        "                row_count = int(raw_count)\n",
        "            else:\n",
        "                row_count = None\n",
        "\n",
        "            self._table_total_rows_cache[table_fqn] = row_count\n",
        "            return row_count\n",
        "        except Exception as exc:  # pragma: no cover - defensive logging path\n",
        "            self.logger.warning(\n",
        "                f\"table_total_rows: unable to compute row count for {table_fqn}: {exc}\"\n",
        "            )\n",
        "            self._table_total_rows_cache[table_fqn] = None\n",
        "            return None\n",
        "\n",
        "    def optimize_table(self) -> OptimizeResult:\n",
        "        \"\"\"\n",
        "        Optimize the Delta table for better performance.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing optimization results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Optimizing Delta table\")\n",
        "            return self.storage_manager.optimize_table()\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to optimize table: {e}\")\n",
        "            raise\n",
        "\n",
        "    def vacuum_table(self, retention_hours: int = 168) -> VacuumResult:\n",
        "        \"\"\"\n",
        "        Vacuum the Delta table to remove old files.\n",
        "\n",
        "        Args:\n",
        "            retention_hours: Hours of retention for old files\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing vacuum results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Vacuuming Delta table (retention: {retention_hours}h)\")\n",
        "            return self.storage_manager.vacuum_table(retention_hours)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to vacuum table: {e}\")\n",
        "            raise\n",
        "\n",
        "    def analyze_quality_trends(self, days: int = 30) -> QualityTrends:\n",
        "        \"\"\"\n",
        "        Analyze data quality trends.\n",
        "\n",
        "        Args:\n",
        "            days: Number of days to analyze\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing quality trend analysis\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Analyzing quality trends for last {days} days\")\n",
        "\n",
        "            # Query recent logs\n",
        "            df = self.storage_manager.query_logs()\n",
        "\n",
        "            # Analyze quality trends\n",
        "            return self.quality_analyzer.analyze_quality_trends(df, days)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to analyze quality trends: {e}\")\n",
        "            raise WriterError(f\"Failed to analyze quality trends: {e}\") from e\n",
        "\n",
        "    def analyze_execution_trends(self, days: int = 30) -> ExecutionTrends:\n",
        "        \"\"\"\n",
        "        Analyze execution trends.\n",
        "\n",
        "        Args:\n",
        "            days: Number of days to analyze\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing execution trend analysis\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Analyzing execution trends for last {days} days\")\n",
        "\n",
        "            # Query recent logs\n",
        "            df = self.storage_manager.query_logs()\n",
        "\n",
        "            # Analyze execution trends\n",
        "            return self.trend_analyzer.analyze_execution_trends(df, days)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to analyze execution trends: {e}\")\n",
        "            raise WriterError(f\"Failed to analyze execution trends: {e}\") from e\n",
        "\n",
        "    def detect_quality_anomalies(self) -> QualityAnomalies:\n",
        "        \"\"\"\n",
        "        Detect data quality anomalies.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing anomaly detection results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Detecting quality anomalies\")\n",
        "\n",
        "            # Query logs\n",
        "            df = self.storage_manager.query_logs()\n",
        "\n",
        "            # Detect anomalies\n",
        "            return self.quality_analyzer.detect_quality_anomalies(df)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to detect quality anomalies: {e}\")\n",
        "            raise WriterError(f\"Failed to detect quality anomalies: {e}\") from e\n",
        "\n",
        "    def generate_performance_report(self) -> PerformanceReport:\n",
        "        \"\"\"\n",
        "        Generate comprehensive performance report.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing performance report\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Generating performance report\")\n",
        "\n",
        "            # Query logs\n",
        "            df = self.storage_manager.query_logs()\n",
        "\n",
        "            # Generate report\n",
        "            return self.analytics_engine.generate_performance_report(df)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to generate performance report: {e}\")\n",
        "            raise WriterError(f\"Failed to generate performance report: {e}\") from e\n",
        "\n",
        "    def get_metrics(self) -> WriterMetrics:\n",
        "        \"\"\"Get current writer metrics.\"\"\"\n",
        "        return self.performance_monitor.get_metrics()\n",
        "\n",
        "    def reset_metrics(self) -> None:\n",
        "        \"\"\"Reset writer metrics.\"\"\"\n",
        "        # Reset LogWriter metrics\n",
        "        self.metrics = {\n",
        "            \"total_writes\": 0,\n",
        "            \"successful_writes\": 0,\n",
        "            \"failed_writes\": 0,\n",
        "            \"total_duration_secs\": 0.0,\n",
        "            \"avg_write_duration_secs\": 0.0,\n",
        "            \"total_rows_written\": 0,\n",
        "            \"memory_usage_peak_mb\": 0.0,\n",
        "        }\n",
        "        # Reset performance monitor metrics\n",
        "        self.performance_monitor.reset_metrics()\n",
        "\n",
        "    def get_memory_usage(self) -> MemoryUsageInfo:\n",
        "        \"\"\"Get current memory usage information.\"\"\"\n",
        "        return self.performance_monitor.get_memory_usage()\n",
        "\n",
        "    def _update_metrics(self, write_result: WriteResult, success: bool) -> None:\n",
        "        \"\"\"Update writer metrics.\"\"\"\n",
        "        try:\n",
        "            self.metrics[\"total_writes\"] += 1\n",
        "            if success:\n",
        "                self.metrics[\"successful_writes\"] += 1\n",
        "            else:\n",
        "                self.metrics[\"failed_writes\"] += 1\n",
        "\n",
        "            if \"rows_written\" in write_result:\n",
        "                self.metrics[\"total_rows_written\"] += write_result[\"rows_written\"]\n",
        "\n",
        "            # Update performance monitor metrics\n",
        "            self.performance_monitor.metrics.update(self.metrics)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to update metrics: {e}\")\n",
        "\n",
        "    # Backward compatibility methods for tests\n",
        "    def _write_log_rows(\n",
        "        self,\n",
        "        log_rows: list[LogRow],\n",
        "        run_id: str,\n",
        "        metadata: Optional[Dict[str, Any]] = None,\n",
        "    ) -> WriteResult:\n",
        "        \"\"\"Write log rows directly (for backward compatibility with tests).\"\"\"\n",
        "        return self.storage_manager.write_batch(log_rows, self.config.write_mode)\n",
        "\n",
        "    def _write_log_rows_batch(\n",
        "        self, log_rows: list[LogRow], run_id: str, batch_size: int = 100\n",
        "    ) -> WriteResult:\n",
        "        \"\"\"Write log rows in batches (for backward compatibility with tests).\"\"\"\n",
        "        results = []\n",
        "        for i in range(0, len(log_rows), batch_size):\n",
        "            batch = log_rows[i : i + batch_size]\n",
        "            result = self._write_log_rows(batch, run_id)\n",
        "            results.append(result)\n",
        "\n",
        "        total_rows = sum(r.get(\"rows_written\", 0) for r in results)\n",
        "        from datetime import datetime\n",
        "\n",
        "        return {\n",
        "            \"table_name\": self.storage_manager.table_fqn,\n",
        "            \"write_mode\": self.config.write_mode.value,\n",
        "            \"rows_written\": total_rows,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"success\": True,\n",
        "        }\n",
        "\n",
        "    def _create_dataframe_from_log_rows(self, log_rows: list[LogRow]) -> Any:\n",
        "        \"\"\"Create DataFrame from log rows (for backward compatibility with tests).\"\"\"\n",
        "        # Convert TypedDict to regular dicts for createDataFrame\n",
        "        dict_rows = [dict(row) for row in log_rows]\n",
        "        return self.spark.createDataFrame(dict_rows, schema=self.schema)\n",
        "\n",
        "    def detect_anomalies(self, log_rows: list[LogRow]) -> AnomalyReport:\n",
        "        \"\"\"Detect anomalies in log data (for backward compatibility with tests).\"\"\"\n",
        "        if not self.config.enable_anomaly_detection:\n",
        "            return {\n",
        "                \"performance_anomalies\": [],\n",
        "                \"quality_anomalies\": [],\n",
        "                \"anomaly_score\": 0.0,\n",
        "                \"total_anomalies\": 0,\n",
        "                \"total_executions\": 0,\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            # Basic anomaly detection logic\n",
        "            if not log_rows:\n",
        "                return {\n",
        "                    \"performance_anomalies\": [],\n",
        "                    \"quality_anomalies\": [],\n",
        "                    \"anomaly_score\": 0.0,\n",
        "                    \"total_anomalies\": 0,\n",
        "                    \"total_executions\": len(log_rows),\n",
        "                }\n",
        "\n",
        "            # Check for duration anomalies (very simple logic)\n",
        "            durations = [\n",
        "                row.get(\"duration_secs\", 0)\n",
        "                for row in log_rows\n",
        "                if \"duration_secs\" in row\n",
        "            ]\n",
        "            if not durations:\n",
        "                return {\n",
        "                    \"performance_anomalies\": [],\n",
        "                    \"quality_anomalies\": [],\n",
        "                    \"anomaly_score\": 0.0,\n",
        "                    \"total_anomalies\": 0,\n",
        "                    \"total_executions\": len(log_rows),\n",
        "                }\n",
        "\n",
        "            avg_duration = sum(durations) / len(durations)\n",
        "            threshold = avg_duration * 2  # 2x average is anomalous\n",
        "\n",
        "            # from .monitoring import PerformanceAnomaly  # Removed: defined in notebook cells above\n",
        "\n",
        "            performance_anomalies = []\n",
        "            for row in log_rows:\n",
        "                duration = row.get(\"duration_secs\", 0)\n",
        "                if duration > threshold:\n",
        "                    anomaly: PerformanceAnomaly = {\n",
        "                        \"step\": row.get(\"step_name\", \"unknown\"),\n",
        "                        \"execution_time\": float(duration),\n",
        "                        \"validation_rate\": float(row.get(\"validation_rate\", 0.0)),\n",
        "                        \"success\": bool(row.get(\"success\", False)),\n",
        "                    }\n",
        "                    performance_anomalies.append(anomaly)\n",
        "\n",
        "            total_anomalies = len(performance_anomalies)\n",
        "            total_executions = len(log_rows)\n",
        "            anomaly_score = (\n",
        "                (total_anomalies / total_executions * 100)\n",
        "                if total_executions > 0\n",
        "                else 0.0\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                \"performance_anomalies\": performance_anomalies,\n",
        "                \"quality_anomalies\": [],\n",
        "                \"anomaly_score\": round(anomaly_score, 2),\n",
        "                \"total_anomalies\": total_anomalies,\n",
        "                \"total_executions\": total_executions,\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Anomaly detection failed: {e}\")\n",
        "            return {\n",
        "                \"performance_anomalies\": [],\n",
        "                \"quality_anomalies\": [],\n",
        "                \"anomaly_score\": 0.0,\n",
        "                \"total_anomalies\": 0,\n",
        "                \"total_executions\": len(log_rows) if log_rows else 0,\n",
        "            }\n",
        "\n",
        "    # Additional methods expected by tests\n",
        "    def validate_log_data_quality(self, log_rows: list[LogRow]) -> DataQualityReport:\n",
        "        \"\"\"Validate log data quality (for backward compatibility with tests).\"\"\"\n",
        "        try:\n",
        "            # from ..validation.utils import get_dataframe_info  # Removed: defined in notebook cells above\n",
        "\n",
        "            if not log_rows:\n",
        "                return {\n",
        "                    \"is_valid\": True,\n",
        "                    \"total_rows\": 0,\n",
        "                    \"null_counts\": {},\n",
        "                    \"validation_issues\": [],\n",
        "                    \"failed_executions\": 0,\n",
        "                    \"data_quality_score\": 100.0,\n",
        "                }\n",
        "\n",
        "            # Create DataFrame for validation\n",
        "            df = self._create_dataframe_from_log_rows(log_rows)\n",
        "\n",
        "            # Get basic info\n",
        "            df_info = get_dataframe_info(df)\n",
        "\n",
        "            # Count failed executions\n",
        "            failed_executions = sum(\n",
        "                1 for row in log_rows if not row.get(\"success\", True)\n",
        "            )\n",
        "\n",
        "            # Calculate quality score\n",
        "            total_rows = df_info.get(\"row_count\", len(log_rows))\n",
        "            validation_rate = 100.0  # Simplified\n",
        "            data_quality_score = (\n",
        "                validation_rate\n",
        "                if failed_executions == 0\n",
        "                else max(0, validation_rate - (failed_executions / total_rows * 100))\n",
        "            )\n",
        "\n",
        "            # Check for null values in critical columns\n",
        "            null_counts: Dict[str, int] = {}\n",
        "\n",
        "            # Determine validation issues\n",
        "            validation_issues = []\n",
        "            if failed_executions > 0:\n",
        "                validation_issues.append(f\"{failed_executions} failed executions\")\n",
        "\n",
        "            return {\n",
        "                \"is_valid\": failed_executions == 0 and len(validation_issues) == 0,\n",
        "                \"total_rows\": total_rows,\n",
        "                \"null_counts\": null_counts,\n",
        "                \"validation_issues\": validation_issues,\n",
        "                \"failed_executions\": failed_executions,\n",
        "                \"data_quality_score\": round(data_quality_score, 2),\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"is_valid\": False,\n",
        "                \"total_rows\": len(log_rows) if log_rows else 0,\n",
        "                \"null_counts\": {},\n",
        "                \"validation_issues\": [str(e)],\n",
        "                \"failed_executions\": 0,\n",
        "                \"data_quality_score\": 0.0,\n",
        "            }\n",
        "\n",
        "    # ========================================================================\n",
        "    # New simplified API methods for working with PipelineReport\n",
        "    # ========================================================================\n",
        "\n",
        "    def _convert_report_to_log_rows(\n",
        "        self, report: PipelineReport, run_id: Optional[str] = None\n",
        "    ) -> list[LogRow]:\n",
        "        \"\"\"\n",
        "        Convert a PipelineReport to log rows for storage.\n",
        "\n",
        "        This method extracts data from a PipelineReport and creates one log row\n",
        "        per pipeline step (bronze, silver, gold) with step-specific metrics.\n",
        "\n",
        "        Args:\n",
        "            report: PipelineReport to convert\n",
        "            run_id: Optional run ID (generated if not provided)\n",
        "\n",
        "        Returns:\n",
        "            List of LogRow dictionaries ready for storage (one per step)\n",
        "        \"\"\"\n",
        "\n",
        "        if run_id is None:\n",
        "            run_id = str(uuid.uuid4())\n",
        "\n",
        "        log_rows: list[LogRow] = []\n",
        "\n",
        "        # Helper function to parse datetime strings\n",
        "        def parse_datetime(dt_str: Optional[str]) -> Optional[datetime]:\n",
        "            if dt_str is None:\n",
        "                return None\n",
        "            try:\n",
        "                return datetime.fromisoformat(dt_str)\n",
        "            except (ValueError, AttributeError):\n",
        "                return None\n",
        "\n",
        "        # Process bronze steps\n",
        "        for step_name, step_info in report.bronze_results.items():\n",
        "            # Calculate valid/invalid rows from validation rate\n",
        "            rows_processed = int(step_info.get(\"rows_processed\") or 0)\n",
        "            validation_rate_val = step_info.get(\"validation_rate\")\n",
        "            validation_rate = float(\n",
        "                validation_rate_val if validation_rate_val is not None else 100.0\n",
        "            )\n",
        "            valid_rows = int(rows_processed * validation_rate / 100.0)\n",
        "            invalid_rows = rows_processed - valid_rows\n",
        "\n",
        "            table_fqn = step_info.get(\"output_table\")\n",
        "            table_total_rows = step_info.get(\"table_total_rows\")\n",
        "            if table_total_rows is None:\n",
        "                table_total_rows = self._get_table_total_rows(table_fqn)\n",
        "\n",
        "            bronze_log_row: LogRow = {\n",
        "                # Run-level information\n",
        "                \"run_id\": run_id,\n",
        "                \"run_mode\": report.mode.value,\n",
        "                \"run_started_at\": report.start_time,\n",
        "                \"run_ended_at\": report.end_time,\n",
        "                # Execution context\n",
        "                \"execution_id\": report.execution_id,\n",
        "                \"pipeline_id\": report.pipeline_id,\n",
        "                \"schema\": self.config.table_schema,\n",
        "                # Step-level information\n",
        "                \"phase\": \"bronze\",\n",
        "                \"step_name\": step_name,\n",
        "                \"step_type\": \"bronze\",\n",
        "                # Timing information\n",
        "                \"start_time\": parse_datetime(step_info.get(\"start_time\")),\n",
        "                \"end_time\": parse_datetime(step_info.get(\"end_time\")),\n",
        "                \"duration_secs\": float(step_info.get(\"duration\", 0.0)),\n",
        "                # Table information\n",
        "                \"table_fqn\": step_info.get(\"output_table\"),\n",
        "                \"write_mode\": step_info.get(\"write_mode\"),\n",
        "                # Data metrics\n",
        "                \"rows_processed\": rows_processed,\n",
        "                \"rows_written\": int(step_info.get(\"rows_written\") or rows_processed),\n",
        "                \"input_rows\": int(step_info.get(\"input_rows\") or rows_processed),\n",
        "                \"output_rows\": int(step_info.get(\"rows_written\") or rows_processed),\n",
        "                \"table_total_rows\": table_total_rows,\n",
        "                # Validation metrics\n",
        "                \"valid_rows\": valid_rows,\n",
        "                \"invalid_rows\": invalid_rows,\n",
        "                \"validation_rate\": validation_rate,\n",
        "                # Execution status\n",
        "                \"success\": step_info.get(\"status\") == \"completed\",\n",
        "                \"error_message\": step_info.get(\"error\"),\n",
        "                # Performance metrics\n",
        "                \"memory_usage_mb\": None,\n",
        "                \"cpu_usage_percent\": None,\n",
        "                # Metadata\n",
        "                \"metadata\": {},\n",
        "            }\n",
        "            log_rows.append(bronze_log_row)\n",
        "\n",
        "        # Process silver steps\n",
        "        for step_name, step_info in report.silver_results.items():\n",
        "            # Calculate valid/invalid rows from validation rate\n",
        "            rows_processed = int(step_info.get(\"rows_processed\") or 0)\n",
        "            validation_rate_val = step_info.get(\"validation_rate\")\n",
        "            validation_rate = float(\n",
        "                validation_rate_val if validation_rate_val is not None else 100.0\n",
        "            )\n",
        "            valid_rows = int(rows_processed * validation_rate / 100.0)\n",
        "            invalid_rows = rows_processed - valid_rows\n",
        "\n",
        "            table_fqn = step_info.get(\"output_table\")\n",
        "            table_total_rows = step_info.get(\"table_total_rows\")\n",
        "            if table_total_rows is None:\n",
        "                table_total_rows = self._get_table_total_rows(table_fqn)\n",
        "\n",
        "            silver_log_row: LogRow = {\n",
        "                # Run-level information\n",
        "                \"run_id\": run_id,\n",
        "                \"run_mode\": report.mode.value,\n",
        "                \"run_started_at\": report.start_time,\n",
        "                \"run_ended_at\": report.end_time,\n",
        "                # Execution context\n",
        "                \"execution_id\": report.execution_id,\n",
        "                \"pipeline_id\": report.pipeline_id,\n",
        "                \"schema\": self.config.table_schema,\n",
        "                # Step-level information\n",
        "                \"phase\": \"silver\",\n",
        "                \"step_name\": step_name,\n",
        "                \"step_type\": \"silver\",\n",
        "                # Timing information\n",
        "                \"start_time\": parse_datetime(step_info.get(\"start_time\")),\n",
        "                \"end_time\": parse_datetime(step_info.get(\"end_time\")),\n",
        "                \"duration_secs\": float(step_info.get(\"duration\", 0.0)),\n",
        "                # Table information\n",
        "                \"table_fqn\": step_info.get(\"output_table\"),\n",
        "                \"write_mode\": step_info.get(\"write_mode\"),\n",
        "                # Data metrics\n",
        "                \"rows_processed\": rows_processed,\n",
        "                \"rows_written\": int(step_info.get(\"rows_written\") or rows_processed),\n",
        "                \"input_rows\": int(step_info.get(\"input_rows\") or rows_processed),\n",
        "                \"output_rows\": int(step_info.get(\"rows_written\") or rows_processed),\n",
        "                \"table_total_rows\": table_total_rows,\n",
        "                # Validation metrics\n",
        "                \"valid_rows\": valid_rows,\n",
        "                \"invalid_rows\": invalid_rows,\n",
        "                \"validation_rate\": validation_rate,\n",
        "                # Execution status\n",
        "                \"success\": step_info.get(\"status\") == \"completed\",\n",
        "                \"error_message\": step_info.get(\"error\"),\n",
        "                # Performance metrics\n",
        "                \"memory_usage_mb\": None,\n",
        "                \"cpu_usage_percent\": None,\n",
        "                # Metadata\n",
        "                \"metadata\": {},\n",
        "            }\n",
        "            log_rows.append(silver_log_row)\n",
        "\n",
        "        # Process gold steps\n",
        "        for step_name, step_info in report.gold_results.items():\n",
        "            # Calculate valid/invalid rows from validation rate\n",
        "            rows_processed = int(step_info.get(\"rows_processed\") or 0)\n",
        "            validation_rate_val = step_info.get(\"validation_rate\")\n",
        "            validation_rate = float(\n",
        "                validation_rate_val if validation_rate_val is not None else 100.0\n",
        "            )\n",
        "            valid_rows = int(rows_processed * validation_rate / 100.0)\n",
        "            invalid_rows = rows_processed - valid_rows\n",
        "\n",
        "            table_fqn = step_info.get(\"output_table\")\n",
        "            table_total_rows = step_info.get(\"table_total_rows\")\n",
        "            if table_total_rows is None:\n",
        "                table_total_rows = self._get_table_total_rows(table_fqn)\n",
        "\n",
        "            gold_log_row: LogRow = {\n",
        "                # Run-level information\n",
        "                \"run_id\": run_id,\n",
        "                \"run_mode\": report.mode.value,\n",
        "                \"run_started_at\": report.start_time,\n",
        "                \"run_ended_at\": report.end_time,\n",
        "                # Execution context\n",
        "                \"execution_id\": report.execution_id,\n",
        "                \"pipeline_id\": report.pipeline_id,\n",
        "                \"schema\": self.config.table_schema,\n",
        "                # Step-level information\n",
        "                \"phase\": \"gold\",\n",
        "                \"step_name\": step_name,\n",
        "                \"step_type\": \"gold\",\n",
        "                # Timing information\n",
        "                \"start_time\": parse_datetime(step_info.get(\"start_time\")),\n",
        "                \"end_time\": parse_datetime(step_info.get(\"end_time\")),\n",
        "                \"duration_secs\": float(step_info.get(\"duration\", 0.0)),\n",
        "                # Table information\n",
        "                \"table_fqn\": step_info.get(\"output_table\"),\n",
        "                \"write_mode\": step_info.get(\"write_mode\"),\n",
        "                # Data metrics\n",
        "                \"rows_processed\": rows_processed,\n",
        "                \"rows_written\": int(step_info.get(\"rows_written\") or rows_processed),\n",
        "                \"input_rows\": int(step_info.get(\"input_rows\") or rows_processed),\n",
        "                \"output_rows\": int(step_info.get(\"rows_written\") or rows_processed),\n",
        "                \"table_total_rows\": table_total_rows,\n",
        "                # Validation metrics\n",
        "                \"valid_rows\": valid_rows,\n",
        "                \"invalid_rows\": invalid_rows,\n",
        "                \"validation_rate\": validation_rate,\n",
        "                # Execution status\n",
        "                \"success\": step_info.get(\"status\") == \"completed\",\n",
        "                \"error_message\": step_info.get(\"error\"),\n",
        "                # Performance metrics\n",
        "                \"memory_usage_mb\": None,\n",
        "                \"cpu_usage_percent\": None,\n",
        "                # Metadata\n",
        "                \"metadata\": {},\n",
        "            }\n",
        "            log_rows.append(gold_log_row)\n",
        "\n",
        "        return log_rows\n",
        "\n",
        "    def create_table(\n",
        "        self, report: PipelineReport, run_id: Optional[str] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Create or overwrite the log table with data from a PipelineReport.\n",
        "\n",
        "        Creates the log table if it doesn't exist, and writes the report data\n",
        "        using OVERWRITE mode (replacing any existing data). This method is\n",
        "        useful for initial table creation or full refresh scenarios.\n",
        "\n",
        "        **Note:** This method uses OVERWRITE mode, which will replace all\n",
        "        existing data in the table. Use `append()` if you want to add data\n",
        "        to an existing table.\n",
        "\n",
        "        Args:\n",
        "            report: PipelineReport instance containing pipeline execution\n",
        "                results. Required. The report should contain results for\n",
        "                bronze, silver, and gold steps.\n",
        "            run_id: Unique run identifier. Optional. If not provided, a UUID\n",
        "                is automatically generated.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with write results containing:\n",
        "                - `success`: Boolean indicating if operation succeeded\n",
        "                - `run_id`: The run identifier used\n",
        "                - `operation_id`: Unique operation identifier\n",
        "                - `rows_written`: Number of rows written to the table\n",
        "                - `table_fqn`: Fully qualified table name (schema.table_name)\n",
        "                - `write_result`: WriteResult dictionary with detailed results\n",
        "                - `operation_metrics`: Performance metrics for the operation\n",
        "\n",
        "        Raises:\n",
        "            WriterTableError: If table creation or write operation fails\n",
        "            WriterValidationError: If report data validation fails\n",
        "\n",
        "        Example:\n",
        "            >>> from pipeline_builder.writer import LogWriter\n",
        "            >>> from pipeline_builder.pipeline.models import PipelineReport\n",
        "            >>>\n",
        "            >>> writer = LogWriter(spark, schema=\"analytics\", table_name=\"logs\")\n",
        "            >>> result = writer.create_table(pipeline_report, run_id=\"run_123\")\n",
        "            >>> print(f\"Created table with {result['rows_written']} rows\")\n",
        "            >>> print(f\"Table: {result['table_fqn']}\")\n",
        "        \"\"\"\n",
        "        operation_id = str(uuid.uuid4())\n",
        "        if run_id is None:\n",
        "            run_id = str(uuid.uuid4())\n",
        "\n",
        "        try:\n",
        "            # Reset per-operation cache\n",
        "            self._reset_table_total_rows_cache()\n",
        "\n",
        "            # Start performance monitoring\n",
        "            self.performance_monitor.start_operation(operation_id, \"create_table\")\n",
        "\n",
        "            # Log operation start\n",
        "            self.logger.info(f\"\ud83d\udcca Creating log table {self.table_fqn} for run {run_id}\")\n",
        "\n",
        "            # Convert report to log rows\n",
        "            log_rows = self._convert_report_to_log_rows(report, run_id)\n",
        "\n",
        "            # Create table if not exists\n",
        "            self.storage_manager.create_table_if_not_exists(self.schema)\n",
        "\n",
        "            # Write to storage with OVERWRITE mode\n",
        "            write_result = self.storage_manager.write_batch(\n",
        "                log_rows, WriteMode.OVERWRITE\n",
        "            )\n",
        "\n",
        "            # Update metrics\n",
        "            self._update_metrics(write_result, True)\n",
        "\n",
        "            # End performance monitoring\n",
        "            operation_metrics = self.performance_monitor.end_operation(\n",
        "                operation_id, True, write_result.get(\"rows_written\", 0)\n",
        "            )\n",
        "\n",
        "            result = {\n",
        "                \"success\": True,\n",
        "                \"run_id\": run_id,\n",
        "                \"operation_id\": operation_id,\n",
        "                \"rows_written\": write_result.get(\"rows_written\", 0),\n",
        "                \"table_fqn\": self.table_fqn,\n",
        "                \"write_result\": write_result,\n",
        "                \"operation_metrics\": operation_metrics,\n",
        "            }\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"\u2705 Successfully created log table {self.table_fqn} with \"\n",
        "                f\"{result['rows_written']} row(s) for run {run_id}\"\n",
        "            )\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            # End performance monitoring with failure\n",
        "            self.performance_monitor.end_operation(operation_id, False, 0, str(e))\n",
        "            # Create empty WriteResult for error case\n",
        "            empty_result: WriteResult = {\n",
        "                \"table_name\": self.storage_manager.table_fqn,\n",
        "                \"write_mode\": self.config.write_mode.value,\n",
        "                \"rows_written\": 0,\n",
        "                \"timestamp\": \"\",\n",
        "                \"success\": False,\n",
        "            }\n",
        "            self._update_metrics(empty_result, False)\n",
        "\n",
        "            self.logger.error(f\"\u274c Failed to create log table for run {run_id}: {e}\")\n",
        "            raise\n",
        "\n",
        "    def append(\n",
        "        self, report: PipelineReport, run_id: Optional[str] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Append data from a PipelineReport to the log table.\n",
        "\n",
        "        Appends the report data to an existing log table using APPEND mode.\n",
        "        If the table doesn't exist, it will be created first. This method is\n",
        "        useful for incremental logging scenarios where you want to preserve\n",
        "        historical data.\n",
        "\n",
        "        **Note:** This method uses APPEND mode, which adds new data to the\n",
        "        existing table. Use `create_table()` if you want to replace all\n",
        "        existing data.\n",
        "\n",
        "        Args:\n",
        "            report: PipelineReport instance containing pipeline execution\n",
        "                results. Required. The report should contain results for\n",
        "                bronze, silver, and gold steps.\n",
        "            run_id: Unique run identifier. Optional. If not provided, a UUID\n",
        "                is automatically generated.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with write results containing:\n",
        "                - `success`: Boolean indicating if operation succeeded\n",
        "                - `run_id`: The run identifier used\n",
        "                - `operation_id`: Unique operation identifier\n",
        "                - `rows_written`: Number of rows written to the table\n",
        "                - `table_fqn`: Fully qualified table name (schema.table_name)\n",
        "                - `write_result`: WriteResult dictionary with detailed results\n",
        "                - `operation_metrics`: Performance metrics for the operation\n",
        "\n",
        "        Raises:\n",
        "            WriterTableError: If table creation or write operation fails\n",
        "            WriterValidationError: If report data validation fails\n",
        "\n",
        "        Example:\n",
        "            >>> from pipeline_builder.writer import LogWriter\n",
        "            >>> from pipeline_builder.pipeline.models import PipelineReport\n",
        "            >>>\n",
        "            >>> writer = LogWriter(spark, schema=\"analytics\", table_name=\"logs\")\n",
        "            >>> result = writer.append(pipeline_report, run_id=\"run_123\")\n",
        "            >>> print(f\"Appended {result['rows_written']} rows to {result['table_fqn']}\")\n",
        "        \"\"\"\n",
        "        operation_id = str(uuid.uuid4())\n",
        "        if run_id is None:\n",
        "            run_id = str(uuid.uuid4())\n",
        "\n",
        "        try:\n",
        "            # Reset per-operation cache\n",
        "            self._reset_table_total_rows_cache()\n",
        "\n",
        "            # Start performance monitoring\n",
        "            self.performance_monitor.start_operation(operation_id, \"append\")\n",
        "\n",
        "            # Log operation start\n",
        "            self.logger.info(\n",
        "                f\"\ud83d\udcca Appending to log table {self.table_fqn} for run {run_id}\"\n",
        "            )\n",
        "\n",
        "            # Convert report to log rows\n",
        "            log_rows = self._convert_report_to_log_rows(report, run_id)\n",
        "\n",
        "            # Create table if not exists (for first append)\n",
        "            self.storage_manager.create_table_if_not_exists(self.schema)\n",
        "\n",
        "            # Write to storage with APPEND mode\n",
        "            write_result = self.storage_manager.write_batch(log_rows, WriteMode.APPEND)\n",
        "\n",
        "            # Update metrics\n",
        "            self._update_metrics(write_result, True)\n",
        "\n",
        "            # End performance monitoring\n",
        "            operation_metrics = self.performance_monitor.end_operation(\n",
        "                operation_id, True, write_result.get(\"rows_written\", 0)\n",
        "            )\n",
        "\n",
        "            result = {\n",
        "                \"success\": True,\n",
        "                \"run_id\": run_id,\n",
        "                \"operation_id\": operation_id,\n",
        "                \"rows_written\": write_result.get(\"rows_written\", 0),\n",
        "                \"table_fqn\": self.table_fqn,\n",
        "                \"write_result\": write_result,\n",
        "                \"operation_metrics\": operation_metrics,\n",
        "            }\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"\u2705 Successfully appended {result['rows_written']} row(s) to \"\n",
        "                f\"{self.table_fqn} for run {run_id}\"\n",
        "            )\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            # End performance monitoring with failure\n",
        "            self.performance_monitor.end_operation(operation_id, False, 0, str(e))\n",
        "            # Create empty WriteResult for error case\n",
        "            empty_result: WriteResult = {\n",
        "                \"table_name\": self.storage_manager.table_fqn,\n",
        "                \"write_mode\": self.config.write_mode.value,\n",
        "                \"rows_written\": 0,\n",
        "                \"timestamp\": \"\",\n",
        "                \"success\": False,\n",
        "            }\n",
        "            self._update_metrics(empty_result, False)\n",
        "\n",
        "            self.logger.error(f\"\u274c Failed to append to log table for run {run_id}: {e}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.pipeline.builder (pipeline_builder)\n",
        "#\n",
        "# Dependencies: abstracts.builder, abstracts.step, pipeline_builder.compat, pipeline_builder.engine, pipeline_builder.functions, pipeline_builder.models, pipeline_builder.pipeline.runner, pipeline_builder.sql_source, pipeline_builder.table_operations, pipeline_builder.types, pipeline_builder.validation, pipeline_builder_base.builder, pipeline_builder_base.dependencies, pipeline_builder_base.errors, pipeline_builder_base.logging, pipeline_builder_base.models, pipeline_builder_base.validation, pipeline_builder_base.validation.pipeline_validator\n",
        "\n",
        "\"\"\"PipelineBuilder for constructing data pipelines.\n",
        "\n",
        "This module provides a clean, maintainable PipelineBuilder that handles\n",
        "pipeline construction with the Medallion Architecture (Bronze \u2192 Silver \u2192 Gold).\n",
        "The builder creates pipelines that can be executed with the execution engine\n",
        "using a service-oriented architecture.\n",
        "\n",
        "Key Features:\n",
        "    - Fluent API for intuitive pipeline construction\n",
        "    - Automatic dependency management\n",
        "    - String-based validation rules\n",
        "    - Multi-schema support\n",
        "    - Comprehensive validation and error handling\n",
        "\n",
        "The builder uses a service-oriented architecture internally:\n",
        "    - StepFactory: Creates step instances\n",
        "    - ExecutionValidator: Validates pipeline configuration\n",
        "    - Step Executors: Execute steps during pipeline run\n",
        "\n",
        "Example:\n",
        "    >>> from pipeline_builder.pipeline.builder import PipelineBuilder\n",
        "    >>> from pipeline_builder.functions import get_default_functions\n",
        "    >>> F = get_default_functions()\n",
        "    >>>\n",
        "    >>> builder = PipelineBuilder(spark=spark, schema=\"analytics\")\n",
        "    >>> builder.with_bronze_rules(\n",
        "    ...     name=\"events\",\n",
        "    ...     rules={\"user_id\": [\"not_null\"], \"timestamp\": [\"not_null\"]},\n",
        "    ...     incremental_col=\"timestamp\"\n",
        "    ... )\n",
        "    >>> builder.add_silver_transform(\n",
        "    ...     name=\"clean_events\",\n",
        "    ...     source_bronze=\"events\",\n",
        "    ...     transform=lambda spark, df, silvers: df.filter(F.col(\"value\") > 0),\n",
        "    ...     rules={\"value\": [\"gt\", 0]},\n",
        "    ...     table_name=\"clean_events\"\n",
        "    ... )\n",
        "    >>> pipeline = builder.to_pipeline()\n",
        "    >>> result = pipeline.run_initial_load(bronze_sources={\"events\": source_df})\n",
        "\n",
        "Note:\n",
        "    This module depends on:\n",
        "    - compat: Spark compatibility layer\n",
        "    - errors: Error handling\n",
        "    - functions: PySpark function protocols\n",
        "    - logging: Pipeline logging\n",
        "    - models: Pipeline and step models\n",
        "    - pipeline.runner: Pipeline execution\n",
        "    - types: Type definitions\n",
        "    - validation: Data and pipeline validation\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "# Engine-specific StructType should satisfy the TypesProtocol.StructType\n",
        "# from .builder import PipelineBuilder as _AbstractsPipelineBuilderClass  # Removed: defined in notebook cells above\n",
        "# from .builder import BasePipelineBuilder  # Removed: defined in notebook cells above\n",
        "# from .errors import (  # Removed: defined in notebook cells above\n",
        "    # ConfigurationError as PipelineConfigurationError,\n",
        "# )\n",
        "# from .errors import (  # Removed: defined in notebook cells above\n",
        "    # ExecutionError as StepError,\n",
        "# )\n",
        "# from .errors import (  # Removed: defined in notebook cells above\n",
        "    # ValidationError,\n",
        "# )\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .models import (  # Removed: defined in notebook cells above\n",
        "    # PipelineConfig,\n",
        "    # ValidationThresholds,\n",
        "# )\n",
        "\n",
        "# from ..compat import SparkSession  # Removed: defined in notebook cells above\n",
        "# from ..engine import SparkEngine  # Removed: defined in notebook cells above\n",
        "# from ..functions import FunctionsProtocol, get_default_functions  # Removed: defined in notebook cells above\n",
        "# from ..models import (  # Removed: defined in notebook cells above\n",
        "    # BronzeStep,\n",
        "    # GoldStep,\n",
        "    # SilverStep,\n",
        "# )\n",
        "# from ..sql_source import JdbcSource, SqlAlchemySource  # Removed: defined in notebook cells above\n",
        "# from ..table_operations import fqn, table_exists  # Removed: defined in notebook cells above\n",
        "# from ..types import (  # Removed: defined in notebook cells above\n",
        "    # ColumnRules,\n",
        "    # GoldTransformFunction,\n",
        "    # SilverTransformFunction,\n",
        "    # StepName,\n",
        "    # TableName,\n",
        "# )\n",
        "# from ..validation import ValidationResult, _convert_rules_to_expressions  # Removed: defined in notebook cells above\n",
        "# from .runner import PipelineRunner  # Removed: defined in notebook cells above\n",
        "\n",
        "class PipelineBuilder(BasePipelineBuilder):\n",
        "    \"\"\"Production-ready builder for creating data pipelines.\n",
        "\n",
        "    The PipelineBuilder provides a fluent API for constructing robust data\n",
        "    pipelines with comprehensive validation, automatic dependency management,\n",
        "    and enterprise-grade features. Uses the Medallion Architecture\n",
        "    (Bronze \u2192 Silver \u2192 Gold) for data layering.\n",
        "\n",
        "    Key Features:\n",
        "        - Fluent API: Chain methods for intuitive pipeline construction\n",
        "        - Robust Validation: Early error detection with clear validation messages\n",
        "        - Auto-inference: Automatic dependency detection and validation\n",
        "        - String Rules: Convert human-readable rules to PySpark expressions\n",
        "        - Multi-schema Support: Cross-schema data flows for enterprise environments\n",
        "        - Comprehensive Error Handling: Detailed error messages with suggestions\n",
        "        - Service-Oriented Architecture: Clean separation of concerns internally\n",
        "\n",
        "    Validation Requirements:\n",
        "        All pipeline steps must have validation rules. Invalid configurations\n",
        "        are rejected during construction with clear error messages.\n",
        "\n",
        "    String Rules Support:\n",
        "        You can use human-readable string rules that are automatically converted\n",
        "        to PySpark expressions:\n",
        "\n",
        "        - \"not_null\" \u2192 F.col(\"column\").isNotNull()\n",
        "        - \"gt\", value \u2192 F.col(\"column\") > value\n",
        "        - \"lt\", value \u2192 F.col(\"column\") < value\n",
        "        - \"eq\", value \u2192 F.col(\"column\") == value\n",
        "        - \"in\", [values] \u2192 F.col(\"column\").isin(values)\n",
        "        - \"between\", min, max \u2192 F.col(\"column\").between(min, max)\n",
        "\n",
        "    Attributes:\n",
        "        spark: SparkSession instance for DataFrame operations.\n",
        "        schema: Target schema name for pipeline tables.\n",
        "        config: PipelineConfig instance with pipeline configuration.\n",
        "        logger: PipelineLogger instance for logging.\n",
        "        functions: FunctionsProtocol instance for PySpark operations.\n",
        "        bronze_steps: Dictionary of BronzeStep instances.\n",
        "        silver_steps: Dictionary of SilverStep instances.\n",
        "        gold_steps: Dictionary of GoldStep instances.\n",
        "        execution_order: List of step names in execution order (topological sort).\n",
        "            Populated automatically after successful pipeline validation.\n",
        "            None if validation hasn't been run or failed.\n",
        "\n",
        "    Example:\n",
        "        Basic pipeline construction:\n",
        "\n",
        "        >>> from pipeline_builder.pipeline.builder import PipelineBuilder\n",
        "        >>> from pipeline_builder.functions import get_default_functions\n",
        "        >>> F = get_default_functions()\n",
        "        >>>\n",
        "        >>> builder = PipelineBuilder(spark=spark, schema=\"analytics\")\n",
        "        >>> builder.with_bronze_rules(\n",
        "        ...     name=\"events\",\n",
        "        ...     rules={\"user_id\": [\"not_null\"], \"timestamp\": [\"not_null\"]},\n",
        "        ...     incremental_col=\"timestamp\"\n",
        "        ... )\n",
        "        >>> builder.add_silver_transform(\n",
        "        ...     name=\"clean_events\",\n",
        "        ...     source_bronze=\"events\",\n",
        "        ...     transform=lambda spark, df, silvers: df.filter(F.col(\"value\") > 0),\n",
        "        ...     rules={\"value\": [\"gt\", 0]},\n",
        "        ...     table_name=\"clean_events\"\n",
        "        ... )\n",
        "        >>> builder.add_gold_transform(\n",
        "        ...     name=\"daily_metrics\",\n",
        "        ...     transform=lambda spark, silvers: silvers[\"clean_events\"]\n",
        "        ...     .groupBy(\"date\")\n",
        "        ...     .agg(F.count(\"*\").alias(\"count\")),\n",
        "        ...     rules={\"count\": [\"gt\", 0]},\n",
        "        ...     table_name=\"daily_metrics\",\n",
        "        ...     source_silvers=[\"clean_events\"]\n",
        "        ... )\n",
        "        >>> pipeline = builder.to_pipeline()\n",
        "        >>> result = pipeline.run_initial_load(bronze_sources={\"events\": source_df})\n",
        "\n",
        "    Raises:\n",
        "        ValidationError: If validation rules are invalid or missing.\n",
        "        ConfigurationError: If configuration parameters are invalid.\n",
        "        StepError: If step dependencies cannot be resolved.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        spark: SparkSession,\n",
        "        schema: str,\n",
        "        min_bronze_rate: float = 95.0,\n",
        "        min_silver_rate: float = 98.0,\n",
        "        min_gold_rate: float = 99.0,\n",
        "        verbose: bool = True,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize a new PipelineBuilder instance.\n",
        "\n",
        "        Creates a PipelineBuilder with the specified configuration. Initializes\n",
        "        all required services including validators, step storage, and execution\n",
        "        engine.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance for data processing.\n",
        "            schema: Database schema name where tables will be created.\n",
        "            min_bronze_rate: Minimum data quality rate for Bronze layer (0-100).\n",
        "                Defaults to 95.0.\n",
        "            min_silver_rate: Minimum data quality rate for Silver layer (0-100).\n",
        "                Defaults to 98.0.\n",
        "            min_gold_rate: Minimum data quality rate for Gold layer (0-100).\n",
        "                Defaults to 99.0.\n",
        "            verbose: Enable verbose logging output. Defaults to True.\n",
        "            functions: Optional FunctionsProtocol instance for PySpark operations.\n",
        "                If None, uses get_default_functions().\n",
        "\n",
        "        Raises:\n",
        "            PipelineConfigurationError: If Spark session is None, schema is empty,\n",
        "                or quality rates are invalid.\n",
        "\n",
        "        Note:\n",
        "            The builder initializes:\n",
        "            - PipelineConfig with validation thresholds\n",
        "            - UnifiedValidator for Spark-specific validation\n",
        "            - SparkEngine for execution\n",
        "            - Step storage dictionaries (bronze_steps, silver_steps, gold_steps)\n",
        "        \"\"\"\n",
        "        # Validate inputs\n",
        "        if not spark:\n",
        "            raise PipelineConfigurationError(\n",
        "                \"Spark session is required\",\n",
        "                suggestions=[\n",
        "                    \"Ensure SparkSession is properly initialized\",\n",
        "                    \"Check Spark configuration\",\n",
        "                ],\n",
        "            )\n",
        "        if not schema:\n",
        "            raise PipelineConfigurationError(\n",
        "                \"Schema name cannot be empty\",\n",
        "                suggestions=[\n",
        "                    \"Provide a valid schema name\",\n",
        "                    \"Check database configuration\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        # Store configuration\n",
        "        thresholds = ValidationThresholds(\n",
        "            bronze=min_bronze_rate, silver=min_silver_rate, gold=min_gold_rate\n",
        "        )\n",
        "        config = PipelineConfig(\n",
        "            schema=schema,\n",
        "            thresholds=thresholds,\n",
        "            verbose=verbose,\n",
        "        )\n",
        "\n",
        "        # Initialize base class (this sets up self.config, self.logger, self.validator, self.step_validator)\n",
        "        super().__init__(config, logger=PipelineLogger(verbose=verbose))\n",
        "\n",
        "        # Initialize Spark-specific components\n",
        "        self.spark = spark\n",
        "        self.functions = functions if functions is not None else get_default_functions()\n",
        "\n",
        "        # Expose schema for backward compatibility\n",
        "        self.schema = schema\n",
        "        self.pipeline_id = (\n",
        "            f\"pipeline_{schema}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        )\n",
        "\n",
        "        # Use Spark-specific validator (UnifiedValidator) in addition to base validator\n",
        "        # Keep the existing UnifiedValidator for Spark-specific validation\n",
        "        # from ..validation import UnifiedValidator  # Removed: defined in notebook cells above\n",
        "\n",
        "        self.spark_validator = UnifiedValidator(self.logger)\n",
        "        # Store base validator before overriding\n",
        "        # Type annotation needed for mypy - validator is set in BasePipelineBuilder.__init__\n",
        "        from typing import cast\n",
        "# from .validation import UnifiedValidator  # Removed: defined in notebook cells above\n",
        "\n",
        "        # Type cast: BasePipelineBuilder.__init__ creates UnifiedValidator instance\n",
        "        # Runtime check: We verify this is actually a UnifiedValidator via isinstance\n",
        "        # This cast is safe because BasePipelineBuilder always creates UnifiedValidator\n",
        "        # NOTE: We use runtime type checks in validate_pipeline() to catch any mismatches\n",
        "        validator: UnifiedValidator = cast(UnifiedValidator, self.validator)  # type: ignore[redundant-cast]\n",
        "        self._base_validator: UnifiedValidator = validator\n",
        "\n",
        "        # Execution order will be populated after validation\n",
        "        self.execution_order: Optional[List[str]] = None\n",
        "\n",
        "        # Track step creation order for deterministic ordering when no explicit dependencies\n",
        "        self._step_creation_order: Dict[str, int] = {}\n",
        "        self._creation_counter: int = 0\n",
        "\n",
        "        # Override base validator with spark_validator for backward compatibility\n",
        "        # This allows add_validator() to work on self.validator\n",
        "        # Type cast: UnifiedValidator implements the UnifiedValidator interface\n",
        "        # but has different return types. We cast for interface compatibility.\n",
        "        # NOTE: Runtime type checks in validate_pipeline() handle the return type differences\n",
        "# from .validation import (  # Removed: defined in notebook cells above\n",
        "            # UnifiedValidator as UnifiedValidator,\n",
        "        # )\n",
        "\n",
        "        self.validator = cast(UnifiedValidator, self.spark_validator)\n",
        "        # Expose validators for backward compatibility\n",
        "        self.validators = self.spark_validator.custom_validators\n",
        "\n",
        "        # Step storage is already initialized by BasePipelineBuilder\n",
        "        # but we need to type them correctly for Spark steps\n",
        "        self.bronze_steps: Dict[str, BronzeStep] = {}\n",
        "        self.silver_steps: Dict[str, SilverStep] = {}\n",
        "        self.gold_steps: Dict[str, GoldStep] = {}\n",
        "\n",
        "        # Create SparkEngine for abstracts layer\n",
        "        self.spark_engine = SparkEngine(\n",
        "            spark=self.spark,\n",
        "            config=self.config,\n",
        "            logger=self.logger,\n",
        "            functions=self.functions,\n",
        "        )\n",
        "\n",
        "        # Create abstracts.PipelineBuilder with SparkEngine injection\n",
        "        # We'll use PipelineRunner as the runner class\n",
        "        self._abstracts_builder = _AbstractsPipelineBuilderClass(\n",
        "            runner_cls=PipelineRunner,\n",
        "            engine=self.spark_engine,\n",
        "        )\n",
        "\n",
        "        self.logger.info(f\"\ud83d\udd27 PipelineBuilder initialized (schema: {schema})\")\n",
        "\n",
        "    def with_bronze_rules(\n",
        "        self,\n",
        "        *,\n",
        "        name: StepName,\n",
        "        rules: ColumnRules,\n",
        "        incremental_col: Optional[str] = None,\n",
        "        description: Optional[str] = None,\n",
        "        schema: Optional[str] = None,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Add Bronze layer validation rules for raw data ingestion.\n",
        "\n",
        "        Bronze steps represent the first layer of the Medallion Architecture,\n",
        "        handling raw data ingestion and initial validation. All Bronze steps\n",
        "        must have non-empty validation rules.\n",
        "\n",
        "        Args:\n",
        "            name: Unique identifier for this Bronze step.\n",
        "            rules: Dictionary mapping column names to validation rule lists.\n",
        "                Supports both PySpark Column expressions and string rules:\n",
        "                - PySpark: {\"user_id\": [F.col(\"user_id\").isNotNull()]}\n",
        "                - String: {\"user_id\": [\"not_null\"], \"age\": [\"gt\", 0]}\n",
        "            incremental_col: Optional column name for incremental processing\n",
        "                (e.g., \"timestamp\", \"updated_at\"). If provided, enables\n",
        "                incremental processing with append mode.\n",
        "            description: Optional description of this Bronze step.\n",
        "            schema: Optional schema name for reading bronze data. If not\n",
        "                provided, uses the builder's default schema.\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining.\n",
        "\n",
        "        Raises:\n",
        "            StepError: If step name is empty, conflicts with existing step,\n",
        "                or schema validation fails.\n",
        "            ValidationError: If rules are empty or invalid.\n",
        "\n",
        "        Example:\n",
        "            Using PySpark Column expressions:\n",
        "\n",
        "            >>> builder.with_bronze_rules(\n",
        "            ...     name=\"events\",\n",
        "            ...     rules={\"user_id\": [F.col(\"user_id\").isNotNull()]},\n",
        "            ...     incremental_col=\"timestamp\"\n",
        "            ... )\n",
        "\n",
        "            Using string rules (automatically converted):\n",
        "\n",
        "            >>> builder.with_bronze_rules(\n",
        "            ...     name=\"users\",\n",
        "            ...     rules={\"user_id\": [\"not_null\"], \"age\": [\"gt\", 0]},\n",
        "            ...     incremental_col=\"updated_at\"\n",
        "            ... )\n",
        "\n",
        "            Cross-schema bronze data:\n",
        "\n",
        "            >>> builder.with_bronze_rules(\n",
        "            ...     name=\"user_events\",\n",
        "            ...     rules={\"user_id\": [F.col(\"user_id\").isNotNull()]},\n",
        "            ...     incremental_col=\"timestamp\",\n",
        "            ...     schema=\"raw_data\"  # Read from different schema\n",
        "            ... )\n",
        "\n",
        "        Note:\n",
        "            String rules are automatically converted to PySpark expressions:\n",
        "            - \"not_null\" \u2192 F.col(\"column\").isNotNull()\n",
        "            - \"gt\", value \u2192 F.col(\"column\") > value\n",
        "            - \"lt\", value \u2192 F.col(\"column\") < value\n",
        "            - \"eq\", value \u2192 F.col(\"column\") == value\n",
        "            - \"in\", [values] \u2192 F.col(\"column\").isin(values)\n",
        "            - \"between\", min, max \u2192 F.col(\"column\").between(min, max)\n",
        "        \"\"\"\n",
        "        if not name:\n",
        "            raise StepError(\n",
        "                \"Bronze step name cannot be empty\",\n",
        "                context={\"step_name\": name or \"unknown\", \"step_type\": \"bronze\"},\n",
        "                suggestions=[\n",
        "                    \"Provide a valid step name\",\n",
        "                    \"Check step naming conventions\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        # Use base class method for duplicate checking\n",
        "        try:\n",
        "            self._check_duplicate_step_name(name, \"bronze\")\n",
        "        except Exception as e:\n",
        "            # Convert to StepError for consistency\n",
        "            raise StepError(\n",
        "                str(e),\n",
        "                context={\"step_name\": name, \"step_type\": \"bronze\"},\n",
        "                suggestions=[\n",
        "                    \"Use a different step name\",\n",
        "                    \"Remove the existing step first\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "        # Validate schema if provided (use base class method)\n",
        "        if schema is not None:\n",
        "            try:\n",
        "                self._validate_schema(schema)\n",
        "            except Exception as e:\n",
        "                # Convert to StepError for consistency\n",
        "                raise StepError(\n",
        "                    str(e),\n",
        "                    context={\n",
        "                        \"step_name\": name,\n",
        "                        \"step_type\": \"bronze\",\n",
        "                        \"schema\": schema,\n",
        "                    },\n",
        "                ) from e\n",
        "\n",
        "        # Convert string rules to PySpark Column objects\n",
        "        converted_rules = _convert_rules_to_expressions(rules, self.functions)\n",
        "\n",
        "        # Create bronze step\n",
        "        bronze_step = BronzeStep(\n",
        "            name=name,\n",
        "            rules=converted_rules,\n",
        "            incremental_col=incremental_col,\n",
        "            schema=schema,\n",
        "        )\n",
        "\n",
        "        self.bronze_steps[name] = bronze_step\n",
        "        # Track creation order for deterministic ordering\n",
        "        self._step_creation_order[name] = self._creation_counter\n",
        "        self._creation_counter += 1\n",
        "        self.logger.info(f\"\u2705 Added Bronze step: {name}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def with_bronze_sql_source(\n",
        "        self,\n",
        "        *,\n",
        "        name: StepName,\n",
        "        sql_source: Union[JdbcSource, SqlAlchemySource],\n",
        "        rules: ColumnRules,\n",
        "        incremental_col: Optional[str] = None,\n",
        "        schema: Optional[str] = None,\n",
        "        description: Optional[str] = None,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Add Bronze layer step that reads from a SQL database (JDBC or SQLAlchemy).\n",
        "\n",
        "        SQL alternative to with_bronze_rules: data is read from the given sql_source\n",
        "        at run time (no DataFrame in bronze_sources). Requires non-empty validation\n",
        "        rules like with_bronze_rules.\n",
        "\n",
        "        Args:\n",
        "            name: Unique identifier for this Bronze step.\n",
        "            sql_source: JdbcSource or SqlAlchemySource (table or query + connection).\n",
        "            rules: Validation rules (PySpark or string rules); must be non-empty.\n",
        "            incremental_col: Optional column for incremental processing.\n",
        "            schema: Optional schema name for reading bronze data.\n",
        "            description: Optional description.\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining.\n",
        "        \"\"\"\n",
        "        if not name:\n",
        "            raise StepError(\n",
        "                \"Bronze step name cannot be empty\",\n",
        "                context={\"step_name\": name or \"unknown\", \"step_type\": \"bronze\"},\n",
        "                suggestions=[\"Provide a valid step name\"],\n",
        "            )\n",
        "        if not isinstance(sql_source, (JdbcSource, SqlAlchemySource)):\n",
        "            raise StepError(\n",
        "                \"sql_source must be JdbcSource or SqlAlchemySource\",\n",
        "                context={\"step_name\": name, \"step_type\": \"bronze\"},\n",
        "            )\n",
        "        if not rules or not isinstance(rules, dict):\n",
        "            raise StepError(\n",
        "                \"Rules must be a non-empty dictionary (same as with_bronze_rules)\",\n",
        "                context={\"step_name\": name, \"step_type\": \"bronze\"},\n",
        "            )\n",
        "        try:\n",
        "            self._check_duplicate_step_name(name, \"bronze\")\n",
        "        except Exception as e:\n",
        "            raise StepError(\n",
        "                str(e), context={\"step_name\": name, \"step_type\": \"bronze\"}\n",
        "            ) from e\n",
        "        if schema is not None:\n",
        "            try:\n",
        "                self._validate_schema(schema)\n",
        "            except Exception as e:\n",
        "                raise StepError(\n",
        "                    str(e),\n",
        "                    context={\n",
        "                        \"step_name\": name,\n",
        "                        \"step_type\": \"bronze\",\n",
        "                        \"schema\": schema,\n",
        "                    },\n",
        "                ) from e\n",
        "        converted_rules = _convert_rules_to_expressions(rules, self.functions)\n",
        "        bronze_step = BronzeStep(\n",
        "            name=name,\n",
        "            rules=converted_rules,\n",
        "            incremental_col=incremental_col,\n",
        "            schema=schema,\n",
        "            sql_source=sql_source,\n",
        "        )\n",
        "        self.bronze_steps[name] = bronze_step\n",
        "        self._step_creation_order[name] = self._creation_counter\n",
        "        self._creation_counter += 1\n",
        "        self.logger.info(f\"\u2705 Added Bronze step (SQL source): {name}\")\n",
        "        return self\n",
        "\n",
        "    def with_silver_rules(\n",
        "        self,\n",
        "        *,\n",
        "        name: StepName,\n",
        "        table_name: TableName,\n",
        "        rules: ColumnRules,\n",
        "        description: Optional[str] = None,\n",
        "        schema: Optional[str] = None,\n",
        "        optional: bool = False,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Add Silver layer validation rules for existing silver tables.\n",
        "\n",
        "        Silver steps created with this method represent validation-only steps\n",
        "        for existing silver tables. They allow subsequent transform functions\n",
        "        to access validated existing silver and gold tables via `prior_silvers`\n",
        "        and `prior_golds` arguments.\n",
        "\n",
        "        Args:\n",
        "            name: Unique identifier for this Silver step.\n",
        "            table_name: Existing Delta table name (without schema).\n",
        "            rules: Dictionary mapping column names to validation rule lists.\n",
        "                Supports both PySpark Column expressions and string rules:\n",
        "                - PySpark: {\"user_id\": [F.col(\"user_id\").isNotNull()]}\n",
        "                - String: {\"user_id\": [\"not_null\"], \"age\": [\"gt\", 0]}\n",
        "            description: Optional description of this Silver step.\n",
        "            schema: Optional schema name for reading silver data. If not\n",
        "                provided, uses the builder's default schema.\n",
        "            optional: If True, step does not fail when the table does not exist;\n",
        "                an empty DataFrame is returned so downstream steps can run.\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining.\n",
        "\n",
        "        Raises:\n",
        "            StepError: If step name is empty, conflicts with existing step,\n",
        "                or schema validation fails.\n",
        "            ValidationError: If rules are empty or invalid.\n",
        "\n",
        "        Example:\n",
        "            Using PySpark Column expressions:\n",
        "\n",
        "            >>> builder.with_silver_rules(\n",
        "            ...     name=\"existing_clean_events\",\n",
        "            ...     table_name=\"clean_events\",\n",
        "            ...     rules={\"user_id\": [F.col(\"user_id\").isNotNull()]}\n",
        "            ... )\n",
        "\n",
        "            Using string rules (automatically converted):\n",
        "\n",
        "            >>> builder.with_silver_rules(\n",
        "            ...     name=\"validated_events\",\n",
        "            ...     table_name=\"events\",\n",
        "            ...     rules={\"user_id\": [\"not_null\"], \"value\": [\"gt\", 0]},\n",
        "            ...     schema=\"staging\"\n",
        "            ... )\n",
        "\n",
        "        Note:\n",
        "            String rules are automatically converted to PySpark expressions.\n",
        "            See with_bronze_rules() for supported string rule formats.\n",
        "            This creates a validation-only step that can be accessed by\n",
        "            subsequent transform functions via prior_silvers.\n",
        "        \"\"\"\n",
        "        if not name:\n",
        "            raise StepError(\n",
        "                \"Silver step name cannot be empty\",\n",
        "                context={\"step_name\": name or \"unknown\", \"step_type\": \"silver\"},\n",
        "                suggestions=[\n",
        "                    \"Provide a valid step name\",\n",
        "                    \"Check step naming conventions\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        # Use base class method for duplicate checking\n",
        "        try:\n",
        "            self._check_duplicate_step_name(name, \"silver\")\n",
        "        except Exception as e:\n",
        "            # Convert to StepError for consistency\n",
        "            raise StepError(\n",
        "                str(e),\n",
        "                context={\"step_name\": name, \"step_type\": \"silver\"},\n",
        "                suggestions=[\n",
        "                    \"Use a different step name\",\n",
        "                    \"Remove the existing step first\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "        # Validate schema if provided (use base class method)\n",
        "        if schema is not None:\n",
        "            try:\n",
        "                self._validate_schema(schema)\n",
        "            except Exception as e:\n",
        "                # Convert to StepError for consistency\n",
        "                raise StepError(\n",
        "                    str(e),\n",
        "                    context={\n",
        "                        \"step_name\": name,\n",
        "                        \"step_type\": \"silver\",\n",
        "                        \"schema\": schema,\n",
        "                    },\n",
        "                ) from e\n",
        "\n",
        "        # Convert string rules to PySpark Column objects\n",
        "        converted_rules = _convert_rules_to_expressions(rules, self.functions)\n",
        "\n",
        "        # Get effective schema (use builder's default if not provided)\n",
        "        effective_schema = self._get_effective_schema(schema)\n",
        "\n",
        "        # Create SilverStep for validation-only (no transform function)\n",
        "        silver_step = SilverStep(\n",
        "            name=name,\n",
        "            source_bronze=\"\",  # No source bronze for existing tables\n",
        "            transform=None,  # No transform function for validation-only steps\n",
        "            rules=converted_rules,\n",
        "            table_name=table_name,\n",
        "            watermark_col=None,  # No watermark needed for validation-only steps\n",
        "            existing=True,\n",
        "            optional=optional,\n",
        "            schema=effective_schema,\n",
        "            source_incremental_col=None,\n",
        "        )\n",
        "\n",
        "        self.silver_steps[name] = silver_step\n",
        "        # Track creation order for deterministic ordering\n",
        "        self._step_creation_order[name] = self._creation_counter\n",
        "        self._creation_counter += 1\n",
        "        self.logger.info(f\"\u2705 Added Silver step (validation-only): {name}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def with_silver_sql_source(\n",
        "        self,\n",
        "        *,\n",
        "        name: StepName,\n",
        "        sql_source: Union[JdbcSource, SqlAlchemySource],\n",
        "        table_name: TableName,\n",
        "        rules: ColumnRules,\n",
        "        schema: Optional[str] = None,\n",
        "        description: Optional[str] = None,\n",
        "        optional: bool = False,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Add Silver layer step that reads from a SQL database (JDBC or SQLAlchemy).\n",
        "\n",
        "        SQL alternative to with_silver_rules: data is read from sql_source at run time,\n",
        "        validated, and written to the Delta table.\n",
        "\n",
        "        Args:\n",
        "            name: Unique identifier for this Silver step.\n",
        "            sql_source: JdbcSource or SqlAlchemySource.\n",
        "            table_name: Target Delta table name (without schema).\n",
        "            rules: Validation rules; must be non-empty.\n",
        "            schema: Optional schema for writing silver data.\n",
        "            description: Optional description.\n",
        "            optional: If True, step does not fail when SQL read fails; empty DataFrame.\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining.\n",
        "        \"\"\"\n",
        "        if not name:\n",
        "            raise StepError(\n",
        "                \"Silver step name cannot be empty\",\n",
        "                context={\"step_name\": name or \"unknown\", \"step_type\": \"silver\"},\n",
        "            )\n",
        "        if not isinstance(sql_source, (JdbcSource, SqlAlchemySource)):\n",
        "            raise StepError(\"sql_source must be JdbcSource or SqlAlchemySource\")\n",
        "        if not rules or not isinstance(rules, dict):\n",
        "            raise StepError(\"Rules must be a non-empty dictionary\")\n",
        "        if not table_name:\n",
        "            raise StepError(\"table_name cannot be empty\")\n",
        "        try:\n",
        "            self._check_duplicate_step_name(name, \"silver\")\n",
        "        except Exception as e:\n",
        "            raise StepError(\n",
        "                str(e), context={\"step_name\": name, \"step_type\": \"silver\"}\n",
        "            ) from e\n",
        "        if schema is not None:\n",
        "            try:\n",
        "                self._validate_schema(schema)\n",
        "            except Exception as e:\n",
        "                raise StepError(\n",
        "                    str(e), context={\"step_name\": name, \"schema\": schema}\n",
        "                ) from e\n",
        "        converted_rules = _convert_rules_to_expressions(rules, self.functions)\n",
        "        effective_schema = self._get_effective_schema(schema)\n",
        "        silver_step = SilverStep(\n",
        "            name=name,\n",
        "            source_bronze=\"\",\n",
        "            transform=None,\n",
        "            rules=converted_rules,\n",
        "            table_name=table_name,\n",
        "            existing=False,\n",
        "            optional=optional,\n",
        "            schema=effective_schema,\n",
        "            sql_source=sql_source,\n",
        "        )\n",
        "        self.silver_steps[name] = silver_step\n",
        "        self._step_creation_order[name] = self._creation_counter\n",
        "        self._creation_counter += 1\n",
        "        self.logger.info(f\"\u2705 Added Silver step (SQL source): {name}\")\n",
        "        return self\n",
        "\n",
        "    def with_gold_rules(\n",
        "        self,\n",
        "        *,\n",
        "        name: StepName,\n",
        "        table_name: TableName,\n",
        "        rules: ColumnRules,\n",
        "        description: Optional[str] = None,\n",
        "        schema: Optional[str] = None,\n",
        "        optional: bool = False,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Add Gold layer validation rules for existing gold tables.\n",
        "\n",
        "        Gold steps created with this method represent validation-only steps\n",
        "        for existing gold tables. They allow subsequent transform functions\n",
        "        to access validated existing silver and gold tables via `prior_silvers`\n",
        "        and `prior_golds` arguments.\n",
        "\n",
        "        Args:\n",
        "            name: Unique identifier for this Gold step.\n",
        "            table_name: Existing Delta table name (without schema).\n",
        "            rules: Dictionary mapping column names to validation rule lists.\n",
        "                Supports both PySpark Column expressions and string rules:\n",
        "                - PySpark: {\"user_id\": [F.col(\"user_id\").isNotNull()]}\n",
        "                - String: {\"user_id\": [\"not_null\"], \"count\": [\"gt\", 0]}\n",
        "            description: Optional description of this Gold step.\n",
        "            schema: Optional schema name for reading gold data. If not\n",
        "                provided, uses the builder's default schema.\n",
        "            optional: If True, step does not fail when the table does not exist;\n",
        "                an empty DataFrame is returned so downstream steps can run.\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining.\n",
        "\n",
        "        Raises:\n",
        "            StepError: If step name is empty, conflicts with existing step,\n",
        "                or schema validation fails.\n",
        "            ValidationError: If rules are empty or invalid.\n",
        "\n",
        "        Example:\n",
        "            Using PySpark Column expressions:\n",
        "\n",
        "            >>> builder.with_gold_rules(\n",
        "            ...     name=\"existing_user_metrics\",\n",
        "            ...     table_name=\"user_metrics\",\n",
        "            ...     rules={\"user_id\": [F.col(\"user_id\").isNotNull()]},\n",
        "            ... )\n",
        "\n",
        "            Using string rules (automatically converted):\n",
        "\n",
        "            >>> builder.with_gold_rules(\n",
        "            ...     name=\"validated_metrics\",\n",
        "            ...     table_name=\"metrics\",\n",
        "            ...     rules={\"user_id\": [\"not_null\"], \"count\": [\"gt\", 0]},\n",
        "            ...     schema=\"analytics\"\n",
        "            ... )\n",
        "\n",
        "        Note:\n",
        "            String rules are automatically converted to PySpark expressions.\n",
        "            See with_bronze_rules() for supported string rule formats.\n",
        "            This creates a validation-only step that can be accessed by\n",
        "            subsequent transform functions via prior_golds.\n",
        "        \"\"\"\n",
        "        if not name:\n",
        "            raise StepError(\n",
        "                \"Gold step name cannot be empty\",\n",
        "                context={\"step_name\": name or \"unknown\", \"step_type\": \"gold\"},\n",
        "                suggestions=[\n",
        "                    \"Provide a valid step name\",\n",
        "                    \"Check step naming conventions\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        # Use base class method for duplicate checking\n",
        "        try:\n",
        "            self._check_duplicate_step_name(name, \"gold\")\n",
        "        except Exception as e:\n",
        "            # Convert to StepError for consistency\n",
        "            raise StepError(\n",
        "                str(e),\n",
        "                context={\"step_name\": name, \"step_type\": \"gold\"},\n",
        "                suggestions=[\n",
        "                    \"Use a different step name\",\n",
        "                    \"Remove the existing step first\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "        # Validate schema if provided (use base class method)\n",
        "        if schema is not None:\n",
        "            try:\n",
        "                self._validate_schema(schema)\n",
        "            except Exception as e:\n",
        "                # Convert to StepError for consistency\n",
        "                raise StepError(\n",
        "                    str(e),\n",
        "                    context={\n",
        "                        \"step_name\": name,\n",
        "                        \"step_type\": \"gold\",\n",
        "                        \"schema\": schema,\n",
        "                    },\n",
        "                ) from e\n",
        "\n",
        "        # Convert string rules to PySpark Column objects\n",
        "        converted_rules = _convert_rules_to_expressions(rules, self.functions)\n",
        "\n",
        "        # Get effective schema (use builder's default if not provided)\n",
        "        effective_schema = self._get_effective_schema(schema)\n",
        "\n",
        "        # Create GoldStep for validation-only (no transform function)\n",
        "        gold_step = GoldStep(\n",
        "            name=name,\n",
        "            transform=None,  # No transform function for validation-only steps\n",
        "            rules=converted_rules,\n",
        "            table_name=table_name,\n",
        "            existing=True,\n",
        "            optional=optional,\n",
        "            schema=effective_schema,\n",
        "            source_silvers=None,  # No source silvers for existing tables\n",
        "        )\n",
        "\n",
        "        self.gold_steps[name] = gold_step\n",
        "        # Track creation order for deterministic ordering\n",
        "        self._step_creation_order[name] = self._creation_counter\n",
        "        self._creation_counter += 1\n",
        "        self.logger.info(f\"\u2705 Added Gold step (validation-only): {name}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def with_gold_sql_source(\n",
        "        self,\n",
        "        *,\n",
        "        name: StepName,\n",
        "        sql_source: Union[JdbcSource, SqlAlchemySource],\n",
        "        table_name: TableName,\n",
        "        rules: ColumnRules,\n",
        "        schema: Optional[str] = None,\n",
        "        description: Optional[str] = None,\n",
        "        optional: bool = False,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Add Gold layer step that reads from a SQL database (JDBC or SQLAlchemy).\n",
        "\n",
        "        SQL alternative to with_gold_rules: data is read from sql_source at run time,\n",
        "        validated, and written to the Delta table.\n",
        "\n",
        "        Args:\n",
        "            name: Unique identifier for this Gold step.\n",
        "            sql_source: JdbcSource or SqlAlchemySource.\n",
        "            table_name: Target Delta table name (without schema).\n",
        "            rules: Validation rules; must be non-empty.\n",
        "            schema: Optional schema for writing gold data.\n",
        "            description: Optional description.\n",
        "            optional: If True, step does not fail when SQL read fails; empty DataFrame.\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining.\n",
        "        \"\"\"\n",
        "        if not name:\n",
        "            raise StepError(\n",
        "                \"Gold step name cannot be empty\",\n",
        "                context={\"step_name\": name or \"unknown\", \"step_type\": \"gold\"},\n",
        "            )\n",
        "        if not isinstance(sql_source, (JdbcSource, SqlAlchemySource)):\n",
        "            raise StepError(\"sql_source must be JdbcSource or SqlAlchemySource\")\n",
        "        if not rules or not isinstance(rules, dict):\n",
        "            raise StepError(\"Rules must be a non-empty dictionary\")\n",
        "        if not table_name:\n",
        "            raise StepError(\"table_name cannot be empty\")\n",
        "        try:\n",
        "            self._check_duplicate_step_name(name, \"gold\")\n",
        "        except Exception as e:\n",
        "            raise StepError(\n",
        "                str(e), context={\"step_name\": name, \"step_type\": \"gold\"}\n",
        "            ) from e\n",
        "        if schema is not None:\n",
        "            try:\n",
        "                self._validate_schema(schema)\n",
        "            except Exception as e:\n",
        "                raise StepError(\n",
        "                    str(e), context={\"step_name\": name, \"schema\": schema}\n",
        "                ) from e\n",
        "        converted_rules = _convert_rules_to_expressions(rules, self.functions)\n",
        "        effective_schema = self._get_effective_schema(schema)\n",
        "        gold_step = GoldStep(\n",
        "            name=name,\n",
        "            transform=None,\n",
        "            rules=converted_rules,\n",
        "            table_name=table_name,\n",
        "            existing=False,\n",
        "            optional=optional,\n",
        "            schema=effective_schema,\n",
        "            source_silvers=None,\n",
        "            sql_source=sql_source,\n",
        "        )\n",
        "        self.gold_steps[name] = gold_step\n",
        "        self._step_creation_order[name] = self._creation_counter\n",
        "        self._creation_counter += 1\n",
        "        self.logger.info(f\"\u2705 Added Gold step (SQL source): {name}\")\n",
        "        return self\n",
        "\n",
        "    def add_validator(self, validator: Any) -> PipelineBuilder:\n",
        "        \"\"\"Add a custom step validator to the pipeline.\n",
        "\n",
        "        Custom validators allow you to add additional validation logic beyond\n",
        "        the built-in validation rules. Validators are called during pipeline\n",
        "        validation to check step configurations.\n",
        "\n",
        "        Args:\n",
        "            validator: Custom validator implementing StepValidator protocol.\n",
        "                Must have a validate() method that accepts step and context\n",
        "                parameters.\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining.\n",
        "\n",
        "        Example:\n",
        "            >>> class CustomValidator(StepValidator):\n",
        "            ...     def validate(self, step, context):\n",
        "            ...         if step.name == \"special_step\":\n",
        "            ...             return [\"Special validation failed\"]\n",
        "            ...         return []\n",
        "            >>>\n",
        "            >>> builder.add_validator(CustomValidator())\n",
        "\n",
        "        Note:\n",
        "            Custom validators are added to the UnifiedValidator and called\n",
        "            during validate_pipeline(). They can return ValidationResult or\n",
        "            List[str] of error messages.\n",
        "        \"\"\"\n",
        "        self.spark_validator.add_validator(validator)\n",
        "        return self\n",
        "\n",
        "    def add_silver_transform(\n",
        "        self,\n",
        "        *,\n",
        "        name: StepName,\n",
        "        source_bronze: Optional[StepName] = None,\n",
        "        transform: SilverTransformFunction,\n",
        "        rules: ColumnRules,\n",
        "        table_name: TableName,\n",
        "        watermark_col: Optional[str] = None,\n",
        "        description: Optional[str] = None,\n",
        "        depends_on: Optional[list[StepName]] = None,\n",
        "        source_silvers: Optional[list[StepName]] = None,\n",
        "        schema: Optional[str] = None,\n",
        "        schema_override: Optional[Any] = None,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Add Silver layer transformation step for data cleaning and enrichment.\n",
        "\n",
        "        Silver steps represent the second layer of the Medallion Architecture,\n",
        "        transforming raw Bronze data into clean, business-ready datasets. All\n",
        "        Silver steps must have non-empty validation rules and a valid transform\n",
        "        function.\n",
        "\n",
        "        Args:\n",
        "            name: Unique identifier for this Silver step.\n",
        "            source_bronze: Optional name of the Bronze step this Silver step\n",
        "                depends on. If not provided, automatically infers from the most\n",
        "                recent with_bronze_rules() call. If no bronze steps exist,\n",
        "                raises an error.\n",
        "            transform: Transformation function with signature:\n",
        "                (spark: SparkSession, bronze_df: DataFrame,\n",
        "                prior_silvers: Dict[str, DataFrame]) -> DataFrame\n",
        "                Must be callable and cannot be None.\n",
        "            rules: Dictionary mapping column names to validation rule lists.\n",
        "                Supports both PySpark Column expressions and string rules:\n",
        "                - PySpark: {\"user_id\": [F.col(\"user_id\").isNotNull()]}\n",
        "                - String: {\"user_id\": [\"not_null\"], \"age\": [\"gt\", 0]}\n",
        "            table_name: Target Delta table name where results will be stored\n",
        "                (without schema).\n",
        "            watermark_col: Optional column name for watermarking (e.g.,\n",
        "                \"timestamp\", \"updated_at\"). If provided, enables incremental\n",
        "                processing with append mode.\n",
        "            description: Optional description of this Silver step.\n",
        "            depends_on: Optional list of other Silver step names that must\n",
        "                complete before this step. Deprecated - use source_silvers instead.\n",
        "            source_silvers: Optional list of Silver step names this Silver step\n",
        "                depends on. These steps will be available in the prior_silvers\n",
        "                dictionary passed to the transform function. If provided, ensures\n",
        "                correct execution order.\n",
        "            schema: Optional schema name for writing silver data. If not\n",
        "                provided, uses the builder's default schema.\n",
        "            schema_override: Optional PySpark StructType schema to override\n",
        "                DataFrame schema when creating tables. Uses Delta Lake's\n",
        "                overwriteSchema option. Applied during initial runs and when\n",
        "                table doesn't exist.\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining.\n",
        "\n",
        "        Raises:\n",
        "            StepError: If step name is empty, conflicts with existing step,\n",
        "                source_bronze not found, or schema validation fails.\n",
        "            ValidationError: If rules are empty, transform is None, or\n",
        "                configuration is invalid.\n",
        "\n",
        "        Example:\n",
        "            Using PySpark Column expressions:\n",
        "\n",
        "            >>> def clean_user_events(spark, bronze_df, prior_silvers):\n",
        "            ...     return (bronze_df\n",
        "            ...         .filter(F.col(\"user_id\").isNotNull())\n",
        "            ...         .withColumn(\"event_date\", F.date_trunc(\"day\", \"timestamp\"))\n",
        "            ...     )\n",
        "            >>>\n",
        "            >>> builder.add_silver_transform(\n",
        "            ...     name=\"clean_events\",\n",
        "            ...     source_bronze=\"user_events\",\n",
        "            ...     transform=clean_user_events,\n",
        "            ...     rules={\"user_id\": [F.col(\"user_id\").isNotNull()]},\n",
        "            ...     table_name=\"clean_events\"\n",
        "            ... )\n",
        "\n",
        "            Using string rules with auto-inferred source:\n",
        "\n",
        "            >>> builder.add_silver_transform(\n",
        "            ...     name=\"enriched_events\",\n",
        "            ...     transform=lambda spark, df, silvers: df.withColumn(\n",
        "            ...         \"processed_at\", F.current_timestamp()\n",
        "            ...     ),\n",
        "            ...     rules={\"user_id\": [\"not_null\"], \"processed_at\": [\"not_null\"]},\n",
        "            ...     table_name=\"enriched_events\",\n",
        "            ...     watermark_col=\"processed_at\"\n",
        "            ... )\n",
        "\n",
        "        Note:\n",
        "            String rules are automatically converted to PySpark expressions.\n",
        "            See with_bronze_rules() for supported string rule formats.\n",
        "        \"\"\"\n",
        "        if not name:\n",
        "            raise StepError(\n",
        "                \"Silver step name cannot be empty\",\n",
        "                context={\"step_name\": name or \"unknown\", \"step_type\": \"silver\"},\n",
        "                suggestions=[\n",
        "                    \"Provide a valid step name\",\n",
        "                    \"Check step naming conventions\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        # Use base class method for duplicate checking\n",
        "        try:\n",
        "            self._check_duplicate_step_name(name, \"silver\")\n",
        "        except Exception as e:\n",
        "            # Convert to StepError for consistency\n",
        "            raise StepError(\n",
        "                str(e),\n",
        "                context={\"step_name\": name, \"step_type\": \"silver\"},\n",
        "                suggestions=[\n",
        "                    \"Use a different step name\",\n",
        "                    \"Remove the existing step first\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "        # Auto-infer source_bronze if not provided\n",
        "        if source_bronze is None:\n",
        "            if not self.bronze_steps:\n",
        "                raise StepError(\n",
        "                    \"No bronze steps available for auto-inference\",\n",
        "                    context={\"step_name\": name, \"step_type\": \"silver\"},\n",
        "                    suggestions=[\n",
        "                        \"Add a bronze step first using with_bronze_rules()\",\n",
        "                        \"Explicitly specify source_bronze parameter\",\n",
        "                    ],\n",
        "                )\n",
        "\n",
        "            # Use the most recently added bronze step\n",
        "            source_bronze = list(self.bronze_steps.keys())[-1]\n",
        "            self.logger.info(f\"\ud83d\udd0d Auto-inferred source_bronze: {source_bronze}\")\n",
        "\n",
        "        # Validate that the source_bronze exists\n",
        "        if source_bronze not in self.bronze_steps:\n",
        "            raise StepError(\n",
        "                f\"Bronze step '{source_bronze}' not found\",\n",
        "                context={\"step_name\": name, \"step_type\": \"silver\"},\n",
        "                suggestions=[\n",
        "                    f\"Available bronze steps: {list(self.bronze_steps.keys())}\",\n",
        "                    \"Add the bronze step first using with_bronze_rules()\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        # Note: Dependency validation is deferred to validate_pipeline()\n",
        "        # This allows for more flexible pipeline construction\n",
        "\n",
        "        # Use builder's schema if not provided\n",
        "        if schema is None:\n",
        "            schema = self.config.schema\n",
        "        else:\n",
        "            self._validate_schema(schema)\n",
        "\n",
        "        # Convert string rules to PySpark Column objects\n",
        "        converted_rules = _convert_rules_to_expressions(rules, self.functions)\n",
        "\n",
        "        # Capture the incremental column from the source bronze step (if any)\n",
        "        source_incremental_col = self.bronze_steps[source_bronze].incremental_col\n",
        "\n",
        "        # Use source_silvers if provided, otherwise fall back to depends_on for backward compatibility\n",
        "        final_source_silvers = (\n",
        "            source_silvers if source_silvers is not None else depends_on\n",
        "        )\n",
        "\n",
        "        # Create silver step\n",
        "        silver_step = SilverStep(\n",
        "            name=name,\n",
        "            source_bronze=source_bronze,\n",
        "            transform=transform,\n",
        "            rules=converted_rules,\n",
        "            table_name=table_name,\n",
        "            watermark_col=watermark_col,\n",
        "            schema=schema,\n",
        "            source_incremental_col=source_incremental_col,\n",
        "            schema_override=schema_override,\n",
        "            source_silvers=final_source_silvers,\n",
        "        )\n",
        "\n",
        "        self.silver_steps[name] = silver_step\n",
        "        # Track creation order for deterministic ordering\n",
        "        self._step_creation_order[name] = self._creation_counter\n",
        "        self._creation_counter += 1\n",
        "        self.logger.info(f\"\u2705 Added Silver step: {name} (source: {source_bronze})\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def add_gold_transform(\n",
        "        self,\n",
        "        *,\n",
        "        name: StepName,\n",
        "        transform: GoldTransformFunction,\n",
        "        rules: ColumnRules,\n",
        "        table_name: TableName,\n",
        "        source_silvers: Optional[list[StepName]] = None,\n",
        "        description: Optional[str] = None,\n",
        "        schema: Optional[str] = None,\n",
        "        schema_override: Optional[Any] = None,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Add Gold layer transformation step for business analytics and aggregations.\n",
        "\n",
        "        Gold steps represent the third layer of the Medallion Architecture,\n",
        "        creating business-ready datasets for analytics and reporting. All Gold\n",
        "        steps must have non-empty validation rules and a valid transform function.\n",
        "\n",
        "        Args:\n",
        "            name: Unique identifier for this Gold step.\n",
        "            transform: Transformation function with signature:\n",
        "                (spark: SparkSession, silvers: Dict[str, DataFrame]) -> DataFrame\n",
        "                Must be callable and cannot be None.\n",
        "            rules: Dictionary mapping column names to validation rule lists.\n",
        "                Supports both PySpark Column expressions and string rules:\n",
        "                - PySpark: {\"user_id\": [F.col(\"user_id\").isNotNull()]}\n",
        "                - String: {\"user_id\": [\"not_null\"], \"count\": [\"gt\", 0]}\n",
        "            table_name: Target Delta table name where results will be stored\n",
        "                (without schema).\n",
        "            source_silvers: Optional list of Silver step names this Gold step\n",
        "                depends on. If not provided, automatically uses all available\n",
        "                Silver steps. If no Silver steps exist, raises an error.\n",
        "            description: Optional description of this Gold step.\n",
        "            schema: Optional schema name for writing gold data. If not provided,\n",
        "                uses the builder's default schema.\n",
        "            schema_override: Optional PySpark StructType schema to override\n",
        "                DataFrame schema when writing to gold tables. Uses Delta Lake's\n",
        "                overwriteSchema option. Always applied for gold table writes.\n",
        "\n",
        "        Returns:\n",
        "            Self for method chaining.\n",
        "\n",
        "        Raises:\n",
        "            StepError: If step name is empty, conflicts with existing step,\n",
        "                source_silvers not found, or schema validation fails.\n",
        "            ValidationError: If rules are empty, transform is None, or\n",
        "                configuration is invalid.\n",
        "\n",
        "        Example:\n",
        "            Using PySpark Column expressions:\n",
        "\n",
        "            >>> def user_daily_metrics(spark, silvers):\n",
        "            ...     events_df = silvers[\"clean_events\"]\n",
        "            ...     return (events_df\n",
        "            ...         .groupBy(\"user_id\", \"event_date\")\n",
        "            ...         .agg(F.count(\"*\").alias(\"event_count\"))\n",
        "            ...     )\n",
        "            >>>\n",
        "            >>> builder.add_gold_transform(\n",
        "            ...     name=\"user_metrics\",\n",
        "            ...     transform=user_daily_metrics,\n",
        "            ...     rules={\"user_id\": [F.col(\"user_id\").isNotNull()]},\n",
        "            ...     table_name=\"user_daily_metrics\",\n",
        "            ...     source_silvers=[\"clean_events\"]\n",
        "            ... )\n",
        "\n",
        "            Using string rules with auto-inferred sources:\n",
        "\n",
        "            >>> builder.add_gold_transform(\n",
        "            ...     name=\"daily_analytics\",\n",
        "            ...     transform=lambda spark, silvers: (\n",
        "            ...         silvers[\"clean_events\"]\n",
        "            ...         .groupBy(\"date\")\n",
        "            ...         .agg(F.count(\"*\").alias(\"count\"))\n",
        "            ...     ),\n",
        "            ...     rules={\"date\": [\"not_null\"], \"count\": [\"gt\", 0]},\n",
        "            ...     table_name=\"daily_analytics\"\n",
        "            ...     # source_silvers auto-inferred from all silver steps\n",
        "            ... )\n",
        "\n",
        "        Note:\n",
        "            String rules are automatically converted to PySpark expressions.\n",
        "            See with_bronze_rules() for supported string rule formats.\n",
        "        \"\"\"\n",
        "        if not name:\n",
        "            raise StepError(\n",
        "                \"Gold step name cannot be empty\",\n",
        "                context={\"step_name\": name or \"unknown\", \"step_type\": \"gold\"},\n",
        "                suggestions=[\n",
        "                    \"Provide a valid step name\",\n",
        "                    \"Check step naming conventions\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        # Use base class method for duplicate checking\n",
        "        try:\n",
        "            self._check_duplicate_step_name(name, \"gold\")\n",
        "        except Exception as e:\n",
        "            # Convert to StepError for consistency\n",
        "            raise StepError(\n",
        "                str(e),\n",
        "                context={\"step_name\": name, \"step_type\": \"gold\"},\n",
        "                suggestions=[\n",
        "                    \"Use a different step name\",\n",
        "                    \"Remove the existing step first\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "        # Auto-infer source_silvers if not provided\n",
        "        if source_silvers is None:\n",
        "            if not self.silver_steps:\n",
        "                raise StepError(\n",
        "                    \"No silver steps available for auto-inference\",\n",
        "                    context={\"step_name\": name, \"step_type\": \"gold\"},\n",
        "                    suggestions=[\n",
        "                        \"Add a silver step first using add_silver_transform()\",\n",
        "                        \"Explicitly specify source_silvers parameter\",\n",
        "                    ],\n",
        "                )\n",
        "\n",
        "            # Use all available silver steps\n",
        "            source_silvers = list(self.silver_steps.keys())\n",
        "            self.logger.info(f\"\ud83d\udd0d Auto-inferred source_silvers: {source_silvers}\")\n",
        "\n",
        "        # Validate that all source_silvers exist\n",
        "        invalid_silvers = [s for s in source_silvers if s not in self.silver_steps]\n",
        "        if invalid_silvers:\n",
        "            raise StepError(\n",
        "                f\"Silver steps not found: {invalid_silvers}\",\n",
        "                context={\"step_name\": name, \"step_type\": \"gold\"},\n",
        "                suggestions=[\n",
        "                    f\"Available silver steps: {list(self.silver_steps.keys())}\",\n",
        "                    \"Add the missing silver steps first using add_silver_transform()\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "        # Note: Dependency validation is deferred to validate_pipeline()\n",
        "        # This allows for more flexible pipeline construction\n",
        "\n",
        "        # Use builder's schema if not provided\n",
        "        if schema is None:\n",
        "            schema = self.config.schema\n",
        "        else:\n",
        "            self._validate_schema(schema)\n",
        "\n",
        "        # Convert string rules to PySpark Column objects\n",
        "        converted_rules = _convert_rules_to_expressions(rules, self.functions)\n",
        "\n",
        "        # Create gold step\n",
        "        gold_step = GoldStep(\n",
        "            name=name,\n",
        "            transform=transform,\n",
        "            rules=converted_rules,\n",
        "            table_name=table_name,\n",
        "            source_silvers=source_silvers,\n",
        "            schema=schema,\n",
        "            schema_override=schema_override,\n",
        "        )\n",
        "\n",
        "        self.gold_steps[name] = gold_step\n",
        "        # Track creation order for deterministic ordering\n",
        "        self._step_creation_order[name] = self._creation_counter\n",
        "        self._creation_counter += 1\n",
        "        self.logger.info(f\"\u2705 Added Gold step: {name} (sources: {source_silvers})\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_errors_from_validator_result(\n",
        "        result: Union[ValidationResult, List[str]],\n",
        "        validator_name: str,\n",
        "        logger: PipelineLogger,\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Type guard function to safely extract errors from validator results.\n",
        "\n",
        "        This function handles both ValidationResult and List[str] return types,\n",
        "        providing runtime type safety and clear error messages. This prevents\n",
        "        type mismatch bugs like the ValidationResult + List[str] concatenation error.\n",
        "\n",
        "        Different validators return different types:\n",
        "        - UnifiedValidator.validate_pipeline() returns List[str]\n",
        "        - UnifiedValidator.validate_pipeline() returns ValidationResult\n",
        "\n",
        "        This function normalizes both to List[str] for safe concatenation.\n",
        "\n",
        "        Args:\n",
        "            result: Result from validator (ValidationResult or List[str])\n",
        "            validator_name: Name of the validator for error messages\n",
        "            logger: Logger instance for warnings/errors\n",
        "\n",
        "        Returns:\n",
        "            List of validation error strings (guaranteed to be List[str])\n",
        "\n",
        "        Raises:\n",
        "            TypeError: If result is neither ValidationResult nor List[str],\n",
        "                      or if List contains non-string items\n",
        "\n",
        "        Example:\n",
        "            >>> base_result = validator.validate_pipeline(...)\n",
        "            >>> errors = PipelineBuilder._extract_errors_from_validator_result(\n",
        "            ...     base_result, \"base_validator\", logger\n",
        "            ... )\n",
        "            >>> # errors is guaranteed to be List[str]\n",
        "        \"\"\"\n",
        "        if isinstance(result, ValidationResult):\n",
        "            # UnifiedValidator returns ValidationResult\n",
        "            return result.errors\n",
        "        elif isinstance(result, list):\n",
        "            # UnifiedValidator returns List[str]\n",
        "            # Verify all items are strings\n",
        "            if not all(isinstance(item, str) for item in result):\n",
        "                error_msg = (\n",
        "                    f\"Validator {validator_name} returned List with non-string items. \"\n",
        "                    f\"Expected List[str]. Got: {result}\"\n",
        "                )\n",
        "                logger.error(error_msg)\n",
        "                raise TypeError(error_msg)\n",
        "            return result\n",
        "        else:\n",
        "            # Unexpected type - this is reachable at runtime even though\n",
        "            # the type hint suggests it shouldn't be (defensive programming)\n",
        "            error_msg = (\n",
        "                f\"Unexpected return type from {validator_name}: {type(result)}. \"\n",
        "                f\"Expected ValidationResult or List[str]. Got: {result}\"\n",
        "            )\n",
        "            logger.error(error_msg)\n",
        "            raise TypeError(error_msg)\n",
        "\n",
        "    def validate_pipeline(self) -> List[str]:\n",
        "        \"\"\"Validate the entire pipeline configuration.\n",
        "\n",
        "        Runs both base validator (UnifiedValidator) and spark validator\n",
        "        (UnifiedValidator), then combines their errors. Runtime type checks\n",
        "        ensure that return types match expectations, preventing type mismatch bugs.\n",
        "\n",
        "        Args:\n",
        "            None (uses instance state).\n",
        "\n",
        "        Returns:\n",
        "            List of validation error strings (empty if valid). Each string\n",
        "            describes a validation issue found in the pipeline configuration.\n",
        "\n",
        "        Raises:\n",
        "            TypeError: If validators return unexpected types (caught by runtime\n",
        "                checks).\n",
        "\n",
        "        Note:\n",
        "            Return types from validators:\n",
        "            - UnifiedValidator.validate_pipeline() returns List[str]\n",
        "            - UnifiedValidator.validate_pipeline() returns ValidationResult\n",
        "\n",
        "            Both are normalized to List[str] using type guard functions before\n",
        "            concatenation. Errors are logged to the logger.\n",
        "        \"\"\"\n",
        "        # Use base class validation first (from BasePipelineBuilder)\n",
        "        # UnifiedValidator.validate_pipeline() returns List[str]\n",
        "        base_result = self._base_validator.validate_pipeline(\n",
        "            self.config, self.bronze_steps, self.silver_steps, self.gold_steps\n",
        "        )\n",
        "\n",
        "        # Extract errors using type guard function for runtime safety\n",
        "        base_errors = self._extract_errors_from_validator_result(\n",
        "            base_result, \"base_validator\", self.logger\n",
        "        )\n",
        "\n",
        "        # Also run Spark-specific validation\n",
        "        # UnifiedValidator.validate_pipeline() returns ValidationResult\n",
        "        spark_result = self.spark_validator.validate_pipeline(\n",
        "            self.config, self.bronze_steps, self.silver_steps, self.gold_steps\n",
        "        )\n",
        "\n",
        "        # Extract errors using type guard function for runtime safety\n",
        "        spark_errors = self._extract_errors_from_validator_result(\n",
        "            spark_result, \"spark_validator\", self.logger\n",
        "        )\n",
        "\n",
        "        # Combine errors - both are now guaranteed to be lists\n",
        "        all_errors = base_errors + spark_errors\n",
        "\n",
        "        if all_errors:\n",
        "            self.logger.error(\n",
        "                f\"Pipeline validation failed with {len(all_errors)} errors\"\n",
        "            )\n",
        "            for error in all_errors:\n",
        "                self.logger.error(f\"  - {error}\")\n",
        "            # Clear execution order if validation fails\n",
        "            self.execution_order = None\n",
        "        else:\n",
        "            self.logger.info(\"\u2705 Pipeline validation passed\")\n",
        "            # Calculate execution order after successful validation\n",
        "            self._calculate_execution_order()\n",
        "\n",
        "        return all_errors\n",
        "\n",
        "    def _calculate_execution_order(self) -> None:\n",
        "        \"\"\"Calculate and store execution order based on step dependencies.\n",
        "\n",
        "        Uses DependencyAnalyzer to determine the topological sort order of steps.\n",
        "        This is called automatically after successful pipeline validation.\n",
        "\n",
        "        Note:\n",
        "            Execution order is stored in self.execution_order attribute.\n",
        "            If dependency analysis fails, execution_order is set to None.\n",
        "            Creation order is used as a tie-breaker for deterministic ordering\n",
        "            when steps have no explicit dependencies.\n",
        "        \"\"\"\n",
        "        try:\n",
        "# from .dependencies import DependencyAnalyzer  # Removed: defined in notebook cells above\n",
        "\n",
        "            # Convert step dictionaries to format expected by DependencyAnalyzer\n",
        "            bronze_dict = dict(self.bronze_steps)\n",
        "            silver_dict = dict(self.silver_steps)\n",
        "            gold_dict = dict(self.gold_steps)\n",
        "\n",
        "            # Analyze dependencies with creation order for deterministic tie-breaking\n",
        "            analyzer = DependencyAnalyzer()\n",
        "            analysis = analyzer.analyze_dependencies(\n",
        "                bronze_steps=bronze_dict,  # type: ignore[arg-type]\n",
        "                silver_steps=silver_dict,  # type: ignore[arg-type]\n",
        "                gold_steps=gold_dict,  # type: ignore[arg-type]\n",
        "                creation_order=self._step_creation_order,  # Pass creation order\n",
        "            )\n",
        "\n",
        "            # Store execution order\n",
        "            self.execution_order = analysis.execution_order\n",
        "\n",
        "            # Log execution order\n",
        "            if self.execution_order:\n",
        "                self.logger.info(\n",
        "                    f\"\ud83d\udccb Execution order ({len(self.execution_order)} steps): \"\n",
        "                    f\"{' \u2192 '.join(self.execution_order)}\"\n",
        "                )\n",
        "            else:\n",
        "                self.logger.warning(\"Execution order is empty - no steps to execute\")\n",
        "        except Exception as e:\n",
        "            self.logger.warning(\n",
        "                f\"Could not calculate execution order: {e}. \"\n",
        "                f\"Execution order will not be available.\"\n",
        "            )\n",
        "            self.execution_order = None\n",
        "\n",
        "    # ============================================================================\n",
        "    # PRESET CONFIGURATIONS AND HELPER METHODS\n",
        "    # ============================================================================\n",
        "\n",
        "    @classmethod\n",
        "    def for_development(\n",
        "        cls,\n",
        "        spark: SparkSession,\n",
        "        schema: str,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Create a PipelineBuilder optimized for development with relaxed validation.\n",
        "\n",
        "        Creates a PipelineBuilder instance with relaxed validation thresholds\n",
        "        suitable for development environments. Allows faster iteration with\n",
        "        lower quality gates.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance for data processing.\n",
        "            schema: Database schema name where tables will be created.\n",
        "            functions: Optional FunctionsProtocol instance for PySpark operations.\n",
        "            **kwargs: Additional configuration parameters passed to __init__.\n",
        "\n",
        "        Returns:\n",
        "            PipelineBuilder instance with development-optimized settings:\n",
        "            - min_bronze_rate: 80.0%\n",
        "            - min_silver_rate: 85.0%\n",
        "            - min_gold_rate: 90.0%\n",
        "            - verbose: True\n",
        "\n",
        "        Example:\n",
        "            >>> builder = PipelineBuilder.for_development(\n",
        "            ...     spark=spark,\n",
        "            ...     schema=\"dev_schema\"\n",
        "            ... )\n",
        "        \"\"\"\n",
        "        return cls(\n",
        "            spark=spark,\n",
        "            schema=schema,\n",
        "            min_bronze_rate=80.0,  # Relaxed validation\n",
        "            min_silver_rate=85.0,\n",
        "            min_gold_rate=90.0,\n",
        "            verbose=True,\n",
        "            functions=functions,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def for_production(\n",
        "        cls,\n",
        "        spark: SparkSession,\n",
        "        schema: str,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Create a PipelineBuilder optimized for production with strict validation.\n",
        "\n",
        "        Creates a PipelineBuilder instance with strict validation thresholds\n",
        "        suitable for production environments. Enforces high data quality standards.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance for data processing.\n",
        "            schema: Database schema name where tables will be created.\n",
        "            functions: Optional FunctionsProtocol instance for PySpark operations.\n",
        "            **kwargs: Additional configuration parameters passed to __init__.\n",
        "\n",
        "        Returns:\n",
        "            PipelineBuilder instance with production-optimized settings:\n",
        "            - min_bronze_rate: 95.0%\n",
        "            - min_silver_rate: 98.0%\n",
        "            - min_gold_rate: 99.0%\n",
        "            - verbose: False\n",
        "\n",
        "        Example:\n",
        "            >>> builder = PipelineBuilder.for_production(\n",
        "            ...     spark=spark,\n",
        "            ...     schema=\"prod_schema\"\n",
        "            ... )\n",
        "        \"\"\"\n",
        "        return cls(\n",
        "            spark=spark,\n",
        "            schema=schema,\n",
        "            min_bronze_rate=95.0,  # Strict validation\n",
        "            min_silver_rate=98.0,\n",
        "            min_gold_rate=99.0,\n",
        "            verbose=False,\n",
        "            functions=functions,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def for_testing(\n",
        "        cls,\n",
        "        spark: SparkSession,\n",
        "        schema: str,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> PipelineBuilder:\n",
        "        \"\"\"Create a PipelineBuilder optimized for testing with minimal validation.\n",
        "\n",
        "        Creates a PipelineBuilder instance with very relaxed validation thresholds\n",
        "        suitable for testing environments. Allows maximum flexibility for test\n",
        "        scenarios.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance for data processing.\n",
        "            schema: Database schema name where tables will be created.\n",
        "            functions: Optional FunctionsProtocol instance for PySpark operations.\n",
        "            **kwargs: Additional configuration parameters passed to __init__.\n",
        "\n",
        "        Returns:\n",
        "            PipelineBuilder instance with testing-optimized settings:\n",
        "            - min_bronze_rate: 70.0%\n",
        "            - min_silver_rate: 75.0%\n",
        "            - min_gold_rate: 80.0%\n",
        "            - verbose: True\n",
        "\n",
        "        Example:\n",
        "            >>> builder = PipelineBuilder.for_testing(\n",
        "            ...     spark=spark,\n",
        "            ...     schema=\"test_schema\"\n",
        "            ... )\n",
        "        \"\"\"\n",
        "        return cls(\n",
        "            spark=spark,\n",
        "            schema=schema,\n",
        "            min_bronze_rate=70.0,  # Very relaxed validation\n",
        "            min_silver_rate=75.0,\n",
        "            min_gold_rate=80.0,\n",
        "            verbose=True,\n",
        "            functions=functions,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    # ============================================================================\n",
        "    # VALIDATION HELPER METHODS\n",
        "    # ============================================================================\n",
        "\n",
        "    @staticmethod\n",
        "    def not_null_rules(\n",
        "        columns: list[str], functions: Optional[FunctionsProtocol] = None\n",
        "    ) -> ColumnRules:\n",
        "        \"\"\"Create validation rules for non-null constraints on multiple columns.\n",
        "\n",
        "        Helper method to quickly create validation rules requiring columns to\n",
        "        be non-null. Useful for common validation patterns.\n",
        "\n",
        "        Args:\n",
        "            columns: List of column names to validate for non-null.\n",
        "            functions: Optional FunctionsProtocol instance for column operations.\n",
        "                If None, uses get_default_functions().\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping column names to lists of validation rules.\n",
        "            Each column gets a single rule: F.col(column).isNotNull().\n",
        "\n",
        "        Example:\n",
        "            >>> rules = PipelineBuilder.not_null_rules([\"user_id\", \"timestamp\", \"value\"])\n",
        "            >>> # Equivalent to:\n",
        "            >>> # {\n",
        "            >>> #     \"user_id\": [F.col(\"user_id\").isNotNull()],\n",
        "            >>> #     \"timestamp\": [F.col(\"timestamp\").isNotNull()],\n",
        "            >>> #     \"value\": [F.col(\"value\").isNotNull()]\n",
        "            >>> # }\n",
        "        \"\"\"\n",
        "        if functions is None:\n",
        "            functions = get_default_functions()\n",
        "        return {col: [functions.col(col).isNotNull()] for col in columns}\n",
        "\n",
        "    @staticmethod\n",
        "    def positive_number_rules(\n",
        "        columns: list[str], functions: Optional[FunctionsProtocol] = None\n",
        "    ) -> ColumnRules:\n",
        "        \"\"\"Create validation rules for positive number constraints on multiple columns.\n",
        "\n",
        "        Helper method to quickly create validation rules requiring columns to\n",
        "        be non-null and greater than zero. Useful for count, amount, and quantity\n",
        "        columns.\n",
        "\n",
        "        Args:\n",
        "            columns: List of column names to validate for positive numbers.\n",
        "            functions: Optional FunctionsProtocol instance for column operations.\n",
        "                If None, uses get_default_functions().\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping column names to lists of validation rules.\n",
        "            Each column gets two rules: isNotNull() and > 0.\n",
        "\n",
        "        Example:\n",
        "            >>> rules = PipelineBuilder.positive_number_rules([\"value\", \"count\"])\n",
        "            >>> # Equivalent to:\n",
        "            >>> # {\n",
        "            >>> #     \"value\": [F.col(\"value\").isNotNull(), F.col(\"value\") > 0],\n",
        "            >>> #     \"count\": [F.col(\"count\").isNotNull(), F.col(\"count\") > 0]\n",
        "            >>> # }\n",
        "        \"\"\"\n",
        "        if functions is None:\n",
        "            functions = get_default_functions()\n",
        "        return {\n",
        "            col: [functions.col(col).isNotNull(), functions.col(col) > 0]\n",
        "            for col in columns\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def string_not_empty_rules(\n",
        "        columns: list[str], functions: Optional[FunctionsProtocol] = None\n",
        "    ) -> ColumnRules:\n",
        "        \"\"\"Create validation rules for non-empty string constraints on multiple columns.\n",
        "\n",
        "        Helper method to quickly create validation rules requiring string columns\n",
        "        to be non-null and have length greater than zero. Useful for name, category,\n",
        "        and other string identifier columns.\n",
        "\n",
        "        Args:\n",
        "            columns: List of column names to validate for non-empty strings.\n",
        "            functions: Optional FunctionsProtocol instance for column operations.\n",
        "                If None, uses get_default_functions().\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping column names to lists of validation rules.\n",
        "            Each column gets two rules: isNotNull() and length() > 0.\n",
        "\n",
        "        Example:\n",
        "            >>> rules = PipelineBuilder.string_not_empty_rules([\"name\", \"category\"])\n",
        "            >>> # Equivalent to:\n",
        "            >>> # {\n",
        "            >>> #     \"name\": [F.col(\"name\").isNotNull(), F.length(F.col(\"name\")) > 0],\n",
        "            >>> #     \"category\": [F.col(\"category\").isNotNull(), F.length(F.col(\"category\")) > 0]\n",
        "            >>> # }\n",
        "        \"\"\"\n",
        "        if functions is None:\n",
        "            functions = get_default_functions()\n",
        "        return {\n",
        "            col: [\n",
        "                functions.col(col).isNotNull(),\n",
        "                functions.length(functions.col(col)) > 0,\n",
        "            ]\n",
        "            for col in columns\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def timestamp_rules(\n",
        "        columns: list[str], functions: Optional[FunctionsProtocol] = None\n",
        "    ) -> ColumnRules:\n",
        "        \"\"\"Create validation rules for timestamp constraints on multiple columns.\n",
        "\n",
        "        Helper method to quickly create validation rules requiring timestamp\n",
        "        columns to be non-null. Useful for created_at, updated_at, and other\n",
        "        timestamp columns.\n",
        "\n",
        "        Args:\n",
        "            columns: List of column names to validate as timestamps.\n",
        "            functions: Optional FunctionsProtocol instance for column operations.\n",
        "                If None, uses get_default_functions().\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping column names to lists of validation rules.\n",
        "            Each column gets a single rule: isNotNull() (applied twice in\n",
        "            current implementation - may be simplified in future).\n",
        "\n",
        "        Example:\n",
        "            >>> rules = PipelineBuilder.timestamp_rules([\"created_at\", \"updated_at\"])\n",
        "            >>> # Equivalent to:\n",
        "            >>> # {\n",
        "            >>> #     \"created_at\": [F.col(\"created_at\").isNotNull()],\n",
        "            >>> #     \"updated_at\": [F.col(\"updated_at\").isNotNull()]\n",
        "            >>> # }\n",
        "        \"\"\"\n",
        "        if functions is None:\n",
        "            functions = get_default_functions()\n",
        "        return {\n",
        "            col: [functions.col(col).isNotNull(), functions.col(col).isNotNull()]\n",
        "            for col in columns\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_timestamp_columns(df_schema: Any) -> list[str]:\n",
        "        \"\"\"Detect timestamp columns from a DataFrame schema.\n",
        "\n",
        "        Analyzes column names to identify potential timestamp columns based\n",
        "        on common naming patterns. Useful for automatically configuring\n",
        "        incremental processing.\n",
        "\n",
        "        Args:\n",
        "            df_schema: DataFrame schema (StructType) or list of column names\n",
        "                with types. Can also be a simple list of column name strings.\n",
        "\n",
        "        Returns:\n",
        "            List of column names that match timestamp naming patterns.\n",
        "            Searches for keywords like \"timestamp\", \"created_at\", \"updated_at\",\n",
        "            etc. in column names (case-insensitive).\n",
        "\n",
        "        Example:\n",
        "            >>> timestamp_cols = PipelineBuilder.detect_timestamp_columns(df.schema)\n",
        "            >>> # Returns columns like [\"timestamp\", \"created_at\", \"updated_at\"]\n",
        "            >>> # if they exist in the schema\n",
        "\n",
        "        Note:\n",
        "            Searches for these keywords in column names (case-insensitive):\n",
        "            - timestamp, created_at, updated_at, event_time, process_time,\n",
        "              ingestion_time, load_time, modified_at, date_time, ts\n",
        "        \"\"\"\n",
        "        timestamp_keywords = [\n",
        "            \"timestamp\",\n",
        "            \"created_at\",\n",
        "            \"updated_at\",\n",
        "            \"event_time\",\n",
        "            \"process_time\",\n",
        "            \"ingestion_time\",\n",
        "            \"load_time\",\n",
        "            \"modified_at\",\n",
        "            \"date_time\",\n",
        "            \"ts\",\n",
        "        ]\n",
        "\n",
        "        if hasattr(df_schema, \"fields\"):\n",
        "            # DataFrame schema\n",
        "            columns = [field.name.lower() for field in df_schema.fields]\n",
        "        else:\n",
        "            # List of column names\n",
        "            columns = [col.lower() for col in df_schema]\n",
        "\n",
        "        # Find columns that match timestamp patterns\n",
        "        timestamp_cols = []\n",
        "        for col in columns:\n",
        "            if any(keyword in col for keyword in timestamp_keywords):\n",
        "                timestamp_cols.append(col)\n",
        "\n",
        "        return timestamp_cols\n",
        "\n",
        "    def _validate_schema(self, schema: str) -> None:\n",
        "        \"\"\"Validate that a schema exists and is accessible.\n",
        "\n",
        "        Overrides the base class method to add Spark-specific schema validation.\n",
        "        First validates schema name format, then checks if schema exists in\n",
        "        Spark catalog.\n",
        "\n",
        "        Args:\n",
        "            schema: Schema name to validate.\n",
        "\n",
        "        Raises:\n",
        "            StepError: If schema doesn't exist, is not accessible, or name\n",
        "                format is invalid.\n",
        "            ValidationError: If schema name format validation fails.\n",
        "\n",
        "        Note:\n",
        "            Uses base validator for format validation, then checks Spark\n",
        "            catalog for existence. Provides helpful suggestions if schema\n",
        "            doesn't exist.\n",
        "        \"\"\"\n",
        "        # First validate schema name format using base validator\n",
        "        try:\n",
        "            errors = self._base_validator.validate_schema(schema)\n",
        "            if errors:\n",
        "                raise ValidationError(errors[0])\n",
        "        except ValidationError:\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            # Convert to StepError for consistency\n",
        "            raise StepError(\n",
        "                str(e),\n",
        "                context={\"step_name\": \"schema_validation\", \"step_type\": \"validation\"},\n",
        "            ) from e\n",
        "\n",
        "        # Then check if schema exists in Spark catalog\n",
        "        try:\n",
        "            databases = [db.name for db in self.spark.catalog.listDatabases()]\n",
        "            if schema not in databases:\n",
        "                raise StepError(\n",
        "                    f\"Schema '{schema}' does not exist\",\n",
        "                    context={\n",
        "                        \"step_name\": \"schema_validation\",\n",
        "                        \"step_type\": \"validation\",\n",
        "                    },\n",
        "                    suggestions=[\n",
        "                        f\"Create the schema first: CREATE SCHEMA IF NOT EXISTS {schema}\",\n",
        "                        \"Check schema permissions\",\n",
        "                        \"Verify schema name spelling\",\n",
        "                    ],\n",
        "                )\n",
        "            self.logger.debug(f\"\u2705 Schema '{schema}' is accessible\")\n",
        "        except StepError:\n",
        "            # Re-raise StepError as-is\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            raise StepError(\n",
        "                f\"Schema '{schema}' is not accessible: {str(e)}\",\n",
        "                context={\"step_name\": \"schema_validation\", \"step_type\": \"validation\"},\n",
        "                suggestions=[\n",
        "                    f\"Create the schema first: CREATE SCHEMA IF NOT EXISTS {schema}\",\n",
        "                    \"Check schema permissions\",\n",
        "                    \"Verify schema name spelling\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "    def _create_schema_if_not_exists(self, schema: str) -> None:\n",
        "        \"\"\"Create a schema if it doesn't exist.\n",
        "\n",
        "        Uses SQL CREATE SCHEMA IF NOT EXISTS to create the schema idempotently.\n",
        "        Logs success or failure.\n",
        "\n",
        "        Args:\n",
        "            schema: Schema name to create.\n",
        "\n",
        "        Raises:\n",
        "            StepError: If schema creation fails.\n",
        "\n",
        "        Note:\n",
        "            Uses CREATE SCHEMA IF NOT EXISTS for idempotent operation.\n",
        "            Errors are wrapped in StepError with helpful suggestions.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Use SQL to create schema\n",
        "            self.spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema}\")\n",
        "            self.logger.info(f\"\u2705 Schema '{schema}' created or already exists\")\n",
        "        except Exception as e:\n",
        "            raise StepError(\n",
        "                f\"Failed to create schema '{schema}': {str(e)}\",\n",
        "                context={\"step_name\": \"schema_creation\", \"step_type\": \"validation\"},\n",
        "                suggestions=[\n",
        "                    \"Check schema permissions\",\n",
        "                    \"Verify schema name is valid\",\n",
        "                    \"Check for naming conflicts\",\n",
        "                ],\n",
        "            ) from e\n",
        "\n",
        "    def _get_effective_schema(self, step_schema: Optional[str]) -> str:\n",
        "        \"\"\"Get the effective schema for a step.\n",
        "\n",
        "        Returns the step-specific schema if provided, otherwise falls back to\n",
        "        the builder's default schema.\n",
        "\n",
        "        Args:\n",
        "            step_schema: Optional schema name specified for the step.\n",
        "\n",
        "        Returns:\n",
        "            The effective schema name (step_schema if provided, otherwise\n",
        "            self.schema).\n",
        "        \"\"\"\n",
        "        return step_schema if step_schema is not None else self.schema\n",
        "\n",
        "    def to_pipeline(self) -> PipelineRunner:\n",
        "        \"\"\"Build and return a PipelineRunner for executing this pipeline.\n",
        "\n",
        "        Validates the pipeline configuration, then creates a PipelineRunner\n",
        "        instance ready for execution. The runner implements the abstracts.Runner\n",
        "        interface and can execute the pipeline using various execution modes.\n",
        "\n",
        "        Args:\n",
        "            None (uses instance state).\n",
        "\n",
        "        Returns:\n",
        "            PipelineRunner instance ready for execution. Implements\n",
        "            abstracts.Runner interface.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If pipeline validation fails or step validation fails.\n",
        "\n",
        "        Example:\n",
        "            >>> builder = PipelineBuilder(spark=spark, schema=\"analytics\")\n",
        "            >>> builder.with_bronze_rules(name=\"events\", rules={\"id\": [\"not_null\"]})\n",
        "            >>> builder.add_silver_transform(\n",
        "            ...     name=\"clean_events\",\n",
        "            ...     transform=lambda spark, df, silvers: df.filter(F.col(\"status\") == \"active\"),\n",
        "            ...     rules={\"status\": [\"not_null\"]},\n",
        "            ...     table_name=\"clean_events\"\n",
        "            ... )\n",
        "            >>> pipeline = builder.to_pipeline()\n",
        "            >>> result = pipeline.run_initial_load(bronze_sources={\"events\": source_df})\n",
        "\n",
        "        Note:\n",
        "            The pipeline is validated before building. All steps are validated\n",
        "            using the abstracts.PipelineBuilder validation to ensure interface\n",
        "            compatibility.\n",
        "        \"\"\"\n",
        "        # Validate pipeline before building\n",
        "        validation_errors = self.validate_pipeline()\n",
        "        if validation_errors:\n",
        "            raise ValueError(\n",
        "                f\"Pipeline validation failed with {len(validation_errors)} errors: {', '.join(validation_errors)}\"\n",
        "            )\n",
        "\n",
        "        # Check that validation-only (with_silver_rules / with_gold_rules) target tables exist\n",
        "        # when optional=False; fail early at build time instead of at run time.\n",
        "        missing_tables: list[str] = []\n",
        "        for step in self.silver_steps.values():\n",
        "            if (\n",
        "                getattr(step, \"existing\", False)\n",
        "                and step.transform is None\n",
        "                and not getattr(step, \"optional\", False)\n",
        "            ):\n",
        "                schema = getattr(step, \"schema\", None) or self.config.schema\n",
        "                table_name = getattr(step, \"table_name\", step.name)\n",
        "                table_fqn = fqn(schema, table_name)\n",
        "                if not table_exists(self.spark, table_fqn):\n",
        "                    missing_tables.append(\n",
        "                        f\"Silver step '{step.name}' requires existing table '{table_fqn}' (optional=False)\"\n",
        "                    )\n",
        "        for gold_step in self.gold_steps.values():\n",
        "            if (\n",
        "                getattr(gold_step, \"existing\", False)\n",
        "                and gold_step.transform is None\n",
        "                and not getattr(gold_step, \"optional\", False)\n",
        "            ):\n",
        "                schema = getattr(gold_step, \"schema\", None) or self.config.schema\n",
        "                table_name = getattr(gold_step, \"table_name\", gold_step.name)\n",
        "                table_fqn = fqn(schema, table_name)\n",
        "                if not table_exists(self.spark, table_fqn):\n",
        "                    missing_tables.append(\n",
        "                        f\"Gold step '{gold_step.name}' requires existing table '{table_fqn}' (optional=False)\"\n",
        "                    )\n",
        "        if missing_tables:\n",
        "            raise ValueError(\n",
        "                \"Validation-only step target table(s) do not exist. \"\n",
        "                \"Create the table(s) or use optional=True for those steps: \"\n",
        "                + \"; \".join(missing_tables)\n",
        "            )\n",
        "\n",
        "        # Build steps list for abstracts.PipelineBuilder validation\n",
        "        all_steps = (\n",
        "            list(self.bronze_steps.values())\n",
        "            + list(self.silver_steps.values())\n",
        "            + list(self.gold_steps.values())\n",
        "        )\n",
        "\n",
        "        # Use abstracts.PipelineBuilder to validate steps\n",
        "        # This ensures step validation follows the abstracts interface\n",
        "        # Type cast needed because BronzeStep/SilverStep/GoldStep satisfy Step Protocol\n",
        "        try:\n",
        "# from .step import Step as AbstractsStep  # Removed: defined in notebook cells above\n",
        "\n",
        "            # Type ignore needed because BronzeStep/SilverStep/GoldStep satisfy Step Protocol\n",
        "            steps_for_validation: list[AbstractsStep] = all_steps  # type: ignore[assignment]\n",
        "            self._abstracts_builder.validate_steps(steps_for_validation)\n",
        "        except ValueError as e:\n",
        "            raise ValueError(f\"Step validation failed: {e}\") from e\n",
        "\n",
        "        # Create PipelineRunner with proper configuration\n",
        "        # PipelineRunner implements abstracts.Runner, so this satisfies the interface\n",
        "        # Note: steps and engine are optional parameters for abstracts compatibility\n",
        "        # but we pass them to ensure the runner is properly initialized\n",
        "        runner = PipelineRunner(\n",
        "            spark=self.spark,\n",
        "            config=self.config,\n",
        "            bronze_steps=self.bronze_steps,\n",
        "            silver_steps=self.silver_steps,\n",
        "            gold_steps=self.gold_steps,\n",
        "            logger=self.logger,\n",
        "            functions=self.functions,\n",
        "            steps=all_steps\n",
        "            if all_steps\n",
        "            else None,  # Pass steps for abstracts.Runner compatibility\n",
        "            engine=self.spark_engine,  # Pass engine for abstracts.Runner compatibility\n",
        "            execution_order=self.execution_order,  # Match to_pipeline() reported order at run time\n",
        "        )\n",
        "\n",
        "        self.logger.info(\n",
        "            f\"\ud83d\ude80 Pipeline built successfully with {len(self.bronze_steps)} bronze, {len(self.silver_steps)} silver, {len(self.gold_steps)} gold steps\"\n",
        "        )\n",
        "\n",
        "        return runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Module: pipeline_builder.pipeline.runner (pipeline_builder)\n",
        "#\n",
        "# Dependencies: abstracts.reports.run, abstracts.runner, abstracts.source, models.pipeline, models.steps, pipeline.models, pipeline_builder.compat, pipeline_builder.compat, pipeline_builder.compat_helpers, pipeline_builder.execution, pipeline_builder.execution, pipeline_builder.functions, pipeline_builder.functions, pipeline_builder.models, pipeline_builder.pipeline.models, pipeline_builder.sql_source, pipeline_builder_base.dependencies, pipeline_builder_base.logging, pipeline_builder_base.logging, pipeline_builder_base.models, pipeline_builder_base.runner\n",
        "\n",
        "\"\"\"\n",
        "Simplified pipeline runner for the framework.\n",
        "\n",
        "This module provides a clean, focused pipeline runner that delegates\n",
        "execution to the simplified execution engine.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, Optional, Union, cast\n",
        "# from .reports.run import Report  # Removed: defined in notebook cells above\n",
        "# from .runner import Runner  # Removed: defined in notebook cells above\n",
        "# from .source import Source  # Removed: defined in notebook cells above\n",
        "# from .logging import PipelineLogger  # Removed: defined in notebook cells above\n",
        "# from .models import (  # Removed: defined in notebook cells above\n",
        "    # ExecutionMode,\n",
        "    # PipelineConfig,\n",
        "    # PipelineMetrics,\n",
        "# )\n",
        "# from .runner import BaseRunner  # Removed: defined in notebook cells above\n",
        "\n",
        "# from ..compat import DataFrame, SparkSession  # Removed: defined in notebook cells above\n",
        "from pyspark.sql import functions as F  # F from pyspark (not from compat)\n",
        "# from ..execution import ExecutionEngine  # Removed: defined in notebook cells above\n",
        "# from ..execution import ExecutionResult as SparkExecutionResult  # Removed: defined in notebook cells above\n",
        "# from ..functions import FunctionsProtocol  # Removed: defined in notebook cells above\n",
        "# from ..models import BronzeStep, GoldStep, SilverStep  # Removed: defined in notebook cells above\n",
        "# from .models import PipelineMode, PipelineReport, PipelineStatus  # Removed: defined in notebook cells above\n",
        "\n",
        "class SimplePipelineRunner(BaseRunner, Runner):\n",
        "    \"\"\"\n",
        "    Simplified pipeline runner that delegates to the execution engine.\n",
        "\n",
        "    This runner focuses on orchestration and reporting, delegating\n",
        "    actual execution to the simplified ExecutionEngine.\n",
        "\n",
        "    Implements abstracts.Runner interface while maintaining backward compatibility\n",
        "    with additional methods (run_full_refresh, run_validation_only).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        spark: SparkSession,  # type: ignore[valid-type]\n",
        "        config: PipelineConfig,\n",
        "        bronze_steps: Optional[Dict[str, BronzeStep]] = None,\n",
        "        silver_steps: Optional[Dict[str, SilverStep]] = None,\n",
        "        gold_steps: Optional[Dict[str, GoldStep]] = None,\n",
        "        logger: Optional[PipelineLogger] = None,\n",
        "        functions: Optional[FunctionsProtocol] = None,\n",
        "        # Abstracts.Runner compatibility - these will be set if using abstracts interface\n",
        "        steps: Optional[list[Union[BronzeStep, SilverStep, GoldStep]]] = None,\n",
        "        engine: Optional[\n",
        "            Any\n",
        "        ] = None,  # Engine from abstracts, but we use ExecutionEngine\n",
        "        execution_order: Optional[list[str]] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the simplified pipeline runner.\n",
        "\n",
        "        Args:\n",
        "            spark: Active SparkSession instance\n",
        "            config: Pipeline configuration\n",
        "            bronze_steps: Bronze steps dictionary\n",
        "            silver_steps: Silver steps dictionary\n",
        "            gold_steps: Gold steps dictionary\n",
        "            logger: Optional logger instance\n",
        "            functions: Optional functions object for PySpark operations\n",
        "            steps: Optional list of steps (for abstracts.Runner compatibility)\n",
        "            engine: Optional engine (for abstracts.Runner compatibility, ignored)\n",
        "            execution_order: Optional pre-computed step order from builder (matches to_pipeline() report).\n",
        "        \"\"\"\n",
        "        # Initialize BaseRunner first\n",
        "        super().__init__(config, logger=logger)\n",
        "\n",
        "        # Initialize abstracts.Runner with empty lists (we'll use our own step storage)\n",
        "        # This satisfies the abstract base class requirement\n",
        "        # Use Any for engine type to avoid type checking issues with _DummyEngine\n",
        "\n",
        "        dummy_engine: Any = _DummyEngine()\n",
        "        Runner.__init__(self, steps=[], engine=engine or dummy_engine)\n",
        "\n",
        "        self.spark = spark\n",
        "        self.bronze_steps = bronze_steps or {}\n",
        "        self.silver_steps = silver_steps or {}\n",
        "        self.gold_steps = gold_steps or {}\n",
        "        self.functions = functions\n",
        "        self.execution_engine = ExecutionEngine(spark, config, self.logger, functions)\n",
        "        self.execution_order = execution_order\n",
        "\n",
        "        # If steps provided (from abstracts interface), convert to step dictionaries\n",
        "        if steps:\n",
        "            for step in steps:\n",
        "                if step.step_type.value == \"bronze\":\n",
        "                    self.bronze_steps[step.name] = step  # type: ignore[assignment]\n",
        "                elif step.step_type.value == \"silver\":\n",
        "                    self.silver_steps[step.name] = step  # type: ignore[assignment]\n",
        "                elif step.step_type.value == \"gold\":\n",
        "                    self.gold_steps[step.name] = step  # type: ignore[assignment]\n",
        "\n",
        "    def run_pipeline(\n",
        "        self,\n",
        "        steps: list[Union[BronzeStep, SilverStep, GoldStep]],\n",
        "        mode: PipelineMode = PipelineMode.INITIAL,\n",
        "        bronze_sources: Optional[Dict[str, DataFrame]] = None,  # type: ignore[valid-type]\n",
        "    ) -> PipelineReport:\n",
        "        \"\"\"\n",
        "        Run a complete pipeline.\n",
        "\n",
        "        Args:\n",
        "            steps: List of pipeline steps to execute\n",
        "            mode: Pipeline execution mode\n",
        "            bronze_sources: Optional bronze source data\n",
        "\n",
        "        Returns:\n",
        "            PipelineReport with execution results\n",
        "        \"\"\"\n",
        "        start_time = datetime.now()\n",
        "        pipeline_id = f\"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "        # Convert PipelineMode to ExecutionMode\n",
        "        execution_mode = self._convert_mode(mode)\n",
        "\n",
        "        try:\n",
        "            self.logger.info(f\"Starting pipeline execution: {pipeline_id}\")\n",
        "\n",
        "            # Prepare bronze sources if provided\n",
        "            if bronze_sources:\n",
        "                # Add bronze sources to context for execution\n",
        "                context = {}\n",
        "                for step in steps:\n",
        "                    if step.step_type.value == \"bronze\" and step.name in bronze_sources:\n",
        "                        context[step.name] = bronze_sources[step.name]\n",
        "            else:\n",
        "                context = {}\n",
        "\n",
        "            # Resolve SQL-source bronze steps (read from JDBC/SQLAlchemy into context)\n",
        "            # from ..sql_source import read_sql_source  # Removed: defined in notebook cells above\n",
        "\n",
        "            for step in steps:\n",
        "                if step.step_type.value != \"bronze\":\n",
        "                    continue\n",
        "                if step.name in context:\n",
        "                    continue\n",
        "                sql_src = getattr(step, \"sql_source\", None)\n",
        "                if sql_src is not None:\n",
        "                    context[step.name] = read_sql_source(sql_src, self.spark)\n",
        "\n",
        "            # Execute pipeline using the execution engine\n",
        "            result = self.execution_engine.execute_pipeline(\n",
        "                steps,\n",
        "                execution_mode,\n",
        "                context=context,\n",
        "                execution_order=self.execution_order,\n",
        "            )\n",
        "\n",
        "            # Convert execution result to pipeline report\n",
        "            report = self._create_spark_pipeline_report(\n",
        "                pipeline_id=pipeline_id,\n",
        "                mode=mode,\n",
        "                start_time=start_time,\n",
        "                execution_result=result,\n",
        "            )\n",
        "\n",
        "            self.logger.info(f\"Completed pipeline execution: {pipeline_id}\")\n",
        "            return report\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Pipeline execution failed: {e}\")\n",
        "            return self._create_error_report(\n",
        "                pipeline_id=pipeline_id, mode=mode, start_time=start_time, error=str(e)\n",
        "            )\n",
        "\n",
        "    def run_initial_load(\n",
        "        self,\n",
        "        bronze_sources: Union[Optional[Dict[str, Source]], list] = None,\n",
        "        steps: Optional[\n",
        "            list\n",
        "        ] = None,  # Backward compatibility: old signature accepted steps as first arg\n",
        "    ) -> Report:  # PipelineReport satisfies Report Protocol\n",
        "        \"\"\"\n",
        "        Run initial load pipeline.\n",
        "\n",
        "        Implements abstracts.Runner.run_initial_load interface.\n",
        "        Also supports backward-compatible signature with steps parameter.\n",
        "\n",
        "        Args:\n",
        "            bronze_sources: Dictionary mapping bronze step names to Source (DataFrame), or None\n",
        "            steps: Optional list of steps (for backward compatibility with old signature)\n",
        "        \"\"\"\n",
        "        # Handle backward compatibility: if first arg is a list, treat it as steps\n",
        "        if isinstance(bronze_sources, list):\n",
        "            # Old signature: run_initial_load([steps])\n",
        "            steps = bronze_sources\n",
        "            bronze_sources = None\n",
        "\n",
        "        # Convert Source (Protocol) to DataFrame if needed\n",
        "        # Source Protocol is satisfied by DataFrame, so we accept any DataFrame-like object\n",
        "        # from ..compat_helpers import is_dataframe_like  # Removed: defined in notebook cells above\n",
        "\n",
        "        bronze_sources_df: Optional[Dict[str, DataFrame]] = None  # type: ignore[valid-type]\n",
        "        if bronze_sources:\n",
        "            bronze_sources_df = {}\n",
        "            for name, source in bronze_sources.items():\n",
        "                # Check if it's a DataFrame-like object using compat helper\n",
        "                if not is_dataframe_like(source):\n",
        "                    raise TypeError(\n",
        "                        f\"bronze_sources must contain DataFrame-like objects, got {type(source)}\"\n",
        "                    )\n",
        "                bronze_sources_df[name] = cast(DataFrame, source)\n",
        "\n",
        "        # Use provided steps or stored steps\n",
        "        if steps is None:\n",
        "            steps = (\n",
        "                list(self.bronze_steps.values())\n",
        "                + list(self.silver_steps.values())\n",
        "                + list(self.gold_steps.values())\n",
        "            )\n",
        "\n",
        "        # PipelineReport satisfies Report Protocol structurally\n",
        "        return self.run_pipeline(steps, PipelineMode.INITIAL, bronze_sources_df)  # type: ignore[return-value]\n",
        "\n",
        "    def run_incremental(\n",
        "        self,\n",
        "        bronze_sources: Union[Optional[Dict[str, Source]], list] = None,\n",
        "        steps: Optional[\n",
        "            list\n",
        "        ] = None,  # Backward compatibility: old signature accepted steps as first arg\n",
        "    ) -> Report:  # PipelineReport satisfies Report Protocol\n",
        "        \"\"\"\n",
        "        Run incremental pipeline with all stored steps.\n",
        "\n",
        "        Implements abstracts.Runner.run_incremental interface.\n",
        "        Also supports backward-compatible signature with steps parameter.\n",
        "\n",
        "        Args:\n",
        "            bronze_sources: Optional dictionary mapping bronze step names to Source (DataFrame), or None\n",
        "            steps: Optional list of steps (for backward compatibility with old signature)\n",
        "\n",
        "        Returns:\n",
        "            Report (PipelineReport) with execution results\n",
        "        \"\"\"\n",
        "        # Handle backward compatibility: if first arg is a list, treat it as steps\n",
        "        if isinstance(bronze_sources, list):\n",
        "            # Old signature: run_incremental([steps])\n",
        "            steps = bronze_sources\n",
        "            bronze_sources = None\n",
        "\n",
        "        # Convert Source (Protocol) to DataFrame if needed\n",
        "        # Source Protocol is satisfied by DataFrame, so we accept any DataFrame-like object\n",
        "        # from ..compat_helpers import is_dataframe_like  # Removed: defined in notebook cells above\n",
        "\n",
        "        bronze_sources_df: Optional[Dict[str, DataFrame]] = None  # type: ignore[valid-type]\n",
        "        if bronze_sources:\n",
        "            bronze_sources_df = {}\n",
        "            for name, source in bronze_sources.items():\n",
        "                # Check if it's a DataFrame-like object using compat helper\n",
        "                if not is_dataframe_like(source):\n",
        "                    raise TypeError(\n",
        "                        f\"bronze_sources must contain DataFrame-like objects, got {type(source)}\"\n",
        "                    )\n",
        "                bronze_sources_df[name] = cast(DataFrame, source)\n",
        "\n",
        "        # Use provided steps or stored steps\n",
        "        if steps is None:\n",
        "            steps = (\n",
        "                list(self.bronze_steps.values())\n",
        "                + list(self.silver_steps.values())\n",
        "                + list(self.gold_steps.values())\n",
        "            )\n",
        "\n",
        "        # PipelineReport satisfies Report Protocol structurally\n",
        "        return self.run_pipeline(steps, PipelineMode.INCREMENTAL, bronze_sources_df)  # type: ignore[return-value]\n",
        "\n",
        "    def run_full_refresh(\n",
        "        self,\n",
        "        bronze_sources: Optional[Dict[str, DataFrame]] = None,  # type: ignore[valid-type]\n",
        "    ) -> PipelineReport:\n",
        "        \"\"\"\n",
        "        Run full refresh pipeline with all stored steps.\n",
        "\n",
        "        Args:\n",
        "            bronze_sources: Optional dictionary mapping bronze step names to DataFrames\n",
        "\n",
        "        Returns:\n",
        "            PipelineReport with execution results\n",
        "        \"\"\"\n",
        "        steps = (\n",
        "            list(self.bronze_steps.values())\n",
        "            + list(self.silver_steps.values())\n",
        "            + list(self.gold_steps.values())\n",
        "        )\n",
        "        return self.run_pipeline(steps, PipelineMode.FULL_REFRESH, bronze_sources)\n",
        "\n",
        "    def run_validation_only(\n",
        "        self,\n",
        "        bronze_sources: Optional[Dict[str, DataFrame]] = None,  # type: ignore[valid-type]\n",
        "    ) -> PipelineReport:\n",
        "        \"\"\"\n",
        "        Run validation-only pipeline with all stored steps.\n",
        "\n",
        "        Args:\n",
        "            bronze_sources: Optional dictionary mapping bronze step names to DataFrames\n",
        "\n",
        "        Returns:\n",
        "            PipelineReport with execution results\n",
        "        \"\"\"\n",
        "        steps = (\n",
        "            list(self.bronze_steps.values())\n",
        "            + list(self.silver_steps.values())\n",
        "            + list(self.gold_steps.values())\n",
        "        )\n",
        "        return self.run_pipeline(steps, PipelineMode.VALIDATION_ONLY, bronze_sources)\n",
        "\n",
        "    def _get_all_steps(\n",
        "        self, steps: Optional[list[Union[BronzeStep, SilverStep, GoldStep]]] = None\n",
        "    ) -> list[Union[BronzeStep, SilverStep, GoldStep]]:\n",
        "        \"\"\"Get all steps from stored dictionaries or provided list.\n",
        "\n",
        "        Args:\n",
        "            steps: Optional list of steps. If None, returns all stored steps.\n",
        "\n",
        "        Returns:\n",
        "            List of all steps (bronze, silver, gold).\n",
        "        \"\"\"\n",
        "        if steps is not None:\n",
        "            return steps\n",
        "        return (\n",
        "            list(self.bronze_steps.values())\n",
        "            + list(self.silver_steps.values())\n",
        "            + list(self.gold_steps.values())\n",
        "        )\n",
        "\n",
        "    def run_until(\n",
        "        self,\n",
        "        step_name: str,\n",
        "        steps: Optional[list[Union[BronzeStep, SilverStep, GoldStep]]] = None,\n",
        "        mode: PipelineMode = PipelineMode.INITIAL,\n",
        "        bronze_sources: Optional[Dict[str, DataFrame]] = None,  # type: ignore[valid-type]\n",
        "        step_params: Optional[Dict[str, Dict[str, Any]]] = None,\n",
        "        write_outputs: bool = True,\n",
        "    ) -> tuple[PipelineReport, Dict[str, DataFrame]]:  # type: ignore[valid-type]\n",
        "        \"\"\"Run pipeline until a specific step completes (inclusive).\n",
        "\n",
        "        Executes steps in dependency order until the specified step completes,\n",
        "        then stops. Useful for debugging or partial pipeline execution.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step to stop after (inclusive).\n",
        "            steps: Optional list of steps. If None, uses all stored steps.\n",
        "            mode: Pipeline execution mode.\n",
        "            bronze_sources: Optional bronze source data.\n",
        "            step_params: Optional dictionary mapping step names to parameter\n",
        "                dictionaries for transform functions.\n",
        "            write_outputs: If True, write outputs to tables. If False, skip writes.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (PipelineReport, context dictionary) where context contains\n",
        "            all step outputs for further execution.\n",
        "\n",
        "        Example:\n",
        "            >>> report, context = runner.run_until(\"clean_events\")\n",
        "            >>> # Now you can inspect context or continue execution\n",
        "        \"\"\"\n",
        "        all_steps = self._get_all_steps(steps)\n",
        "        start_time = datetime.now()\n",
        "        pipeline_id = f\"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        execution_mode = self._convert_mode(mode)\n",
        "\n",
        "        try:\n",
        "            self.logger.info(\n",
        "                f\"Starting pipeline execution until step '{step_name}': {pipeline_id}\"\n",
        "            )\n",
        "\n",
        "            # Prepare context\n",
        "            context: Dict[str, DataFrame] = {}  # type: ignore[valid-type]\n",
        "            if bronze_sources:\n",
        "                for step in all_steps:\n",
        "                    if step.step_type.value == \"bronze\" and step.name in bronze_sources:\n",
        "                        context[step.name] = bronze_sources[step.name]\n",
        "\n",
        "            # Execute pipeline with stop_after_step\n",
        "            result = self.execution_engine.execute_pipeline(\n",
        "                all_steps,\n",
        "                execution_mode,\n",
        "                context=context,\n",
        "                step_params=step_params,\n",
        "                stop_after_step=step_name,\n",
        "                write_outputs=write_outputs,\n",
        "                execution_order=self.execution_order,\n",
        "            )\n",
        "\n",
        "            # Create report\n",
        "            report = self._create_spark_pipeline_report(\n",
        "                pipeline_id=pipeline_id,\n",
        "                mode=mode,\n",
        "                start_time=start_time,\n",
        "                execution_result=result,\n",
        "            )\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"Completed pipeline execution until step '{step_name}': {pipeline_id}\"\n",
        "            )\n",
        "            return report, context\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Pipeline execution failed: {e}\")\n",
        "            error_report = self._create_error_report(\n",
        "                pipeline_id=pipeline_id, mode=mode, start_time=start_time, error=str(e)\n",
        "            )\n",
        "            return error_report, context\n",
        "\n",
        "    def run_step(\n",
        "        self,\n",
        "        step_name: str,\n",
        "        steps: Optional[list[Union[BronzeStep, SilverStep, GoldStep]]] = None,\n",
        "        mode: PipelineMode = PipelineMode.INITIAL,\n",
        "        context: Optional[Dict[str, DataFrame]] = None,  # type: ignore[valid-type]\n",
        "        step_params: Optional[Dict[str, Dict[str, Any]]] = None,\n",
        "        write_outputs: bool = True,\n",
        "    ) -> tuple[PipelineReport, Dict[str, DataFrame]]:  # type: ignore[valid-type]\n",
        "        \"\"\"Run a single step, loading dependencies from context or tables.\n",
        "\n",
        "        Executes only the specified step, using existing outputs from context\n",
        "        or reading from tables for dependencies. Useful for debugging individual steps.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step to execute.\n",
        "            steps: Optional list of steps. If None, uses all stored steps.\n",
        "            mode: Pipeline execution mode.\n",
        "            context: Optional execution context. If None, empty dict is used.\n",
        "                Dependencies will be loaded from tables if not in context.\n",
        "            step_params: Optional dictionary mapping step names to parameter\n",
        "                dictionaries for transform functions.\n",
        "            write_outputs: If True, write outputs to tables. If False, skip writes.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (PipelineReport, context dictionary) with updated context.\n",
        "\n",
        "        Example:\n",
        "            >>> report, context = runner.run_step(\"clean_events\", context=context)\n",
        "            >>> # Step executed, context updated with output\n",
        "        \"\"\"\n",
        "        all_steps = self._get_all_steps(steps)\n",
        "        start_time = datetime.now()\n",
        "        pipeline_id = f\"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        execution_mode = self._convert_mode(mode)\n",
        "\n",
        "        if context is None:\n",
        "            context = {}\n",
        "\n",
        "        try:\n",
        "            self.logger.info(\n",
        "                f\"Starting single step execution '{step_name}': {pipeline_id}\"\n",
        "            )\n",
        "\n",
        "            # Execute pipeline starting at this step\n",
        "            result = self.execution_engine.execute_pipeline(\n",
        "                all_steps,\n",
        "                execution_mode,\n",
        "                context=context,\n",
        "                step_params=step_params,\n",
        "                start_at_step=step_name,\n",
        "                stop_after_step=step_name,\n",
        "                write_outputs=write_outputs,\n",
        "                execution_order=self.execution_order,\n",
        "            )\n",
        "\n",
        "            # Create report\n",
        "            report = self._create_spark_pipeline_report(\n",
        "                pipeline_id=pipeline_id,\n",
        "                mode=mode,\n",
        "                start_time=start_time,\n",
        "                execution_result=result,\n",
        "            )\n",
        "\n",
        "            self.logger.info(f\"Completed step execution '{step_name}': {pipeline_id}\")\n",
        "            return report, context\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Step execution failed: {e}\")\n",
        "            error_report = self._create_error_report(\n",
        "                pipeline_id=pipeline_id, mode=mode, start_time=start_time, error=str(e)\n",
        "            )\n",
        "            return error_report, context\n",
        "\n",
        "    def rerun_step(\n",
        "        self,\n",
        "        step_name: str,\n",
        "        steps: Optional[list[Union[BronzeStep, SilverStep, GoldStep]]] = None,\n",
        "        mode: PipelineMode = PipelineMode.INITIAL,\n",
        "        context: Optional[Dict[str, DataFrame]] = None,  # type: ignore[valid-type]\n",
        "        step_params: Optional[Dict[str, Dict[str, Any]]] = None,\n",
        "        invalidate_downstream: bool = True,\n",
        "        write_outputs: bool = True,\n",
        "    ) -> tuple[PipelineReport, Dict[str, DataFrame]]:  # type: ignore[valid-type]\n",
        "        \"\"\"Rerun a step with optional parameter overrides.\n",
        "\n",
        "        Reruns the specified step, optionally removing downstream outputs from\n",
        "        context to ensure clean execution. Useful for debugging and iterative refinement.\n",
        "\n",
        "        Args:\n",
        "            step_name: Name of the step to rerun.\n",
        "            steps: Optional list of steps. If None, uses all stored steps.\n",
        "            mode: Pipeline execution mode.\n",
        "            context: Optional execution context. If None, empty dict is used.\n",
        "            step_params: Optional dictionary mapping step names to parameter\n",
        "                dictionaries for transform functions. Overrides are applied to\n",
        "                the specified step.\n",
        "            invalidate_downstream: If True, remove downstream step outputs from\n",
        "                context to ensure clean rerun. Defaults to True.\n",
        "            write_outputs: If True, write outputs to tables. If False, skip writes.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (PipelineReport, context dictionary) with updated context.\n",
        "\n",
        "        Example:\n",
        "            >>> # First run\n",
        "            >>> report, context = runner.run_step(\"clean_events\")\n",
        "            >>> # Rerun with different parameters\n",
        "            >>> report2, context = runner.rerun_step(\n",
        "            ...     \"clean_events\",\n",
        "            ...     context=context,\n",
        "            ...     step_params={\"clean_events\": {\"filter_threshold\": 0.9}}\n",
        "            ... )\n",
        "        \"\"\"\n",
        "        all_steps = self._get_all_steps(steps)\n",
        "        start_time = datetime.now()\n",
        "        pipeline_id = f\"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        execution_mode = self._convert_mode(mode)\n",
        "\n",
        "        if context is None:\n",
        "            context = {}\n",
        "\n",
        "        # Invalidate downstream steps if requested\n",
        "        if invalidate_downstream:\n",
        "# from .dependencies import DependencyAnalyzer  # Removed: defined in notebook cells above\n",
        "\n",
        "            # Build dependency graph to find downstream steps\n",
        "            bronze_steps = [s for s in all_steps if s.step_type.value == \"bronze\"]\n",
        "            silver_steps = [s for s in all_steps if s.step_type.value == \"silver\"]\n",
        "            gold_steps = [s for s in all_steps if s.step_type.value == \"gold\"]\n",
        "\n",
        "            analyzer = DependencyAnalyzer()\n",
        "            analysis = analyzer.analyze_dependencies(\n",
        "                bronze_steps={s.name: s for s in bronze_steps},  # type: ignore[misc]\n",
        "                silver_steps={s.name: s for s in silver_steps},  # type: ignore[misc]\n",
        "                gold_steps={s.name: s for s in gold_steps},  # type: ignore[misc]\n",
        "            )\n",
        "\n",
        "            # Find downstream steps (steps that depend on step_name)\n",
        "            execution_order = analysis.execution_order\n",
        "            if step_name in execution_order:\n",
        "                step_index = execution_order.index(step_name)\n",
        "                downstream_steps = execution_order[step_index + 1 :]\n",
        "\n",
        "                # Remove downstream outputs from context\n",
        "                for downstream_name in downstream_steps:\n",
        "                    if downstream_name in context:\n",
        "                        del context[downstream_name]\n",
        "                        self.logger.debug(\n",
        "                            f\"Removed downstream step '{downstream_name}' from context\"\n",
        "                        )\n",
        "\n",
        "        try:\n",
        "            self.logger.info(f\"Rerunning step '{step_name}': {pipeline_id}\")\n",
        "\n",
        "            # Execute pipeline starting at this step\n",
        "            result = self.execution_engine.execute_pipeline(\n",
        "                all_steps,\n",
        "                execution_mode,\n",
        "                context=context,\n",
        "                step_params=step_params,\n",
        "                start_at_step=step_name,\n",
        "                stop_after_step=step_name,\n",
        "                write_outputs=write_outputs,\n",
        "                execution_order=self.execution_order,\n",
        "            )\n",
        "\n",
        "            # Create report\n",
        "            report = self._create_spark_pipeline_report(\n",
        "                pipeline_id=pipeline_id,\n",
        "                mode=mode,\n",
        "                start_time=start_time,\n",
        "                execution_result=result,\n",
        "            )\n",
        "\n",
        "            self.logger.info(f\"Completed step rerun '{step_name}': {pipeline_id}\")\n",
        "            return report, context\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Step rerun failed: {e}\")\n",
        "            error_report = self._create_error_report(\n",
        "                pipeline_id=pipeline_id, mode=mode, start_time=start_time, error=str(e)\n",
        "            )\n",
        "            return error_report, context\n",
        "\n",
        "    def _convert_mode(self, mode: PipelineMode) -> ExecutionMode:\n",
        "        \"\"\"Convert PipelineMode to ExecutionMode.\"\"\"\n",
        "        mode_map = {\n",
        "            PipelineMode.INITIAL: ExecutionMode.INITIAL,\n",
        "            PipelineMode.INCREMENTAL: ExecutionMode.INCREMENTAL,\n",
        "            PipelineMode.FULL_REFRESH: ExecutionMode.FULL_REFRESH,\n",
        "            PipelineMode.VALIDATION_ONLY: ExecutionMode.VALIDATION_ONLY,\n",
        "        }\n",
        "        return mode_map.get(mode, ExecutionMode.INITIAL)\n",
        "\n",
        "    def _create_spark_pipeline_report(\n",
        "        self,\n",
        "        pipeline_id: str,\n",
        "        mode: PipelineMode,\n",
        "        start_time: datetime,\n",
        "        execution_result: SparkExecutionResult,\n",
        "    ) -> PipelineReport:\n",
        "        \"\"\"Create a pipeline report from execution result.\"\"\"\n",
        "        end_time = execution_result.end_time or datetime.now()\n",
        "        duration = (end_time - start_time).total_seconds()\n",
        "\n",
        "        # Count successful and failed steps\n",
        "        steps = execution_result.steps or []\n",
        "        successful_steps = [s for s in steps if s.status.value == \"completed\"]\n",
        "        failed_steps = [s for s in steps if s.status.value == \"failed\"]\n",
        "\n",
        "        # Import StepType for layer filtering\n",
        "        # from ..execution import StepType  # Removed: defined in notebook cells above\n",
        "\n",
        "        # Organize step results by layer (bronze/silver/gold)\n",
        "        bronze_results = {}\n",
        "        silver_results = {}\n",
        "        gold_results = {}\n",
        "\n",
        "        for step_result in steps:\n",
        "            step_info = {\n",
        "                \"status\": step_result.status.value,\n",
        "                \"duration\": step_result.duration,\n",
        "                \"rows_processed\": step_result.rows_processed,\n",
        "                \"output_table\": step_result.output_table,\n",
        "                \"start_time\": step_result.start_time.isoformat(),\n",
        "                \"end_time\": step_result.end_time.isoformat()\n",
        "                if step_result.end_time\n",
        "                else None,\n",
        "                \"write_mode\": step_result.write_mode,  # type: ignore[attr-defined]\n",
        "                \"validation_rate\": step_result.validation_rate,\n",
        "                \"rows_written\": step_result.rows_written,\n",
        "                \"input_rows\": step_result.input_rows,\n",
        "            }\n",
        "\n",
        "            # Add error if present\n",
        "            if step_result.error:\n",
        "                step_info[\"error\"] = step_result.error\n",
        "\n",
        "            # Add dataframe if available in context (for users who want to access output)\n",
        "            if hasattr(execution_result, \"context\"):\n",
        "                context = getattr(execution_result, \"context\", None)\n",
        "                if (\n",
        "                    context\n",
        "                    and isinstance(context, dict)\n",
        "                    and step_result.step_name in context\n",
        "                ):\n",
        "                    step_info[\"dataframe\"] = context[step_result.step_name]\n",
        "\n",
        "            # Categorize by step type\n",
        "            if step_result.step_type.value == \"bronze\":\n",
        "                bronze_results[step_result.step_name] = step_info\n",
        "            elif step_result.step_type.value == \"silver\":\n",
        "                silver_results[step_result.step_name] = step_info\n",
        "            elif step_result.step_type.value == \"gold\":\n",
        "                gold_results[step_result.step_name] = step_info\n",
        "\n",
        "        # Aggregate row counts from step results\n",
        "        total_rows_processed = sum(s.rows_processed or 0 for s in steps)\n",
        "        # For rows_written, only count Silver/Gold steps (those with output_table)\n",
        "        total_rows_written = sum(\n",
        "            s.rows_processed or 0 for s in steps if s.output_table is not None\n",
        "        )\n",
        "\n",
        "        # Calculate durations by layer\n",
        "        bronze_duration = sum(\n",
        "            s.duration or 0 for s in steps if s.step_type == StepType.BRONZE\n",
        "        )\n",
        "        silver_duration = sum(\n",
        "            s.duration or 0 for s in steps if s.step_type == StepType.SILVER\n",
        "        )\n",
        "        gold_duration = sum(\n",
        "            s.duration or 0 for s in steps if s.step_type == StepType.GOLD\n",
        "        )\n",
        "\n",
        "        return PipelineReport(\n",
        "            pipeline_id=pipeline_id,\n",
        "            execution_id=execution_result.execution_id,\n",
        "            status=(\n",
        "                PipelineStatus.COMPLETED\n",
        "                if execution_result.status == \"completed\"\n",
        "                else PipelineStatus.FAILED\n",
        "            ),\n",
        "            mode=mode,\n",
        "            start_time=start_time,\n",
        "            end_time=end_time,\n",
        "            duration_seconds=duration,\n",
        "            metrics=PipelineMetrics(\n",
        "                total_steps=len(steps),\n",
        "                successful_steps=len(successful_steps),\n",
        "                failed_steps=len(failed_steps),\n",
        "                total_duration=duration,\n",
        "                bronze_duration=bronze_duration,\n",
        "                silver_duration=silver_duration,\n",
        "                gold_duration=gold_duration,\n",
        "                total_rows_processed=total_rows_processed,\n",
        "                total_rows_written=total_rows_written,\n",
        "            ),\n",
        "            bronze_results=bronze_results,\n",
        "            silver_results=silver_results,\n",
        "            gold_results=gold_results,\n",
        "            errors=[s.error for s in failed_steps if s.error],\n",
        "            warnings=[],\n",
        "        )\n",
        "\n",
        "    def _create_error_report(\n",
        "        self, pipeline_id: str, mode: PipelineMode, start_time: datetime, error: str\n",
        "    ) -> PipelineReport:\n",
        "        \"\"\"Create an error pipeline report.\"\"\"\n",
        "        end_time = datetime.now()\n",
        "        duration = (end_time - start_time).total_seconds()\n",
        "\n",
        "        return PipelineReport(\n",
        "            pipeline_id=pipeline_id,\n",
        "            execution_id=f\"error_{pipeline_id}\",\n",
        "            status=PipelineStatus.FAILED,\n",
        "            mode=mode,\n",
        "            start_time=start_time,\n",
        "            end_time=end_time,\n",
        "            duration_seconds=duration,\n",
        "            metrics=PipelineMetrics(\n",
        "                total_steps=0,\n",
        "                successful_steps=0,\n",
        "                failed_steps=0,\n",
        "                total_duration=duration,\n",
        "            ),\n",
        "            errors=[error],\n",
        "            warnings=[],\n",
        "        )\n",
        "\n",
        "class _DummyEngine:\n",
        "    \"\"\"Dummy engine for Runner.__init__ compatibility.\"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "# Alias for backward compatibility\n",
        "PipelineRunner = SimplePipelineRunner\n",
        "\n",
        "# Explicitly clear abstract methods since they are implemented\n",
        "# Python's ABC mechanism sometimes doesn't recognize implementations with positional-only args\n",
        "if hasattr(SimplePipelineRunner, \"__abstractmethods__\"):\n",
        "    SimplePipelineRunner.__abstractmethods__ = frozenset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Engine Configuration Helper (PySpark-only)\n",
        "# This helper automatically configures the engine with PySpark components\n",
        "# In standalone notebooks, we use PySpark directly (no mock Spark support)\n",
        "\n",
        "# Store reference to original configure_engine before we wrap it\n",
        "# The configure_engine function is already defined in the engine_config module cell above\n",
        "_original_configure_engine_for_pyspark = configure_engine\n",
        "\n",
        "def configure_engine_pyspark(spark):\n",
        "    \"\"\"Configure engine with PySpark components for standalone notebooks.\n",
        "\n",
        "    This is a convenience function for notebooks that automatically configures\n",
        "    the engine with PySpark components. In standalone notebooks, we only\n",
        "    support PySpark (not mock Spark/sparkless).\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance\n",
        "    \"\"\"\n",
        "    from pyspark.sql import functions as F\n",
        "    from pyspark.sql.types import (\n",
        "        BooleanType, FloatType, IntegerType, StringType,\n",
        "        StructField, StructType, TimestampType\n",
        "    )\n",
        "    from pyspark.sql.utils import AnalysisException\n",
        "    from pyspark.sql.window import Window\n",
        "\n",
        "    # Configure engine with PySpark components\n",
        "    # Use the original configure_engine function (stored before wrapping)\n",
        "    # Note: engine_name, dataframe_cls, spark_session_cls, column_cls are optional\n",
        "    try:\n",
        "        _original_configure_engine_for_pyspark(\n",
        "            functions=F,\n",
        "            types=StructType,\n",
        "            analysis_exception=AnalysisException,\n",
        "            window=Window,\n",
        "            engine_name=\"pyspark\",\n",
        "            dataframe_cls=type(spark.createDataFrame([], \"id int\")),\n",
        "            spark_session_cls=type(spark),\n",
        "            column_cls=type(F.col(\"dummy\")),\n",
        "        )\n",
        "    except TypeError:\n",
        "        # Fallback if some parameters aren't accepted\n",
        "        _original_configure_engine_for_pyspark(\n",
        "            functions=F,\n",
        "            types=StructType,\n",
        "            analysis_exception=AnalysisException,\n",
        "            window=Window,\n",
        "        )\n",
        "    print(\"\u2705 Engine configured with PySpark components\")\n",
        "\n",
        "# Make configure_engine accept spark parameter for convenience\n",
        "# This allows using configure_engine(spark=spark) like in examples\n",
        "# We already stored the original function above as _original_configure_engine_for_pyspark\n",
        "\n",
        "def configure_engine_wrapper(*, spark=None, **kwargs):\n",
        "    \"\"\"Configure engine - accepts spark parameter for convenience.\n",
        "\n",
        "    In standalone notebooks, you can call configure_engine(spark=spark)\n",
        "    and it will automatically configure with PySpark components.\n",
        "    \"\"\"\n",
        "    if spark is not None:\n",
        "        # Auto-configure with PySpark\n",
        "        configure_engine_pyspark(spark)\n",
        "    else:\n",
        "        # Use original function\n",
        "        _original_configure_engine_for_pyspark(**kwargs)\n",
        "\n",
        "# Replace configure_engine in the current namespace\n",
        "configure_engine = configure_engine_wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Usage Example\n",
        "#\n",
        "# Here's how to initialize PipelineBuilder and LogWriter:\n",
        "\n",
        "# Example: Initialize PipelineBuilder and LogWriter\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PipelineBuilder Example\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Configure engine (required! - uses PySpark automatically)\n",
        "configure_engine(spark=spark)\n",
        "\n",
        "# Initialize PipelineBuilder\n",
        "builder = PipelineBuilder(spark=spark, schema=\"analytics\")\n",
        "print(\"\u2705 PipelineBuilder initialized\")\n",
        "\n",
        "# Initialize LogWriter (simplified API)\n",
        "log_writer = LogWriter(spark, schema=\"analytics\", table_name=\"pipeline_logs\")\n",
        "print(\"\u2705 LogWriter initialized\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}